<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: logstash | @johtaniの日記 2nd]]></title>
  <link href="http://blog.johtani.info/blog/categories/logstash/atom.xml" rel="self"/>
  <link href="http://blog.johtani.info/"/>
  <updated>2019-12-16T16:06:01+00:00</updated>
  <id>http://blog.johtani.info/</id>
  <author>
    <name><![CDATA[johtani]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Logstash 2.0.0リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2015/10/29/logstash-2-0-0-released-ja/"/>
    <updated>2015-10-29T07:19:57+00:00</updated>
    <id>http://blog.johtani.info/blog/2015/10/29/logstash-2-0-0-released-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="https://www.elastic.co/blog/logstash-2-0-0-released">Logstash 2.0.0 released</a></p>

<!-- more -->


<p>Logstash 2.0.0が本日（10/28）リリースされました。
この<a href="https://www.elastic.co/downloads/logstash">リリース</a>は
いくつかの設定に関する重要な変更があります。
詳細については、<a href="https://github.com/elastic/logstash/blob/2.0/CHANGELOG.md">changelog</a>または、新しい<a href="https://www.elastic.co/guide/en/logstash/2.0/breaking-changes.html">breaking changes</a>ドキュメントをご覧下さい。</p>

<p>これまでの2.0.0直前のリリースに関する変更点はこちらをご覧ください。</p>

<ul>
<li><a href="https://www.elastic.co/blog/logstash-2-0-0-beta1-released">beta1</a></li>
<li><a href="https://www.elastic.co/blog/logstash-2-0-0-beta2-released">beta2</a></li>
<li><a href="https://www.elastic.co/blog/logstash-2-0-0-beta3-released">beta3</a></li>
<li><a href="https://www.elastic.co/blog/logstash-2-0-0-rc1-released">RC</a></li>
</ul>


<p>ここでは、2.0の主な変更点の概要を説明します。</p>

<h3>Elasticsearch 2.0との互換性</h3>

<p>多くの機能および改善を含んだ<a href="https://www.elastic.co/blog/elasticsearch-2-0-0-released">Elasticsearch 2.0がリリース</a>されました。
Logstash 2.0はこのリリースに対応しています。
Logstashのこれまでのリリースでは、デフォルトで、Javaの <code>node client</code>をElasticsearchとの通信として
使用してきました。
2.0では、HTTPクライアントがデフォルトになります。
これにより、シームレスにユーザのデータを取り込み、付加価値をつけ、Elasticsearchに保存して解析することができます。</p>

<p>HTTPは他のプロトコル（<code>node</code>や<code>transport</code>）同等の機能を持っていますが、
単一のクライアントに接続する時に、少しだけ遅いですが、管理や動作がより簡単です。
HTTPプロトコルを使うことで、Elasticsearchのバージョンのアップグレードが、Logstashのアップグレードすることなく
行うことができます。
デフォルトをHTTPに変更したさらに詳しい情報については<a href="https://www.elastic.co/blog/logstash-2-0-0-beta1-released">beta1のブログ</a>をご覧ください。</p>

<p>他のプロトコル（<code>node</code>と<code>transport</code>）もサポートしますが、これらを利用する場合には、
プラグインを別途インストールする必要があります。</p>

<pre><code>bin/plugin install --version 2.0.0 logstash-output-elasticsearch_java
</code></pre>

<h4>互換性のマトリックス</h4>

<p>LogstashとElasticsearchのバージョンの互換性は次のようになります。</p>

<p>画像あり。
<a href="https://www.elastic.co/blog/kibana-4-2-0">※画像に関しては原文をご覧ください。</a></p>

<h1>Image <a href="https://www.elastic.co/assets/bltde5b69e2164aa82f%2Fcompat_matrix.png">https://www.elastic.co/assets/bltde5b69e2164aa82f%2Fcompat_matrix.png</a></h1>

<h2>Shield 2.0との互換性</h2>

<p>このリリースはShield 2.0リリースにも対応しています。
HTTPプロトコルで、追加のプラグインは必要ありません。
<a href="https://www.elastic.co/guide/en/shield/current/logstash.html">こちらのドキュメント</a>をご覧ください。
<code>transport</code>プロトコルでは、Shield 2.0対応のプラグインを個別にインストールする必要があります。</p>

<pre><code>bin/plugin install --version 2.0.0 logstash-output-elasticsearch_java_shield
</code></pre>

<h2>パフォーマンスの改善</h2>

<p>このリリースはまた、多くの部分のパフォーマンスの改善を含んでおり、Logstashを利用してデータをより早く処理することができます。
いくつかをここで説明します。</p>

<ul>
<li><p><strong>UserAgentとGeoIPフィルタ</strong>：これらのフィルタで、LRUキャッシュを追加して改善しています。
これにより、IPとユーザエージェントがまとまって現れるというWebリクエストの特性を用いています。
ユーザエージェントフィルタのケースでは、サンプルデータセットにおいて3.7倍ほど早くなりました。
GeoIPでは、1.69倍早くなっています。</p></li>
<li><p><strong>JSONプロセシング</strong>：LogstashでJSONのsiriaraizu/でシリアライズに利用しているJrJacksonを新しいバージョンにしました。
これにより、JSONの処理が改善されています。</p></li>
<li><p><strong>フィルタワーカーのより良い値をデフォルトに</strong>：以前のリリースでは、<code>filter_workers</code>の設定は1がデフォルトでした。
これは、フィルタの処理を行うワーカーが1つであるという意味です。
<code>filter_workers</code>の設定のデフォルト値はCPUコア数の半分の値を設定します。フィルタ実行の並列性が上がります。
ですので、複雑なgrokパターンやuseragentフィルタの処理がにとっては重要です。</p></li>
</ul>


<h2>Filebeat Support</h2>

<p><a href="https://www.elastic.co/products/beats/filebeat">Filebeat</a>のベータバージョンを<a href="https://www.elastic.co/blog/beats-beta4-filebeat-lightweight-log-forwarding">先日リリース</a>しました。
これは、Logstash Forwarderの次期バージョンです。
Filebeatはファイルベースのログをさらに処理するためにLogstashに送るためのエージェントです。
2.0.0は<a href="https://www.elastic.co/guide/en/logstash/2.0/plugins-inputs-beats.html">logstash-input-beatsプラグイン</a>を使えばFilebeat 1.0.0-beta4とすぐに動作します。</p>

<h2>シャットダウン操作</h2>

<p>これまでのLogstashでは、シャットダウンが開始した時に、例外の機構でシャットダウンが開始したことを
プラグインに通知していました。
この処理はサードパーティのコードを使ったプラグインで問題を起こしていました。
Logstashはどの例外を処理するか知らないため、予期しない動作をしていました。
これを修正するためにAPI呼び出し（例えば<code>stop</code>）を各プラグインにシャットダウンのイベントを通知し、
プラグイン自身がきちんと停止するようにしました。
これは、200以上のプラグインに新しいAPIを利用するように修正しないといけないことを意味しました。
しかし、Logstashの停止についてはまだ完全にはフィックスしていません。
とちゅうでおわっているoutputがシャットダウンを遅らせる可能性があるからです。
2.0でAPIの破壊的な変更は適切なリリースでの変更を繰り返すことができる出発点です。</p>

<p>プラグインの開発者へ：もし、Logstash　1.5のプラグインを開発しているなら、
シャットダウンに関する新しいAPIのリストに関するbreaking changesのドキュメントに助言をください。
また、<a href="https://github.com/logstash-plugins/logstash-input-example">example input</a>リポジトリにて、新しいシャットダウンメカニズムの使い方のサンプルコードを提供しています。</p>

<h2>ドキュメント</h2>

<p>2.0に更新された<a href="https://www.elastic.co/guide/en/logstash/2.0/index.html">ドキュメントはこちら</a>です。設定の変更についてもこちらをご覧ください。</p>

<h3>2.0へのアップデート</h3>

<p>2.0へアップデートする前に、<a href="https://www.elastic.co/guide/en/logstash/2.0/upgrading-logstash.html">アップデートガイド</a>もご覧ください。</p>

<h2>フィードバック</h2>

<p>2.0のリリースできたことに、多くのコントリビューター、ユーザに感謝しています。
このリリースに含まれている多くのパッチと全てのプレリリースのテストにも感謝しています。
将来の修正やリリースなどについては<a href="https://www.elastic.co/guide/en/logstash-roadmap/current/index.html">ロードマップ</a>をご覧ください。
2.0は<a href="https://www.elastic.co/downloads/logstash">今日リリース</a>されました。
ご意見ご感想は<a href="https://discuss.elastic.co/c/logstash">Webフォーラム</a>で！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Release, we have（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2015/10/29/release-we-have-ja/"/>
    <updated>2015-10-29T05:18:59+00:00</updated>
    <id>http://blog.johtani.info/blog/2015/10/29/release-we-have-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="https://www.elastic.co/blog/release-we-have">Relase, we have</a>
※画像に関しては原文をご覧ください。</p>

<!-- more -->


<p>Elasticにとって大きな1日（社内では「release bonanza」と呼んでいる）です。
多くの主要なプロダクトを新たにリリースしました。
そして、本日、それらを一緒に利用する時にそれらを一緒に利用する時にユーザの体験についてまとめてみました。</p>

<p>次の通りです。</p>

<p><a href="https://www.elastic.co/blog/elasticsearch-2-0-0-released">Elasticsearch 2.0</a>リリース。
大きなマイルストーン、チームによる改善、そして、コミュニティからの素晴らしい貢献。
Pipeline Aggsと呼ばれる新しいタイプのaggregations、
クエリとフィルタのコンセプトを統合することにより簡素化されたクエリDSL、
better compressionオプション、
JavaのSecurity Managerを有効にすることによる強化されたセキュリティ、
FSの挙動に関する強化（fsync、checksum、atmicなリネーム）、
パフォーマンス、マッピングの挙動の一貫性などなどです。
また、我々のチームによる改善も含まれているLucene 5ベースにアップグレードしています。</p>

<p><a href="https://www.elastic.co/blog/kibana-4-2-0">Kibana 4.2</a>リリース。
Elasticsearch 2.0対応、ダークテーマ、カスタマイズ可能な地図、多くの改善。
Kibana 4.2の多くに作業については外部プラグインサポートといった、内蔵に関するものでした。
この後の説明に続きます。</p>

<p><a href="https://www.elastic.co/blog/shield-watcher-and-marvel-2-0-ga-released">Marvel 2.0</a>リリース。
Elasticsearch 2.0対応、合理化されたメトリックス、簡素化されたUI、
多くはKibanaプラグイン（Kibanaプラットフォーム上に構築）としての書き換えです。
このKibana拡張の最初の努力は、Kibanaのプラグインをどうやって書くか、
Kibanaユーザに公式に何をする必要があるかといったものを特定するのに役立ちました。
おっと、忘れるところでした、Marvelを全てのユーザにフリーで使えるようにしました。
マルチクラスタサポートについては有償となります。</p>

<p><a href="https://www.elastic.co/blog/sense-2-0-0-beta1">Sense 2.0</a>リリース。
2つ目のKibanaプラグインがこれです。
SenseをKibanaプラグインとして書き換えました。
Elasticsearch 2.0サポート、複数リクエストの実行、
curlへのコピーなどです。
おっと、忘れるところでした。オープンソースとすることにしました！</p>

<p><a href="https://www.elastic.co/blog/shield-watcher-and-marvel-2-0-ga-released">Shield + Watcher 2.0</a>リリース。ElasticsearchのためのセキュリティプラグインであるShieldと、アラート管理のためのプラグインであるWatcherにも
多くの結果が入っています。
最も要求のあった機能である、フィールドお呼びドキュメントレベルでのセキュリティについて、Luceneに落とし込んで実装しました。
また、セキュリティの操作についてプラガブルに実装できるように変更しました。
Watcherは監視の無効化、SlackやHipChatへの通知（bot ops向け）が可能です。</p>

<p><a href="https://www.elastic.co/blog/logstash-2-0-0-released">Logstash 2.0</a>リリース。
Elasticsearch 2.0のサポート、クリーンな停止、全面的なパフォーマンス改善、<a href="https://www.elastic.co/products/beats">Beats</a>サポート。</p>

<p>ご覧の通り、すべてのプロダクトに関する大きな結果です。
チーム間およびFoundの開発者との間での密な連携に感謝します。
これらが私たちが公式にElasticsearch / Kibanaをホストしている<a href="https://www.elastic.co/found">Found</a>で
利用可能です。</p>

<p>ひゅう、息切れしました。
チームがしてきたことは、感動的で、謙虚で、刺激的です！
Elasticが会社として、全てのユーザ、コントリビュータがどのように私たちの大きなミッションに対する結果をもたらしたかという素晴らしい良い例です。
ユーザに愛され、楽しまれ、成功に導き、革新させる製品を是非ご利用ください。ありがとうございます。</p>

<p>&ldquo;A Lion, in Africa?&rdquo; - まだまだ終わりではありません。この文言で終わりにしますが、すぐに（本当にすぐに）戻ってきます。;)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logstashを使ったElasticsearchの再インデックス（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2015/05/26/reindex-elasticsearch-with-logstash-ja/"/>
    <updated>2015-05-26T07:08:10+00:00</updated>
    <id>http://blog.johtani.info/blog/2015/05/26/reindex-elasticsearch-with-logstash-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://david.pilato.fr/blog/2015/05/20/reindex-elasticsearch-with-logstash/">Reindex Elasticsearch With Logstash</a></p>

<p>Thanks David!</p>

<!-- more -->


<p>マッピングを変更したり、インデックスの設定を変更したり、あるサーバから他のサーバや、
あるクラスタから他のクラスタ（例えば複数のデータセンターのような場合）にデータを再インデックスしたくなることがあるでしょう。</p>

<p>後者のような場合は<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html">SnapshotやRestoreの機能</a>を利用することもできますが、インデックスの設定を変更をしたい場合は
その他の方法が必要になります。</p>

<p><a href="https://www.elastic.co/blog/logstash-1-5-0-ga-released">Logstash 1.5.0</a>で、
<a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-elasticsearch.html">elasticsearch input</a>と<a href="https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html">elasticsearch output</a>を使うことで、とても簡単に再インデックスができます。</p>

<p>ではやってみましょう。</p>

<h2>古いクラスタ</h2>

<p>elasticsearch 1.5.2 はすでにダウンロード済みとして、<code>localhost:9200</code>で<code>old</code>という名前のクラスタを起動します。</p>

<pre><code class="bash">bin/elasticsearch --cluster.name=old
</code></pre>

<p>クラスタに<code>person</code>という名前のインデックスが存在します。
これは、5シャードで、100万件のドキュメントを持っています。</p>

<p><img class="<a" src="href="http://david.pilato.fr/blog/images/reindex-es01/sense01.png">http://david.pilato.fr/blog/images/reindex-es01/sense01.png</a>&#8221;></p>

<h2>新しいクラスタ</h2>

<p>次に新しいクラスタを起動します。
<code>localhost:9201</code>で<code>new</code>という名前のクラスタを起動します。</p>

<pre><code class="bash">bin/elasticsearch --cluster.name=new
</code></pre>

<p>こちらは、空です。</p>

<pre><code class="bash">curl -XGET "http://localhost:9201/person"
</code></pre>

<pre><code class="json">{
   "error": "IndexMissingException[[person] missing]",
   "status": 404
}
</code></pre>

<h2>Logstashのインストール</h2>

<p>次に、Logstash 1.5.0をダウンロードして、インストールします。</p>

<pre><code class="bash">wget http://download.elastic.co/logstash/logstash/logstash-1.5.0.tar.gz
tar xzf logstash-1.5.0.tar.gz
cd logstash-1.5.0
</code></pre>

<p>logstashの設定ファイル<code>logstash.conf</code>を次のように設定します。</p>

<pre><code>input {
  # We read from the "old" cluster
  elasticsearch {
    hosts =&gt; [ "localhost" ]
    port =&gt; "9200"
    index =&gt; "person"
    size =&gt; 500
    scroll =&gt; "5m"
    docinfo =&gt; true
  }
}

output {
  # We write to the "new" cluster
  elasticsearch {
    host =&gt; "localhost"
    port =&gt; "9201"
    protocol =&gt; "http"
    index =&gt; "%{[@metadata][_index]}"
    index_type =&gt; "%{[@metadata][_type]}"
    document_id =&gt; "%{[@metadata][_id]}"
  }
  # We print dots to see it in action
  stdout {
    codec =&gt; "dots"
  }
}
</code></pre>

<h2>実行と修正</h2>

<p>実行します。</p>

<pre><code class="bash">bin/logstash -f logstash.conf
</code></pre>

<h3>ドキュメントのチェックと修正</h3>

<p>何が起きたでしょう？</p>

<pre><code class="bash">curl -XGET "http://localhost:9200/person/person/AU1wqyQWZJKU8OibfxgH"
</code></pre>

<pre><code class="json">{
   "_index": "person",
   "_type": "person",
   "_id": "AU1wqyQWZJKU8OibfxgH",
   "_version": 1,
   "found": true,
   "_source": {
      "name": "Tali Elyne",
      "dateOfBirth": "1955-05-03",
      "gender": "female",
      "children": 2,
      "marketing": {
         "cars": null,
         "shoes": null,
         "toys": null,
         "fashion": null,
         "music": null,
         "garden": null,
         "electronic": null,
         "hifi": null,
         "food": 846
      },
      "address": {
         "country": "Germany",
         "zipcode": "0099",
         "city": "Bonn",
         "countrycode": "DE",
         "location": [
            7.075943707068682,
            50.72883500730124
         ]
      }
   }
}
</code></pre>

<p>もう一方のクラスタと比較してみましょう。</p>

<pre><code class="bash">curl -XGET "http://localhost:9201/person/person/AU1wqyQWZJKU8OibfxgH"
</code></pre>

<pre><code class="json">{
   "_index": "person",
   "_type": "person",
   "_id": "AU1wqyQWZJKU8OibfxgH",
   "_version": 1,
   "found": true,
   "_source": {
      "name": "Tali Elyne",
      "dateOfBirth": "1955-05-03",
      "gender": "female",
      "children": 2,
      "marketing": {
         "cars": null,
         "shoes": null,
         "toys": null,
         "fashion": null,
         "music": null,
         "garden": null,
         "electronic": null,
         "hifi": null,
         "food": 846
      },
      "address": {
         "country": "Germany",
         "zipcode": "0099",
         "city": "Bonn",
         "countrycode": "DE",
         "location": [
            7.075943707068682,
            50.72883500730124
         ]
      },
      "@version": "1",
      "@timestamp": "2015-05-20T09:53:44.089Z"
   }
}
</code></pre>

<p>Logstashは<code>@version</code>と<code>@timestamp</code>フィールドを追加してしました。
これらを除去したいので、<a href="http://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html">Mutate filter plugin</a>の<a href="http://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html#plugins-filters-mutate-remove_field"><code>remove_field</code></a>を使います。</p>

<pre><code>filter {
  mutate {
    remove_field =&gt; [ "@timestamp", "@version" ]
  }
}
</code></pre>

<h3>マッピングのチェックと修正</h3>

<p>実際に、logstashは<code>_source</code>フィールドを既存のドキュメントから読み込み、
それらを新しいクラスタに直接投入しています。
しかし、logstashはマッピングについてはケアしていません。</p>

<p>古いマッピングと新しいマッピングを比較するために、マッピングを取得してみましょう。</p>

<pre><code class="bash">curl -XGET "http://localhost:9200/person/person/_mapping"
</code></pre>

<pre><code class="json">{
   "person": {
      "mappings": {
         "person": {
            "properties": {
               "address": {
                  "properties": {
                     "city": {
                        "type": "string",
                        "index": "not_analyzed"
                     },
                     "country": {
                        "type": "string",
                        "index": "not_analyzed"
                     },
                     "countrycode": {
                        "type": "string",
                        "index": "not_analyzed"
                     },
                     "location": {
                        "type": "geo_point"
                     },
                     "zipcode": {
                        "type": "string"
                     }
                  }
               },
               "children": {
                  "type": "long"
               },
               "dateOfBirth": {
                  "type": "date",
                  "format": "dateOptionalTime"
               },
               "gender": {
                  "type": "string",
                  "index": "not_analyzed"
               },
               "marketing": {
                  "properties": {
                     "cars": {
                        "type": "long"
                     },
                     "electronic": {
                        "type": "long"
                     },
                     "fashion": {
                        "type": "long"
                     },
                     "food": {
                        "type": "long"
                     },
                     "garden": {
                        "type": "long"
                     },
                     "hifi": {
                        "type": "long"
                     },
                     "music": {
                        "type": "long"
                     },
                     "shoes": {
                        "type": "long"
                     },
                     "toys": {
                        "type": "long"
                     }
                  }
               },
               "name": {
                  "type": "string"
               }
            }
         }
      }
   }
}
</code></pre>

<pre><code class="bash">curl -XGET "http://localhost:9201/person/person/_mapping"
</code></pre>

<pre><code class="json">{
   "person": {
      "mappings": {
         "person": {
            "properties": {
               "address": {
                  "properties": {
                     "city": {
                        "type": "string"
                     },
                     "country": {
                        "type": "string"
                     },
                     "countrycode": {
                        "type": "string"
                     },
                     "location": {
                        "type": "double"
                     },
                     "zipcode": {
                        "type": "string"
                     }
                  }
               },
               "children": {
                  "type": "long"
               },
               "dateOfBirth": {
                  "type": "date",
                  "format": "dateOptionalTime"
               },
               "gender": {
                  "type": "string"
               },
               "marketing": {
                  "properties": {
                     "cars": {
                        "type": "long"
                     },
                     "electronic": {
                        "type": "long"
                     },
                     "fashion": {
                        "type": "long"
                     },
                     "food": {
                        "type": "long"
                     },
                     "garden": {
                        "type": "long"
                     },
                     "hifi": {
                        "type": "long"
                     },
                     "music": {
                        "type": "long"
                     },
                     "shoes": {
                        "type": "long"
                     },
                     "toys": {
                        "type": "long"
                     }
                  }
               },
               "name": {
                  "type": "string"
               }
            }
         }
      }
   }
}
</code></pre>

<p>これにより、いくつかの相違を発見できます。</p>

<pre><code class="json"> "location": {
    "type": "geo_point"
 }
</code></pre>

<pre><code class="json"> "location": {
    "type": "double"
 }
</code></pre>

<p>データをインデックスする「前」に、実際に利用したいマッピングでインデックスを作成しておくことで、
この問題に対処できます。
この時点で、オリジナルのマッピングを望んだ形に変更することができます。例えば、アナライザを変更したりです。
また、インデックスの設定を新しく定義することもできます。
デフォルトでは、Elasticsearchは5つのシャードと各シャードに対して1つのレプリカを作成します。
しかし、この時点でもう一度変更することが可能です。</p>

<pre><code class="bash">curl -XDELETE "http://localhost:9201/person"
curl -XPUT "http://localhost:9201/person" -d'
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 0
  }
}'
curl -XPUT "http://localhost:9201/person/person/_mapping" -d'
{
  "person": {
    "properties": {
      "address": {
        "properties": {
          "city": {
            "type": "string",
            "index": "not_analyzed"
          },
          "country": {
            "type": "string",
            "index": "not_analyzed"
          },
          "countrycode": {
            "type": "string",
            "index": "not_analyzed"
          },
          "location": {
            "type": "geo_point"
          },
          "zipcode": {
            "type": "string"
          }
        }
      },
      "children": {
        "type": "long"
      },
      "dateOfBirth": {
        "type": "date",
        "format": "dateOptionalTime"
      },
      "gender": {
        "type": "string",
        "index": "not_analyzed"
      },
      "marketing": {
        "properties": {
          "cars": {
            "type": "long"
          },
          "electronic": {
            "type": "long"
          },
          "fashion": {
            "type": "long"
          },
          "food": {
            "type": "long"
          },
          "garden": {
            "type": "long"
          },
          "hifi": {
            "type": "long"
          },
          "music": {
            "type": "long"
          },
          "shoes": {
            "type": "long"
          },
          "toys": {
            "type": "long"
          }
        }
      },
      "name": {
        "type": "string"
      }
    }
  }
}'
</code></pre>

<p>さて、もう一度再インデックスしましょう！</p>

<pre><code class="bash">bin/logstash -f logstash.conf
</code></pre>

<p><img class="<a" src="href="http://david.pilato.fr/blog/images/reindex-es01/sense02.png">http://david.pilato.fr/blog/images/reindex-es01/sense02.png</a>&#8221;></p>

<h2>インデックスやタイプ名の変更</h2>

<p>もちろん、インデックス名やタイプ名、IDを変更したい場合も変更が可能です！:)</p>

<pre><code class="json">  elasticsearch {
    host =&gt; "localhost"
    port =&gt; "9201"
    protocol =&gt; "http"
    index =&gt; "europe_people"
    index_type =&gt; "someone"
    document_id =&gt; "%{[@metadata][_id]}"
  }
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logstashプラグインのエコシステムの変更（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/13/plugin-ecosystem-changes/"/>
    <updated>2014-12-13T16:00:40+00:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/13/plugin-ecosystem-changes</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/plugin-ecosystem-changes/">exciting logstash plugin ecosystem changes</a></p>

<p>Logstash 1.5.0 Beta 1(<a href="http://www.elasticsearch.org/overview/logstash/download/">お試しはこちら</a>)のリリースで、
プラグインのインストール、管理、公開の方法を変更しています。
ユーザやコミュニティからフィードバックをもらいました。
その目的は、プラグインの利用や開発をより簡単にすることです。
このプロジェクトは始まったばかりです。プラグインのコミュニティを探し、
共有するためのワンストップソリューションを提供するこのアイデアを改善していく予定です。
このブログで、この決定を行った理由を説明し、新しいワークフローをと今後のロードマップを説明します。</p>

<!-- more -->


<h2>プラグインがあります！</h2>

<p>Logstashは、プラグイン（input、filter、output、codec）が豊富にあります。
これらは、Elasticsearchにより開発されたものと、コミュニティからコントリビュートされたものです。
Logstashの主な特長の1つは、これらのプラグインの有効性と動作を拡張するプラグインを追加するのが簡単なことです。
現在、165以上のプラグインがエコシステムにあり、これらは、2つのプロジェクトに分かれています。</p>

<ul>
<li><code>logstash-core</code>は最もよく使われるプラグインで、Logstashにデフォルトで含まれます</li>
<li><code>logstash-contrib</code>はコミュニティにより開発されたプラグインを含み、別途ダウンロードできます</li>
</ul>


<h2>新プラグインエコシステムの変更</h2>

<p>1.5.0では、全てのプラグインは、Logstashコアから分離され、rubygemsを使って個別にパッケージングされます。
rubygemsを選択したのは、依存関係のあるライブラリの配布とパッケージングがパワフルで一般的なものだからです。
さらに、<a href="http://rubygems.org/">rubygems.org</a>プラットフォームは配布や探索に影響があります。
また、Logstashにプラグインをインストール、アップデート、削除するのが簡単な基盤も追加しました。
<code>contrib</code>プロジェクトは徐々に終了します。全てのプラグインは個別のプロジェクトになります。</p>

<h2>プラグインエコシステム変更の理由</h2>

<p>多数のプラグインをもっていると、配布と公開に関して難題が出てきます。
私たちが変更するに至った理由は次のようなものです。</p>

<ul>
<li>現在は、プラグインの更新に伴い、Logstashの新バージョンのリリースが必要</li>
<li>開発者は、Logstashのリリース間隔とは別に、新バージョンをリリースをしたい</li>
<li>プラグイン開発者は、外部依存を記述できるようにしたい</li>
<li>Logstashコアの配布パッケージのダウンロードサイズを小さくし、ユーザは必要なプラグインのみインストール</li>
<li><code>logstash-contrib</code>を1つのリポジトリとして管理するのは難しい</li>
</ul>


<h2>詳細：</h2>

<h3>ソースコードの場所</h3>

<p>Logstashのソースコードは、今後も<a href="https://github.com/elasticsearch/logstash">現在のGitHubのリポジトリ</a>のままです。
しかし、プラグインに関するコードやテストコードは含まなくなります。
この分離により、個別のプラグインの改善と同様にコアの改善に集中できます。
これにより、Logstashプロジェクトの全体の品質も向上します。</p>

<p>全プラグインのソースコードは、新しいGitHub organization、<a href="https://github.com/logstash-plugins">logstash-plugins</a>にて管理します。
各プラグインは個別のリポジトリとして、ここに配置されます。
一見すると、これはメンテナンスが難しくなるように思えます。しかし、テスト、Issue、依存関係を明確にすることができます。
私たちの目的は、テスト、ドキュメント、gemの公開の自動化であり、これを簡単にするためのツールを追加します。</p>

<p>しかし、プラグインの開発者はプラグインのソースコードソースコードをlogstash-pluginsに置く必要はありません。
 ー コミュニティで利用可能にするために、<a href="http://rubygems.org/">rubygems.org</a>でそれを公開するだけで良いです。</p>

<h2>ワークフロー</h2>

<p>ここで、新プラグインエコシステムのやりとり/ワークフローについて、いくつかの観点から説明します。</p>

<h3>logstashユーザ:</h3>

<p>ユーザは、これまでのリリース同様にLogstashのバイナリをダウンロードします。
Logstash 1.5.0は、1.4.2でパッケージされていたプラグインと同等のものが含まれています。
新しいシステムに簡単に移行できるようにです。
そして、ユーザは、最初のデプロイの後に、Logstashプラグインのをインストール、アップグレードできるようになります。</p>

<p><code>$LS_HOME/bin/plugin</code>スクリプトがプラグイン操作に関連するコマンドになります。</p>

<h5>プラグインのインストール</h5>

<p>プラグインのほとんどはgemとして<a href="http://rubygems.org/">rubygems.org</a>にアップロードされます。
例えば、もしユーザが<a href="https://github.com/logstash-plugins/logstash-output-kafka">Apache Kafka outputプラグイン</a>をインストールする場合、次のコマンドを実行します。</p>

<pre><code>bin/plugin install logstash-output-kafka
</code></pre>

<p>または、ファイルをダウンロード済みの場合は次のコマンドとなります。</p>

<pre><code>bin/plugin install /path/to/logstash-output-kafka-1.0.0.gem
</code></pre>

<h5>プラグインの削除</h5>

<pre><code>bin/plugin uninstall logstash-output-kafka
</code></pre>

<h5>1つまた全プラグインのアップデート</h5>

<pre><code>bin/plugin update
</code></pre>

<pre><code>bin/plugin update logstash-output-kafka
</code></pre>

<h5>プラグインのリストアップ</h5>

<pre><code>bin/plugin list
</code></pre>

<pre><code>bin/plugin list elasticsearch ( List all plugins containing a name )
</code></pre>

<pre><code>bin/plugin list --group output ( list all outputs )
</code></pre>

<h4>ドキュメント</h4>

<p>プラグインが個別に管理されても、<a href="http://www.elasticsearch.org/guide/en/logstash/current/index.html">全プラグインのドキュメントは1カ所</a>です。</p>

<h3>logstash plugin開発者:</h3>

<p>プラグイン開発者と作者は、Logstashエコシステムのためにプラグインを公開することができます。
プラグインは、gemやJavaライブラリの依存関係を宣言できます。
より重要なのは、Logstashのリリース間隔に関係なく、プラグインの改善版をリリースできます。</p>

<p>Rubygemsテクノロジはパッケージングシステム、依存関係管理、ホスティングのために選択されてきました。
Rubyのgemを公開することに慣れている開発者は、Logstashプラグインを簡単に公開することができます。
Elasticsearchはこれらの機能に関して開発者を支援するために、ツールを提供、メンテナンスします。</p>

<h4>開発およびローカルでのテスト</h4>

<p>JRuby <code>1.7.16</code>がプラグインを開発するための唯一の前提条件です。
プラグインにパッチを提供するのは以前と同様です。
例えば、<code>logstash-output-kafka</code>にパッチを送るのは次のようになります。</p>

<ol>
<li><code>git clone https://github.com/logstash-plugins/logstash-output-kafka.git</code></li>
<li>変更</li>
<li>プラグインをローカルでテスト

<ul>
<li><code>bundle install</code></li>
<li><code>bundle exec rspec</code></li>
<li>Logstashの他のバージョンもしくはローカルでテストする場合、Gemfileを編集し、    次のように別のロケーションを加えます。<code>gem "logstash", :github =&gt; "elasticsearch/logstash", :ref =&gt; "master"</code></li>
</ul>
</li>
<li>新しいPull Requestを<code>logstash-output-kafka</code>に対して作成</li>
<li>コミュニティでコードレビューを受け、Elasticsearchがパッチを受け入れ</li>
</ol>


<h4>バージョン</h4>

<p>バージョン情報は、それぞれのプラグインの<code>.gemspec</code>で管理します。
例えば、Apache Kafka outputのgemspecは<a href="https://github.com/logstash-plugins/logstash-output-kafka/blob/master/logstash-output-kafka.gemspec">こちら</a>です。
バージョニングは<a href="http://semver.org/">semantic versioning</a>のルールに従い、
Logstashのバージョニングとは別に、プラグインの開発者によって管理されます。
Logstash 1.5.0がリリースされると、マイルストーン1のプラグインはバージョン1.0.0となり、マイルストーン2のプラグインはバージョン2.0.0となるでしょう。</p>

<h4>公開</h4>

<p>開発者が変更を加えプラグインを公開したいと思った時、<code>.gemspec</code>のバージョン番号を変更します。
全テストが成功した時、Elasticsearchはrubygems.orgにプラグインを手動で公開します。
もし、テストが失敗した場合、プラグインは公開されません。
長期的には、プラグインの公開の自動化を行いたいと思っています。
この変更は新しいため、公開の自動化を提供する前に、自動化についてより理解し、プラグインのテスト基盤を改良したいと思っています。</p>

<h4>Issue</h4>

<p>Issueは、各プラグインのGitHubリポジトリに対してオープンなければなりません。
Logstashコアのリポジトリは、コアのパイプラインや共通的な機能に関連するIssueについて扱います。</p>

<h4>ドキュメント</h4>

<p>プラグインのドキュメントはソースコード自体から生成されます。
それぞれのプラグインのドキュメントは、そのプラグインのリポジトリに含まれます。
Elasticsearchは
<a href="http://www.elasticsearch.org/guide">elasticsearch.org/guide</a>に全てのプラグインのドキュメントを集め生成できる基盤を提供します。</p>

<h4>移行</h4>

<p>全ての新しいpull requestとissueは<a href="https://github.com/logstash-plugins">logstash-plugin</a> organisation配下にある各プラグインのリポジトリに対してオープンする必要があります。</p>

<h5>すでにあるPRはどうすれば良いですか？</h5>

<p>気にしないでください。すでにあるpull requestは開発者によって移行する必要はありません。
LogstashチームがLogstashコアリポジトリに対してのPRを、個別の関連するプラグインのリポジトリに対してマージします。</p>

<pre><code>git clone … # clone the specific plugin repo
# now apply the patch
curl -s https://github.com/elasticsearch/logstash/pull/XXXX | git am --3way
git push
</code></pre>

<p><strong>Note:このプロセスはすでにあるPRに対してgit historyを管理します</strong></p>

<h5>GitHub Issue</h5>

<p>現在、LogstashリポジトリにオープンされているIssueは、それぞれのプラグインのリポジトリに移行します。
Logstashチームがgithub.com APIを利用してこの処理を自動的に行います。
安心してください。私たちが個別のプラグインに対する既存のIssueを移行します。</p>

<h2>今後のロードマップ</h2>

<p>これは、最初のステップであり、これらの変更は、ユーザや開発者に対してエコシステムをよりよくするために、
しっかりとした基盤を提供します。</p>

<p>短期的には、開発者のためにpull requestのフィードバックでテスト自動化を提供する基盤を追加していきます。
プラグインリポジトリのブートストラップや管理のためのツールも提供していきます。</p>

<p>長期的には、すべてのLogstashプラグインを探し、公開するためのコミュニティポータルを提供したいと思っています。
このアイデアは、Puppet ForgeやAWS marketplaceのようなものです。</p>

<p><a href="http://www.elasticsearch.org/blog/logstash-1-5-0-beta1-released/">Logstash 1.5.0 Beta 1</a>をリリースし、これは新しいエコシステムを提供します。
ぜひ、試していただき、これらの変更に関して感じたことを教えてください。
あなたのフィードバック(<a href="http://twitter.com/elasticsearch">Twitter</a>もしくは<a href="https://github.com/elasticsearch/logstash/issues/new">GitHub</a>)はとても貴重です！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logstash 1.5.0 Beta1リリース(日本語訳)]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/12/logstash-1-5-0-beta1-released-ja/"/>
    <updated>2014-12-12T08:17:26+00:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/12/logstash-1-5-0-beta1-released-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/logstash-1-5-0-beta1-released/">logstash 1.5.0.beta1 released</a></p>

<p>Logstash 1.5.0 Beta1をリリースしました。<a href="http://www.elasticsearch.org/overview/logstash/download/">こちらのページ</a>からダウンロードできます。</p>

<p><strong>Note: ベータリリースです。本番環境では使用しないでください。</strong></p>

<!-- more -->


<h2>1.5.0の主な変更点は？</h2>

<p>1.5.0の主なテーマはプラグイン管理、パフォーマンス改善、<a href="http://kafka.apache.org/">Apache Kafka</a>インテグレーションです。Logstashの主な特徴の1つは
プラグインを利用できることであり、パイプラインの動作を拡張するためにプラグインを追加するのが簡単なことです。
このリリースで、プラグインの開発、管理、公開がより簡単になります。
また、Logstashの速度をより良くしたため、より多くのデータを短時間に処理することができます。
興味ありませんか？では、詳細を見ていきましょう。</p>

<h2>plugin ecosystemの変更</h2>

<p>Logstashは165ものプラグイン(inputs、filters、outputs、codecs)を持っており、
これらはElasticsearchとコミュニティからのコントリビュートで開発されています。
多くのプラグインを管理することは、使いやすさと素早さの間のトレードオフがあります。
Logstashの全てのプラグインをまとめることは使いやすさがある一方、プラグインの更新を取り込むために
Logstashの新しいリリースを待ってもらうことになります。
Logstashからプラグインを分離して個別に配布する場合、更新は簡単になりますが、使いやすさ（特に新しいユーザに）に影響が出ます。</p>

<p>私たちは、プロジェクトを前進させるために、これらのバランスをとることを考えました。
これまで、全ての利用可能なプラグインは’core’と&#8217;contrib&#8217;の2つに分割していました。
&lsquo;core&#8217;にあるよく使われるプラグインは、Logstashに含めていました。
コミュニティによりコントリビュートされたプラグインは&#8217;contrib&#8217;パッケージとして分離して配布していました。
1.5.0のリリースで、ユーザに対してより良いプラグイン管理をできるように変更しました。
全てのプラグインは、それ自身によるパッケージに移行しました。
パッケージングフレームワークとしてrubygemsを使い、<a href="http://rubygems.org/">rubygem.org</a>経由でこれらのプラグインを配布、公開します。
また、Logstashにプラグインのインストール、更新、削除を簡単にするための構造も追加しました。</p>

<p>例えば、S3 output pluginをインストールするには、以下のコマンドを実行します。</p>

<pre><code>$LS_HOME/bin/plugin install logstash-output-s3
</code></pre>

<p>それだけです！Logstashがgemと依存するgemをrubygems.orgからダウンロードし、インストールします。
あなたは、S3にデータを送ることができるようになります。</p>

<p>ダウンロード可能なLogstashリリースはプラグインをまだ多く含んでいますが、
いつでも、個別にプラグインをアップグレードし、インストールすることができます。
プラグインエコシステムの変更に関する詳細のブログ記事をお待ち下さい。</p>

<h2>パフォーマンス改善</h2>

<p>Logstash 1.5.0はより高速になっています。パフォーマンスが改善された2カ所について説明します。</p>

<h3>grok filter</h3>

<p>Grok filterはLogstashで、構造化データを抽出するためにパターンを記述するのに使われます。
本リリースで、人気のある幾つかのパターンのgrok filterのスループットを100%に改善しました。
言い換えると、grok filterを使うときに、Logstashを通してより多くのデータを処理することができます。</p>

<p>私たちのベンチマークテストで、1.5.0と1.4.2のスループットの比較をしました。
利用したデータは690万件のApache Webアクセスlogで、<code>COMBINEDAPACHELOG</code>のgrok patternです。
1.5.0で、スループットは34,000 event per sec(eps)から50,000 epsに増加しました。
両方のテストを8コアのマシンでLogstashで8つのワーカーを実行しました。
これらのテストで、一つのgrok filterを実行し、
<code>stdin</code>と<code>stdout</code>を使ったパイプラインでイベントのスループットを計測しました。
全体的なパフォーマンスは、様々なハードウェアやLogstashのコンフィグによって変化することに注意してください。</p>

<h3>json serialization / deserialization</h3>

<p>JSONのシリアライズ/でシリアライズを<a href="https://github.com/guyboertje/jrjackson">JrJackson</a>ライブラリを利用して実装しました。
これにより、100%以上のスループットの改善がありました。
先ほど説明したパフォーマンステストにおいて、1.3KBのサイズの500,00 JSONイベントを送信し、
16,000 epsから30,000 epsにスループットが改善しました。
45,000サイズのイベントで、850 epsから3500 epsにスループットが増加しました。
すばらしいです。</p>

<h2>apache kafka integration</h2>

<p>いまでは、Apache Kafkaが大規模スケールデータ処理システムでよく利用されます。
Logstashの配備のスケーリングにおいて、Kafkaもまた、shippingインスタンスとindexingインスタンス間の
データを保存するための中間メッセージバッファとして使うことができます。</p>

<p>1.5.0で、Logstash Kafkaのinputとoutputのプラグインのビルトインサポートを追加しました。
これは、<a href="https://github.com/joekiller/logstash-kafka">Joseph Lawson</a>によって最初に開発されました。
私たちは、これらのプラグインにインテグレーションテストとドキュメントを追加することにより改良し、
新しいKafkaの機能を開発し続けます。
また、<a href="http://avro.apache.org/">Apache Avro</a> codecを追加することで、Kafkaに保存されたイベントを
簡単に取得でき、ELKスタックを使ってそれらを解析できるようにしました。</p>

<p>Kafka inputを追加するのは次のコマンドです。</p>

<pre><code>$LS_HOME/bin/plugin install logstash-input-kafka
</code></pre>

<p>Kafka outputは次のコマンドです。</p>

<pre><code>$LS_HOME/bin/plugin install logstash-output-kafka
</code></pre>

<h2>セキュリティに関する改善</h2>

<p>認証と経路暗号化のサポートを追加し、Elasticsearchのoutput、input、filterのセキュリティを改良しました。
例えば、HTTPプロトコルでSSL/TLSにより暗号化を有効にでき、
HTTPベーシック認証をユーザ名とパスワードをリクエストに与えることで設定できます。
これらの機能は、時期にリリースされる<a href="http://www.elasticsearch.org/overview/shield/">Elasticsearch Shield</a>セキュリティプロダクトとLogstashを統合できます。</p>

<h2>ドキュメント</h2>

<p>これまで、Logstashのドキュメントは[logstash.net])(<a href="http://logstash.net/">http://logstash.net/</a>)に置いてあり、
他のELKスタックと一緒に動かす時に、情報を探すのが厄介でした。
1.5.0および、今後のバージョンのドキュメントはelasticsearch.orgの<a href="http://www.elasticsearch.org/guide/en/logstash/current/index.html">Logstash Guide</a>に移行します。
この移行で<a href="http://elasticsearch.org/guide">elasticsearch.org/guide</a>にELKスタックを利用、
学習するためにドキュメントが1つになりました。
このベータリリースのイテレーションで、私たちはプレゼンテーションとドキュメントの品質を改善することに活発に取り組んでいきます。
(過去のLogstashのドキュメントの全てはいままでの<a href="http://logstash.net/docs/1.4.2/">logstash.net</a>で引き続き公開していく予定です。)</p>

<h2>バグフィックスと改善</h2>

<p>ここまでの新しい機能に加えて、Logstash 1.5.0では、多くのバグフィックスと多くの機能改善があります。
ここで、これらのいくつかを紹介します。</p>

<ul>
<li>出力しない&#8217;metadata&#8217;をイベントに格納可能に。これは、例えば、date filterに使う中間フィールドのために必要。(<a href="https://github.com/elasticsearch/logstash/issues/1834">#1834</a>,<a href="https://logstash.jira.com/browse/LOGSTASH-1798"> #LOGSTASH-1798</a>)</li>
<li>HTTPを利用しているときのファイルデスクリプタリークの修正。Logstashがストールするのを防ぎ、OOMエラーからクラッシュするケースも防ぎます。(<a href="https://github.com/elasticsearch/logstash/issues/1604">#1604</a>)</li>
<li>Twitter input:<code>full_tweet</code>オプションの追加、Twitter rate limitingエラーのハンドリング(<a href="https://github.com/elasticsearch/logstash/issues/1471">#1471</a>)</li>
<li>イベントを生成するfilter(multiline、clone、split、metrics)により、
後続の条件文にこれらのイベントを正しく伝搬(<a href="https://github.com/elasticsearch/logstash/issues/1431">#1431</a>)</li>
<li>Elasticsearch output:Logstashはデフォルトで<code>message.raw</code>フィールドを作成しない。messageフィールドはElasticsearch
により<code>not_analyzed</code>でマルチフィールドとして追加される。マルチフィールドはディスクスペースが2倍必要だが、利点がない。</li>
<li>bin/logstashの複数のサブコマンドを除去(<a href="https://github.com/elasticsearch/logstash/issues/1797">#1797</a>)</li>
</ul>


<p>これらの機能、改善、バグフィックスについては、Logstash 1.5.0.Beta1 の<a href="https://github.com/elasticsearch/logstash/blob/master/CHANGELOG">changelog</a>をごらんください。</p>

<h2>試してみてください！</h2>

<p>ぜひ、Logstash 1.5.0 Beta 1をダウンロードして試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/logstash/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
</feed>
