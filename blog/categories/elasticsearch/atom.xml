<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: elasticsearch | @johtaniの日記 2nd]]></title>
  <link href="http://blog.johtani.info/blog/categories/elasticsearch/atom.xml" rel="self"/>
  <link href="http://blog.johtani.info/"/>
  <updated>2015-07-08T14:50:11+09:00</updated>
  <id>http://blog.johtani.info/</id>
  <author>
    <name><![CDATA[johtani]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Mappingのすばらしいリファクタリング（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2015/07/08/great-mapping-refactoring-ja/"/>
    <updated>2015-07-08T18:11:31+09:00</updated>
    <id>http://blog.johtani.info/blog/2015/07/08/great-mapping-refactoring-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="https://www.elastic.co/blog/great-mapping-refactoring">The Great Mapping Refactoring</a></p>

<!-- more -->


<p>Elasticsearchのユーザの悩みの最も大きなものの一つは、
タイプとフィールドのマッピングに関する多義性です。
この多義性は、インデックス時の例外やクエリ時の例外、
正しくない結果、リクエストからリクエストへ変化する結果、
また、インデックスの故障やデータのロスを結果として引き起こします。</p>

<p>Elasticsearchをより強固で予測可能な振る舞いをするようにする作業において、
フィールドやタイプのマッピングをより厳格でより信頼性を高くするかといったことに
多くの変更を費やしました。
多くのケースで、Elasticsearch v2.0で新しいインデックスを作るときにのみ、
新しいルールを強制し、これまでのインデックスに関しては後方互換性を保つようにします。</p>

<p>しかし、幾つかのケースでは、先ほど説明したようなフィールドマッピングの
コンフリクトなどが存在するため、それらを利用できないです。</p>

<blockquote><p>コンフリクトしたフィールドのマッピングをもつインデックスはElasticsearch v2.0にはアップグレードできません。</p></blockquote>

<p>もし、これらのインデックスのデータが必要ない場合は、インデックスを消せばいいです。
そうでない場合はマッピングを正しくして再度インデックスする必要があるでしょう。</p>

<p>マッピングを正しく変更することは、私たちが簡単に決めることではありません。
ここからは、現在ある問題点と、私たちがどのように実装して解決したかについて説明します。</p>

<ul>
<li><a href="#conflicting-field-mappings">フィールドマッピングのコンフリクト</a></li>
<li><a href="#ambiguous-field-lookup">あいまいなフィールドのルックアップ</a></li>
<li><a href="#type-meta-fields">タイプのメタフィールド</a></li>
<li><a href="#analyzer-settings">アナライザ設定</a></li>
<li><a href="#index_name-and-path"><code>index_name</code>と<code>path</code></a></li>
<li><a href="#mapping-update">同期的なマッピングの更新</a></li>
<li><a href="#delete-mapping">マッピングの削除</a></li>
<li><a href="#prepare-2_0">2.0のための準備</a></li>
</ul>


<h2><a name="conflicting-field-mappings">フィールドマッピングのコンフリクト</a></h2>

<p>これまで、わたしたちはドキュメントのタイプは「データベースのテーブルのようなもの」と説明していました。
タイプの目的を説明する簡単な方法だったからです。
しかし、残念なことにこれは、真実ではありません。
「同じ」インデックスの「異なるタイプ」にある同じ名前のフィールドは、
内部的に、Luceneのフィールド名が同じものになります。</p>

<p>もし<code>error</code>フィールドとして、ドキュメントタイプが<code>apache</code>のものには数値（integer）を、
ドキュメントタイプが<code>nginx</code>のものには文字列（string）を割り当てた場合、
Elasticsearchは同じLuceneのフィールドに数値と文字列のデータをもつことになります。
このフィールドに対して、検索やaggregationを行う場合、おかしな結果を受け取るか、例外が帰ってくるか、
インデックスが破損することになります。</p>

<p>この問題を解決するために、まず、ドキュメントタイプの名前をフィールドの名前の前に追加することを考えました。
各フィールドは完全に別のものとなります。
このアプローチの利点はドキュメントタイプが実際のテーブルのようになることです。</p>

<p>しかし、この方法には多くの欠点があります。</p>

<ul>
<li>フィールドは常に、他のタイプとは異なるものであると区別するためもしくは、複数のタイプに同じフィールドのクエリのためにワイルドカードをつけた場合、
ドキュメントタイプを前につける必要があります。</li>
<li>複数のドキュメントタイプに対して同じフィールド名で検索する場合、クエリを個別に発行しなければならなく遅くなります。</li>
<li>多くの検索で、既存の多くのクエリを壊してしまうために、単純な<code>match</code>や<code>term</code>クエリの代わりに、multi-fieldクエリを使う必要があります。</li>
<li>圧縮の効率の悪さから、ヒープ利用量、ディスク使用量、I/Oなどが、増加します。</li>
<li>複数のドキュメントタイプに対するaggregationは、global ordinalの利点を利用できなくなるために、遅くなり、メモリの使用量も増えます。</li>
</ul>


<h3>解決方法</h3>

<p>最終的に、同じインデックスの同じ名前を持つ全てのフィールドは、同じマッピングを持つ必要があるというルールを採用することに決めました。
ただ、<code>copy_to</code>や<code>enabled</code>のようなパラメータはタイプごとに指定することができるようになっています。
これにより、データの破損、クエリ時の例外そして、おかしな結果が発生する問題を防ぎます。
クエリとaggregationは現在でも高速なままで、圧縮率を最大化し、ヒープ使用量やディスク使用率の低減させます。</p>

<p>この解決方法の欠点は、個別のテーブルとしてタイプを扱いたいユーザが彼らの考え方を変える必要があるということです。
これは、思ったよりも問題ではありません。
実際には、多くのフィールド名はデータの明確なタイプを表現しています。
<code>created_date</code>は常に、日付ですし、<code>number_of_hits</code>フィールドはいつも数値です。
フィールドマッピングがコンフリクトしているユーザはデータを失ったり、おかしなデータを受け取ったり、データを欠損させています。
ベストプラクティスにユーザが従っているかどうかによらず、インデックス時に正しい振る舞いを強制することが現在の違いです。</p>

<p>ユーザの多くがコンフリクトしていないフィールドマッピングをもっていれば、
コンフリクトが起きた場合、技術がこれらのシチュエーションを扱うことが可能になると思いませんか？
そこにはいくつかの解決方法があります。</p>

<h4>タイプの代わりにインデックスを別々に</h4>

<p>最も簡単な解決方法です。インデックスを別々のインデックスとし、実際のデータベーステーブルのようにします。
インデックスをまたいだ検索はタイプをまたいだ検索のように動作しますし、
ソートやaggregationも同じデータタイプへのクエリのように動作します。これまでと同じ制限です。</p>

<h4>コンフリクトしたフィールドの名前の変更</h4>

<p>コンフリクトがごくわずかな場合、（Logstashやアプリケーションで使っているものも一緒に）よりわかりやすいフィールド名に変更することで解決できます。
例えば、2つの<code>error</code>フィールドがあった場合に、<code>error_code</code>と<code>error_message</code>に変更します。</p>

<h4><code>copy_to</code>もしくはmulti-fieldsを利用</h4>

<p>異なるドキュメントタイプのフィールドは別々の<code>copy_to</code>を設定できます。
元の<code>error</code>フィールドは<code>index</code>の設定に<code>no</code>が設定してあり、全てのドキュメントタイプで無効化されていますが、
特定のタイプだけ、<code>error</code>フィールドの値を数値の<code>error_code</code>フィールドにコピーすることができます。</p>

<pre><code>PUT my_index/_mapping/mapping_one
{
  "properties": {
    "error": {
      "type": "string",
      "index": "no",
      "copy_to": "error_code"
    },
    "error_code": {
      "type": "integer"
    }
  }
}
</code></pre>

<p>他のタイプでは文字列の<code>error_message</code>にコピーします。</p>

<pre><code>PUT my_index/_mapping/mapping_two
{
  "properties": {
    "error": {
      "type": "string",
      "index": "no",
      "copy_to": "error_message"
    },
    "error_message": {
      "type": "string"
    }
  }
}
</code></pre>

<p>同様の解決方法として<a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/mapping-core-types.html#multi-fields">multi-field</a>も使えます。</p>

<h4>各データタイプに対してネストしたフィールドに</h4>

<p>ときどき、Elasticsearchに送ったドキュメントやドキュメントがもっているフィールドを制御できない場合があります。
部分的なコンフリクトに加え、闇雲に、ユーザが送ってきたフィールドを受け入れると、マッピングが肥大化します。
タイムスタンプやIPアドレスをフィールド名に使うようなドキュメントがあると考えてください。</p>

<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-nested-type.html"><code>nested</code> フィールド</a>にすることで、<code>str_val</code>、<code>int_val</code>、<code>date_val</code>というような各データタイプを利用できます。</p>

<p>このアプローチによって、次のドキュメントは</p>

<pre><code>{
  "message": "some string",
  "count":   1,
  "date":    "2015-06-01"
}
</code></pre>

<p>アプリケーションによって、次のようにフォーマットしなおす必要があります。</p>

<pre><code>{
  "data": [
    {"key": "message", "str_val":  "some_string" },
    {"key": "count",   "int_val":  1             },
    {"key": "date",    "date_val": "2015-06-01"  }
  ]
}
</code></pre>

<p>この解決方法は、アプリケーションサイドでより多くの作業が必要ですが、コンフリクトの問題とマッピングの肥大化の問題を同時に解決します。</p>

<h2><a name="#ambiguous-field-lookup">あいまいなフィールドのルックアップ</a></h2>

<p>現在、フィールドの指定には&#8221;short name&#8221;、フルパス、ドキュメントタイプを前につけたフルパスが利用できます。
これらのオプションがあいまいさをもたらしています。
サンプルとして次のマッピングをご覧ください。</p>

<pre><code>{
  "mappings": {
    "user": {
      "properties": {
        "title": {
          "type": "string"
        }
      }
    },
    "blog": {
      "properties": {
        "title": {
          "type": "string"
        },
        "user": {
          "type": "object",
          "fields": {
            "title": {
              "type": "string"
            }
          }
        }
      }
    }
  }
}
</code></pre>

<ul>
<li><code>title</code>は<code>user.title</code>、<code>blog.title</code>、<code>blog.user.title</code>のどれでしょう？</li>
<li><code>user.title</code>は<code>user.title</code>または<code>blog.user.title</code>のどちらでしょう？</li>
</ul>


<p>答えは「場合によります。」です。Elasticsearchが最初に見つけたものになります。
フィールドはリクエストごとに変わるため、各ノードでマッピングがどのようにシリアライズされたかに依存します。</p>

<p>2.0では、フィールドを指定する時に、ドキュメントタイプを除いたフルパス名を使用するべきでしょう。</p>

<ul>
<li><code>user.title</code>は、<code>blog</code>タイプの<code>user.title</code>を意味します。</li>
<li><code>title</code>は、<code>user</code>と<code>blog</code>タイプの<code>title</code>フィールドを意味します。</li>
<li><code>*title</code>は<code>user.title</code>と<code>title</code>フィールドの両方にマッチします。</li>
</ul>


<p><code>user</code>タイプの<code>title</code>フィールドと<code>blog</code>タイプの<code>title</code>の違いはどのように指定するのでしょう？</p>

<p>指定できません。<a href="#conflicting-field-mappings">フィールドマッピングのコンフリクト</a>で説明した変更により、
<code>title</code>フィールドは両方のタイプで同じフィールドになります。
本質的に<code>title</code>と呼ばれる1つのフィールドになります。</p>

<p><code>user.</code>や<code>blog.</code>のようなタイプのプレフィックスはタイプを指定することによるフィルタリングで効果があります。
クエリの<code>blog.title</code>フィールドは<code>blog</code>タイプのドキュメントだけを検索し、<code>user</code>タイプのドキュメントを検索しません。
このシンタックスは誤解を招きやすいです。なぜなら、いつでも動作するわけではないからです。
aggregationやsuggestionはすべてのタイプに関する結果を含みます。
この利用のため、上記の例のあいまいさがあるので、タイプのプレフィックスはサポートしません。</p>

<p><strong>重要</strong> short nameやタイププレフィックスを利用したpercolatorは更新する必要があります。</p>

<h2><a name="type-meta-fields">タイプのメタフィールド</a></h2>

<p>すべてのタイプはメタフィールドを持っています。<code>_id</code>、<code>_index</code>、<code>_routing</code>、<code>_parent</code>、<code>_timestamp</code>などです。
これらのほとんどは<code>index</code>、<code>store</code>、<code>path</code>のような幾つかの設定をサポートしています。
これらの設定について次のようにシンプルにしました。</p>

<ul>
<li><code>_id</code>と<code>_type</code>は変更不可</li>
<li><code>_index</code>は、ドキュメントのもつインデックスを保存するために<code>enabled</code></li>
<li><code>_routing</code>は<code>required</code>のみを指定</li>
<li><code>_size</code>は<code>enabled</code>のみ</li>
<li><code>_timestamp</code>はデフォルトで保存される</li>
<li><code>_boost</code>と<code>_analyzer</code>は廃止。古いインデックスのものは無視される</li>
</ul>


<p>ドキュメントのフィールドから<code>_id</code>と<code>_routing</code>と<code>_timestamp</code>の値を抽出することができました。
この機能は廃止されます。これは、ドキュメントのパースとコンフリクトを起こすためです。
代わりに、これらの値はURLもしくはquery stringで指定可能です。</p>

<p><code>_boost</code>と<code>_analyzer</code>フィールドは例外で、すでにあるメタフィールドの設定は古いインデックスのものが採用されます。</p>

<h2><a name="analyzer-settings">アナライザ設定</a></h2>

<p>これまで、indexとsearchのアナライザがインデックス、タイプ、フィールド、ドキュメント（<code>_analyzer</code>フィールドで）の
それぞれのレベルで指定可能でした。
同じフィールドに対して異なるanalysis chainの組み合わせができることにより、おかしな関連度を引き起こしていました。
フィールドマッピングのコンフリクトを解消することに加え、アナライザの設定も簡略化します。</p>

<ul>
<li>Analyzedな文字列フィールドは、<code>analyzer</code>設定と<code>search_analyzer</code>設定（<code>analyzer</code>設定の値をデフォルトとする）を指定できます。<code>index_analyzer</code>設定は<code>analyzer</code>となります。</li>
<li>複数のタイプで同じ名前のフィールドがある場合、フィールドはすべて、同じアナライザの設定を持たなければなりません。</li>
<li>タイプレベルのデフォルト設定の<code>analyzer</code>、<code>index_analyzer</code>、<code>search_analyzer</code>設定は廃止されます。</li>
<li>デフォルトアナライザはインデックスごとにインデックスの<code>analysis</code>設定で設定します。これらは<code>default</code>もしくは<code>default_search</code>という名前で設定します。</li>
<li>ドキュメントごとの<code>_analyzer</code>フィールドはサポートしません。既存のインデックスのものは無視されます。</li>
</ul>


<h2><a name="index_name-and-path"><code>index_name</code>と<code>path</code></a></h2>

<p><code>index_name</code>と<code>path</code>設定は（Elasticsearch v1.0.0から利用できる）<code>copy_to</code>によって置き換わりました。
既存のインデックスについてはこれらは機能しますが、新しいインデックスでは指定できません。</p>

<h2><a name="mapping-update">同期的なマッピングの更新</a></h2>

<p>現在、これまで存在していないフィールドを含むドキュメントをインデキシングするとき、
フィールドはローカルのマッピングに追加され、それから、マスターに変更（新しいマッピングをすべてのシャードに適用する更新）が送信されていました。
同時に2つのシャードに同じフィールドを追加することができます。
また、そのとき、異なる2つのマッピングがある可能性があります。
1つは<code>double</code>でもう1つは<code>long</code>だったり、<code>string</code>と<code>date</code>だったりと。</p>

<p>このような場合、マスターに最初に届いたマッピングが採用されます。
しかし、「負けた」マッピングをもつシャードでは、すでに異なるデータのタイプを利用しているため、
これを利用し続けます。
そのご、ノードをリスタートしたときに、シャードが別のノードに移動し、マスターにあるマッピングを適用します。
このとき、インデックスが破損したりデータを失ったりします。</p>

<p>これを防ぐために、シャードはインデキシングを続ける前に、新しいマッピングがマスターによって採用されるかどうかを待つようになりました。
これはすべてのマッピングが安全に更新されます。
新しいフィールドをもっているドキュメントをインデキシングすると、前よりも処理が遅くなるでしょう。
受け入れられることを待つ必要があるためです。
しかし、クラスタの状態の更新処理のスピードが次の2つの新しい機能によって大きく改善されています。</p>

<ul>
<li><strong>クラスタ状態の差分</strong>：可能であれば、クラスタの状態の変更はクラスタ状態全体の変更ではなく、部分的なものとする。</li>
<li><strong>シャードへのリクエストの非同期化</strong>：シャードアロケーション処理中に、マスタノードは、
割り当てられていないシャードのコピーの日付が最新のものを持っているかを見つけるために、リクエストをデータノードに対して送信します。
ここで、クラスタ状態を変更する呼び出しがブロッキングで行われていました。v1.6.0から、このリクエストはバックグラウンドで非同期で実行されます。
これにより、マッピング更新のようなペンディングタスクをより早く処理できるようになります。</li>
</ul>


<h2><a name="delete-mapping">マッピングの削除</a></h2>

<p>（そのタイプのドキュメントがある場合）タイプマッピングを削除できないようにします。
マッピングを削除した後に、削除されたフィールドの情報は、Luceneレベルでは存在し続け、
もし、後から同じ名前のフィールドが追加されたときにインデックスの破損を引き起こします。
そのようなマッピングは残しておくか、新しいインデックスに再インデックスすることができます。</p>

<h2><a name="prepare-2_0">2.0のための準備</a></h2>

<p>マッピングがコンフリクトしているかどうかを決めることは、手動で行うには慎重に行う必要があります。
私たちは、<a href="https://github.com/elastic/elasticsearch-migration">Elasticsearch Migration Plugin</a>を提供します。
これは、2.0で非推奨になったり廃止された機能を利用しているかどうかを見つけるために役に立つでしょう。</p>

<p>もし、コンフリクトしたマッピングを持っている場合、
正しいマッピングを持つ新しいインデックスにデータを再インデックスするか、
必要ないなら削除します。
これらのコンフリクトを解決しない限り2.0にはアップグレードできないでしょう。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 2.0.0.beta1リリース間近（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2015/07/07/elasticsearch-2-dot-0-0-dot-beta1-coming-soon-ja/"/>
    <updated>2015-07-07T15:25:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2015/07/07/elasticsearch-2-dot-0-0-dot-beta1-coming-soon-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="https://www.elastic.co/blog/elasticsearch-2.0.0.beta1-coming-soon">Elasticsearch 2.0.0.beta1 coming soon!</a></p>

<p>Elasticsearch 2.0.0.beta1のリリースの準備をしています。
これは、Lucene 5.2.1に含まれる多くの改善が利用できるようになります。
このリリースに関するいくつかの機能は次のようなものです。</p>

<!-- more -->


<h4>Pipeline Aggregations</h4>

<p>差分や移動平均、他のAggregationsの結果に対する
series arithmeticのようなaggregationが利用可能になります。
この機能は、これまでは、クライアントサイドで実行する必要がありました。
しかし、この計算をより強力な解析クエリを構築してElasticsearchで
実行することができるようになります。
クライアントのコードをより簡潔にすることができます。
これにより、予測解析や異常検知のようなことができるようになります。</p>

<h4>Query/Filter merging</h4>

<p>Filterはなくなります。全てのフィルタは、クエリになります。
クエリコンテキストで利用されると、効率的に関連度スコアを計算し、
フィルタコンテキストで利用されると、単に、
マッチしていないドキュメントを除外する（今のフィルタのようなもの）だけです
この変更は、クエリ実行が自動的に、より効率的な順番で実行されるように
最適化されることを意味します。
例えば、フレーズやgeoクエリのような遅いクエリは
まず、近似フェーズを実行し、それから、より遅い実際のフェーズが
結果に対して行われます。
フィルタコンテキストにおいて、頻繁に利用される条件は自動的にキャッシュされます。</p>

<h4>Configurable store compression</h4>

<p><code>index.codec</code>設定により、高速化のためのLZ4圧縮（<code>default</code>）か
インデックスサイズを小さくするためのDEFLATE（<code>best_compression</code>）を
選択できます。これは、ロギングでとくに役に立ちます。
これにより、古いインデックスオプティマイズする前に<code>best_compression</code>に
変更できます。</p>

<p>これらに関するブログ記事がすぐに公開されるでしょう。</p>

<h3>Performance and resilience</h3>

<p>以降では、新しいメジャーリリースに関して簡単に紹介します。
2.0の変更の多くは内部の機能に関するものであり、
直接ユーザに関連するわけではないからです。</p>

<p>新しいメジャーバージョンのテーマは、パフォーマンス、安定性、
堅牢性、予測可能性、そして使い勝手の良さです。</p>

<ul>
<li>物事が予測した通りに動作する</li>
<li>何か問題があった場合に、Elasticsearchから役立つフィードバックがある</li>
<li>ローレベルの設定を扱う必要はなく、Elasticsearchが良い設定を決定する</li>
<li>これらに加え、データがより安全に</li>
</ul>


<p>これらの目標は完全ではありません。
まだ、多くの改善があります。しかし、2.xブランチで、
すでに500コミットを超える大きな改善が実施されています。</p>

<ul>
<li>on-diskの doc valuesをデフォルトで利用（これまではfielddata）。
ヒープ使用量を減らして、スケーラビリティを向上</li>
<li>セグメントマージ処理中のメモリ使用量の削減</li>
<li>normsの圧縮率の改善。ヒープスペースを利用している大きな処理のひとつだったため。</li>
<li>全てのリクエストの後に、transaction logをfsyncすることで、デフォルトで耐久性を向上</li>
<li>全てのファイル変更をアトミックに（部分的なファイルの書き出しはなし）</li>
<li>マージを自動で制限</li>
<li>フレーズクエリやスパンクエリを高速化</li>
<li>フィルタキャッシュをより効率化するための圧縮されたビットセット</li>
<li>クラスタ状態の差分更新</li>
<li>構造化されたJSON形式の例外</li>
<li>よりきめ細かいLuceneのメモリレポート</li>
<li>デフォルトではlocalhostにのみバインド。開発のノードが他のクラスタにジョインするのを防ぐ</li>
<li>parent/childのクエリ実行最適化のためにリライト</li>
<li>Java Security Managerで必要最小限なパーミッションで実行</li>
<li>全てのコアなプラグインをelasticsearchリポジトリに移行し、Elasticsearchのバージョンに同期してリリースされる予定</li>
</ul>


<h2>アップグレード前に</h2>

<p>メジャーバージョンのアップグレードは問題のあるものを一掃する機会を与えてくれます。
できる限り、これらの変更をアップグレードするために、簡単な方法を提供しようとしています。
しかし、Elasticsearch 2.0にアップグレードする前に、必要な処理が2つあります。</p>

<p>1つ目は、フィールドとタイプマッピングに関することです。
mapping APIは、現在、それほど厳密ではありません。
内蔵された保護機構を提供する代わりに、ユーザがベストプラクティスを知っていると信頼していました。
2.0では、mappingはより厳密で安全ですが、いくつかの変更では、後方互換性を保っていません。
詳細については<a href="https://www.elastic.co/blog/great-mapping-refactoring">The Great Mapping Recatoring</a>をごらんください。</p>

<p>2つ目はElasticsearch 0.20以前のユーザに関する変更です。
これは、Lucene 3.xを使っています。
Elasticsearch 2.xはLucene 5をベースにしています。
Lucene 5はLucene 4.xによって作成されたインデックスの読み込みはサポートしていますが、
Lucene 3.xに関してはサポートしていません。</p>

<p>Elasticsearch 0.20以前のバージョンによって生成されたインデックスを持っている場合、
Elasticsearch 2.xのクラスタをスタートすることはできません。
これらの古いインデックスを削除するか、Elaticsearch 1.6.0以上に含まれている
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-upgrade.html">upgrade API</a>を使用してアップグレードする必要があります。</p>

<p>upgrade APIの実行は2つのジョブを実行します。</p>

<ul>
<li>古いLuceneフォーマットのセグメントを最新のフォーマットで書き換えます</li>
<li>Elasticsearch 2.xによって読み込めるようという印をインデックスに追加します</li>
</ul>


<p>全てのセグメントを最新バージョンにアップグレードするのも良い案ですが、
アップグレード前に必要な処理を最小限に抑えることも可能です。
（Lucene 3.xのセグメントだけをアップグレード）
その場合は、<code>only_ancient_segments</code>パラメータを指定します。</p>

<h2>Elasticsearch Migration Plugin</h2>

<p>Elasticsearch 2.0 に移行する前に、インデックスがアップグレードが必要なのか、
ほかになにかするべきことがあるのかをチェックする助けになる
Elasticsearch Migration Pluginをリリースしました。</p>

<p>まず、プラグインをインストールします</p>

<pre><code>./bin/plugin -i elastic/elasticsearch-migration
</code></pre>

<p>プラグインのインストール後はノードのリスタートは必要ありません。</p>

<p>以下のリンクをブラウザで開きます。</p>

<p><a href="http://localhost:9200/_plugin/migration">http://localhost:9200/_plugin/migration</a></p>

<p>（<code>localhost:9200</code>はインストールしたホスト名に変更してください。）</p>

<p>Migration pluginに関してバグやご意見がある場合は、<a href="http://github.com/elastic/elasticsearch-migration/issues">GitHubのIssue</a>にお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[さらに進化したFound（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2015/07/07/we-just-made-found-more-awesome-ja/"/>
    <updated>2015-07-07T15:20:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2015/07/07/we-just-made-found-more-awesome-ja</id>
    <content type="html"><![CDATA[<p>4ヶ月前に、<a href="https://www.elastic.co/blog/welcome-found">Found joined our team at Elastic</a>をアナウンスしました。
Foundの素晴らしいチームと一緒に仕事をしていますが、彼らによって、より素晴らしい
hosted Elasticsearchを提供することになりました。</p>

<!-- more -->


<p>私たちがともに密接に働くことにより、本日（2015/7/1）、
<a href="https://www.elastic.co/products/found">新しい2つのFound</a>を提供することになりました。
Found StandardはこれまでのFoundの機能に加え、さらに低価格を提供します。
Found Premiumは、SLAサポートと、ShieldやWatcherを将来Found上で提供します。</p>

<h2>Found Standard</h2>

<p>Foundは素晴らしいです。専用のElasticsearchクラスタ、簡単なスケール、
ビルトインのセキュリティそして、時間単位での課金などを持っています。
私たちは、hosted Elasticsearchを探している方に、
Foundが適したソリューションであると思っていますし、
すべての方に利用できて手頃な価格であるということを確信したいと思っています。</p>

<p>本日（2015/07/01）からFoundの価格をかなり低価格にし、
<strong>月額50ドル以下</strong>でhosted Elasticsearchを簡単に試してもらえるようにしました。</p>

<p>価格を下げることは正しい重要なステップですが、
Foundを利用している全ての人に、より良い経験を持っていただきたいと考えています。
低価格化と一緒に、<strong>free backups</strong>と<strong>built in SSD</strong>もFoundで提供を始めることになります。</p>

<p>Foundの重要な特徴の一つが、高可用性のために、クラスタをいくつのデータセンターに持つかを
選択できることです。
データは重要です。これが正しい選択でユーザの助けになると考えています。
これにより、私たちの価格は、<strong>複数のデータセンターにより安価に</strong>配置することができます。</p>

<p>また、KibanaもElasticsearchのデータを可視化する素晴らしい方法だと考えています。
Kibana 4が最新バージョンですが、
これは、サーバサイドコンポーネントを持っています。
これは、サービスとしてこれを提供するために、追加の料金がかかることを意味します。
Foundチームが築いた素晴らしい基盤とKibanaチームの努力により、
hosted Elasticsearchクラスタで<strong>無料のKibana 4</strong>を7月15日より提供することになりました。</p>

<h2>Found Premium</h2>

<p>また、私たちは、オープンソースプロダクトに関してサブスクリプションを提供していますが、
Found Standardに対しても提供することになりました。
これが、Found Premiumです。</p>

<p>フォーラムベースのサポートよりもSLAベースのサポートを望んでいる場合、
プロダクトを開発しているチームからのサポートを受けることができるオプションを
提供し始めました。
クリティカルなイベントを持っていたり、私たちのプロダクトに関する
問題を予測するためのベストなヘルプやガイダンス、アドバイスを探しているような場合にサポートします。</p>

<p>さらに近い将来、サブスクリプションの一部として、<a href="https://www.elastic.co/products/shield">Shield</a>（Elasticasearchのセキュリティプラグイン）や<a href="https://www.elastic.co/products/watcher">Watcher</a>（アラーティングプラグイン）が利用できるようになります。</p>

<p>私たちのチームがともに働き、多くのことを可能にし、すばらしい仕事をユーザに提供したかを
将来も楽しみです。
私は非常に誇りに思っていますし、気に入っていただけたらと思っています。
ぜひ、<a href="https://www.elastic.co/webinars/getting-started-with-found">7/15のWebnarに参加して</a>くわしい話を聞いていただき、疑問を解消してください。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 1.6.0リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2015/06/10/elasticsearch-1-6-0-released-ja/"/>
    <updated>2015-06-10T13:31:02+09:00</updated>
    <id>http://blog.johtani.info/blog/2015/06/10/elasticsearch-1-6-0-released-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="https://www.elastic.co/blog/elasticsearch-1-6-0-released">Elasticsearch 1.6.0 released</a></p>

<p>本日（6/9）、<strong>Lucene 4.10.4</strong>ベースの<strong>Elasticsearch 1.6.0</strong>をリリースしました。
このリリースはElasticsearchの最新の安定バージョンとなります。
また、素晴らしい新機能がいくつか追加されています。</p>

<!-- more -->


<ul>
<li>synced flushによるリスタートの高速化</li>
<li>シャード配置は保留中のタスクをブロックしない</li>
<li>レスポンスボディのJSONのフィルタリング</li>
<li>共有ファイルシステムリポジトリに対するセキュリティフィックス</li>
<li>古いインデックスのためのUpgrade API</li>
<li>Kibanaユーザのためのハイライトの強化</li>
<li>Windowsユーザのための<code>mlockall</code></li>
<li>より詳細なスクリプト設定</li>
</ul>


<p><a href="https://www.elastic.co/downloads/past-releases/elasticsearch-1-6-0">すべての変更リストとダウンロード</a>はこちらをごらんください。</p>

<h2>synced flushによるリスタートの高速化</h2>

<p>1.6.0より前のバージョンでは、メンテナンスやローリングアップグレード時の
ノードの再起動で、必要であるかどうかに関わらず、多くの場合、
ノードのすべてのシャードのすべてのデータを再度コピーする必要がありました。
この新しいsynced flush機能により、
sync-flushされたインデックスに対して、既存のデータを再利用し、
より早くクラスタを正常な状態にすることができるようにします。</p>

<p>ここで、この変更以前にどのように動いていたかを説明します。
すでにあるレプリカシャードは、ノードがリスタートした後に、
プライマリから復元するときに、
最初のステップはプライマリにあるセグメントとレプリカにあるセグメントを
比較することです。そして、セグメントに違いがあった場合にコピーされます。
問題は、セグメントプライマリのセグメントのマージと
レプリカのセグメントのマージが別々に起こっており、
各シャードのセグメントが完全に異なるが、
それらが同じデータを持っているという点です。</p>

<p>新しいsynced-flush機能では、<code>sync_id</code>がプライマリと
レプリカシャードに、シャードのコンテンツが同一であるという判別するために、
書き込まれます。これは、リカバリがセグメントの比較のステップを
スキップできることを意味します。
リカバリのスピードを高速にします。</p>

<p>synced flushはアイドル状態のインデックスで自動的に実行されます。
直前の5分間でデータが登録、更新削除されていないインデックスに対してです。
これは、ロギングのユースケースで特に役に立ちます。
機能のインデックスはインデキシングがストップしたあとの5分で自動的に
syncされるでしょう。</p>

<p>ノードのリスタートやクラスタのリスタートが必要で、
自動的に発生するsyncを待てない場合は次のようなことが可能です。</p>

<ul>
<li>インデキシングを停止（実行中のリクエストが停止するのも待つ）</li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-cluster.html">シャードのアロケーションを停止</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-synced-flush.html">synced-flush</a>リクエストの発行</li>
<li>ノードのリスタート</li>
<li>シャードのアロケーションの再開</li>
<li>クラスタの状態がグリーンになるまで待つ</li>
<li>インデキシングの再開</li>
</ul>


<p><strong>NOTE:</strong> &ldquo;シャードのアロケーションを停止&#8221;のステップが必要です。
これがない場合、Elasticsearchはノードの再起動が始まると、
異なるノードにシャードの再配置を始めます。
これは、新しいノードにシャードデータの全てをコピーする必要があります。</p>

<p>ドキュメントのインデキシング、更新、削除のあとに最初のフラッシュが
発生したときに、
シャードの<code>sync_id</code>が自動的に無効化されます。
詳細については<a href="https://github.com/elastic/elasticsearch/issues/11336">#11336</a>と<a href="https://github.com/elastic/elasticsearch/issues/11179">#11179</a>をごらんください。</p>

<h2>シャード配置は保留中のタスクをブロックしない</h2>

<p>多数のノードやインデックスを持っているユーザは
クラスタ全体のリスタートのあとのシャードのリカバリで、
長い間、リカバリが止まって見えることに気づいたかもしれません。
これらのリカバリが止まって見える間は、クラスタ設定の更新のような軽微なアクションでさえ、
例外が発生したり、その設定が反映されるまでに長時間かかるといったことが起きていました。
この問題の兆候は保留中のタスクのキューが大きくなることです。</p>

<p>これらの遅延の原因はシャードの配置のプロセスにあります。
配置されるべきシャードのコピーを
持っているのがどのノードかを全てのデータノードに聞きます。
多くのシャードや遅いディスクを持ったデータノードは
反応するのに時間がかかります。
特に、シャードのリカバリがすでにI/Oを利用しているような時です。
このバージョン以前のものは、シャード情報のためのリクエストを
同期的に処理していました。
クラスタ状態の更新はアロケーションプロセスを続けるために
必要な情報を待っている間、ブロックされます。</p>

<p> <a href="https://github.com/elastic/elasticsearch/issues/11262">#11262</a>での変更は
この情報のためのリクエストを非同期にします。
クラスタ状態の更新はこのタスクによってブロックされません。
これは、保留中のタスクがより早く処理でき、
クラスタが変更に対してより早く反応できます。
処理中のshard infoリクエストの数は
<code>number_of_in_flight_fetch</code>キーとしてcluster-health APIで取得できます。</p>

<p>さらに、シャードがある理由で復旧に失敗すると、
クラスタは、シャードのリカバリが成功するまで、同じノードに対して
シャードをアロケーションしないようにします。</p>

<h2>レスポンスボディのJSONのフィルタリング</h2>

<p>Elasticsearchは全ての情報を返します。
例えば、検索リクエストは<code>_index</code>、<code>_type</code>、<code>_id</code>、
<code>_score</code>、<code>_source</code>を返します。
しかし、全ての情報が必要でない場合があります。
また、これらのデータを遅いネットワークで転送することは
遅延の原因となります。</p>

<p>ユーザはこの検索メタデータを無効にするための特殊な設定を
行ったり、他のAPIのレスポンスのフォーマットを
コントロールするための設定があります。
<a href="https://github.com/elastic/elasticsearch/issues/10980">#10980</a>の変更で、任意のレスポンスボディのJSONに対して、
必要な要素だけを取得する機能が追加されました。
<code>filter_path</code>パラメータを使用します。</p>

<p>例えば、検索リクエストからは<code>total</code>数と、各要素の<code>hits</code>の配列を欲しい場合、
次のように指定します。</p>

<pre><code>GET _search?filter_path=hits.total,hits.hits
</code></pre>

<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-info.html">nodes-info API</a>から各ノードの<code>http_address</code>だけを取得したい場合は、
ノード名の部分にワイルドカード(<code>*</code>)を使用します。</p>

<pre><code>GET _nodes?filter_path=nodes.*.http_address
</code></pre>

<p>単一の<code>*</code>がJSON階層の1つの階層に対しての
ワイルドカードとして機能します。
2つの<code>**</code>は複数階層に対してとなります。
複数のフィルタはカンマ区切りで指定可能です。
詳細について<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/common-options.html#_response_filtering">Response filtering</a>をごらんください。</p>

<h2>共有ファイルシステムリポジトリに対するセキュリティフィックス</h2>

<p>本リリースはsnapshot-restoreで使われる
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html#_shared_file_system_repository">共有ファイルシステムリポジトリ</a>に関するセキュリティ強化の変更が含まれます。
現在、Elasticsearchのユーザは、Elasticsearchプロセスによって書き込み可能
任意のディレクトリに<code>.snapshot</code>ファイルを書き込むことができます。
<a href="https://github.com/elastic/elasticsearch/issues/11284">#11284</a>の変更で、リポジトリのために使用できるディレクトリを
強制的に指定できるようになりました。
適切なディレクトリが<code>config/elasticsearch.yml</code>設定ファイルの
<code>path.repo</code>に指定される必要があります。</p>

<p>次のように設定されたElasticsearchインスタンスはこのセキュリティ問題に対して影響を受けにくいです。</p>

<ul>
<li><code>root</code>ではなく<code>elasticsearch</code>ユーザとしてElasticsearchを実行</li>
<li><code>elasticsearch</code>ユーザが<code>data</code>ディレクトリに対してのみ
書き込み権限を持っていて、共有ファイルシステムリポジトリに対しても利用できる</li>
<li>ファイアウォールやプロキシ、Shieldを使って、snapshot APIの実行を任意のユーザから実行されるのを防いでいる</li>
</ul>


<p>この問題を<a href="https://www.elastic.co/community/security">CVE-2015-4165</a>としています。</p>

<h2>古いインデックスのためのUpgrade API</h2>

<p>Elasticsearch 2.0以降では、
Lucene 5ベースとなり、Lucene 3
（Elasticsearchのバージョンでは0.90以前）
によって書き出されたセグメントを含んだインデックスを読み込むことが
できなくなります。
これらの「古いインデックス」はLucene 4にアップグレードする必要があり、
2.0-compatibleとして印をつける必要があります。
そうしなければ、Elasticsearch 2.0に以降できないでしょう。</p>

<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-upgrade.html">upgrade API</a>は
、最新のLuceneフォーマットにインデックスにある全てのセグメントを
アップグレードするためにすでに利用できます。
また、最新のフォーマットは性能向上やバグフィックスといった利点もあります。
さらに、2.0-compatibleとして古いインデックスをマークする設定も
書き込むことができます。
さらに、<code>upgrade_only_ancient_segments</code>オプションが
Lucene 3のセグメントだけをアップグレードするために利用でき、
移行前の必要な処理を減らすことができます。</p>

<h2>Kibanaユーザのためのハイライトの強化</h2>

<p>KibanaユーザはElasticsearchのハイライトについて2つの点で問題を見つけていました。</p>

<ul>
<li>ワイルドカードでフィールド名を指定した場合に、ハイライトに適さないフィールドも帰ってくる（日付や数値のフィールドなど）</li>
<li>古いインデックスが非常に大きなターム（> 32kB）を含んでいて、ハイライトが失敗する。
最近のバージョンでは、これらの大きなタームはインデックス時に除去される</li>
</ul>


<p><a href="https://github.com/elastic/elasticsearch/issues/11364">#11364</a>の変更で
これらの問題が修正されました。
ワイルドカードを利用したフィールド名では、stringフィールドのみを返し、非常に長いタームによる例外は無視するようになります。</p>

<h2>Windowsユーザのための<code>mlockall</code></h2>

<p>速いGCはノードの安定性と性能について重要です。
小さなバイトのヒープでさえ、ディスクにスワップすることを許可してしまうと、GCに対して大きな影響が出てしまいます。
ですので、これらのコストは排除されるべきです。</p>

<p>Linuxユーザは<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration.html#setup-configuration-memory"><code>bootstrap.mloclall</code>設定</a>による恩恵を受けています。
これは、RAMにJVMのヒープを起動時にロックします。
<a href="https://github.com/elastic/elasticsearch/issues/10887">#10887</a>では、同様の機能をWindowsユーザにも提供します。</p>

<h2>より詳細なスクリプト設定</h2>

<p>Scriptsはリクエストにインラインで指定できます。
<code>.scripts</code>インデックスにインデックスもでき、<code>config/</code>ディレクトリ配下にファイルとして保存もできます。
これまでは、インラインかインデックスされたスクリプトの両方を同時に有効無効にすることが選択できましたが、
<code>.scripts</code>インデックスをプロキシやShieldで保護することもできました。</p>

<p><a href="https://github.com/elastic/elasticsearch/issues/10116">#10116</a>で追加されたより詳細なスクリプトの設定で、インラインか、インデックスされたものか、ファイル化を個別に言語ごとに設定できるようになりました。
また、例えば、search APIではスクリプトを許可するが、update APIでは許可しないといったような設定も可能です。</p>

<h2>最後に</h2>

<p>ぜひ、<a href="https://www.elastic.co/downloads/past-releases/elasticsearch-1-6-0">Elasticsearch 1.6.0</a>を試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elastic">@elastic</a>)や<a href="https://discuss.elastic.co/c/elasticsearch">Webフォーラム</a>などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elastic/elasticsearch/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第10回Elasticsearch勉強会を開催しました。#elasticsearchjp]]></title>
    <link href="http://blog.johtani.info/blog/2015/06/02/10th-elasticsearch-jp/"/>
    <updated>2015-06-02T15:06:36+09:00</updated>
    <id>http://blog.johtani.info/blog/2015/06/02/10th-elasticsearch-jp</id>
    <content type="html"><![CDATA[<p><a href="https://elasticsearch.doorkeeper.jp/events/25297">第10回Elsticsearch勉強会</a>を開催しました。
スタッフの皆さん、スピーカーの皆さん、開場提供していただいた<a href="http://recruit-tech.co.jp">リクルートテクノロジーズさん</a>、ありがとうございました！
次回もよろしくお願いします！参加していただき盛り上げていただいた参加者の皆さんもありがとうございました。</p>

<!-- more -->


<p>今回も新規の方が結構いたような気がしました。
最終的に、124人がアプリでチェックインした形になりました。
直前にキャンセル待ちから繰り上がると来れない人がいますよねぇ。
多少キャパシティオーバーするくらいの人数で募集するのがいいのでしょうか。
あと、カードが2枚不明で。。。心あたりある人いないでしょうか？</p>

<p>さて、いつもの通り簡単なメモです。</p>

<h2>Elastic{ON}報告＋有償プラグインの紹介　Elastic Jun Ohtani @johtani</h2>

<p>スライド：<a href="https://speakerdeck.com/johtani/elastic-on-bao-gao-toshang-yong-puraguinfalseshao-jie">elastic{ON}報告と商用プラグインの紹介</a></p>

<p>少し時間が経ってしまいましたが、弊社初のカンファレンス<a href="http://www.elasticon.com">elastic{ON}</a>の紹介をしました。
約1300名の方に参加していただいたカンファレンスで、非常に盛り上がりました。
Microsoft、GitHubなど、いろいろな会社の方が話をしたり、弊社のエンジニアが濃い話をしたりと。
今回は、日本の方はいなかったですが、次回は日本からも参加してもらえると嬉しいです！</p>

<p>あとは、5月に弊社にも日本の営業の人が入社したので、有償プラグインについて簡単ですが説明をしました。
プラグインなどに興味があるかたがいらっしゃいましたら、Twitterなどで連絡いただければと。
もちろん、弊社サイトからの問い合わせでも大丈夫です。</p>

<p><a href="https://www.elastic.co/elasticon">カンファレンスの資料やビデオが弊社サイトで公開</a>されています。
ぜひ一度見ていただければと。</p>

<h2>AWSで実現するelasticsearchの大規模運用 株式会社インティメート・マージャー　松田和樹さん　<a href="https://twitter.com/mats116">@mats116</a></h2>

<p>スライド：<a href="http://www.slideshare.net/im_docs/elasticsearch-48873206">第10回elasticsearch勉強会 公開用資料</a></p>

<p>パブリックDMPのサービスの裏側でElasticsearchを利用しているというお話でした。
AWS Auto Scalingに詳しくないので、勉強しないといけないんですが、
リバランスがどのくらいの頻度で発生するのかはちょっと気になります。</p>

<p>SSDを利用したり、doc valuesを利用したりと、性能を気にしながら利用されている点、負荷試験を行って検証されていたりと、
参考になる話でした。
今回はインフラ側の話に寄っていたので、今度はアプリ側でどんな使い方をしているかといった話を聞いてみたいですね！</p>

<h2>Spark in small or middle scale data processing with Elasticsearch　株式会社ビズリーチ 島本　多可子さん <a href="https://twitter.com/chibochibo03">@chibochibo03</a></h2>

<p>スライド：<a href="http://www.slideshare.net/chibochibo/spark-with-elasticsearch">Spark in small or middle scale data processing with Elasticsearch</a></p>

<p>ScalaとSparkとElasticsearchで検索サービスを作っている話でした。
サービスのアーキテクチャの選別についての説明を順を追って説明していただきました。
失敗と言われていたアーキテクチャを見た時に、「あー、それは。。。」と思っていたら、
思った通りの改善案のアーキテクチャが出てきたので少しホッとしましたw</p>

<p>JSONのクエリが辛いという話がありましたが、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-validate.html">validate API</a>などを利用してもらって、事前にチェックをしてもらうと
少しは改善できるかもなぁと。</p>

<p>Sparkをぼんやりとしかわかってないので、もう一度話を聴きたいなぁと思ったので、
押しかけて話を聴きたいと思います。</p>

<p>話の中で出てきた自作のScalaのElasticsearchクライアントがHTTPのクライアントになった理由が知りたかったです。</p>

<h2>LT</h2>

<h3>Elasticsearchのサジェスト機能を使った話　株式会社アイスタイル　渡邊 紘太朗さん <a href="https://twitter.com/ktaro_w">@ktaro_w</a></h3>

<p>スライド：<a href="http://www.slideshare.net/ktaro_w/elasticsearch-48826694">Elasticsearchのサジェスト機能を使った話</a></p>

<p>ぴったり5分でしたwまだ2年目なのにこんなにうまく話をしていただけるとは。。。</p>

<p>Gatling便利そうですね。サーバが1台しかないので、単一インデックスの方が性能が出るだろうなと。
Elasticsearchは1インデックスに対してデフォルトだと5シャードで、シャード単位でLuceneのインデックスが作成されます。
この話で行くと、18インデックスを作ると、かなりの数のファイルI/Oが発生するので、いろいろなインデックスに検索をすると
キツいだろうなと。</p>

<p>サジェストについての日本語の資料が少ないという事だったので、ブログを書いてもらえると嬉しいですw</p>

<h3>Elasticsearchで作る形態素解析サーバ　株式会社エヌツーエスエム　菅谷信介さん</h3>

<p>スライド：<a href="http://www.slideshare.net/shinsuke/es-analyzeapi201506">Elasticsearchで作る形態素解析サーバ</a></p>

<p>いつも発表ありがとうございます。私以外の最多発表者じゃないかという話でした。
今回はElasticsearchを形態素解析サーバにしてしまおうという話で、ちょっと面白い話でした。
Elasticsearch以外の場所で形態素解析したい場合には手軽に使えるかもしれないですし、Elasticsearchと同じ解析結果を別の場所で欲しい場合にも便利かも。</p>

<p><a href="https://github.com/johtani/elasticsearch-extended-analyze">extended analyze API</a>の紹介までしていただいて。。。</p>

<p>ちなみに、今は、extended analyze プラグインも指定したAttributeの情報だけ返せるようになってたり、
マルチバリューへの対応もしていたりします。
そのうち本家のanalyze APIに機能を取り込む予定です。（早くしないと）</p>

<h3>開発効率UP! Elasticsearch Client Tool 作ってみた　ナレッジワークス株式会社　木戸国彦さん <a href="https://twitter.com/9215">@9215</a></h3>

<p>スライド：<a href="https://speakerdeck.com/kunihikokido/kai-fa-xiao-lu-atupu-elasticsearch-client-tool-zuo-tutemita">開発効率アップ!Elasticsearch Client Tool 作ってみた</a></p>

<p>Hello Elasticsearch!にはお世話になっている人が多いんじゃないかなと。
今回はSublime Textのプラグインのお話でした。（すみません、Sublime Text使ってなくて。。。）
AtomとかIntellijのプラグインもあるとうれしいなー</p>

<h3>変わり種プラグインの作り方　日本IBM　黒澤亮二さん</h3>

<p>スライド：<a href="http://www.slideshare.net/kuron99/elasticsearch-plugin-48848087">変わり種プラグインの作り方</a></p>

<p>Elasticsearchの拡張ポイントの話と、簡単なプラグインの作り方と少しElasticsearch内部の話をしていただきました。
Foundの資料が上がってました。さすが。あそこのブログは面白い話が多いんですよね。
社内で実際に使われてる話とかも聞いてみたい！</p>

<h2>その他、感想などのブログ</h2>

<ul>
<li><a href="http://suzuki.tdiary.net/20150602.html">第10回 Elasticsearch 勉強会へ参加してきた昨日の話</a></li>
<li><a href="http://qiita.com/t-sato/items/45ec24b8df9155d6488f">第10回elasticsearch勉強会 #elasticsearch #elasticsearchjp</a></li>
<li><a href="http://blog.shibayu36.org/entry/2015/06/02/162724">第10回elasticsearch勉強会に行ってきました</a></li>
<li><a href="http://tech.im-dmp.net/archives/3271">elasticsearch勉強会に登壇してきました</a></li>
</ul>


<h2>まとめ</h2>

<p>懇親会で24Fに移動していただくということで、少し手間をかけてしまいました、すみませんでした。
今回も初参加の方がそこそこいたんじゃないかなと。
あとは、AWSサミットがあるために上京してて参加しましたという方もいらっしゃいました。
大きなカンファレンスの期間の前後に行うとこんなメリットもあるんですね、今後の参考にしたいと思います。
次回は7/27を予定しています。CTOのShayが来日予定です！</p>

<p>あと、東京以外の勉強会も検討しつつあります。興味のある方はコメントやTwitterで反応をいただけると嬉しいです。</p>

<p>スピーカーは随時募集中ですので、コメント、メール、ツイートなど、コンタクトしていただければと思います。
よろしくお願いいたします。</p>
]]></content>
  </entry>
  
</feed>
