<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: elasticsearch | @johtaniの日記 2nd]]></title>
  <link href="http://blog.johtani.info/blog/categories/elasticsearch/atom.xml" rel="self"/>
  <link href="http://blog.johtani.info/"/>
  <updated>2015-07-07T15:24:40+09:00</updated>
  <id>http://blog.johtani.info/</id>
  <author>
    <name><![CDATA[johtani]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[さらに進化したFound（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2015/07/06/we-just-made-found-more-awesome-ja/"/>
    <updated>2015-07-06T16:51:41+09:00</updated>
    <id>http://blog.johtani.info/blog/2015/07/06/we-just-made-found-more-awesome-ja</id>
    <content type="html"><![CDATA[<p>4ヶ月前に、<a href="https://www.elastic.co/blog/welcome-found">Found joined our team at Elastic</a>をアナウンスしました。
Foundの素晴らしいチームと一緒に仕事をしていますが、彼らによって、より素晴らしい
hosted Elasticsearchを提供することになりました。</p>

<!-- more -->


<p>私たちがともに密接に働くことにより、本日（2015/7/1）、
<a href="https://www.elastic.co/products/found">新しい2つのFound</a>を提供することになりました。
Found StandardはこれまでのFoundの機能に加え、さらに低価格を提供します。
Found Premiumは、SLAサポートと、ShieldやWatcherを将来Found上で提供します。</p>

<h2>Found Standard</h2>

<p>Foundは素晴らしいです。専用のElasticsearchクラスタ、簡単なスケール、
ビルトインのセキュリティそして、時間単位での課金などを持っています。
私たちは、hosted Elasticsearchを探している方に、
Foundが適したソリューションであると思っていますし、
すべての方に利用できて手頃な価格であるということを確信したいと思っています。</p>

<p>本日（2015/07/01）からFoundの価格をかなり低価格にし、
<strong>月額50ドル以下</strong>でhosted Elasticsearchを簡単に試してもらえるようにしました。</p>

<p>価格を下げることは正しい重要なステップですが、
Foundを利用している全ての人に、より良い経験を持っていただきたいと考えています。
低価格化と一緒に、<strong>free backups</strong>と<strong>built in SSD</strong>もFoundで提供を始めることになります。</p>

<p>Foundの重要な特徴の一つが、高可用性のために、クラスタをいくつのデータセンターに持つかを
選択できることです。
データは重要です。これが正しい選択でユーザの助けになると考えています。
これにより、私たちの価格は、<strong>複数のデータセンターにより安価に</strong>配置することができます。</p>

<p>また、KibanaもElasticsearchのデータを可視化する素晴らしい方法だと考えています。
Kibana 4が最新バージョンですが、
これは、サーバサイドコンポーネントを持っています。
これは、サービスとしてこれを提供するために、追加の料金がかかることを意味します。
Foundチームが築いた素晴らしい基盤とKibanaチームの努力により、
hosted Elasticsearchクラスタで<strong>無料のKibana 4</strong>を7月15日より提供することになりました。</p>

<h2>Found Premium</h2>

<p>また、私たちは、オープンソースプロダクトに関してサブスクリプションを提供していますが、
Found Standardに対しても提供することになりました。
これが、Found Premiumです。</p>

<p>フォーラムベースのサポートよりもSLAベースのサポートを望んでいる場合、
プロダクトを開発しているチームからのサポートを受けることができるオプションを
提供し始めました。
クリティカルなイベントを持っていたり、私たちのプロダクトに関する
問題を予測するためのベストなヘルプやガイダンス、アドバイスを探しているような場合にサポートします。</p>

<p>さらに近い将来、サブスクリプションの一部として、<a href="https://www.elastic.co/products/shield">Shield</a>（Elasticasearchのセキュリティプラグイン）や<a href="https://www.elastic.co/products/watcher">Watcher</a>（アラーティングプラグイン）が利用できるようになります。</p>

<p>私たちのチームがともに働き、多くのことを可能にし、すばらしい仕事をユーザに提供したかを
将来も楽しみです。
私は非常に誇りに思っていますし、気に入っていただけたらと思っています。
ぜひ、<a href="https://www.elastic.co/webinars/getting-started-with-found">7/15のWebnarに参加して</a>くわしい話を聞いていただき、疑問を解消してください。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 2.0.0.beta1リリース間近（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2015/06/30/elasticsearch-2-dot-0-0-dot-beta1-coming-soon-ja/"/>
    <updated>2015-06-30T14:11:14+09:00</updated>
    <id>http://blog.johtani.info/blog/2015/06/30/elasticsearch-2-dot-0-0-dot-beta1-coming-soon-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="https://www.elastic.co/blog/elasticsearch-2.0.0.beta1-coming-soon">Elasticsearch 2.0.0.beta1 coming soon!</a></p>

<p>Elasticsearch 2.0.0.beta1のリリースの準備をしています。
これは、Lucene 5.2.1に含まれる多くの改善が利用できるようになります。
このリリースに関するいくつかの機能は次のようなものです。</p>

<!-- more -->


<h4>Pipeline Aggregations</h4>

<p>デリバティブやmoving average、他のAggregationsの結果に対する
series arithmeticのようなaggregationが利用可能になります。
この機能は、これまでは、クライアントサイドで実行する必要がありました。
しかし、この計算をより強力な解析クエリを構築してElasticsearchで
実行することができるようになります。
クライアントのコードをより簡潔にすることができます。
これにより、予測解析や異常検知のようなことができるようになります。</p>

<h4>Query/Filter merging</h4>

<p>Filterはなくなります。全てのフィルタは、クエリになります。
クエリコンテキストで利用されると、効率的に関連度スコアを計算し、
フィルタコンテキストで利用されると、単に、
マッチしていないドキュメントを除外する（今のフィルタのようなもの）だけです
この変更は、クエリ実行が自動的に、より効率的な順番で実行されるように
最適化されることを意味します。
例えば、フレーズやgeoクエリのような遅いクエリは
まず、近似フェーズを実行し、それから、より遅い実際のフェーズが
結果に対して行われます。
フィルタコンテキストにおいて、頻繁に利用される条件は自動的にキャッシュされます。</p>

<h4>Configurable store compression</h4>

<p><code>index.codec</code>設定により、高速化のためのLZ4圧縮（<code>default</code>）か
インデックスサイズを小さくするためのDEFLATE（<code>best_compression</code>）を
選択できます。これは、ロギングでとくに役に立ちます。
これにより、古いインデックスオプティマイズする前に<code>best_compression</code>に
変更できます。</p>

<p>これらに関するブログ記事がすぐに公開されるでしょう。</p>

<h3>Performance and resilience</h3>

<p>以降では、新しいメジャーリリースに関して簡単に紹介します。
2.0の変更の多くは内部の機能に関するものであり、
直接ユーザに関連するわけではないからです。</p>

<p>新しいメジャーバージョンのテーマは、パフォーマンス、安定性、
堅牢性、予測可能性、そして使い勝手の良さです。</p>

<ul>
<li>物事が予測した通りに動作する</li>
<li>何か問題があった場合に、Elasticsearchから役立つフィードバックがある</li>
<li>ローレベルの設定を扱う必要はなく、Elasticsearchが良い設定を決定する</li>
<li>これらに加え、データがより安全に</li>
</ul>


<p>これらの目標は完全ではありません。
まだ、多くの改善があります。しかし、2.xブランチで、
すでに500コミットを超える大きな改善が実施されています。</p>

<ul>
<li>on-diskの doc valuesをデフォルトで利用（これまではfielddata）。
ヒープ使用量を減らして、スケーラビリティを向上</li>
<li>セグメントマージ処理中のメモリ使用量の削減</li>
<li>normsの圧縮率の改善。ヒープスペースを利用している大きな処理のひとつだったため。</li>
<li>全てのリクエストの後に、transaction logをfsyncすることで、デフォルトで耐久性を向上</li>
<li>全てのファイル変更をアトミックに（部分的なファイルの書き出しはなし）</li>
<li>マージを自動で制限</li>
<li>フレーズクエリやスパンクエリを高速化</li>
<li>フィルタキャッシュをより効率化するための圧縮されたビットセット</li>
<li>クラスタ状態の差分更新</li>
<li>構造化されたJSON形式の例外</li>
<li>よりきめ細かいLuceneのメモリレポート</li>
<li>デフォルトではlocalhostにのみバインド。開発のノードが他のクラスタにジョインするのを防ぐ</li>
<li>parent/childのクエリ実行最適化のためにリライト</li>
<li>Java Security Managerで必要最小限なパーミッションで実行</li>
<li>全てのコアなプラグインをelasticsearchリポジトリに移行し、Elasticsearchのバージョンに同期してリリースされる予定</li>
</ul>


<h2>アップグレード前に</h2>

<p>メジャーバージョンのアップグレードは問題のあるものを一掃する機会を与えてくれます。
できる限り、これらの変更をアップグレードするために、簡単な方法を提供しようとしています。
しかし、Elasticsearch 2.0にアップグレードする前に、必要な処理が2つあります。</p>

<p>1つ目は、フィールドとタイプマッピングに関することです。
mapping APIは、現在、それほど厳密ではありません。
内蔵された保護機構を提供する代わりに、ユーザがベストプラクティスを知っていると信頼していました。
2.0では、mappingはより厳密で安全ですが、いくつかの変更では、後方互換性を保っていません。
詳細については<a href="https://www.elastic.co/blog/great-mapping-refactoring">The Great Mapping Recatoring</a>をごらんください。</p>

<p>2つ目はElasticsearch 0.20以前のユーザに関する変更です。
これは、Lucene 3.xを使っています。
Elasticsearch 2.xはLucene 5をベースにしています。
Lucene 5はLucene 4.xによって作成されたインデックスの読み込みはサポートしていますが、
Lucene 3.xに関してはサポートしていません。</p>

<p>Elasticsearch 0.20以前のバージョンによって生成されたインデックスを持っている場合、
Elasticsearch 2.xのクラスタをスタートすることはできません。
これらの古いインデックスを削除するか、Elaticsearch 1.6.0以上に含まれている
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-upgrade.html">upgrade API</a>を使用してアップグレードする必要があります。</p>

<p>upgrade APIの実行は2つのジョブを実行します。</p>

<ul>
<li>古いLuceneフォーマットのセグメントを最新のフォーマットで書き換えます</li>
<li>Elasticsearch 2.xによって読み込めるようという印をインデックスに追加します</li>
</ul>


<p>全てのセグメントを最新バージョンにアップグレードするのも良い案ですが、
アップグレード前に必要な処理を最小限に抑えることも可能です。
（Lucene 3.xのセグメントだけをアップグレード）
その場合は、<code>only_ancient_segments</code>パラメータを指定します。</p>

<h2>Elasticsearch Migration Plugin</h2>

<p>Elasticsearch 2.0 に移行する前に、インデックスがアップグレードが必要なのか、
ほかになにかするべきことがあるのかをチェックする助けになる
Elasticsearch Migration Pluginをリリースしました。</p>

<p>まず、プラグインをインストールします</p>

<pre><code>./bin/plugin -i elastic/elasticsearch-migration
</code></pre>

<p>プラグインのインストール後はノードのリスタートは必要ありません。</p>

<p>以下のリンクをブラウザで開きます。</p>

<p><a href="http://localhost:9200/_plugin/migration">http://localhost:9200/_plugin/migration</a></p>

<p>（<code>localhost:9200</code>はインストールしたホスト名に変更してください。）</p>

<p>Migration pluginに関してバグやご意見がある場合は、<a href="http://github.com/elastic/elasticsearch-migration/issues">GitHubのIssue</a>にお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 1.6.0リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2015/06/10/elasticsearch-1-6-0-released-ja/"/>
    <updated>2015-06-10T13:31:02+09:00</updated>
    <id>http://blog.johtani.info/blog/2015/06/10/elasticsearch-1-6-0-released-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="https://www.elastic.co/blog/elasticsearch-1-6-0-released">Elasticsearch 1.6.0 released</a></p>

<p>本日（6/9）、<strong>Lucene 4.10.4</strong>ベースの<strong>Elasticsearch 1.6.0</strong>をリリースしました。
このリリースはElasticsearchの最新の安定バージョンとなります。
また、素晴らしい新機能がいくつか追加されています。</p>

<!-- more -->


<ul>
<li>synced flushによるリスタートの高速化</li>
<li>シャード配置は保留中のタスクをブロックしない</li>
<li>レスポンスボディのJSONのフィルタリング</li>
<li>共有ファイルシステムリポジトリに対するセキュリティフィックス</li>
<li>古いインデックスのためのUpgrade API</li>
<li>Kibanaユーザのためのハイライトの強化</li>
<li>Windowsユーザのための<code>mlockall</code></li>
<li>より詳細なスクリプト設定</li>
</ul>


<p><a href="https://www.elastic.co/downloads/past-releases/elasticsearch-1-6-0">すべての変更リストとダウンロード</a>はこちらをごらんください。</p>

<h2>synced flushによるリスタートの高速化</h2>

<p>1.6.0より前のバージョンでは、メンテナンスやローリングアップグレード時の
ノードの再起動で、必要であるかどうかに関わらず、多くの場合、
ノードのすべてのシャードのすべてのデータを再度コピーする必要がありました。
この新しいsynced flush機能により、
sync-flushされたインデックスに対して、既存のデータを再利用し、
より早くクラスタを正常な状態にすることができるようにします。</p>

<p>ここで、この変更以前にどのように動いていたかを説明します。
すでにあるレプリカシャードは、ノードがリスタートした後に、
プライマリから復元するときに、
最初のステップはプライマリにあるセグメントとレプリカにあるセグメントを
比較することです。そして、セグメントに違いがあった場合にコピーされます。
問題は、セグメントプライマリのセグメントのマージと
レプリカのセグメントのマージが別々に起こっており、
各シャードのセグメントが完全に異なるが、
それらが同じデータを持っているという点です。</p>

<p>新しいsynced-flush機能では、<code>sync_id</code>がプライマリと
レプリカシャードに、シャードのコンテンツが同一であるという判別するために、
書き込まれます。これは、リカバリがセグメントの比較のステップを
スキップできることを意味します。
リカバリのスピードを高速にします。</p>

<p>synced flushはアイドル状態のインデックスで自動的に実行されます。
直前の5分間でデータが登録、更新削除されていないインデックスに対してです。
これは、ロギングのユースケースで特に役に立ちます。
機能のインデックスはインデキシングがストップしたあとの5分で自動的に
syncされるでしょう。</p>

<p>ノードのリスタートやクラスタのリスタートが必要で、
自動的に発生するsyncを待てない場合は次のようなことが可能です。</p>

<ul>
<li>インデキシングを停止（実行中のリクエストが停止するのも待つ）</li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-cluster.html">シャードのアロケーションを停止</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-synced-flush.html">synced-flush</a>リクエストの発行</li>
<li>ノードのリスタート</li>
<li>シャードのアロケーションの再開</li>
<li>クラスタの状態がグリーンになるまで待つ</li>
<li>インデキシングの再開</li>
</ul>


<p><strong>NOTE:</strong> &ldquo;シャードのアロケーションを停止&#8221;のステップが必要です。
これがない場合、Elasticsearchはノードの再起動が始まると、
異なるノードにシャードの再配置を始めます。
これは、新しいノードにシャードデータの全てをコピーする必要があります。</p>

<p>ドキュメントのインデキシング、更新、削除のあとに最初のフラッシュが
発生したときに、
シャードの<code>sync_id</code>が自動的に無効化されます。
詳細については<a href="https://github.com/elastic/elasticsearch/issues/11336">#11336</a>と<a href="https://github.com/elastic/elasticsearch/issues/11179">#11179</a>をごらんください。</p>

<h2>シャード配置は保留中のタスクをブロックしない</h2>

<p>多数のノードやインデックスを持っているユーザは
クラスタ全体のリスタートのあとのシャードのリカバリで、
長い間、リカバリが止まって見えることに気づいたかもしれません。
これらのリカバリが止まって見える間は、クラスタ設定の更新のような軽微なアクションでさえ、
例外が発生したり、その設定が反映されるまでに長時間かかるといったことが起きていました。
この問題の兆候は保留中のタスクのキューが大きくなることです。</p>

<p>これらの遅延の原因はシャードの配置のプロセスにあります。
配置されるべきシャードのコピーを
持っているのがどのノードかを全てのデータノードに聞きます。
多くのシャードや遅いディスクを持ったデータノードは
反応するのに時間がかかります。
特に、シャードのリカバリがすでにI/Oを利用しているような時です。
このバージョン以前のものは、シャード情報のためのリクエストを
同期的に処理していました。
クラスタ状態の更新はアロケーションプロセスを続けるために
必要な情報を待っている間、ブロックされます。</p>

<p> <a href="https://github.com/elastic/elasticsearch/issues/11262">#11262</a>での変更は
この情報のためのリクエストを非同期にします。
クラスタ状態の更新はこのタスクによってブロックされません。
これは、保留中のタスクがより早く処理でき、
クラスタが変更に対してより早く反応できます。
処理中のshard infoリクエストの数は
<code>number_of_in_flight_fetch</code>キーとしてcluster-health APIで取得できます。</p>

<p>さらに、シャードがある理由で復旧に失敗すると、
クラスタは、シャードのリカバリが成功するまで、同じノードに対して
シャードをアロケーションしないようにします。</p>

<h2>レスポンスボディのJSONのフィルタリング</h2>

<p>Elasticsearchは全ての情報を返します。
例えば、検索リクエストは<code>_index</code>、<code>_type</code>、<code>_id</code>、
<code>_score</code>、<code>_source</code>を返します。
しかし、全ての情報が必要でない場合があります。
また、これらのデータを遅いネットワークで転送することは
遅延の原因となります。</p>

<p>ユーザはこの検索メタデータを無効にするための特殊な設定を
行ったり、他のAPIのレスポンスのフォーマットを
コントロールするための設定があります。
<a href="https://github.com/elastic/elasticsearch/issues/10980">#10980</a>の変更で、任意のレスポンスボディのJSONに対して、
必要な要素だけを取得する機能が追加されました。
<code>filter_path</code>パラメータを使用します。</p>

<p>例えば、検索リクエストからは<code>total</code>数と、各要素の<code>hits</code>の配列を欲しい場合、
次のように指定します。</p>

<pre><code>GET _search?filter_path=hits.total,hits.hits
</code></pre>

<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-info.html">nodes-info API</a>から各ノードの<code>http_address</code>だけを取得したい場合は、
ノード名の部分にワイルドカード(<code>*</code>)を使用します。</p>

<pre><code>GET _nodes?filter_path=nodes.*.http_address
</code></pre>

<p>単一の<code>*</code>がJSON階層の1つの階層に対しての
ワイルドカードとして機能します。
2つの<code>**</code>は複数階層に対してとなります。
複数のフィルタはカンマ区切りで指定可能です。
詳細について<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/common-options.html#_response_filtering">Response filtering</a>をごらんください。</p>

<h2>共有ファイルシステムリポジトリに対するセキュリティフィックス</h2>

<p>本リリースはsnapshot-restoreで使われる
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html#_shared_file_system_repository">共有ファイルシステムリポジトリ</a>に関するセキュリティ強化の変更が含まれます。
現在、Elasticsearchのユーザは、Elasticsearchプロセスによって書き込み可能
任意のディレクトリに<code>.snapshot</code>ファイルを書き込むことができます。
<a href="https://github.com/elastic/elasticsearch/issues/11284">#11284</a>の変更で、リポジトリのために使用できるディレクトリを
強制的に指定できるようになりました。
適切なディレクトリが<code>config/elasticsearch.yml</code>設定ファイルの
<code>path.repo</code>に指定される必要があります。</p>

<p>次のように設定されたElasticsearchインスタンスはこのセキュリティ問題に対して影響を受けにくいです。</p>

<ul>
<li><code>root</code>ではなく<code>elasticsearch</code>ユーザとしてElasticsearchを実行</li>
<li><code>elasticsearch</code>ユーザが<code>data</code>ディレクトリに対してのみ
書き込み権限を持っていて、共有ファイルシステムリポジトリに対しても利用できる</li>
<li>ファイアウォールやプロキシ、Shieldを使って、snapshot APIの実行を任意のユーザから実行されるのを防いでいる</li>
</ul>


<p>この問題を<a href="https://www.elastic.co/community/security">CVE-2015-4165</a>としています。</p>

<h2>古いインデックスのためのUpgrade API</h2>

<p>Elasticsearch 2.0以降では、
Lucene 5ベースとなり、Lucene 3
（Elasticsearchのバージョンでは0.90以前）
によって書き出されたセグメントを含んだインデックスを読み込むことが
できなくなります。
これらの「古いインデックス」はLucene 4にアップグレードする必要があり、
2.0-compatibleとして印をつける必要があります。
そうしなければ、Elasticsearch 2.0に以降できないでしょう。</p>

<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-upgrade.html">upgrade API</a>は
、最新のLuceneフォーマットにインデックスにある全てのセグメントを
アップグレードするためにすでに利用できます。
また、最新のフォーマットは性能向上やバグフィックスといった利点もあります。
さらに、2.0-compatibleとして古いインデックスをマークする設定も
書き込むことができます。
さらに、<code>upgrade_only_ancient_segments</code>オプションが
Lucene 3のセグメントだけをアップグレードするために利用でき、
移行前の必要な処理を減らすことができます。</p>

<h2>Kibanaユーザのためのハイライトの強化</h2>

<p>KibanaユーザはElasticsearchのハイライトについて2つの点で問題を見つけていました。</p>

<ul>
<li>ワイルドカードでフィールド名を指定した場合に、ハイライトに適さないフィールドも帰ってくる（日付や数値のフィールドなど）</li>
<li>古いインデックスが非常に大きなターム（> 32kB）を含んでいて、ハイライトが失敗する。
最近のバージョンでは、これらの大きなタームはインデックス時に除去される</li>
</ul>


<p><a href="https://github.com/elastic/elasticsearch/issues/11364">#11364</a>の変更で
これらの問題が修正されました。
ワイルドカードを利用したフィールド名では、stringフィールドのみを返し、非常に長いタームによる例外は無視するようになります。</p>

<h2>Windowsユーザのための<code>mlockall</code></h2>

<p>速いGCはノードの安定性と性能について重要です。
小さなバイトのヒープでさえ、ディスクにスワップすることを許可してしまうと、GCに対して大きな影響が出てしまいます。
ですので、これらのコストは排除されるべきです。</p>

<p>Linuxユーザは<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration.html#setup-configuration-memory"><code>bootstrap.mloclall</code>設定</a>による恩恵を受けています。
これは、RAMにJVMのヒープを起動時にロックします。
<a href="https://github.com/elastic/elasticsearch/issues/10887">#10887</a>では、同様の機能をWindowsユーザにも提供します。</p>

<h2>より詳細なスクリプト設定</h2>

<p>Scriptsはリクエストにインラインで指定できます。
<code>.scripts</code>インデックスにインデックスもでき、<code>config/</code>ディレクトリ配下にファイルとして保存もできます。
これまでは、インラインかインデックスされたスクリプトの両方を同時に有効無効にすることが選択できましたが、
<code>.scripts</code>インデックスをプロキシやShieldで保護することもできました。</p>

<p><a href="https://github.com/elastic/elasticsearch/issues/10116">#10116</a>で追加されたより詳細なスクリプトの設定で、インラインか、インデックスされたものか、ファイル化を個別に言語ごとに設定できるようになりました。
また、例えば、search APIではスクリプトを許可するが、update APIでは許可しないといったような設定も可能です。</p>

<h2>最後に</h2>

<p>ぜひ、<a href="https://www.elastic.co/downloads/past-releases/elasticsearch-1-6-0">Elasticsearch 1.6.0</a>を試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elastic">@elastic</a>)や<a href="https://discuss.elastic.co/c/elasticsearch">Webフォーラム</a>などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elastic/elasticsearch/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第10回Elasticsearch勉強会を開催しました。#elasticsearchjp]]></title>
    <link href="http://blog.johtani.info/blog/2015/06/02/10th-elasticsearch-jp/"/>
    <updated>2015-06-02T15:06:36+09:00</updated>
    <id>http://blog.johtani.info/blog/2015/06/02/10th-elasticsearch-jp</id>
    <content type="html"><![CDATA[<p><a href="https://elasticsearch.doorkeeper.jp/events/25297">第10回Elsticsearch勉強会</a>を開催しました。
スタッフの皆さん、スピーカーの皆さん、開場提供していただいた<a href="http://recruit-tech.co.jp">リクルートテクノロジーズさん</a>、ありがとうございました！
次回もよろしくお願いします！参加していただき盛り上げていただいた参加者の皆さんもありがとうございました。</p>

<!-- more -->


<p>今回も新規の方が結構いたような気がしました。
最終的に、124人がアプリでチェックインした形になりました。
直前にキャンセル待ちから繰り上がると来れない人がいますよねぇ。
多少キャパシティオーバーするくらいの人数で募集するのがいいのでしょうか。
あと、カードが2枚不明で。。。心あたりある人いないでしょうか？</p>

<p>さて、いつもの通り簡単なメモです。</p>

<h2>Elastic{ON}報告＋有償プラグインの紹介　Elastic Jun Ohtani @johtani</h2>

<p>スライド：<a href="https://speakerdeck.com/johtani/elastic-on-bao-gao-toshang-yong-puraguinfalseshao-jie">elastic{ON}報告と商用プラグインの紹介</a></p>

<p>少し時間が経ってしまいましたが、弊社初のカンファレンス<a href="http://www.elasticon.com">elastic{ON}</a>の紹介をしました。
約1300名の方に参加していただいたカンファレンスで、非常に盛り上がりました。
Microsoft、GitHubなど、いろいろな会社の方が話をしたり、弊社のエンジニアが濃い話をしたりと。
今回は、日本の方はいなかったですが、次回は日本からも参加してもらえると嬉しいです！</p>

<p>あとは、5月に弊社にも日本の営業の人が入社したので、有償プラグインについて簡単ですが説明をしました。
プラグインなどに興味があるかたがいらっしゃいましたら、Twitterなどで連絡いただければと。
もちろん、弊社サイトからの問い合わせでも大丈夫です。</p>

<p><a href="https://www.elastic.co/elasticon">カンファレンスの資料やビデオが弊社サイトで公開</a>されています。
ぜひ一度見ていただければと。</p>

<h2>AWSで実現するelasticsearchの大規模運用 株式会社インティメート・マージャー　松田和樹さん　<a href="https://twitter.com/mats116">@mats116</a></h2>

<p>スライド：<a href="http://www.slideshare.net/im_docs/elasticsearch-48873206">第10回elasticsearch勉強会 公開用資料</a></p>

<p>パブリックDMPのサービスの裏側でElasticsearchを利用しているというお話でした。
AWS Auto Scalingに詳しくないので、勉強しないといけないんですが、
リバランスがどのくらいの頻度で発生するのかはちょっと気になります。</p>

<p>SSDを利用したり、doc valuesを利用したりと、性能を気にしながら利用されている点、負荷試験を行って検証されていたりと、
参考になる話でした。
今回はインフラ側の話に寄っていたので、今度はアプリ側でどんな使い方をしているかといった話を聞いてみたいですね！</p>

<h2>Spark in small or middle scale data processing with Elasticsearch　株式会社ビズリーチ 島本　多可子さん <a href="https://twitter.com/chibochibo03">@chibochibo03</a></h2>

<p>スライド：<a href="http://www.slideshare.net/chibochibo/spark-with-elasticsearch">Spark in small or middle scale data processing with Elasticsearch</a></p>

<p>ScalaとSparkとElasticsearchで検索サービスを作っている話でした。
サービスのアーキテクチャの選別についての説明を順を追って説明していただきました。
失敗と言われていたアーキテクチャを見た時に、「あー、それは。。。」と思っていたら、
思った通りの改善案のアーキテクチャが出てきたので少しホッとしましたw</p>

<p>JSONのクエリが辛いという話がありましたが、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-validate.html">validate API</a>などを利用してもらって、事前にチェックをしてもらうと
少しは改善できるかもなぁと。</p>

<p>Sparkをぼんやりとしかわかってないので、もう一度話を聴きたいなぁと思ったので、
押しかけて話を聴きたいと思います。</p>

<p>話の中で出てきた自作のScalaのElasticsearchクライアントがHTTPのクライアントになった理由が知りたかったです。</p>

<h2>LT</h2>

<h3>Elasticsearchのサジェスト機能を使った話　株式会社アイスタイル　渡邊 紘太朗さん <a href="https://twitter.com/ktaro_w">@ktaro_w</a></h3>

<p>スライド：<a href="http://www.slideshare.net/ktaro_w/elasticsearch-48826694">Elasticsearchのサジェスト機能を使った話</a></p>

<p>ぴったり5分でしたwまだ2年目なのにこんなにうまく話をしていただけるとは。。。</p>

<p>Gatling便利そうですね。サーバが1台しかないので、単一インデックスの方が性能が出るだろうなと。
Elasticsearchは1インデックスに対してデフォルトだと5シャードで、シャード単位でLuceneのインデックスが作成されます。
この話で行くと、18インデックスを作ると、かなりの数のファイルI/Oが発生するので、いろいろなインデックスに検索をすると
キツいだろうなと。</p>

<p>サジェストについての日本語の資料が少ないという事だったので、ブログを書いてもらえると嬉しいですw</p>

<h3>Elasticsearchで作る形態素解析サーバ　株式会社エヌツーエスエム　菅谷信介さん</h3>

<p>スライド：<a href="http://www.slideshare.net/shinsuke/es-analyzeapi201506">Elasticsearchで作る形態素解析サーバ</a></p>

<p>いつも発表ありがとうございます。私以外の最多発表者じゃないかという話でした。
今回はElasticsearchを形態素解析サーバにしてしまおうという話で、ちょっと面白い話でした。
Elasticsearch以外の場所で形態素解析したい場合には手軽に使えるかもしれないですし、Elasticsearchと同じ解析結果を別の場所で欲しい場合にも便利かも。</p>

<p><a href="https://github.com/johtani/elasticsearch-extended-analyze">extended analyze API</a>の紹介までしていただいて。。。</p>

<p>ちなみに、今は、extended analyze プラグインも指定したAttributeの情報だけ返せるようになってたり、
マルチバリューへの対応もしていたりします。
そのうち本家のanalyze APIに機能を取り込む予定です。（早くしないと）</p>

<h3>開発効率UP! Elasticsearch Client Tool 作ってみた　ナレッジワークス株式会社　木戸国彦さん <a href="https://twitter.com/9215">@9215</a></h3>

<p>スライド：<a href="https://speakerdeck.com/kunihikokido/kai-fa-xiao-lu-atupu-elasticsearch-client-tool-zuo-tutemita">開発効率アップ!Elasticsearch Client Tool 作ってみた</a></p>

<p>Hello Elasticsearch!にはお世話になっている人が多いんじゃないかなと。
今回はSublime Textのプラグインのお話でした。（すみません、Sublime Text使ってなくて。。。）
AtomとかIntellijのプラグインもあるとうれしいなー</p>

<h3>変わり種プラグインの作り方　日本IBM　黒澤亮二さん</h3>

<p>スライド：<a href="http://www.slideshare.net/kuron99/elasticsearch-plugin-48848087">変わり種プラグインの作り方</a></p>

<p>Elasticsearchの拡張ポイントの話と、簡単なプラグインの作り方と少しElasticsearch内部の話をしていただきました。
Foundの資料が上がってました。さすが。あそこのブログは面白い話が多いんですよね。
社内で実際に使われてる話とかも聞いてみたい！</p>

<h2>その他、感想などのブログ</h2>

<ul>
<li><a href="http://suzuki.tdiary.net/20150602.html">第10回 Elasticsearch 勉強会へ参加してきた昨日の話</a></li>
<li><a href="http://qiita.com/t-sato/items/45ec24b8df9155d6488f">第10回elasticsearch勉強会 #elasticsearch #elasticsearchjp</a></li>
<li><a href="http://blog.shibayu36.org/entry/2015/06/02/162724">第10回elasticsearch勉強会に行ってきました</a></li>
<li><a href="http://tech.im-dmp.net/archives/3271">elasticsearch勉強会に登壇してきました</a></li>
</ul>


<h2>まとめ</h2>

<p>懇親会で24Fに移動していただくということで、少し手間をかけてしまいました、すみませんでした。
今回も初参加の方がそこそこいたんじゃないかなと。
あとは、AWSサミットがあるために上京してて参加しましたという方もいらっしゃいました。
大きなカンファレンスの期間の前後に行うとこんなメリットもあるんですね、今後の参考にしたいと思います。
次回は7/27を予定しています。CTOのShayが来日予定です！</p>

<p>あと、東京以外の勉強会も検討しつつあります。興味のある方はコメントやTwitterで反応をいただけると嬉しいです。</p>

<p>スピーカーは随時募集中ですので、コメント、メール、ツイートなど、コンタクトしていただければと思います。
よろしくお願いいたします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logstashを使ったElasticsearchの再インデックス（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2015/05/26/reindex-elasticsearch-with-logstash-ja/"/>
    <updated>2015-05-26T16:08:10+09:00</updated>
    <id>http://blog.johtani.info/blog/2015/05/26/reindex-elasticsearch-with-logstash-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://david.pilato.fr/blog/2015/05/20/reindex-elasticsearch-with-logstash/">Reindex Elasticsearch With Logstash</a></p>

<p>Thanks David!</p>

<!-- more -->


<p>マッピングを変更したり、インデックスの設定を変更したり、あるサーバから他のサーバや、
あるクラスタから他のクラスタ（例えば複数のデータセンターのような場合）にデータを再インデックスしたくなることがあるでしょう。</p>

<p>後者のような場合は<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html">SnapshotやRestoreの機能</a>を利用することもできますが、インデックスの設定を変更をしたい場合は
その他の方法が必要になります。</p>

<p><a href="https://www.elastic.co/blog/logstash-1-5-0-ga-released">Logstash 1.5.0</a>で、
<a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-elasticsearch.html">elasticsearch input</a>と<a href="https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html">elasticsearch output</a>を使うことで、とても簡単に再インデックスができます。</p>

<p>ではやってみましょう。</p>

<h2>古いクラスタ</h2>

<p>elasticsearch 1.5.2 はすでにダウンロード済みとして、<code>localhost:9200</code>で<code>old</code>という名前のクラスタを起動します。</p>

<pre><code class="bash">bin/elasticsearch --cluster.name=old
</code></pre>

<p>クラスタに<code>person</code>という名前のインデックスが存在します。
これは、5シャードで、100万件のドキュメントを持っています。</p>

<p><img class="<a" src="href="http://david.pilato.fr/blog/images/reindex-es01/sense01.png">http://david.pilato.fr/blog/images/reindex-es01/sense01.png</a>&#8221;></p>

<h2>新しいクラスタ</h2>

<p>次に新しいクラスタを起動します。
<code>localhost:9201</code>で<code>new</code>という名前のクラスタを起動します。</p>

<pre><code class="bash">bin/elasticsearch --cluster.name=new
</code></pre>

<p>こちらは、空です。</p>

<pre><code class="bash">curl -XGET "http://localhost:9201/person"
</code></pre>

<pre><code class="json">{
   "error": "IndexMissingException[[person] missing]",
   "status": 404
}
</code></pre>

<h2>Logstashのインストール</h2>

<p>次に、Logstash 1.5.0をダウンロードして、インストールします。</p>

<pre><code class="bash">wget http://download.elastic.co/logstash/logstash/logstash-1.5.0.tar.gz
tar xzf logstash-1.5.0.tar.gz
cd logstash-1.5.0
</code></pre>

<p>logstashの設定ファイル<code>logstash.conf</code>を次のように設定します。</p>

<pre><code>input {
  # We read from the "old" cluster
  elasticsearch {
    hosts =&gt; [ "localhost" ]
    port =&gt; "9200"
    index =&gt; "person"
    size =&gt; 500
    scroll =&gt; "5m"
    docinfo =&gt; true
  }
}

output {
  # We write to the "new" cluster
  elasticsearch {
    host =&gt; "localhost"
    port =&gt; "9201"
    protocol =&gt; "http"
    index =&gt; "%{[@metadata][_index]}"
    index_type =&gt; "%{[@metadata][_type]}"
    document_id =&gt; "%{[@metadata][_id]}"
  }
  # We print dots to see it in action
  stdout {
    codec =&gt; "dots"
  }
}
</code></pre>

<h2>実行と修正</h2>

<p>実行します。</p>

<pre><code class="bash">bin/logstash -f logstash.conf
</code></pre>

<h3>ドキュメントのチェックと修正</h3>

<p>何が起きたでしょう？</p>

<pre><code class="bash">curl -XGET "http://localhost:9200/person/person/AU1wqyQWZJKU8OibfxgH"
</code></pre>

<pre><code class="json">{
   "_index": "person",
   "_type": "person",
   "_id": "AU1wqyQWZJKU8OibfxgH",
   "_version": 1,
   "found": true,
   "_source": {
      "name": "Tali Elyne",
      "dateOfBirth": "1955-05-03",
      "gender": "female",
      "children": 2,
      "marketing": {
         "cars": null,
         "shoes": null,
         "toys": null,
         "fashion": null,
         "music": null,
         "garden": null,
         "electronic": null,
         "hifi": null,
         "food": 846
      },
      "address": {
         "country": "Germany",
         "zipcode": "0099",
         "city": "Bonn",
         "countrycode": "DE",
         "location": [
            7.075943707068682,
            50.72883500730124
         ]
      }
   }
}
</code></pre>

<p>もう一方のクラスタと比較してみましょう。</p>

<pre><code class="bash">curl -XGET "http://localhost:9201/person/person/AU1wqyQWZJKU8OibfxgH"
</code></pre>

<pre><code class="json">{
   "_index": "person",
   "_type": "person",
   "_id": "AU1wqyQWZJKU8OibfxgH",
   "_version": 1,
   "found": true,
   "_source": {
      "name": "Tali Elyne",
      "dateOfBirth": "1955-05-03",
      "gender": "female",
      "children": 2,
      "marketing": {
         "cars": null,
         "shoes": null,
         "toys": null,
         "fashion": null,
         "music": null,
         "garden": null,
         "electronic": null,
         "hifi": null,
         "food": 846
      },
      "address": {
         "country": "Germany",
         "zipcode": "0099",
         "city": "Bonn",
         "countrycode": "DE",
         "location": [
            7.075943707068682,
            50.72883500730124
         ]
      },
      "@version": "1",
      "@timestamp": "2015-05-20T09:53:44.089Z"
   }
}
</code></pre>

<p>Logstashは<code>@version</code>と<code>@timestamp</code>フィールドを追加してしました。
これらを除去したいので、<a href="http://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html">Mutate filter plugin</a>の<a href="http://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html#plugins-filters-mutate-remove_field"><code>remove_field</code></a>を使います。</p>

<pre><code>filter {
  mutate {
    remove_field =&gt; [ "@timestamp", "@version" ]
  }
}
</code></pre>

<h3>マッピングのチェックと修正</h3>

<p>実際に、logstashは<code>_source</code>フィールドを既存のドキュメントから読み込み、
それらを新しいクラスタに直接投入しています。
しかし、logstashはマッピングについてはケアしていません。</p>

<p>古いマッピングと新しいマッピングを比較するために、マッピングを取得してみましょう。</p>

<pre><code class="bash">curl -XGET "http://localhost:9200/person/person/_mapping"
</code></pre>

<pre><code class="json">{
   "person": {
      "mappings": {
         "person": {
            "properties": {
               "address": {
                  "properties": {
                     "city": {
                        "type": "string",
                        "index": "not_analyzed"
                     },
                     "country": {
                        "type": "string",
                        "index": "not_analyzed"
                     },
                     "countrycode": {
                        "type": "string",
                        "index": "not_analyzed"
                     },
                     "location": {
                        "type": "geo_point"
                     },
                     "zipcode": {
                        "type": "string"
                     }
                  }
               },
               "children": {
                  "type": "long"
               },
               "dateOfBirth": {
                  "type": "date",
                  "format": "dateOptionalTime"
               },
               "gender": {
                  "type": "string",
                  "index": "not_analyzed"
               },
               "marketing": {
                  "properties": {
                     "cars": {
                        "type": "long"
                     },
                     "electronic": {
                        "type": "long"
                     },
                     "fashion": {
                        "type": "long"
                     },
                     "food": {
                        "type": "long"
                     },
                     "garden": {
                        "type": "long"
                     },
                     "hifi": {
                        "type": "long"
                     },
                     "music": {
                        "type": "long"
                     },
                     "shoes": {
                        "type": "long"
                     },
                     "toys": {
                        "type": "long"
                     }
                  }
               },
               "name": {
                  "type": "string"
               }
            }
         }
      }
   }
}
</code></pre>

<pre><code class="bash">curl -XGET "http://localhost:9201/person/person/_mapping"
</code></pre>

<pre><code class="json">{
   "person": {
      "mappings": {
         "person": {
            "properties": {
               "address": {
                  "properties": {
                     "city": {
                        "type": "string"
                     },
                     "country": {
                        "type": "string"
                     },
                     "countrycode": {
                        "type": "string"
                     },
                     "location": {
                        "type": "double"
                     },
                     "zipcode": {
                        "type": "string"
                     }
                  }
               },
               "children": {
                  "type": "long"
               },
               "dateOfBirth": {
                  "type": "date",
                  "format": "dateOptionalTime"
               },
               "gender": {
                  "type": "string"
               },
               "marketing": {
                  "properties": {
                     "cars": {
                        "type": "long"
                     },
                     "electronic": {
                        "type": "long"
                     },
                     "fashion": {
                        "type": "long"
                     },
                     "food": {
                        "type": "long"
                     },
                     "garden": {
                        "type": "long"
                     },
                     "hifi": {
                        "type": "long"
                     },
                     "music": {
                        "type": "long"
                     },
                     "shoes": {
                        "type": "long"
                     },
                     "toys": {
                        "type": "long"
                     }
                  }
               },
               "name": {
                  "type": "string"
               }
            }
         }
      }
   }
}
</code></pre>

<p>これにより、いくつかの相違を発見できます。</p>

<pre><code class="json"> "location": {
    "type": "geo_point"
 }
</code></pre>

<pre><code class="json"> "location": {
    "type": "double"
 }
</code></pre>

<p>データをインデックスする「前」に、実際に利用したいマッピングでインデックスを作成しておくことで、
この問題に対処できます。
この時点で、オリジナルのマッピングを望んだ形に変更することができます。例えば、アナライザを変更したりです。
また、インデックスの設定を新しく定義することもできます。
デフォルトでは、Elasticsearchは5つのシャードと各シャードに対して1つのレプリカを作成します。
しかし、この時点でもう一度変更することが可能です。</p>

<pre><code class="bash">curl -XDELETE "http://localhost:9201/person"
curl -XPUT "http://localhost:9201/person" -d'
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 0
  }
}'
curl -XPUT "http://localhost:9201/person/person/_mapping" -d'
{
  "person": {
    "properties": {
      "address": {
        "properties": {
          "city": {
            "type": "string",
            "index": "not_analyzed"
          },
          "country": {
            "type": "string",
            "index": "not_analyzed"
          },
          "countrycode": {
            "type": "string",
            "index": "not_analyzed"
          },
          "location": {
            "type": "geo_point"
          },
          "zipcode": {
            "type": "string"
          }
        }
      },
      "children": {
        "type": "long"
      },
      "dateOfBirth": {
        "type": "date",
        "format": "dateOptionalTime"
      },
      "gender": {
        "type": "string",
        "index": "not_analyzed"
      },
      "marketing": {
        "properties": {
          "cars": {
            "type": "long"
          },
          "electronic": {
            "type": "long"
          },
          "fashion": {
            "type": "long"
          },
          "food": {
            "type": "long"
          },
          "garden": {
            "type": "long"
          },
          "hifi": {
            "type": "long"
          },
          "music": {
            "type": "long"
          },
          "shoes": {
            "type": "long"
          },
          "toys": {
            "type": "long"
          }
        }
      },
      "name": {
        "type": "string"
      }
    }
  }
}'
</code></pre>

<p>さて、もう一度再インデックスしましょう！</p>

<pre><code class="bash">bin/logstash -f logstash.conf
</code></pre>

<p><img class="<a" src="href="http://david.pilato.fr/blog/images/reindex-es01/sense02.png">http://david.pilato.fr/blog/images/reindex-es01/sense02.png</a>&#8221;></p>

<h2>インデックスやタイプ名の変更</h2>

<p>もちろん、インデックス名やタイプ名、IDを変更したい場合も変更が可能です！:)</p>

<pre><code class="json">  elasticsearch {
    host =&gt; "localhost"
    port =&gt; "9201"
    protocol =&gt; "http"
    index =&gt; "europe_people"
    index_type =&gt; "someone"
    document_id =&gt; "%{[@metadata][_id]}"
  }
</code></pre>
]]></content>
  </entry>
  
</feed>
