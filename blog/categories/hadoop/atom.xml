<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: hadoop | @johtaniの日記 2nd]]></title>
  <link href="http://blog.johtani.info/blog/categories/hadoop/atom.xml" rel="self"/>
  <link href="http://blog.johtani.info/"/>
  <updated>2016-12-01T22:48:21+09:00</updated>
  <id>http://blog.johtani.info/</id>
  <author>
    <name><![CDATA[johtani]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Cloudera World Tokyo 2013に参加しました！ #cwt2013 ]]></title>
    <link href="http://blog.johtani.info/blog/2013/11/07/cloudera-world-tokyo-2013/"/>
    <updated>2013-11-07T10:11:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2013/11/07/cloudera-world-tokyo-2013</id>
    <content type="html"><![CDATA[<p><a href="http://www.cloudera.co.jp/jpevents/cwt2013/index.html">Cloudera World Tokyo 2013</a>に参加してきました。</p>

<p>午前中はあいにくの雨でしたが、それでも結構な人数が最初の基調講演から参加されてました。
私が参加したセッションは大盛況な感じでした。</p>

<p>おみやげとしてカステラも頂いちゃいました！</p>

<p><img src="/images/entries/20131107/kasutera.jpg" width="300" title="カステラ" ></p>

<p>また、色々なセッションに現れたこんなメッセージ画像も見つけました！</p>

<blockquote class="twitter-tweet"><p>昨日の写真データの整理をしていたら、こんなものが・・・ <a href="https://twitter.com/shiumachi">@shiumachi</a> さんよ・・・ <a href="https://twitter.com/search?q=%23cwt2013&amp;src=hash">#cwt2013</a> <a href="http://t.co/S0JsxSYXIx">pic.twitter.com/S0JsxSYXIx</a></p>&mdash; Kenichiro HAMANO (@hamaken) <a href="https://twitter.com/hamaken/statuses/398613935399510016">November 8, 2013</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>




<!-- more -->


<p>やっぱり、スーツの人が多いなという印象。</p>

<p>名刺を毎回回収されるのはちょっとつらかったです。なにか、いい方法ないですかねぇ。</p>

<p>以下はいつもの個人メモです。</p>

<h2>「ビッグデータプラットフォームとして進化するHadoop」</h2>

<h4>Cloudera株式会社　代表取締役　ジュセッペ小林氏</h4>

<ul>
<li>Costcoなどの写真を元にビッグデータを可視化</li>
</ul>


<h3>BigDataとHadoopの関係</h3>

<p>検索、SQL、機会学習、数理処理、データ管理などにもHadoopの活用されつつある。
セキュリティ、データ管理、クラスタ上でのツールの実行なども増えてきてる。</p>

<p>「今日ビッグデータは明日のスモールデータ」</p>

<h4>アーキテクチャとしてのビッグデータ</h4>

<p>多種多様なデータを一箇所に集約し、生データを直接活用できる。
OSSとしての責任も。</p>

<h3>データサイエンス</h3>

<p>Opsだけでないデータ解析にも活用</p>

<h2>「Clouderaのビッグデータプラットフォーム戦略」（仮）</h2>

<h4>講師：Cloudera, Inc. CTO Dr.Amr Awadallah</h4>

<p>レガシーな情報アーキテクチャ→スケールできない、可視化の限界、硬直したスキーマなどなど。</p>

<p>エンタープライズデータハブとしてのHadoopとか。</p>

<h2>ビッグデータの歴史と将来展望</h2>

<h4>講師：国立情報学研究所　アーキテクチャ科学研究系　教授　佐藤一郎氏</h4>

<h3>ビッグデータの歴史的経緯とか</h3>

<ul>
<li>最初の事例はアメリカの1880年国勢調査。</li>
<li><p>「ビッグデータがコンピュータを生み出した」。コンピュータがビッグデータを生み出したんじゃない。</p></li>
<li><p>少量データにもHadoopを</p>

<ul>
<li>バッチ処理のリアルタイム化とか（一晩から10分へ）</li>
</ul>
</li>
<li>原点は検索データのインデクシング</li>
<li>Hadoopを使うのが目的じゃないんだから、構築には手を掛けないのがいいよね。</li>
<li>プラットフォームと発展している</li>
</ul>


<h3>分散システム研究者から見たHadoop</h3>

<ul>
<li>分散ししテムの難しさを、処理範囲を限定することで巧みに回避</li>
<li>データの近くで処理</li>
<li>研究レベルではリアルタイム化や逐次処理化が活発</li>
<li>全工程で逐次・リアルタイムが必要とは限らない</li>
<li>聞いてばかりじゃなくて、動かしてみましょう。</li>
</ul>


<h2>データサイエンス：超並列分散処理を活用した新たなビジネス価値の創出</h2>

<h4>講師：アクセンチュア株式会社　工藤卓哉氏</h4>

<ul>
<li>「日経BPのビッグデータ総覧2013」に記事書いてる。</li>
<li>多様化するデータ（社外のデータも）をどうやってうまく活用していくか。</li>
<li>データが教えてくれたこと→まず、データありき、まずデータためましょう。それから解析とかすればいいのでは？というはなし？</li>
<li>競合他社さんはNGだけど、ブースでデモ？実機？が見れますと。</li>
</ul>


<h2>Hadoopデータプラットフォーム</h2>

<h4>Cloudera株式会社　嶋内　翔氏</h4>

<h3>まずは宣伝</h3>

<ul>
<li>Cloudera Implaraのフリーブックの日本語版</li>
<li>Hadoop Operationの書籍でるよ</li>
</ul>


<h3>プラットフォームを構成するもの</h3>

<ul>
<li>Flume</li>
<li>Sqoop</li>
<li>HBase</li>
<li>Hive</li>
<li>Impala</li>
</ul>


<h3>データ登録してBIアナリストのお仕事にどうやって役立てる？</h3>

<ul>
<li>外部テーブル：Hiveからはテーブルのように見える仕組み。元ファイルは消えない</li>
<li>SerDe（さーでぃー）：データをHiveレコードに変換する仕組み</li>
<li>生データを少し加工しましょう

<ul>
<li>圧縮したりファイル結合したりはしときましょう。</li>
</ul>
</li>
<li>Hadoop活用のポイント

<ul>
<li>富豪的プログラミング。リソースケチるな。</li>
<li>ローカルでできることはローカル。むりにHadoopでやんなくてもいいですよねと。バランス重要</li>
</ul>
</li>
<li>スケジューリング実行などはOozie使うと便利。（日次集計とか）</li>
<li>Cloudera Searchで元データにインデックス貼れるぞと。検索しながら分析ができる</li>
</ul>


<h3>クラスタ管理とか</h3>

<ul>
<li>Cloudera manager便利ですよ</li>
<li>ストレージリソースの管理。

<ul>
<li>声掛け、管理者が容量チェック、Cloudera Managerのレポート</li>
</ul>
</li>
<li>少数精鋭でHadoop使おう＝手が回らなくなる。</li>
<li>みんなで使おう＝Kerberos認証とか管理をちゃんと考えないと。けど、文化が根付けば強力。Sentry、Cloudera Navigatorとか。</li>
<li>Hadoopシステムの全体構成図。データの流れと各製品のつながり。</li>
<li>We are hiring!ということで、興味のある方は@shiumachiさんにコンタクトをとりましょうとのこと。</li>
</ul>


<h2>SQLで実現するバッチ処理とストリーム処理</h2>

<h4>LINE株式会社　田籠 聡氏</h4>

<p>資料：<a href="http://www.slideshare.net/tagomoris/batch-and-stream-processing-with-sql">Batch and Stream processing with SQL</a></p>

<ul>
<li>LINEのキャラがちらほら出てきた。</li>
<li>SQL好きですか？</li>
<li>ログの量とか。2.1TB/Day</li>
<li>バッチ処理とストリーム

<ul>
<li>速い集計のためにHadoopが重要</li>
</ul>
</li>
<li><p>エラー系のログとかはストリームで処理したい</p></li>
<li><p>アーキテクチャ説明</p></li>
<li>データ解析する人って色々。

<ul>
<li>管理者</li>
<li>プログラマ</li>
<li>サービスディレクタ</li>
<li>経営陣</li>
</ul>
</li>
<li>みんなが集計用処理を理解、編集ができるほうがいい。</li>
<li>顔あげたらHiveアイコンだらけだったｗ</li>
<li>Shibとか。</li>
<li><p>なんでHiveに限るの？</p>

<ul>
<li>Hiveに着目したバージョンアップだけを考えれば良くなる。</li>
</ul>
</li>
<li><p>スケジュールクエリが増えてきて、つらい。</p>

<ul>
<li>TimeWindowを固定して集計処理をすることで、回避できる。</li>
</ul>
</li>
</ul>


<h3>Norikra!!</h3>

<ul>
<li>スキーマレス</li>
<li>OSS。Esperベース。</li>
<li>インストールが楽</li>
<li>クエリの動作のお話。</li>
<li><p><a href="http://norikra.github.io">http://norikra.github.io</a></p></li>
<li><p>We Are Hiring!</p></li>
</ul>


<h2>Hadoop コミュニティと YARN の現状</h2>

<h4>日本電信電話株式会社　小沢 健史氏</h4>

<h3>なんでHadoop？</h3>

<ul>
<li>PostgreSQLでやってたけど、大きなデータにはHadoopを使おうという感じになってきた。</li>
<li>なんで使い分けるの？

<ul>
<li>スキーマ後付け</li>
</ul>
</li>
<li>NTTDocomoのモバイル位置情報の統計処理とか？</li>
<li>技術的な話をするので、HiveTに着替えます！ｗ</li>
<li>YARNのなにが嬉しいの？

<ul>
<li>ImpalaとMapReduceが同時に動くような環境の時に、リソースをうまく管理できないのがV1</li>
<li>そこでYARN</li>
</ul>
</li>
<li>Apache Mesosとだいたい一緒。</li>
<li>Apache MesosとYARNの比較</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[『プログラミング Hive』 『Hadoop 第3版』刊行記念セミナーに参加しました！ #oreilly0724]]></title>
    <link href="http://blog.johtani.info/blog/2013/07/25/hadoop-hive-publication-party/"/>
    <updated>2013-07-25T02:11:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2013/07/25/hadoop-hive-publication-party</id>
    <content type="html"><![CDATA[<p>Hadoopとか離れちゃってるし、Hive触ったこと無いにもかかわらず参加しました！<br/>
（たまたま近くにいるからって理由なのは内緒で）<br/>
玉川さんの四方山話を聞くのが主目的で参加しました。（ちょっと翻訳が気になってるので）</p>

<p>イベントページは<a href="http://connpass.com/event/2944/">こちら</a><br/>
刊行記念イベントにも関わらず、想像以上の人の入りでびっくりしました。Hadoop、Hive界隈はまだまだ人気なんだなぁと。<br/>
プレゼントじゃんけん大会もあったのですが、そうそうに負けてしまったのが悔やまれます。。。<br/>
Team Geek欲しかったなぁ。もちろん、懇親会まで参加しました。</p>

<p>以下、いつものメモです。</p>

<!--  more -->


<h2>Hiveの正しい使い方（Cloudera 嶋内さん）</h2>

<p>残念ながら、マサカリは持ってなかったです。</p>

<ul>
<li>スライドの各所に本の章番号が書いてあるのがうれしい。</li>
<li>Hiveロゴが回ってたのでスライドの時に集中できなかったｗ</li>
<li>Impalaの話も出てきた。

<ul>
<li>速いけど、色々足りない。Hiveの置き換えじゃないよと。</li>
</ul>
</li>
</ul>


<h2>HiveとImpalaのおいしいとこ取り（セラン　須田さん）</h2>

<p>スライド：<a href="http://www.slideshare.net/sudabon/20130724-oreilly-org">http://www.slideshare.net/sudabon/20130724-oreilly-org</a></p>

<ul>
<li>オンプレだとCDH便利だよと教えてもらう</li>
<li>いくつかSlideshareにImpalaの性能評価の資料を上げてある（必要になったら検索で。。。）</li>
<li>リリースされたその日に性能評価やってレポート書くとかすごすぎ！</li>
</ul>


<h2>翻訳の四方山話（玉川さん）</h2>

<ul>
<li>翻訳＝写経です</li>
<li>締め切り駆動勉強法ｗ</li>
<li>4page/day</li>
<li>自分から電突してオライリーさんに翻訳させてくださいと。</li>
<li>他の方の本が読めない（チェックしちゃうのでｗ）</li>
<li>動機があるから読めるってのはあるだろうなぁ。</li>
<li>選び方：わくわくするもの、仕事に活きるもの</li>
<li>今年もあと2冊やる予定（Hadoop Operations、Vagrantを翻訳中）</li>
<li>来年の候補（Chefとか）</li>
</ul>


<h2>高可用性HDFSのご紹介（Cloudera 小林さん）</h2>

<ul>
<li>スライドにどの版で書いてあったかがわかりやすく書いてある。</li>
<li>3段階の開発フェーズを経てる</li>
<li>QJMのお話</li>
</ul>


<h2>Cloudera UniversityとHadoop認定試験（Cloudera 川崎さん）</h2>

<ul>
<li>Clouderaデータアナリスト向けトレーニング（3日間、10月日本語で開催予定）

<ul>
<li>Hive、Pig、Impalaなど</li>
</ul>
</li>
<li>Data Science入門コースも準備中</li>
<li>出版記念！

<ul>
<li>8月管理者向け先着20 or 30名にHadoop第3版贈呈予定</li>
<li>先着20名にプログラミングHive贈呈予定</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cloudera Searchメモ（妄想版）]]></title>
    <link href="http://blog.johtani.info/blog/2013/06/06/cloudera-search-memo2/"/>
    <updated>2013-06-06T12:26:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2013/06/06/cloudera-search-memo2</id>
    <content type="html"><![CDATA[<p>ざっとインストールガイドとかCloudera Searchのソース眺めて、テキトーにメモを書いてみました。
（ユーザガイドはまだ読んでないです。）</p>

<!-- more -->


<h2>ざっくりメモ</h2>

<ul>
<li>ストリーム処理でインデックス作るときはFlume経由でSolrに

<ul>
<li>SinkとEventの両方が用意されてる？（Flumeを良く知らないので、違いがわからない）</li>
<li>FluemeからはリモートのSolrに対してインデックス登録するクラスがある。SolrServerDocumentLoaderがソレだと思う。</li>
</ul>
</li>
<li>バッチ処理でインデックス作るときはMapReduceIndexerToolsってのを使ってSolrに

<ul>
<li><a href="https://issues.apache.org/jira/browse/SOLR-1301">SOLR-1301</a>がベースになっている。色々と改良されてるようだけど、コアとなってる処理はSOLR-1301。</li>
<li>GoLiveってクラスの処理の中で、現在動作してるSolrに配布したバッチで作成されたIndexをマージする処理が書いてある。</li>
<li>HDFSへ出力されたインデックスはリモートのSolrからアクセスするとオーバヘッドとかどーなるのかなぁ？</li>
</ul>
</li>
<li>検索処理自体はHueでもできるけど、基本的にSolrCloud任せ</li>
<li>インデキシングの処理のフローについてはCloudera Mrophlinesで定義</li>
</ul>


<p>ということで、
2つの流れがありそう。</p>

<ul>
<li>HDFS→Flume→Solr</li>
<li>HDFS→MapReduce→Solr</li>
</ul>


<p>で、まだ、わかってないですが、構成要素として</p>

<ul>
<li>Hadoop（HDFS）：データソース</li>
<li>Hadoop（MapReduce）：データ変換処理、バッチインデキシング</li>
<li>Zookeeper：SolrCloudのクラスタ管理</li>
<li>Solr：インデキシング、検索エンジン</li>
<li>Flume：データをストリーミングでSolrへ</li>
<li>Coudera Morphlines：HDFSからSolrまでのETLデータ処理を定義実行する環境</li>
</ul>


<p>って感じでしょうか。
SolrCloudのクラスタとHadoopのクラスタが同一マシン上なのか、別なのかとか。組み合わせがどんなものができるのかがまだわかってないです。
ユーザガイド読んでみたらなにか出てくるかなぁ。</p>

<p>ちなみに、Cloudera SearchのgithubリポジトリにあるソースはCloudera Morphlinesのコードがメインで、SolrのHDFS対応版のソースがあるわけでは無かったです。</p>

<ul>
<li>SolrのHdfsDirectoryってのがClouderaのリポジトリにあるSolrには追加されていて、これが、HDFSのインデックスを読み込んだりする処理が出来る仕組みっぽい。</li>
<li>一応、SolrCloud以外（分散検索）も考慮された形になってるっぽい。</li>
</ul>


<p>ってとこでしょうか。</p>

<h2>感想</h2>

<p>読んでて思ったんですが、Cloudera Searchの肝はじつは、検索じゃなくて、Morphlinesにあるんじゃないかなぁと。今はSolrが出力先ですが、
その他のデータ変換処理とかが増えてくると、処理の流れがMorphlinesで定義できてデータ変換処理が簡便になりそうな気が。</p>

<h2>その他に気になる観点</h2>

<ul>
<li>CDH経由でSolrCloudのクラスタの管理するのかな？</li>
<li>SolrCloud用のクラスタとCDHのクラスタって同一マシンに載るの？別マシンにもできるの？

<ul>
<li>併存したらIOがキツそうだけど</li>
</ul>
</li>
<li>Hueで検索アプリとか組めるの？（そもそもHueがわかってないんだけど。。。）</li>
</ul>


<p>ま、とりあえず、こんなとこで。
つぎは余力があれば、ユーザガイドかなぁ。
英語力。。。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cloudera Searchのモジュールたち]]></title>
    <link href="http://blog.johtani.info/blog/2013/06/05/cloudera-search-modules/"/>
    <updated>2013-06-05T15:12:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2013/06/05/cloudera-search-modules</id>
    <content type="html"><![CDATA[<p>Cloudera Searchは次のようなモジュールから構成されています。
これはCloudera Searchのモジュールで、さらにこれらがSolrとかを使ってるみたいですね。pom.xmlを見たら何を使ってるかがわかるかな。</p>

<ul>
<li>cdk-morphlines</li>
<li>search-contrib</li>
<li>search-core</li>
<li>search-flume</li>
<li>search-mr</li>
<li>search-solrcell</li>
</ul>


<p>てきとーに、README.mdみながらメモを残してみました。ソースとかはまだ読んでないです。
ざっと眺めたけど、インデキシング処理の話がメインで、検索側がどうやって動くかってのがわからなかったなぁ。
<a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/Search/latest/PDF/Cloudera-Search-User-Guide.pdf">ユーザガイド（注：PDF）</a>ってのがあるから、これを読んでみるか。。。</p>

<p>各モジュールについては、以下。</p>

<!-- more -->


<h2>cdk-morphlines（Cloudera Morphlines）</h2>

<p>Cloudera Morphlinesという名前みたい。
検インデキシングアプリの構築、変更をラクにするためのフレームワーク。
ETLの処理チェインを簡単にCloudera Searchにデータを入れる設定（Extract/Transform/Load処理）がかけると。
バッチ処理、Near Real Timeのために使えるみたい。検索結果をさらに入れるとかもできるんかなぁ。？</p>

<p>Unixパイプラインのの進化版みたいなもので、一般的なレコードに対するStream処理から、Flueme、MapReduce、Pig、Hie、SqoopのようなHadoopコンポーネントも使えるみたい。</p>

<p>Hadoop ETLアプリケーションのプロトタイピングにも使えて、リアルタイムで複雑なStreamやイベント処理やログファイル解析とかに使えるの？</p>

<p>設定ファイルのフォーマットは<a href="https://github.com/typesafehub/config/blob/master/HOCON.md">HOCONフォーマット</a>。AkkaやPlayで使われてる。</p>

<h3>cdk-morphlines-core</h3>

<p>Cloudera Morphlinesのコンパイラ、実行環境、コマンドのライブラリを含んでる。
ログファイル解析やsingle-lineレコード、multi-lineレコード、CSVファイル、正規表現パターンマッチ、フィールドごとの比較とか条件分岐とか、文字列変換とか色々なコマンドを含んでる。</p>

<h3>cdk-morphlines-avro</h3>

<p>Avroファイルやオブジェクトの抽出、変換、読み込み処理コマンド</p>

<h3>cdk-morphlines-tika</h3>

<p>バイナリデータからMIMEタイプを検出して、解凍するコマンド。Tikaに依存</p>

<h4>雑感</h4>

<p>Cloudera Searchへのデータの流し込みを設定ファイルに記述して実行するとデータの変換処理とかが記述できるって感じかな？
Morphlinesのコマンドとして独自処理や使えそうな処理を作ることで、いろんな処理ができるって感じかなぁ。</p>

<h2>search-core</h2>

<p>Solrに対するMorphlineコマンドの上位モジュール</p>

<h3>search-solrcell</h3>

<p>Tikaパーサを使ったSolrCellを使うためのMorphlineコマンド。
HTML、XML、PDF、Wordなど、Tikaがサポートしてるものがサポート対象。</p>

<h3>search-flume</h3>

<p>Flueme Morphline Solr Sink。
Apache Flumeのイベントから検索ドキュメントを抽出、変換し、SolrにNearRealTimeで読み込むためのコマンド</p>

<h3>search-mr</h3>

<p>HDFSに保存されたファイルに含まれる大量データをMapReduceで処理してHDFS上の検索インデックスに焼きこむモジュール。</p>

<p><code>MapReduceIndexerTool</code>は入力ファイルの集合からSolrのインデックスシャードの集合を作るためのmorphlineのタスクで、MapReduceのバッチジョブドライバー。
HDFSにインデックスを書き込む。
動作してるSolrサーバに対して出力されたデータをマージするのもサポートしてる。</p>

<p>とりあえず、Near Real Time検索するにはFlueme使って、バッチ処理でインデックス焼くのはMapReduceIndexerToolみたいだなぁ。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cloudera Searchってのが出たらしい（とりあえず、雑感？）]]></title>
    <link href="http://blog.johtani.info/blog/2013/06/05/what-is-cloudera-search/"/>
    <updated>2013-06-05T15:05:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2013/06/05/what-is-cloudera-search</id>
    <content type="html"><![CDATA[<p>AWS Summitに来ていたのですが、TLでは、Cloudera Searchが賑わってました。
ということで、軽くどんなものか読んだり調べたりしたメモを残しとこうかと。
英語力はあやしいので、おかしいとこがあったらツッコミを。</p>

<!-- more -->


<h2>Cloudera Searchとは？</h2>

<p>CDH4.3に対応したCDHユーザ向けの検索システム（beta版）なのかな？
CDHに統合された検索フレームワークなのかな？</p>

<p>基本はLucene/Solr 4.3でHadoopのペタバイトデータを検索することができるようになるみたいです。</p>

<h2>どんな仕組み？</h2>

<p>次のものを利用しているようです。（GithubのREADMEから。）</p>

<h4>使ってるもの</h4>

<ul>
<li>Apache Solr(4.3.0＋α？)

<ul>
<li>Apache Lucene（Solrつかってるからね）</li>
<li>Apache SolrCloud（うーん、Solrに含まれるのに別に出してるのなんで？）</li>
</ul>
</li>
<li>Apache Flume</li>
<li>Apache Hadoop MapReduce &amp; HDFS</li>
<li>Apache Tika

<ul>
<li>SolrCellとしてSolrにも組み込まれてる、いろんな文書（WordとかHTMLなどなど）からメタデータと本文データとかを取り出せるライブラリラッパー。実際にはさらにpdfboxとかを使って各文書からのデータを取り出してる。</li>
</ul>
</li>
</ul>


<h4>何ができるの？</h4>

<p>HBaseやHDFSの用にZookeeperを使ってインデックスのシャーディングや高可用性ができる。（SolrCloudがZookeeperを使ってるからね。）
MapReduceのジョブの出力から自動的にSolrのインデックスにデータをマージできるらしい。
Cloudera Managerを使って、デプロイ、設定モニタリングなどが可能。</p>

<p>Flumeのフィードをつかって、ストリーミングしてインデックスを作れる。FluemeがデータをSolrに流しこむのかな？
将来的にはHiveやHBaseのテーブルをインデックスすることも可能になるらしい。Impalaクエリの結果もフィードできるのか？</p>

<p><a href="http://incubator.apache.org/blur/how_it_works.html">Apache Blur</a>ってキーワードも出てきた。HDFSのデータからLuceneのインデックス作るのかな？
NGDataのチームがSolr/HBaseの統合とかしてるみたい。</p>

<h3>参考URL</h3>

<ul>
<li><a href="http://blog.cloudera.com/blog/2013/06/cloudera-search-the-newest-hadoop-framework-for-cdh-users-and-developers/">Cloudera社のブログ</a></li>
<li><a href="http://cloudera.com/content/cloudera-content/cloudera-docs/Search/latest/PDF/Cloudera-Search-Frequently-Asked-Questions.pdf">Cloudera SearchのFAQ（注：PDF）</a></li>
<li><a href="https://github.com/cloudera/search">Githubのリポジトリ</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
