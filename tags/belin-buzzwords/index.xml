<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">

  <channel>
    <title>Belin Buzzwords on @johtaniの日記 3rd</title>
    <link>https://blog.johtani.info/tags/belin-buzzwords/</link>
    <description>Recent content in Belin Buzzwords on @johtaniの日記 3rd</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Wed, 21 Jun 2023 01:30:45 +0900</lastBuildDate><atom:link href="https://blog.johtani.info/tags/belin-buzzwords/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>今年もオンラインでBerlin Buzzwordsに参加した</title>
      <link>https://blog.johtani.info/blog/2023/06/21/attend-berlin-buzzwords-2023/</link>
      <pubDate>Wed, 21 Jun 2023 01:30:45 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2023/06/21/attend-berlin-buzzwords-2023/</guid>
      <description>今年もこの季節がやってきました。 Berlin Buzzwordsにオンラインで出張してました。 今年もハイブリッド開催をしてくれたので、オンラインで参加で</description>
      <content:encoded>&lt;p&gt;今年もこの季節がやってきました。
&lt;a href=&#34;https://2023.berlinbuzzwords.de/&#34;&gt;Berlin Buzzwords&lt;/a&gt;にオンラインで出張してました。
今年もハイブリッド開催をしてくれたので、オンラインで参加できました。
現地ではブースが出たり、朝食なども用意されているようでした。今年は昨年と違いマスク必須でもなくなったようです。
&lt;a href=&#34;https://mices.co/&#34;&gt;MICES&lt;/a&gt;も去年同様、現地開催のみのようです（今見たら、&lt;a href=&#34;https://mices.co/mices_eu_2022/index.html&#34;&gt;昨年のビデオとスライドが公開されてる&lt;/a&gt;ので、時間見つけてみてみよう）。&lt;/p&gt;
&lt;p&gt;今年はうれしいことに検索に絡むセッションが大多数でした。世の中的にChatGPTの盛り上がりやベクトル検索がいろんな検索エンジンで使えるようになってきたこともあり、
大規模言語モデルと検索エンジン、ベクトルデータベースに関する話がたくさんありました（昨年まではKafkaやストリーム処理の話も多かったんですが）。&lt;/p&gt;
&lt;p&gt;ということで、今年もセッションを見ながら残したメモを公開しておきます。&lt;/p&gt;
&lt;h2 id=&#34;簡単にメモ&#34;&gt;簡単にメモ&lt;/h2&gt;
&lt;h3 id=&#34;what-defines-the-open-in-open-ai&#34;&gt;What defines the “open” in “open AI”?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;セッションページ：&lt;a href=&#34;https://program.berlinbuzzwords.de/berlin-buzzwords-2023/talk/BKUVLR/&#34;&gt;What defines the “open” in “open AI”?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;動画： &lt;a href=&#34;https://www.youtube.com/watch?v=RSRHSlQiKJ4&#34;&gt;Jennifer Ding - What defines the &amp;ldquo;open&amp;rdquo; in &amp;ldquo;open AI&amp;rdquo;? - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;ldquo;OpenAI&amp;quot;の話ではなく、オープンなAIとは？という話で、ライセンスの話であったり、コミュニティ（データセットの公開とかベンチマークの共有とか）に関する話であったり。
後半は気を抜いてしまって話をうまく聞き取れてないので、興味がある方はビデオで。。。&lt;/p&gt;
&lt;h3 id=&#34;vectorize-your-open-source-search-engine&#34;&gt;Vectorize Your Open Source Search Engine&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;セッションページ：&lt;a href=&#34;https://program.berlinbuzzwords.de/berlin-buzzwords-2023/talk/VUGYME/&#34;&gt;Vectorize Your Open Source Search Engine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;動画： &lt;a href=&#34;https://www.youtube.com/watch?v=U7PQNyeQrXQ&#34;&gt;Atita Arora - Vectorize Your Open Source Search Engine - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ベクトル検索が流行ってきてるけど、これまでの検索（エンジン）に対して、どうやってベクトル検索を取り入れる？という話です。
ベクトル検索ってどんなもので、どういうことの助けになりそうか？じゃあ、どうやって、これまでの検索が改善したかを見ていくのか？
という、これからベクトル検索を取り入れようとしている時にどのようなアーキテクチャにして、
どのような考慮するポイント（モデルの選択とかスケーラビリティとか）にどんなものがあるのか？といった紹介でした。
ざっくりですが、ベクトル検索やるのにどんなことをやっていけばよいのか？という地図になるようなセッションでした。&lt;/p&gt;
&lt;h3 id=&#34;supercharging-your-transformers-with-synthetic-query-generation-and-lexical-search&#34;&gt;Supercharging your transformers with synthetic query generation and lexical search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;セッションページ： &lt;a href=&#34;https://program.berlinbuzzwords.de/berlin-buzzwords-2023/talk/ZQ9CPX/&#34;&gt;Supercharging your transformers with synthetic query generation and lexical search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;動画： &lt;a href=&#34;https://www.youtube.com/watch?v=QfNkJIWCZc4&#34;&gt;Milind Shyani - Supercharging your transformers with synthetic query generation and lexical search - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;AWSの人の話でした。こちらもトランスフォーマーが検索に使えると便利だよねという話なのですが。
LLMを使うと高コストでサイズがどんどん大きくなっていて、小さな学習済みのモデルだといまいちな精度でだし、
ファインチューニングしたい場合、ドメインに特化したデータはなかなかないよね。とくにデータ（検索したいもの）はあるけど、クエリがないということがよくあるよね。
そこで、LLMを使って、データからクエリを作って、正解データを作り、それでファインチューニングすればいいのでは？
ということで、やってみました、どうでしたという話でした。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://opensearch.org/blog/semantic-science-benchmarks/&#34;&gt;ブログ&lt;/a&gt;などもあるので参考にすると面白いかも&lt;/p&gt;
&lt;h3 id=&#34;the-debate-returns-with-more-vectors-which-search-engine&#34;&gt;The Debate Returns (with more vectors) Which Search Engine?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;セッションページ：&lt;a href=&#34;https://program.berlinbuzzwords.de/berlin-buzzwords-2023/talk/73UNZD/&#34;&gt;The Debate Returns (with more vectors) Which Search Engine?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;動画：&lt;a href=&#34;https://www.youtube.com/watch?v=iI40L4wMtyI&#34;&gt;Charlie Hull - The Debate Returns (with more vectors) Which Search Engine? - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;今年も検索エンジンの人を集めてパネルディスカッションです。今年は次の方たちが参加してディスカッションでした。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参加者
&lt;ul&gt;
&lt;li&gt;Jo：Vespaの人。ランキングとかがよくできてるからVespa好き&lt;/li&gt;
&lt;li&gt;Alessandro：Apache Solrの人。SolrのPMCメンバー。なんでSolr？Pure OSSだし。スケーラブルだ&lt;/li&gt;
&lt;li&gt;Etienne：Weaviateの人。新しいAI nativeなベクトルデータベース&lt;/li&gt;
&lt;li&gt;Philipp：Elasticの人。&lt;/li&gt;
&lt;li&gt;Kacper：Qdrantの人。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;質問は次のようなものでした。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最初の質問：スケールの話。スケールアウトかな？&lt;/li&gt;
&lt;li&gt;2つ目の質問：どんなアプリケーションが適していないか？&lt;/li&gt;
&lt;li&gt;3つ目の質問：どうやってAIをサポートできるの？&lt;/li&gt;
&lt;li&gt;4つ目の質問：どうやってコミュニティにアプローチしてる？&lt;/li&gt;
&lt;li&gt;5つ目の質問：自分の検索エンジンが使えない時に何を使う？&lt;/li&gt;
&lt;li&gt;6つ目の質問：今後に何が面白そう？&lt;/li&gt;
&lt;li&gt;最後の質問：あなたの検索エンジンが使われてるユースケースで一番好きなものは？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2つ目や5つ目の質問が面白いですよね。実際の内容はぜひビデオを見ていただくのがいいかと（メモも取ったけど、聞いてもらうほうが面白そうだし）。&lt;/p&gt;
&lt;h3 id=&#34;whats-coming-next-with-apache-lucene&#34;&gt;What&amp;rsquo;s coming next with Apache Lucene?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;セッションページ：&lt;a href=&#34;https://program.berlinbuzzwords.de/berlin-buzzwords-2023/talk/NNNZ8W/&#34;&gt;What&amp;rsquo;s coming next with Apache Lucene?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;動画：&lt;a href=&#34;https://www.youtube.com/watch?v=EHJjSYWjIF0&#34;&gt;Uwe Schindler - What&amp;rsquo;s coming next with Apache Lucene? - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;毎年恒例Uweさん。今年Luceneが25周年という話で、これまでの進化の話を駆け足でしてくれました。
あとは、後半は来週9.7が出るよということで、9.7で入ってくるベクトルの距離計算の最適化に関して説明してくれています。
次のバージョンのElasticsearchでもこの最適化が使えるようになるという話もされていましたので、ベクトル検索を使ってる方は、次のバージョンも楽しみですね。&lt;/p&gt;
&lt;h3 id=&#34;building-mlops-infrastructure-at-japans-largest-c2c-e-commerce-site&#34;&gt;Building MLOps Infrastructure at Japan&amp;rsquo;s Largest C2C E-Commerce Site&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;セッションページ：&lt;a href=&#34;https://program.berlinbuzzwords.de/berlin-buzzwords-2023/talk/YLCZP8/&#34;&gt;Building MLOps Infrastructure at Japan&amp;rsquo;s Largest C2C E-Commerce Site&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;動画：&lt;a href=&#34;https://www.youtube.com/watch?v=11xxPUSJTss&#34;&gt;Berlin Buzzwords 2023： Building MLOps Infrastructure at Japan&amp;rsquo;s Largest C2C E-Commerce Site - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;メルカリの検索システムに関係しているMLOps周りがどうやって進化してきたのか？という話でした。
英語にいらすとやの絵があるスライドがドイツで使われているのがとても新鮮ですｗ&lt;/p&gt;
&lt;h3 id=&#34;highly-available-search-at-shopify&#34;&gt;Highly Available Search at Shopify&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;セッションページ：&lt;a href=&#34;https://program.berlinbuzzwords.de/berlin-buzzwords-2023/talk/N9JRVC/&#34;&gt;Highly Available Search at Shopify&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;動画：&lt;a href=&#34;https://www.youtube.com/watch?v=iqWlQbzT-DM&#34;&gt;Khosrow Ebrahimpour - Highly Available Search at Shopify - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Shopifyの検索プラットフォームチームの人の、Shopifyの検索プラットフォームがどういったものか？（EsとKafka使ってる）どんな工夫をしているか？という話です。
Kubeconでも他の同僚の方が話をされている見たいで、そちらも参考になるとのことでした（&lt;a href=&#34;https://www.youtube.com/watch?v=a0aNdOUDqhA&#34;&gt;動画&lt;/a&gt;）。
スキーマ変更時の話とかもあり、実践的でした。最後に将来的な話でやはりベクトル検索というキーワードが出てきていました。あとは、データ量が大きいのでスケーリングの挑戦もあるとのこと。&lt;/p&gt;
&lt;h3 id=&#34;using-dense-vector-search-at-the-eu-publications-office&#34;&gt;Using Dense Vector search at the EU Publications Office&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;セッションページ：&lt;a href=&#34;https://program.berlinbuzzwords.de/berlin-buzzwords-2023/talk/K8AR9R/&#34;&gt;Using Dense Vector search at the EU Publications Office&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;動画：&lt;a href=&#34;https://www.youtube.com/watch?v=V_qzTDL11DU&#34;&gt;Martin Bayton - Using Dense Vector search at the EU Publications Office - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;EUのPublication Office（日本だと公文書館とかになるのかなぁ？）の検索サービスで、Googleみたいなこと（検索結果の上にスニペットが出たり、そこにハイライトされたり）をやってみたいよね？という話みたいでした。実際公開してるかはわからないですが、途中からはPureinsightsという会社のプラットフォームで似たようなことをやるデモになってました。&lt;/p&gt;
&lt;p&gt;Googleでも12%のクエリが、質問の自然文になっているという話で、検索結果にナレッジグラフからの情報（スニペットとか、質問に対する答えとか、地図とか）が出るようになってきていますと。
それをPublication Officeのデータで再現したデモを行った後に、どんな感じのアーキテクチャなのか？という概略を説明されています。国会図書館とかの検索サービスやってる方が興味を持ったりするかもなーと思ったり、思わなかったり？&lt;/p&gt;
&lt;h3 id=&#34;learning-to-hybrid-search&#34;&gt;Learning to hybrid search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;セッションページ：&lt;a href=&#34;https://program.berlinbuzzwords.de/berlin-buzzwords-2023/talk/FKKNBD/&#34;&gt;Learning to hybrid search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;動画：&lt;a href=&#34;https://www.youtube.com/watch?v=TBGkis0U1bg&#34;&gt;Berlin Buzzwords 2023： Learning to hybrid search - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これまたキーワード検索とセマンティック検索のハイブリッドの話です。
よくハイブリッド検索というのを聞きますが、データだったりベンチマークなどの話があまりないですよね？昨年&lt;a href=&#34;https://github.com/amazon-science/esci-data&#34;&gt;AmazonがECSIというデータセットを公開&lt;/a&gt;したりしています（&lt;a href=&#34;https://zenn.dev/rejasupotaro/articles/321b62c83a5d66&#34;&gt;rejasupotaroさんが年末に書かれた記事にも出てきていました&lt;/a&gt;）。
これにLearn to Rankとかもテストできるような&lt;a href=&#34;https://github.com/shuttie/esci-s&#34;&gt;データ（レビューや評価、カテゴリーとか）を拡張したもの&lt;/a&gt;を作って、それをもとにいろいろとハイブリッド検索で精度を測ってみたというお話でした。
&lt;a href=&#34;https://www.metarank.ai/&#34;&gt;Metarank&lt;/a&gt;というリランキングエンジンの会社の方たちで、Metarankを使ってハイブリッドな検索結果のリランキングで精度がどのように上げられるか？という話です。
&lt;a href=&#34;https://trec-product-search.github.io/&#34;&gt;今年のTRECのProduct Search Track&lt;/a&gt;の話もされていました。
&lt;a href=&#34;https://blog.metarank.ai/from-zero-to-semantic-search-embedding-model-592e16d94b61&#34;&gt;これが元ネタのブログかな？&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;catch-the-fraud--with-observability-and-analytics&#34;&gt;Catch the fraud — with observability and analytics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;セッションページ：&lt;a href=&#34;https://program.berlinbuzzwords.de/berlin-buzzwords-2023/talk/HAKWWW/&#34;&gt;Catch the fraud — with observability and analytics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;動画：まだ？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最後は元同僚のセッションです。こちらは検索ではなく、ちょっと自虐的なネタをもとにしたオブザバビリティおよび分析のお話です。
コミュニティの人たちの貢献（ブログ書いたりプルリク送ったり、どこかで話をしたり）を計測して、年間の貢献者に対してプレゼントを上げるというのをやっているみたいです。
で、昨年の最も貢献した人にMac Bookをプレゼントするというすばらしい（&lt;del&gt;暴挙&lt;/del&gt;）話で、チートしようとした人がいてそれを分析した話でしたｗ
締め切り直前に信じられない量の貢献したという登録がブラジルからあり、何かおかしいよね？ということで、Elastic Stackのオブザバビリティの機能などを元に分析してチートした人を除外していったよという話でした。
Kibanaが使いやすくなってるのがわかるセッションで面白かったです。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;検索がまたすごく盛り上がってきたなーという時間があるカンファレンスでした。みんな似たような話（ベクトル検索、LLM、AIなど）だったりしますが、
知らないプロダクトで興味が出てくるものもあったし、Amazonのデータセットがあるからいろいろ試してみることもできそうだなぁと。&lt;/p&gt;
&lt;p&gt;すでにビデオが公開されはじめているので、気になったセッションのビデオも見てから後日またブログを書こうとおもいます
（たぶん、一覧が作成されるので後日リンクを貼っておきます）。&lt;/p&gt;
&lt;p&gt;来年の予定（6月11日から開催）も公開されていましたし。来年も楽しみですね。
来年はプロダクションでベクトル検索やってみた話とかがさらに出てくるのかなぁ？&lt;/p&gt;
</content:encoded>
    </item>
    
  </channel>
</rss>
