<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">

  <channel>
    <title>MICES on @johtaniの日記 3rd</title>
    <link>https://blog.johtani.info/tags/mices/</link>
    <description>Recent content in MICES on @johtaniの日記 3rd</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Tue, 13 Jul 2021 16:08:23 +0900</lastBuildDate><atom:link href="https://blog.johtani.info/tags/mices/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>今年もMICESにオンライン出張してた</title>
      <link>https://blog.johtani.info/blog/2021/07/13/attend-mices-2021/</link>
      <pubDate>Tue, 13 Jul 2021 16:08:23 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2021/07/13/attend-mices-2021/</guid>
      <description>今年もMICESにも参加してました。 昨年はBerlin Buzzwordsと共同開催でしたが、今年は別開催（別日程）でした。 MICESは201</description>
      <content:encoded>&lt;p&gt;今年も&lt;a href=&#34;https://mices.co/&#34;&gt;MICES&lt;/a&gt;にも参加してました。
昨年は&lt;a href=&#34;https://blog.johtani.info/blog/2020/07/06/attend-berlin-buzzwords/#berlin-buzzwords%E3%81%A8%E3%81%AF&#34;&gt;Berlin Buzzwordsと共同開催&lt;/a&gt;でしたが、今年は別開催（別日程）でした。&lt;/p&gt;
&lt;p&gt;MICESは2017年から始まったe-commerceの検索にフォーカスしたカンファレンスです。
ECに関連する話に特化されていますが、話題は多岐にわたっています。色々やることありますねぇ、ECも。&lt;/p&gt;
&lt;h2 id=&#34;参加したセッション&#34;&gt;参加したセッション&lt;/h2&gt;
&lt;p&gt;参加したセッションの個人メモを今回も残しておきます。
セッション個別のリンクは用意されていないみたいですが、&lt;a href=&#34;https://mices.co/mices2021/index.html&#34;&gt;公式サイト&lt;/a&gt;にタイムテーブルがあり、セッションのタイトル、概要に加えて、スライドのPDFもリンクがあります。動画が公開されているものもあります。&lt;/p&gt;
&lt;h3 id=&#34;dreaming-search&#34;&gt;Dreaming Search&lt;/h3&gt;
&lt;p&gt;ビデオが公開されています。スライドがざっくりしたものなので最初に聞いた時にはしっくりこなかったので、聞き直してのメモです。
GDPRのような話で、個人の情報を自分たちで管理しようと流れがあります。
それぞれのECサイトなどでのユーザーのイベント（何を検索して、何をクリックした）情報はそれぞれのサイトで閉じた情報になっています。このため、自分の興味のある情報が断片化された情報でそれぞれのサイトで管理されてしまい、パーソナライゼーションされるもの（ランキングだったりレコメンドだったり）がいまいちな場合があります。
この個人の情報（ユーザーのイベント）をユーザー自身がハンドリングして、どの情報までをどこまで公開できるようにするというように管理できる仕組みができないか？という話のようでした。実際にそのための仕組み（もっと大きな話の仕様）を検討している&lt;a href=&#34;https://solidproject.org/about&#34;&gt;プロジェクト&lt;/a&gt;があり、それに関連して検索という観点で夢を語っているセッションです。&lt;/p&gt;
&lt;p&gt;ざっくり私が理解したのをまとめましたが、empathy.coという会社としてはいくつかPoCなども実施されているようでした。
個人の情報の扱い方に関する話は新鮮で面白かったです。
仕組みが出来上がり、各サイトが対応するとより個人が欲しい情報が集まりやすくなるのかなぁ？&lt;/p&gt;
&lt;h3 id=&#34;forget-facets-welcome-refinements-tm&#34;&gt;Forget Facets, welcome Refinements (TM)&lt;/h3&gt;
&lt;p&gt;Berlin BuzzwordsでいくつかLTをやられていた方によるファセットとその応用（彼らはRefinementsと名前をつけたみたい）についての話でした（ビデオとスライドが公開済み。）。
検索エンジンとファセットの関係の歴史から始まって、Kibanaでの使い方、モバイルや音声検索・チャットボットでのファセットは難しいよね？という話につながります。
ということで、Refinementsとして、ファセットを提示してユーザーに選んでもらうだけでなく状況に応じて、提案するための情報としてファセットを使うといいのでは？という話でした。例えば、チャットボットや音声検索での結果の場合、検索結果数が多くなるとユーザーが望んだものが返せるとは限らないです。その時に、ファセットの情報をもとに絞り込み条件を聞き返すネタに使うのはどうか？というような話でした。オートサジェスト（検索があいまいな時に、追加のキーワードを提案するもの）のような形でブランド名だったり、カテゴリーなどを表示する仕組みです。
実際の実装の話は、彼らが過去にBerlin Buzzwordsなどで話をしているのでそちらが参考になるとのことでした（参考：&lt;a href=&#34;https://www.youtube.com/watch?v=IbXjSFLqrW8&amp;amp;list=PLq-odUc2x7i9-bGb8F8ytYBfCAzcmpaUe&amp;amp;index=32&#34;&gt;berlin buzzwords 2019&lt;/a&gt; / &lt;a href=&#34;https://haystackconf.com/europe2019/relevant-facets/&#34;&gt;Heystack 2019&lt;/a&gt;）&lt;/p&gt;
&lt;h3 id=&#34;reinforcement-learning-in-search&#34;&gt;Reinforcement learning in search&lt;/h3&gt;
&lt;p&gt;検索における強化学習の話みたいです。ビデオとスライドが公開されています。ビジネス的に検索のランキングが重要だが、そのランキングをどうやって良くしていくのか？という話です。
ランキングでデフォルトのBM25から始まり、LtRを導入し、A/Bテストなどをしつつ、モデルの変化がどのようにビジネスに影響するかをはかるのが難しくなります。
LtRに対するオンライン機械学習のアプローチについて実際に直面した課題の話などがされている（はず？）です（どうも、実際にCTRなどを用いたところまでは行ってなさそう）。&lt;/p&gt;
&lt;p&gt;多腕バンディットなどの強化学習の話が続いたあたりでギブアップしてしまいました。。。&lt;/p&gt;
&lt;h3 id=&#34;better-search-through-query-understanding---panel&#34;&gt;Better Search through Query Understanding - Panel&lt;/h3&gt;
&lt;p&gt;Query Understandingに関するパネルとして3社の人がそれぞれどういった取り組みをしてるか？という話をしたあと質問などに答えていく形式でした。残念ながらビデオはまだ公開されていませんが、スライドが公開されています。QA部分も結構な時間だったのでビデオの公開がされるといいなぁ。&lt;/p&gt;
&lt;h4 id=&#34;understanding-queries-by-analysing-user-interaction--andrea-schütt-otto&#34;&gt;Understanding queries by analysing user interaction / Andrea Schütt (OTTO)&lt;/h4&gt;
&lt;p&gt;OTTOというECサイトでのQuery Understandingの紹介と、LtR導入にまつわる話。
データサイエンスとして最初はQuery Understandingやってたけど、スケールしないのでLtR導入して色々と試行錯誤しているところのようだった。&lt;/p&gt;
&lt;h4 id=&#34;query-understanding-ai-search&#34;&gt;Query Understanding AI search&lt;/h4&gt;
&lt;p&gt;eBayの方の発表。Query Understanding = ユーザーの興味をクエリから類推するという定義から、クエリを分類する、同定するためにどうしているか？という話でっした。
単語の表面的な文字としての近さだけでは、語順が変わると意味が変わるものや、ステミングのせいで同じになってしまうものといった例を紹介しつつ、クエリをベクトルにして表現（コンバージョン、クリックなどの情報を元にプロダクトのベクトルにしてみたり）し似ているかどうか？を判断している話です。&lt;/p&gt;
&lt;h4 id=&#34;case-study--autocomplete-search-suggestions&#34;&gt;Case study : Autocomplete Search Suggestions&lt;/h4&gt;
&lt;p&gt;Digitec Galaxusというサイトでのオートコンプリートをもっと使いやすくするためにどんなデータを集めて、どうやって表示しているか？という話でした。
とりあえず入力されたものにヒットしたものを出すような実装だった場合に、サジェストされる量が多く、ノイズも多いので使いにくかったものをどうやって改善して行ったかという処理の流れなどの説明もありました。&lt;/p&gt;
&lt;h3 id=&#34;the-need-for-an-open-web-search-in-europe---the-approach-of-the-open-search-foundation-and-its-implications-for-e-commerce-companies&#34;&gt;The need for an open web search in Europe - The approach of the Open Search Foundation and its implications for E-Commerce-Companies&lt;/h3&gt;
&lt;p&gt;Speaker: Alexander Decker / OPEN SEARCH FOUNDATION&lt;/p&gt;
&lt;p&gt;もっとオープンな検索システムを作っていこうという&lt;a href=&#34;https://opensearchfoundation.org/en/open-search-foundation-home/&#34;&gt;団体&lt;/a&gt;の話でした。
AWSが最近1.0をリリースしたやつとは別物です。
Googleでみんな検索しているけど、ブラックボックスなのでバイアスがかかっている。
もっとバイアスフリーなインデックスを提供できると、使いやすくなるよね？みんなでそういうインデックスを作っていかないか？という話でした。
ECとの直接の関係はセッションからは読み取れませんでした。
どうやって、集めるデータの基準（入れるべき、入れるべきではないなど）を作るんだろう？という疑問が残っています。公共的なものやオープンデータについてはあるとよさそうかもなぁ。&lt;/p&gt;
&lt;h3 id=&#34;101-hints-to-improving-the-customer-satisfaction-on-search-engines-in-the-retail-industry&#34;&gt;101 hints to improving the customer satisfaction on search engines in the retail industry&lt;/h3&gt;
&lt;p&gt;Speaker: Marion Hemery (Carrefour France) &amp;amp; Lucian Precup (a// &amp;amp; Adelean)&lt;/p&gt;
&lt;p&gt;カルフールのECサイトでの検索に関する顧客満足度の改善についての話です。
どんなものをどうやって図るのか、フィードバックを取るための仕組みは？
そこからわかったものをどうやってシステムに優先度をつけながら取り込んでいくのか？
というのをどんなものを使っているかという説明を交えながらのセッションです。
スライドが結構細かく書かれているのでスライドを見るだけでもわかりやすいかな。&lt;/p&gt;
&lt;h3 id=&#34;an-ounce-of-prevention-is-worth-a-pound-of-cure-establishing-a-gold-standard-based-evaluation-in-customer-projects&#34;&gt;“An ounce of prevention is worth a pound of cure”: establishing a gold standard-based evaluation in customer projects&lt;/h3&gt;
&lt;p&gt;Speaker: Bertram Sändig &amp;amp; Cornelia Werk / NEOFONIE&lt;/p&gt;
&lt;p&gt;検索の性能指標（速度ではないほうの性能）をきちんと評価する仕組みが重要だよというセッションです。
検索の仕組みを変更（例ではステミングを導入するはなしをしてました）した場合に、現行システムにどういう影響が出るのか？それをどうやって図るのか、どうやってテストしていくのか？という話です。
ステミングを導入したら、検索にヒットしやすくなったものも出てきたけどその弊害として今までよかった検索の結果にノイズが増え多という話をもとに、検索結果としてこうあってほしいというゴールデンスタンダードをきちんと作って育てていくべきですよという話でした。完ぺきなものなどないので少しずつやっていきましょうと。&lt;/p&gt;
&lt;p&gt;ということで、見ていないもの（LTや最後のワークショップ）もありますが、見たものに関してメモを残してみました。&lt;/p&gt;
</content:encoded>
    </item>
    
  </channel>
</rss>
