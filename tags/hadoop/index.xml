<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hadoop on @johtaniの日記 3rd</title>
    <link>https://blog.johtani.info/tags/hadoop/</link>
    <description>Recent content in hadoop on @johtaniの日記 3rd</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Thu, 07 Nov 2013 10:11:00 +0900</lastBuildDate><atom:link href="https://blog.johtani.info/tags/hadoop/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cloudera World Tokyo 2013に参加しました！ #cwt2013 </title>
      <link>https://blog.johtani.info/blog/2013/11/07/cloudera-world-tokyo-2013/</link>
      <pubDate>Thu, 07 Nov 2013 10:11:00 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2013/11/07/cloudera-world-tokyo-2013/</guid>
      <description>Cloudera World Tokyo 2013に参加してきました。 午前中はあいにくの雨でしたが、それでも結構な人数が最初の基調講演から参加されてました。 私が参加したセッショ</description>
      <content:encoded><p><a href="http://www.cloudera.co.jp/jpevents/cwt2013/index.html">Cloudera World Tokyo 2013</a>に参加してきました。</p>
<p>午前中はあいにくの雨でしたが、それでも結構な人数が最初の基調講演から参加されてました。
私が参加したセッションは大盛況な感じでした。</p>
<p>おみやげとしてカステラも頂いちゃいました！</p>

<link rel="stylesheet" href="/css/hugo-easy-gallery.css" />
<div class="box" style="max-width:300">
  <figure  itemprop="associatedMedia" itemscope itemtype="http://schema.org/ImageObject">
    <div class="img">
      <img itemprop="thumbnail" src="/images/entries/20131107/kasutera.jpg" />
    </div>
    <a href="/images/entries/20131107/kasutera.jpg" itemprop="contentUrl"></a>
  </figure>
</div>

<p>また、色々なセッションに現れたこんなメッセージ画像も見つけました！</p>
<blockquote class="twitter-tweet"><p>昨日の写真データの整理をしていたら、こんなものが・・・ <a href="https://twitter.com/shiumachi">@shiumachi</a> さんよ・・・ <a href="https://twitter.com/search?q=%23cwt2013&amp;src=hash">#cwt2013</a> <a href="http://t.co/S0JsxSYXIx">pic.twitter.com/S0JsxSYXIx</a></p>&mdash; Kenichiro HAMANO (@hamaken) <a href="https://twitter.com/hamaken/statuses/398613935399510016">November 8, 2013</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<!-- more -->
<p>やっぱり、スーツの人が多いなという印象。</p>
<p>名刺を毎回回収されるのはちょっとつらかったです。なにか、いい方法ないですかねぇ。</p>
<p>以下はいつもの個人メモです。</p>
<h2 id="ビッグデータプラットフォームとして進化するhadoop">「ビッグデータプラットフォームとして進化するHadoop」</h2>
<h4 id="cloudera株式会社代表取締役ジュセッペ小林氏">Cloudera株式会社　代表取締役　ジュセッペ小林氏</h4>
<ul>
<li>Costcoなどの写真を元にビッグデータを可視化</li>
</ul>
<h3 id="bigdataとhadoopの関係">BigDataとHadoopの関係</h3>
<p>検索、SQL、機会学習、数理処理、データ管理などにもHadoopの活用されつつある。
セキュリティ、データ管理、クラスタ上でのツールの実行なども増えてきてる。</p>
<p>「今日ビッグデータは明日のスモールデータ」</p>
<h4 id="アーキテクチャとしてのビッグデータ">アーキテクチャとしてのビッグデータ</h4>
<p>多種多様なデータを一箇所に集約し、生データを直接活用できる。
OSSとしての責任も。</p>
<h3 id="データサイエンス">データサイエンス</h3>
<p>Opsだけでないデータ解析にも活用</p>
<h2 id="clouderaのビッグデータプラットフォーム戦略仮">「Clouderaのビッグデータプラットフォーム戦略」（仮）</h2>
<h4 id="講師cloudera-inc-cto-dramr-awadallah">講師：Cloudera, Inc. CTO Dr.Amr Awadallah</h4>
<p>レガシーな情報アーキテクチャ→スケールできない、可視化の限界、硬直したスキーマなどなど。</p>
<p>エンタープライズデータハブとしてのHadoopとか。</p>
<h2 id="ビッグデータの歴史と将来展望">ビッグデータの歴史と将来展望</h2>
<h4 id="講師国立情報学研究所アーキテクチャ科学研究系教授佐藤一郎氏">講師：国立情報学研究所　アーキテクチャ科学研究系　教授　佐藤一郎氏</h4>
<h3 id="ビッグデータの歴史的経緯とか">ビッグデータの歴史的経緯とか</h3>
<ul>
<li>
<p>最初の事例はアメリカの1880年国勢調査。</p>
</li>
<li>
<p>「ビッグデータがコンピュータを生み出した」。コンピュータがビッグデータを生み出したんじゃない。</p>
</li>
<li>
<p>少量データにもHadoopを</p>
<ul>
<li>バッチ処理のリアルタイム化とか（一晩から10分へ）</li>
</ul>
</li>
<li>
<p>原点は検索データのインデクシング</p>
</li>
<li>
<p>Hadoopを使うのが目的じゃないんだから、構築には手を掛けないのがいいよね。</p>
</li>
<li>
<p>プラットフォームと発展している</p>
</li>
</ul>
<h3 id="分散システム研究者から見たhadoop">分散システム研究者から見たHadoop</h3>
<ul>
<li>分散ししテムの難しさを、処理範囲を限定することで巧みに回避</li>
<li>データの近くで処理</li>
<li>研究レベルではリアルタイム化や逐次処理化が活発</li>
<li>全工程で逐次・リアルタイムが必要とは限らない</li>
<li>聞いてばかりじゃなくて、動かしてみましょう。</li>
</ul>
<h2 id="データサイエンス超並列分散処理を活用した新たなビジネス価値の創出">データサイエンス：超並列分散処理を活用した新たなビジネス価値の創出</h2>
<h4 id="講師アクセンチュア株式会社工藤卓哉氏">講師：アクセンチュア株式会社　工藤卓哉氏</h4>
<ul>
<li>「日経BPのビッグデータ総覧2013」に記事書いてる。</li>
<li>多様化するデータ（社外のデータも）をどうやってうまく活用していくか。</li>
<li>データが教えてくれたこと→まず、データありき、まずデータためましょう。それから解析とかすればいいのでは？というはなし？</li>
<li>競合他社さんはNGだけど、ブースでデモ？実機？が見れますと。</li>
</ul>
<h2 id="hadoopデータプラットフォーム">Hadoopデータプラットフォーム</h2>
<h4 id="cloudera株式会社嶋内翔氏">Cloudera株式会社　嶋内　翔氏</h4>
<h3 id="まずは宣伝">まずは宣伝</h3>
<ul>
<li>Cloudera Implaraのフリーブックの日本語版</li>
<li>Hadoop Operationの書籍でるよ</li>
</ul>
<h3 id="プラットフォームを構成するもの">プラットフォームを構成するもの</h3>
<ul>
<li>Flume</li>
<li>Sqoop</li>
<li>HBase</li>
<li>Hive</li>
<li>Impala</li>
</ul>
<h3 id="データ登録してbiアナリストのお仕事にどうやって役立てる">データ登録してBIアナリストのお仕事にどうやって役立てる？</h3>
<ul>
<li>外部テーブル：Hiveからはテーブルのように見える仕組み。元ファイルは消えない</li>
<li>SerDe（さーでぃー）：データをHiveレコードに変換する仕組み</li>
<li>生データを少し加工しましょう
<ul>
<li>圧縮したりファイル結合したりはしときましょう。</li>
</ul>
</li>
<li>Hadoop活用のポイント
<ul>
<li>富豪的プログラミング。リソースケチるな。</li>
<li>ローカルでできることはローカル。むりにHadoopでやんなくてもいいですよねと。バランス重要</li>
</ul>
</li>
<li>スケジューリング実行などはOozie使うと便利。（日次集計とか）</li>
<li>Cloudera Searchで元データにインデックス貼れるぞと。検索しながら分析ができる</li>
</ul>
<h3 id="クラスタ管理とか">クラスタ管理とか</h3>
<ul>
<li>Cloudera manager便利ですよ</li>
<li>ストレージリソースの管理。
<ul>
<li>声掛け、管理者が容量チェック、Cloudera Managerのレポート</li>
</ul>
</li>
<li>少数精鋭でHadoop使おう＝手が回らなくなる。</li>
<li>みんなで使おう＝Kerberos認証とか管理をちゃんと考えないと。けど、文化が根付けば強力。Sentry、Cloudera Navigatorとか。</li>
<li>Hadoopシステムの全体構成図。データの流れと各製品のつながり。</li>
<li>We are hiring!ということで、興味のある方は@shiumachiさんにコンタクトをとりましょうとのこと。</li>
</ul>
<h2 id="sqlで実現するバッチ処理とストリーム処理">SQLで実現するバッチ処理とストリーム処理</h2>
<h4 id="line株式会社田籠-聡氏">LINE株式会社　田籠 聡氏</h4>
<p>資料：<a href="http://www.slideshare.net/tagomoris/batch-and-stream-processing-with-sql">Batch and Stream processing with SQL</a></p>
<ul>
<li>
<p>LINEのキャラがちらほら出てきた。</p>
</li>
<li>
<p>SQL好きですか？</p>
</li>
<li>
<p>ログの量とか。2.1TB/Day</p>
</li>
<li>
<p>バッチ処理とストリーム</p>
<ul>
<li>速い集計のためにHadoopが重要</li>
</ul>
</li>
<li>
<p>エラー系のログとかはストリームで処理したい</p>
</li>
<li>
<p>アーキテクチャ説明</p>
</li>
<li>
<p>データ解析する人って色々。</p>
<ul>
<li>管理者</li>
<li>プログラマ</li>
<li>サービスディレクタ</li>
<li>経営陣</li>
</ul>
</li>
<li>
<p>みんなが集計用処理を理解、編集ができるほうがいい。</p>
</li>
<li>
<p>顔あげたらHiveアイコンだらけだったｗ</p>
</li>
<li>
<p>Shibとか。</p>
</li>
<li>
<p>なんでHiveに限るの？</p>
<ul>
<li>Hiveに着目したバージョンアップだけを考えれば良くなる。</li>
</ul>
</li>
<li>
<p>スケジュールクエリが増えてきて、つらい。</p>
<ul>
<li>TimeWindowを固定して集計処理をすることで、回避できる。</li>
</ul>
</li>
</ul>
<h3 id="norikra">Norikra!!</h3>
<ul>
<li>
<p>スキーマレス</p>
</li>
<li>
<p>OSS。Esperベース。</p>
</li>
<li>
<p>インストールが楽</p>
</li>
<li>
<p>クエリの動作のお話。</p>
</li>
<li>
<p><a href="http://norikra.github.io">http://norikra.github.io</a></p>
</li>
<li>
<p>We Are Hiring!</p>
</li>
</ul>
<h2 id="hadoop-コミュニティと-yarn-の現状">Hadoop コミュニティと YARN の現状</h2>
<h4 id="日本電信電話株式会社小沢-健史氏">日本電信電話株式会社　小沢 健史氏</h4>
<h3 id="なんでhadoop">なんでHadoop？</h3>
<ul>
<li>PostgreSQLでやってたけど、大きなデータにはHadoopを使おうという感じになってきた。</li>
<li>なんで使い分けるの？
<ul>
<li>スキーマ後付け</li>
</ul>
</li>
<li>NTTDocomoのモバイル位置情報の統計処理とか？</li>
<li>技術的な話をするので、HiveTに着替えます！ｗ</li>
<li>YARNのなにが嬉しいの？
<ul>
<li>ImpalaとMapReduceが同時に動くような環境の時に、リソースをうまく管理できないのがV1</li>
<li>そこでYARN</li>
</ul>
</li>
<li>Apache Mesosとだいたい一緒。</li>
<li>Apache MesosとYARNの比較</li>
</ul>
</content:encoded>
    </item>
    
    <item>
      <title>『プログラミング Hive』 『Hadoop 第3版』刊行記念セミナーに参加しました！ #oreilly0724</title>
      <link>https://blog.johtani.info/blog/2013/07/25/hadoop-hive-publication-party/</link>
      <pubDate>Thu, 25 Jul 2013 02:11:00 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2013/07/25/hadoop-hive-publication-party/</guid>
      <description>Hadoopとか離れちゃってるし、Hive触ったこと無いにもかかわらず参加しました！ （たまたま近くにいるからって理由なのは内緒で） 玉川さんの</description>
      <content:encoded><p>Hadoopとか離れちゃってるし、Hive触ったこと無いにもかかわらず参加しました！<br>
（たまたま近くにいるからって理由なのは内緒で）<br>
玉川さんの四方山話を聞くのが主目的で参加しました。（ちょっと翻訳が気になってるので）</p>
<p>イベントページは<a href="http://connpass.com/event/2944/">こちら</a><br>
刊行記念イベントにも関わらず、想像以上の人の入りでびっくりしました。Hadoop、Hive界隈はまだまだ人気なんだなぁと。<br>
プレゼントじゃんけん大会もあったのですが、そうそうに負けてしまったのが悔やまれます。。。<br>
Team Geek欲しかったなぁ。もちろん、懇親会まで参加しました。</p>
<p>以下、いつものメモです。</p>
<!--  more -->
<h2 id="hiveの正しい使い方cloudera-嶋内さん">Hiveの正しい使い方（Cloudera 嶋内さん）</h2>
<p>残念ながら、マサカリは持ってなかったです。</p>
<ul>
<li>スライドの各所に本の章番号が書いてあるのがうれしい。</li>
<li>Hiveロゴが回ってたのでスライドの時に集中できなかったｗ</li>
<li>Impalaの話も出てきた。
<ul>
<li>速いけど、色々足りない。Hiveの置き換えじゃないよと。</li>
</ul>
</li>
</ul>
<h2 id="hiveとimpalaのおいしいとこ取りセラン須田さん">HiveとImpalaのおいしいとこ取り（セラン　須田さん）</h2>
<p>スライド：<a href="http://www.slideshare.net/sudabon/20130724-oreilly-org">http://www.slideshare.net/sudabon/20130724-oreilly-org</a></p>
<ul>
<li>オンプレだとCDH便利だよと教えてもらう</li>
<li>いくつかSlideshareにImpalaの性能評価の資料を上げてある（必要になったら検索で。。。）</li>
<li>リリースされたその日に性能評価やってレポート書くとかすごすぎ！</li>
</ul>
<h2 id="翻訳の四方山話玉川さん">翻訳の四方山話（玉川さん）</h2>
<ul>
<li>翻訳＝写経です</li>
<li>締め切り駆動勉強法ｗ</li>
<li>4page/day</li>
<li>自分から電突してオライリーさんに翻訳させてくださいと。</li>
<li>他の方の本が読めない（チェックしちゃうのでｗ）</li>
<li>動機があるから読めるってのはあるだろうなぁ。</li>
<li>選び方：わくわくするもの、仕事に活きるもの</li>
<li>今年もあと2冊やる予定（Hadoop Operations、Vagrantを翻訳中）</li>
<li>来年の候補（Chefとか）</li>
</ul>
<h2 id="高可用性hdfsのご紹介cloudera-小林さん">高可用性HDFSのご紹介（Cloudera 小林さん）</h2>
<ul>
<li>スライドにどの版で書いてあったかがわかりやすく書いてある。</li>
<li>3段階の開発フェーズを経てる</li>
<li>QJMのお話</li>
</ul>
<h2 id="cloudera-universityとhadoop認定試験cloudera-川崎さん">Cloudera UniversityとHadoop認定試験（Cloudera 川崎さん）</h2>
<ul>
<li>Clouderaデータアナリスト向けトレーニング（3日間、10月日本語で開催予定）
<ul>
<li>Hive、Pig、Impalaなど</li>
</ul>
</li>
<li>Data Science入門コースも準備中</li>
<li>出版記念！
<ul>
<li>8月管理者向け先着20 or 30名にHadoop第3版贈呈予定</li>
<li>先着20名にプログラミングHive贈呈予定</li>
</ul>
</li>
</ul>
</content:encoded>
    </item>
    
    <item>
      <title>Cloudera Searchメモ（妄想版）</title>
      <link>https://blog.johtani.info/blog/2013/06/06/cloudera-search-memo2/</link>
      <pubDate>Thu, 06 Jun 2013 12:26:00 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2013/06/06/cloudera-search-memo2/</guid>
      <description>ざっとインストールガイドとかCloudera Searchのソース眺めて、テキトーにメモを書いてみました。 （ユーザガイドはまだ読んでないです。</description>
      <content:encoded><p>ざっとインストールガイドとかCloudera Searchのソース眺めて、テキトーにメモを書いてみました。
（ユーザガイドはまだ読んでないです。）</p>
<!-- more -->
<h2 id="ざっくりメモ">ざっくりメモ</h2>
<ul>
<li>ストリーム処理でインデックス作るときはFlume経由でSolrに
<ul>
<li>SinkとEventの両方が用意されてる？（Flumeを良く知らないので、違いがわからない）</li>
<li>FluemeからはリモートのSolrに対してインデックス登録するクラスがある。SolrServerDocumentLoaderがソレだと思う。</li>
</ul>
</li>
<li>バッチ処理でインデックス作るときはMapReduceIndexerToolsってのを使ってSolrに
<ul>
<li><a href="https://issues.apache.org/jira/browse/SOLR-1301">SOLR-1301</a>がベースになっている。色々と改良されてるようだけど、コアとなってる処理はSOLR-1301。</li>
<li>GoLiveってクラスの処理の中で、現在動作してるSolrに配布したバッチで作成されたIndexをマージする処理が書いてある。</li>
<li>HDFSへ出力されたインデックスはリモートのSolrからアクセスするとオーバヘッドとかどーなるのかなぁ？</li>
</ul>
</li>
<li>検索処理自体はHueでもできるけど、基本的にSolrCloud任せ</li>
<li>インデキシングの処理のフローについてはCloudera Mrophlinesで定義</li>
</ul>
<p>ということで、
2つの流れがありそう。</p>
<ul>
<li>HDFS→Flume→Solr</li>
<li>HDFS→MapReduce→Solr</li>
</ul>
<p>で、まだ、わかってないですが、構成要素として</p>
<ul>
<li>Hadoop（HDFS）：データソース</li>
<li>Hadoop（MapReduce）：データ変換処理、バッチインデキシング</li>
<li>Zookeeper：SolrCloudのクラスタ管理</li>
<li>Solr：インデキシング、検索エンジン</li>
<li>Flume：データをストリーミングでSolrへ</li>
<li>Coudera Morphlines：HDFSからSolrまでのETLデータ処理を定義実行する環境</li>
</ul>
<p>って感じでしょうか。
SolrCloudのクラスタとHadoopのクラスタが同一マシン上なのか、別なのかとか。組み合わせがどんなものができるのかがまだわかってないです。
ユーザガイド読んでみたらなにか出てくるかなぁ。</p>
<p>ちなみに、Cloudera SearchのgithubリポジトリにあるソースはCloudera Morphlinesのコードがメインで、SolrのHDFS対応版のソースがあるわけでは無かったです。</p>
<ul>
<li>SolrのHdfsDirectoryってのがClouderaのリポジトリにあるSolrには追加されていて、これが、HDFSのインデックスを読み込んだりする処理が出来る仕組みっぽい。</li>
<li>一応、SolrCloud以外（分散検索）も考慮された形になってるっぽい。</li>
</ul>
<p>ってとこでしょうか。</p>
<h2 id="感想">感想</h2>
<p>読んでて思ったんですが、Cloudera Searchの肝はじつは、検索じゃなくて、Morphlinesにあるんじゃないかなぁと。今はSolrが出力先ですが、
その他のデータ変換処理とかが増えてくると、処理の流れがMorphlinesで定義できてデータ変換処理が簡便になりそうな気が。</p>
<h2 id="その他に気になる観点">その他に気になる観点</h2>
<ul>
<li>CDH経由でSolrCloudのクラスタの管理するのかな？</li>
<li>SolrCloud用のクラスタとCDHのクラスタって同一マシンに載るの？別マシンにもできるの？
<ul>
<li>併存したらIOがキツそうだけど</li>
</ul>
</li>
<li>Hueで検索アプリとか組めるの？（そもそもHueがわかってないんだけど。。。）</li>
</ul>
<p>ま、とりあえず、こんなとこで。
つぎは余力があれば、ユーザガイドかなぁ。
英語力。。。</p>
</content:encoded>
    </item>
    
    <item>
      <title>Cloudera Searchのモジュールたち</title>
      <link>https://blog.johtani.info/blog/2013/06/05/cloudera-search-modules/</link>
      <pubDate>Wed, 05 Jun 2013 15:12:00 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2013/06/05/cloudera-search-modules/</guid>
      <description>Cloudera Searchは次のようなモジュールから構成されています。 これはCloudera Searchのモジュールで、さらにこれらがSolrとかを使っ</description>
      <content:encoded><p>Cloudera Searchは次のようなモジュールから構成されています。
これはCloudera Searchのモジュールで、さらにこれらがSolrとかを使ってるみたいですね。pom.xmlを見たら何を使ってるかがわかるかな。</p>
<ul>
<li>cdk-morphlines</li>
<li>search-contrib</li>
<li>search-core</li>
<li>search-flume</li>
<li>search-mr</li>
<li>search-solrcell</li>
</ul>
<p>てきとーに、README.mdみながらメモを残してみました。ソースとかはまだ読んでないです。
ざっと眺めたけど、インデキシング処理の話がメインで、検索側がどうやって動くかってのがわからなかったなぁ。
<a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/Search/latest/PDF/Cloudera-Search-User-Guide.pdf">ユーザガイド（注：PDF）</a>ってのがあるから、これを読んでみるか。。。</p>
<p>各モジュールについては、以下。</p>
<!-- more -->
<h2 id="cdk-morphlinescloudera-morphlines">cdk-morphlines（Cloudera Morphlines）</h2>
<p>Cloudera Morphlinesという名前みたい。
検インデキシングアプリの構築、変更をラクにするためのフレームワーク。
ETLの処理チェインを簡単にCloudera Searchにデータを入れる設定（Extract/Transform/Load処理）がかけると。
バッチ処理、Near Real Timeのために使えるみたい。検索結果をさらに入れるとかもできるんかなぁ。？</p>
<p>Unixパイプラインのの進化版みたいなもので、一般的なレコードに対するStream処理から、Flueme、MapReduce、Pig、Hie、SqoopのようなHadoopコンポーネントも使えるみたい。</p>
<p>Hadoop ETLアプリケーションのプロトタイピングにも使えて、リアルタイムで複雑なStreamやイベント処理やログファイル解析とかに使えるの？</p>
<p>設定ファイルのフォーマットは<a href="https://github.com/typesafehub/config/blob/master/HOCON.md">HOCONフォーマット</a>。AkkaやPlayで使われてる。</p>
<h3 id="cdk-morphlines-core">cdk-morphlines-core</h3>
<p>Cloudera Morphlinesのコンパイラ、実行環境、コマンドのライブラリを含んでる。
ログファイル解析やsingle-lineレコード、multi-lineレコード、CSVファイル、正規表現パターンマッチ、フィールドごとの比較とか条件分岐とか、文字列変換とか色々なコマンドを含んでる。</p>
<h3 id="cdk-morphlines-avro">cdk-morphlines-avro</h3>
<p>Avroファイルやオブジェクトの抽出、変換、読み込み処理コマンド</p>
<h3 id="cdk-morphlines-tika">cdk-morphlines-tika</h3>
<p>バイナリデータからMIMEタイプを検出して、解凍するコマンド。Tikaに依存</p>
<h4 id="雑感">雑感</h4>
<p>Cloudera Searchへのデータの流し込みを設定ファイルに記述して実行するとデータの変換処理とかが記述できるって感じかな？
Morphlinesのコマンドとして独自処理や使えそうな処理を作ることで、いろんな処理ができるって感じかなぁ。</p>
<h2 id="search-core">search-core</h2>
<p>Solrに対するMorphlineコマンドの上位モジュール</p>
<h3 id="search-solrcell">search-solrcell</h3>
<p>Tikaパーサを使ったSolrCellを使うためのMorphlineコマンド。
HTML、XML、PDF、Wordなど、Tikaがサポートしてるものがサポート対象。</p>
<h3 id="search-flume">search-flume</h3>
<p>Flueme Morphline Solr Sink。
Apache Flumeのイベントから検索ドキュメントを抽出、変換し、SolrにNearRealTimeで読み込むためのコマンド</p>
<h3 id="search-mr">search-mr</h3>
<p>HDFSに保存されたファイルに含まれる大量データをMapReduceで処理してHDFS上の検索インデックスに焼きこむモジュール。</p>
<p><code>MapReduceIndexerTool</code>は入力ファイルの集合からSolrのインデックスシャードの集合を作るためのmorphlineのタスクで、MapReduceのバッチジョブドライバー。
HDFSにインデックスを書き込む。
動作してるSolrサーバに対して出力されたデータをマージするのもサポートしてる。</p>
<p>とりあえず、Near Real Time検索するにはFlueme使って、バッチ処理でインデックス焼くのはMapReduceIndexerToolみたいだなぁ。</p>
</content:encoded>
    </item>
    
    <item>
      <title>Cloudera Searchってのが出たらしい（とりあえず、雑感？）</title>
      <link>https://blog.johtani.info/blog/2013/06/05/what-is-cloudera-search/</link>
      <pubDate>Wed, 05 Jun 2013 15:05:00 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2013/06/05/what-is-cloudera-search/</guid>
      <description>AWS Summitに来ていたのですが、TLでは、Cloudera Searchが賑わってました。 ということで、軽くどんなものか読んだり調べたりした</description>
      <content:encoded><p>AWS Summitに来ていたのですが、TLでは、Cloudera Searchが賑わってました。
ということで、軽くどんなものか読んだり調べたりしたメモを残しとこうかと。
英語力はあやしいので、おかしいとこがあったらツッコミを。</p>
<!-- more -->
<h2 id="cloudera-searchとは">Cloudera Searchとは？</h2>
<p>CDH4.3に対応したCDHユーザ向けの検索システム（beta版）なのかな？
CDHに統合された検索フレームワークなのかな？</p>
<p>基本はLucene/Solr 4.3でHadoopのペタバイトデータを検索することができるようになるみたいです。</p>
<h2 id="どんな仕組み">どんな仕組み？</h2>
<p>次のものを利用しているようです。（GithubのREADMEから。）</p>
<h4 id="使ってるもの">使ってるもの</h4>
<ul>
<li>Apache Solr(4.3.0＋α？)
<ul>
<li>Apache Lucene（Solrつかってるからね）</li>
<li>Apache SolrCloud（うーん、Solrに含まれるのに別に出してるのなんで？）</li>
</ul>
</li>
<li>Apache Flume</li>
<li>Apache Hadoop MapReduce &amp; HDFS</li>
<li>Apache Tika
<ul>
<li>SolrCellとしてSolrにも組み込まれてる、いろんな文書（WordとかHTMLなどなど）からメタデータと本文データとかを取り出せるライブラリラッパー。実際にはさらにpdfboxとかを使って各文書からのデータを取り出してる。</li>
</ul>
</li>
</ul>
<h4 id="何ができるの">何ができるの？</h4>
<p>HBaseやHDFSの用にZookeeperを使ってインデックスのシャーディングや高可用性ができる。（SolrCloudがZookeeperを使ってるからね。）
MapReduceのジョブの出力から自動的にSolrのインデックスにデータをマージできるらしい。
Cloudera Managerを使って、デプロイ、設定モニタリングなどが可能。</p>
<p>Flumeのフィードをつかって、ストリーミングしてインデックスを作れる。FluemeがデータをSolrに流しこむのかな？
将来的にはHiveやHBaseのテーブルをインデックスすることも可能になるらしい。Impalaクエリの結果もフィードできるのか？</p>
<p><a href="http://incubator.apache.org/blur/how_it_works.html">Apache Blur</a>ってキーワードも出てきた。HDFSのデータからLuceneのインデックス作るのかな？
NGDataのチームがSolr/HBaseの統合とかしてるみたい。</p>
<h3 id="参考url">参考URL</h3>
<ul>
<li><a href="http://blog.cloudera.com/blog/2013/06/cloudera-search-the-newest-hadoop-framework-for-cdh-users-and-developers/">Cloudera社のブログ</a></li>
<li><a href="http://cloudera.com/content/cloudera-content/cloudera-docs/Search/latest/PDF/Cloudera-Search-Frequently-Asked-Questions.pdf">Cloudera SearchのFAQ（注：PDF）</a></li>
<li><a href="https://github.com/cloudera/search">Githubのリポジトリ</a></li>
</ul>
</content:encoded>
    </item>
    
    <item>
      <title>Hadoop Conference Japan 2011 Fallに参加してきました。(Jugemより移植)</title>
      <link>https://blog.johtani.info/blog/2011/09/27/hadoop-conference-japan-2011-fall%E3%81%AB%E5%8F%82%E5%8A%A0%E3%81%97%E3%81%A6%E3%81%8D%E3%81%BE%E3%81%97%E3%81%9F/</link>
      <pubDate>Tue, 27 Sep 2011 17:51:00 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2011/09/27/hadoop-conference-japan-2011-fall%E3%81%AB%E5%8F%82%E5%8A%A0%E3%81%97%E3%81%A6%E3%81%8D%E3%81%BE%E3%81%97%E3%81%9F/</guid>
      <description>Hadoop Conference Japan 2011 Fallに行ってきました。 まずは、ユーザ会の方々、運営の方々、発表された方々お疲れ様でした。こんな機会を用意していただき、ありがとう</description>
      <content:encoded><p>Hadoop Conference Japan 2011 Fallに行ってきました。
まずは、ユーザ会の方々、運営の方々、発表された方々お疲れ様でした。こんな機会を用意していただき、ありがとうございます。
Hadoopは昨年触っていたのですが、最近は縁がなくなってしまいました。
ただ、触っていたときに面白かったので参加してきました。
ということで、今回も自分用にメモを取ったので。（今回は英語のヒアリングがあって、メモがひどい事になってます。。。）
いつものことながら、おかしいところとかあれば、ツッコミなどフィードバックをもらえると嬉しいです。</p>
<p>場所：ベルサール汐留
日時：2011/09/26 10:00～18:00＋懇親会：18:30～21:00</p>
<p>オープニングトーク：濱野、太田
　参加者：1100名超！（実際は800名弱？）
　Hadoopの経験：利用経験なしな方が580名
　カンファレンスの認知：Twitterよりも知人、その他が多かった。
　会場提供：リクルート様
　リクルート米谷様より一言。
　　Question VOTE！！サイトを用意。
　　http://mit.recruit.co.jpにて情報提供。
　※残念ながら地下だったため、E-mobileにつながらず、あと、電源確保が難しかったのでMBAをスタンドアロンにしてメモをとっていたので、
　　QAサイトにはアクセスしませんでした。もう少し活用したかったんですが、携帯でTwitterを追っかけるので精一杯。。。</p>
<p><strong>◎The role of the Distribution in the Apache Hadoop Ecosystem：Todd Lipcon（Cloudera）</strong></p>
<pre><code>
　1.Introduction
　　Todd Lipcon：Clouderaエンジニア
　　Hadoop とHBaseのコミッター
　2. Hadoop Overview
　　HDFS＋MapReduceの説明
　　Hadoopの生まれてきた経緯　
　　　様々な形式のデータが大量に存在し、データのハンドリングが難しくなってきたため。
　　　Flexible, Scalable Solutionが必要に。
　　Hadoop の2つのユースケース
　　　1.Advanced Analytics
　　　　SNS（Web）、Content Optimization（Media）、Network Analytics（Telco）、
　　　2.Data Processing
　　　　Clickstream SessionizationEngagement

　3.Cloudera Overview
　　ClouderaCustomers
　　　・Large National Bank
　　　・Web-Based Media
　　　　click-through dataや広告のログ
　　　・Wireless Telecom
　　　　大量のデータ
　　目標：大量データからビジネスを引き出すこと。
　　Cloudera Japan：トレーニング。NTTDと協業して開発支援も
　4.CDH Overview
　　100% pure Apache Hadoop
　　SCM Epress(Service &amp;amp; Configuration Manager)
　　　Free 
　　なぜ、CDHを利用するの？
　　　Linuxを利用する場合にLinux.orgからはダウンロードしないように、Hadoopも同じように提供したい。
　　　　RedHat系を目指しているみたい。
　　　様々なパッケージの依存関係が混乱を招く。
　　　　CDHならテストが終わってるものが提供されてる。
　　※SolrはLWEがLucidWorksEnterpriseがこれを目指してるのか。
　5.Cloudera Enterprise
　　Activity Monitor：Jobのパフォーマンスをリアルタイムに監視
　　SCM：設定のvalidateや管理。
　　Resource Manager：。。。
　6.まとめ
　　CDH：簡単にHadopが使えるよ。
　　SCM Express：簡単にHadoopの設定ができてフリーだよ
　　Cloudera：Hadoopに関していろいろサポートしているよ。（Enterprise用ソフトやトレーニングなど）
</code></pre><p><strong>◎About Hortonworks：Owen O&rsquo;Malley（Hortonworks）</strong></p>
<pre><code>
　1.About Hortonworks
　　2011/2月に設立
　　22人のYahooからのアーキテクトとコミッタにより設立
　2.Credentials
　　Yahooのクラスタの経験者がいますよ。
　　OSSに長けた人達によるチームです。
　3.What is Apache Hadoop
　　Hadoopの説明（別の側面が幾つかあり。）
　　Commodity Hardwareで動く
　　簡単にプログラムできる
　　典型的なアプリケーションのタグクラウド（あとでちゃんと見る）
　　HadoopのほとんどのソースコードはYahooで作られてるよ。
　　Clouderaとか目じゃないよ
　4.Hadoop @ Yahoo!
　　各種サーバや規模など
　　Science Hadoop Cluster &lt;-&amp;gt; Production Hadoop Cluster &lt;-&amp;gt; Serving Systems
　　　という構成で、いろいろやってます。
　5.Hadoop Market
　　ビジネス：ビッグデータを扱って色々やろうね
　　金融系：IT系のコストをOSSとHadoopで削減
　　技術系：
　6.Hortonworks Strategy
　　Hadoopを利用、管理しやすくするためのいろんなことをコミュニティに還元しますよ。
　　性能などについても同様。
　　トレーニングやテクニカルサポートやりますよ。
　QA：
　　Q：42Kのノードの管理ツールはなに？
　　A：手で管理してます。
　　Q：社名の由来は？
　　A：童話でHortonという名前の象の話がある。
　　Q：CDHはおすすめ？それともほかのものがいい？
　　A：※聞き取れず。。。
　　Q：500万Query/月はアドホックQueryもあるの？
　　A：幾つかのクラスタに分けて使ってる。アドホックは不明
</code></pre><p><strong>◎How Hadoop needs to evolve and integrate into the enterprise：Ted Dunning（MapR）</strong></p>
<pre><code>
　・Quick History
　・英語わからない身には辛い。。。
　Zookeeperの人らしい。
　Narrow Foundations
　　HDFSとNASの間には大きな壁があり、大きなデータを移動するのはコストが掛かる。
　Broad Foundation
　　HDFSの代わりにNAS、RDBMSの下に位置するMapRを用意
　　ど、どんな仕組み？-&amp;gt;テクニカルセッションで。
　QA：
　　Q：MapRはOSSにしないのか？
　　A：MapRで開発したものはApacheに還元はしますが、OSSにはしないよ。フリー版は提供するかも
</code></pre><p>ここで昼食。午前中からいた人にはランチボックスが提供されました。
午後からはコミュニティトラックとテクニカルトラックの2トラックがありましたが、LTが聞きたかった（それよりも英語が辛かった？）のでコミュニティトラックのど真ん中、最前列に入り浸りました。
<strong>★コミュニティトラック</strong>
<strong>◎Elastic MapReduce Amazonが提供するHadoop：大谷晋平（Amazon）</strong></p>
<pre><code>
　・Amazonとは
　　Eコマース
　　流通
　　AWS
　　の3つのサービス
　・AWS
　　Low-level、High-level、Cross Service、Tools to access services、アプリケーション
　　色々あるなー
　・Bigデータが大変な理由
　　ケタ違いのデータ量、異なる形式データ、即時性
　　現状システムはスケールしない
　　ビジネスとして成立する？
　　　成立するならすぐスケールだめならすぐ縮小
　・Hadoopとは？
　　これまでのお話。
　　スケーラブル、低価格なハード
　　誰でも入手可能で、実績多数。
　・Amazon EMR
　　AWS上でスケーラブルなインフラ上に構築が可能
　　オンプレミスからMapReduceアプリを移行可能なため、分析、解析に集中可能
　　S3からデータIN/OUTするので、データ欠損がない。
　　Hadoopそのままではチューニングやクラスタサイズ見積もりも難しい
　　　＝＞クラスタサイズを動的に拡張伸縮可能。パフォーマンス最適化もできるよ。
　　0.18、0.20が利用可能。
　　EMRはHDFSとジョブ（タスク）トラッカーを別構成にしている。
　　EC2上にMaster、Core、タスクノードを展開
　　S3にデータを格納
　　SimpleDB（KVS）を利用
　・EMR注目機能
　　ジョブフローの高速化
　　　ジョブの再起動無しにコスト/パフォーマンス比を変更可能。
　　　タスクノードを動的に増やせる
　　柔軟なデータウェアハウスクラスタ
　　　タスクノードをバッチ実行時にのみ増やせる。
　　※増減できるのはタスクノード
　　　Coreノードは増加のみ
　　EMR＋Spotインスタンスの活用
　　　コスト削減効果が非常に高い
　　　AWSの余剰リソースをリーズナブルに提供（Amazon的にもウハハだ）
　・その他の機能
　　東海岸だけだけど、スパコンレベルのインスタンスも利用可能
　　AWS上での最適化設計など
　　※ちょっと時間足りなくなってきたｗ
　・EMRの事例
　　1.Razorfish
　　　ROAS（広告費用対効果）を500%改善（すげー）
　　2.So-net
　・EMR都市伝説
　　物理vs仮想
　　　そりゃ、物理が速いよ
　　EMRの柔軟性・拡張性がセールスポイント
　　　ビッグデータは成功/失敗が読めないのもあるので、
　　　インフラに投資する部分を少なくできるよ。
　　オンプレミスが安い？
　　　いやいや、HWの購入から設定など時間かかる。
　・Beyond Hadoop
　　HadoopのIn/Out含めてスケーラブル、フレキシビリティが重要
　　運用管理の仕組みも重要
　　まだまだやってくよ。
　QA
　　Q：EMRは複数サービスから構築してるけど、一部がダウンするとどーなる？（例：SimpleDBが落ちてるとか）
　　A：ジョブはReRunしてもらうか、SimpleDBの状態をみてリカバリをしてもらう。
　　Q：上記にともない、SLAの計算は？
　　A：SLAはEMRについては定義できてない。S3などはリージョン跨いで
　　Q：S3のセキュリティが心配だが、どう考えてるか？
　　A：いままで脆弱性を晒してデータをロストしてない。
　　　　ユーザコントロールなどもできる。基本的には問題ない
　　Q：EMRでS3を使う＝Hadoopのローカリティの利点が失われるのでは？
　　A：オーバヘッドはあるが、実際のデータはS3で守られているので、HDFSが飛んでも大丈夫。
　　Q：S3からのコピーオーバヘッドはどーなるか？
　　A：Single5で少しずつor分割して全部送るも可能
　　Q：EMRはマルチテナントだけど他のユーザのネットワークの影響を受けないの？
　　A：マルチテナントだと起こる可能性がある。
　　　　M1（？）だと内部ネットワークは専有可能らしい。
</code></pre><p><strong>◎LT</strong></p>
<pre><code>
　・Hadoop and Subsystems in livedoor @tagomoris
　　ピーク時に15Gbps。
　　10ノード（36コア）
　　CDH3b2を利用
　　データマイニングではなく、ログからレポーティングをするのに利用している。
　　hadoop streaming + Hiveで実施
　　580G/dayが96サーバから来る
　　ScribeにてHadoop Streaming（Perl）でper hourでHiveにload
　　scribelineをWebサーバに入れててログ配送してくれる。
</code></pre><p>**　・Lightweight　@stanaka（はてなCTO：田中慎司さん）**</p>
<pre><code>
　　EMR以前
　　　自前20台クラスタ
　　　ジョブがあふれてきた
　　　ナマMapReduceを利用
　　　PerlでMapper/Reducerを記述（Hadoop Streaming）
　　EMR導入
　　　リソース増やせて便利！
　　　必要な台数に伸縮可能
　　　問題点：
　　　　S3にアップしないとダメ
　　　　　＝＞ログデータをS3に展開するlog2s3.plを作成。毎時実行。
　　　　起動、ジョブキック、結果改修どーする？
　　　　　＝＞Net::Amazon::EMR::Wrapperを作成した。
　　　　　　クラスタ起動、ジョブキック、クラスタ停止などできる
　　　　　作ってみて思ったこと
　　　　　　よかったところ：
　　　　　　　Perlでかける。Cronで実行可能。HiveQL便利。
　　　　　　悪かったところ。
　　　　　　　途中で失敗してクラスタ起動しっぱなしとかがある。S3にデータを展開が大変。複雑な計算がきつい。
　　　　慣れてないエンジニアにも触れるようにしたい
　　　　　＝＞Perlで書けるようにした？。
</code></pre><p>**　・HBaseでグラフ構造を扱う（開発中）：アメーバ鈴木**</p>
<pre><code>
　　自己紹介@brfrnl69
　　アメーバのソーシャルグラフ
　　　基本はMySQL
　　　マスタ分散が難しい、シャーディング管理が面倒
　　　　＝＞HBaseでやってみるか。
　　目的　
　　　グラフデータに対して高速に更新追加したい。
　　　隣接ノードが取れればいい（これを高速化したい）
　　　オンライン処理したい
　　　運用コストの削減したい。
　　Not目的
　　　マルチホップはどうでもいい。
　　アーキテクチャ
　　　JavaでGatewayつくってみる。
　・Large-Scale Graph Processing：井上さん（@doryokujin）さん
　　Map/Reduceではグラフ計算だめ？
　　　Vertex基本だとShuffleに問題ががが。
　　BSPの紹介
　　　Bulk Synchronous Processing
　　Google Pregel 
　　SSSP：MapReduce Model
　　　すごい計算時間が掛かりそう。MRの組み合わせが何回回ることやら。
　　　枝が少ないとこっちのほうがいいのか？
　　SSSP：PregelModel
　　　シンプルなアルゴリズム
　　Pregel使えるのあるの？
　　　Hama
　　　GoldenOrb
　　　Giraph
　　　　YERN？YARN？
</code></pre><p><strong>◎リクルート式Hadoopの使い方：石川（リクルート）</strong></p>
<pre><code>
　@ground_beetle
　・導入の課題点
　　バッチ処理時間対策のため。
　　　＝＞実は入れたかっただけｗ
　・導入の障壁
　　現行システムへの影響＋開発工数
　　　＝＞これへの対処がこのあとの話
　・課題の克服と活用シーン
　　Azkaban知らなかった。ジョブスケジューリングツール
　　Hadoop単体ではなく、エコシステム（関連ツール）が魅力
　・活用シーン：Hive
　　SQLゆーがざ多く、HiveQLがSQLライクのため導入が簡単に！
　　既存機能のリプレイス系案件に活躍（低工数＋簡単に高速化）
　　とりあえず、Hive実装
　　　＝＞性能アップのためにMapReduceで書きなおし
　　Hotpepperなどのアトリビューション分析に利用
　・活用シーン：Sqoop＋Hive
　　RDBとHadoop連携のツール：Sqoop
　　現行システムの横にHadoopを配置でき、RDBMSの利点も利用しつつHiveも利用できるようになる。
　　　（※気を付けないといけないけどねぇ。）
　　ゼクシィで活用しようとしてるところ。
　・活用シーン：Mahout
　　マイニング用ツール
　　カーセンサーのレコメンド（同時に閲覧される車種）
　　アソシエーション分析＋クラスタリング
　・活用シーン：BIツールの導入
　　何度か導入しようとして失敗してます。。。
　　BIツールの前処理（クレンジングなど）にHadoopを活用
　・インフラリソースは？
　　全部で118台。
　　最小のクラスタ構成はサーバ6台で構成してる
　・Hadoopで複数処理を回す方法
　　ここまで紹介したものを入れてますよ。Hive、Sqoop、Solr。。。
　・Azkaban
　　TomcatにWar配置で利用可能。
　　LinedInのチームにより作成
　※若干マシントラブルで中断
　・今後のHadoop導入
　　ログ基盤
　　分析エンジン・レコメンドエンジンとして
　　バッチ処理短縮＝トライアンドエラーが簡単にできるようになる。＝色々な気づきが出てくる。
　　アジャイル的な解析が可能に。
　・開発サイクルの短縮ができるエコシステムでビジネスが回りだす。
　・今後の展開
　　MapRが気になってる。
　　　マルチテナント対応ができてうはうはできそう。
　　　EMCと共同して検証中

　QA：
　　Q：性能監視ツールの選別の理由は？
　　A：Zabbix、Cactiです。今から利用しようと思っている段階。
　　Q：CDH、GreenPlum、Apacheをそれぞれ利用してるけど、使い分けのシーンは？比較は？
　　A：CDH3u0です。GreenPlumは使ってないです。理由は言うとクビが飛ぶ可能性ががが。
　　Q：高度なデータ分析ができる技術者はどこからヘッドハントしてるの？
　　A：MITに別途分析チームが存在し、高度な分析をしてくれる。
　　Q：NameNodeの冗長化はどーやってんの？
　　A：象本と一緒DRBD＋HeartBeat
　　Q：EMRの導入を検討してる？
　　A：今後、サーバ数が多くなると導入の検討をしていくと思う。
　　　　現時点は、運用ノウハウも入手するために社内で使ってる。
　　　　EMRになるかRCloud（リクルート社内クラウド）になるかは不明。
　　Q：HBaseを利用してる？
　　A：してないです。スペック的にサーバが買ってもらえないと厳しいです。
</code></pre><p><strong>◎The history and the future of Hadoop use case at Rakuten：Tarje Marthinussen（楽天）</strong></p>
<pre><code>
　・Introduction（self、rakuten）
　　NextGeneration Search Group
　　Norwayから来ましたよ。
　・RakutenのBigDataとは
　・Hadoop at rakuten　
　　Recommendation（2009）
　　ProductRanking、GenreRanking、Log解析、（2010）
　　Enhance Search。。。（2011）
　・PigやHiveのようなものが簡単に利用できるようになってきた
　・新しい検索プラットフォームを構築中
　　index 10k docs/sec
　　search 400qps
　・What's Next Generation Search
　　20%はインデックスとQuery評価の
　　50%がデータの前処理（データとQuery）
　　30%がアナライズ
　・Collecting Data？
　　ログの取得はバッチ処理だった。これをStreamingに（Flume）
　・Flume
　　Zookeeperを利用してFlumeを管理してる？？？
　・気になる部分があったので、改善のコーディングしてるよ。
　　・セキュリティ
　　　マスタで管理できるように
　　・Pools
　　　Agentが送信先がコケてると他のPoolにスイッチ可能に。
　　・MasterlessACKs
　QA
　　Q：パッチ作成は何人でやってるの？
　　A：50人が働いていてOSSコミッターが何人いるかはわからんです。
　　Q：ログはテキストだけど、パース処理はどこで？（古橋さん）
　　A：Flumeは各ノードでうまい構成になっていて
　　　　Decorator
　　　性能問題は？
　　　HiveはJSONデータをうまく活用できてるよ。
　　Q：Masterlessとそうじゃないバージョンの性能比は？
　　A：ノード数が増えると
　　Q：HBaseじゃなくてCassandraなの？
　　A：（※英語きつい。。。聞き取れず）
</code></pre><p><strong>◎マーケティング向け大規模ログ解析事例紹介：原謙治（NTTコミュニケーション）</strong></p>
<pre><code>
　・自己紹介
　・BizCITYというクラウドサービスを展開中
　　まずは、宣伝。
　　Bizストレージ、Bizマーケティングとして大規模データ、分散処理を実施してる。
　・Hadoop in Bizマーケティング
　　CGMデータを解析して口コミ情報抽出
　　アクセスログから行動情報抽出
　・Hadoop in BuzzFinder
　　CGM DBからHDFSにインポートして解析開始。DBはPostgreSQL
　　処理フローは資料参照。
　　リッチインデクシング技術（NTT研究所が開発した日本語解析技術）
　　※検索インデックスってどんなものなんだろう？
　　ポジネガ分析気になる。
　・Fast Map-Reduce for PaaS Services
　　アクセス解析やマーケティング解析を行う上でShuffleコストが大きくなるため大量マシンが必要
　　　＝＞マシン数を減らすことが目的？
　　Map Multi-Reduce、PJoinはNTT研究所が開発した技術！？（子象本にないっけ？？）
　　　＝＞Multi-Reduce。同一ノード上のMap出力をReduceすることで、shuffleフェーズに渡るデータを削減している。
　　　　＝＞PJoin　
　QA
　　Q：Map multi-reduce、PJoinはどう実現してるのか？公開するのか？
　　A：Hadoopの0.19に改造をしてる。
　　　　公開できるかどうかはわかりません。NTT研究所が研究しているものを試しに実装してみてるから。
　　　　なのでパッチにはなりませんかね（研究所に聞いてみないとわからないっす）
　　Q：性能が向上したパターンはあったが、悪化する場合などはあるのか？
　　A：不明
　　Q：Map-side Joinとの違いは？
　　A：。。。
※この辺で少し集中力が途切れてしまいました、すみません。（次に集中したかったので。。。）
</code></pre><p><strong>◎ミクシィにおけるHadoopの利用：伊藤敬彦（mixi）</strong></p>
<pre><code>
　LSH-Based Recommendation engine powered by hadoop
　・実はmixiの話はすくないよ。
　・利用している環境。5or6台/クラスタ
　・Hadoopの活用
　　ログデータをHDFSに保存
　　DBコンテンツをHDFSに入れることで、DBに負荷をかけずに解析する。
　・マイニングも検証中
　　検索クエリログをベースにデータマイニング
　では、本題。
　・LSHを利用した推薦
　・推薦とは？
　　mixiにはいろいろ推薦（レコメンド）を付加できるサービスがある。
　・推薦するには？
　　類似インスタンス集合を抽出する。
　　インスタンスは文書だったりユーザだったり
　・類似インスタンスとは？
　　同じ特徴を持つ集合
　　例：同一商品購入したユーザとか同一単語を持つ文書とか
　・抽出するには？
　　全ユーザごとに全ユーザとの類似性をチェックすると時間がかかりすぎる！
　　＝＞LSHを利用しよう！
　・LSHについて
　　特徴：
　　・速い！
　　・精度はそれほどではない
　　事例：
　　・Google Newsのレコメンド（USロケール）
　・LSHの処理ステップ
　　2つだけ。
　　1.インスタンスベクトルを計算（似ているデータは同じ値が返りやすい関数）
　　2.同一値が帰ってきたデータが類似インスタンス
　・インスタンスベクトル例（あとでスライド見ようね）
　・Likelikeがいち実装。Hadoopでうごくよ
　・実験について
　　トップページに表示されていない記事を知ってもらうために推薦してみるぞ！
　・実験１
　　性能を測ってみた
　・実験２
　　精度を調べてみた。
　　精度はほんとにひどいな。。。
　　＝＞同一カテゴリの遷移を元に計算したらそれなりになってきた。
　・今後
　　データソースを増やしたい。
　　他のアルゴリズムも実装したい
　・CM
　　以下も作ってますよ。
　　Oluolu
　　Anuenue

　QA
　　Q：Mahoutは使わないんですか？
　　A：Likelikeを作った頃にMahoutになかったので作った。
　　　　性能比較したいと思ってる。
　　Q：ログサーバのデータ転送はどーやってる？
　　A：伊藤さんのところにはどういう仕組みかは上がって来てない。

　　Q：ベクトルの次元数はどのくらいまで耐えられる？
　　A：高次元のデータに対して耐えられるように作られてる。
　　　　次元数が低くて良い制度が欲しければ他のアルゴリズムがいいかも。
　　Q：ユーザのベクトルを作るテクニックは？
　　A：画像などであれば大変だけど、ユーザであれば、単語とかキーワードとかで

　　Q：ニュース以外のデータは？
　　A：まだまだ実験中。まだやってない。

　　Q：推薦される記事数のばらつきはどういった理由が考えられる？
　　A：後ほど考察してQAサイトに入れます。

　　Q：LSHをMapReduceに載せたということだけど、関数の計算をさせてる？
　　A：Iterationはしてない。
　　　Map側でLSH関数計算してる。Reduceにて類似インスタンスを導出してる。

　　Q：今後の予定の空間木とは？R-Treeだと高次元できついのでは？
　　A：低次元にて利用できるように用意したい。
　　　
　　Q：HamaとかGiraphで高速化させてみるのはどう？
　　A：イテレーションがいらないからあまり利用用途がないかなぁ。
</code></pre><p><strong>◎懇親会</strong></p>
<pre><code>
　AWSを採用しない企業がいくつかあったのでそのあたりを質問してみた。
　AWSは通常運用に利用すると結構なコストがかかる場合があるので、ノウハウがある企業や
　データ量が多い場合は、オンプレミスの場合を選択しているらしい。
　やはりスポットで利用する方がお得感があるみたいだった。
　Twitter上だけの知り合いだった方々と面識が持てたのが一番の収穫でした。
</code></pre><p><strong>感想＋調べること</strong></p>
<p><strong>感想</strong></p>
<pre><code>
　会場規模とかQAサイトとかオープニングムービーとかすごかったです。しかも無料。さすがリクルートさん。
　ランチボックスとか出てきたし。装飾もとても無料のカンファレンスと思えない出来でした。
　午前中はHadoopをもとにした各社の戦略とCMという感じが色濃かったです。少しずつ各社の立ち位置が違いそれはそれで面白かったです。

　AWSの説明を聞いてやはりAWSを扱える技術は必要だと再認識。
　お金かけないで触ってみれるレベルでまずは触ってみるかなぁ。
　洗脳されてるのかもしれないけど、自社or自前でHadoop運用するのは厳しそうです。（懇親会ですこし認識が変わった）

　カフェコーナーでは、リクルートのMITの冊子が配られていたり、映像や案内に使われていたHadoopマスコットのシールが配られていたりと小技も聞いてました。
　あと、オライリーの販売コーナーも用意されていて、思わず子象本を買ってしまう罠にはまったりもしましたが。。。

　mixiの伊藤さんの話は最後で疲れていたのですが、ストーリーが上手くできていて、実験や事例もあったのでわかりやすかったです。
　Hadoopはエコシステムと呼ばれるHadoopを活用するツール群（Hiveの話が多かった？）、Hadoopの今後、Hadoopを活用したログ解析の話など、
　話題が豊富でそれぞれの話が面白くて困ってしいまうくらいです。
　いくつかのセッションで出てきたのですが、アクセスログなどをHDFS上に集めるための仕組みがまだ乱立（定番がまだない）している感じを受けました。
　Flume、Scribe、MapR。。。などなど

　あとは、テクニカルセッションのビデオがアップされたらまた目を通さないと。。。
　残念ながらHadoopから少し縁遠くなっていますが、これからもネタや参考になりそうな話には事欠かなそうなのでかじりついていこうと思います。
　※一番やらないといけないのは英語の勉強かもしれないです。。。
</code></pre><p><strong>調べること</strong>
一応Solrの人なので、Solrに関連しそうな話に興味がいってしまいます。</p>
<ul>
<li>NTT研究所のリッチインデクシング技術</li>
<li>やっぱりAWS触ってみる。EMRまでとは言わないが。（herokuもちょっと興味あるが。）</li>
<li>Mesos、GreenPlum、Scribe、Storm、Flume、Giraphこれらの概要</li>
</ul>
<p><strong>関連サイト</strong>
　<a href="http://mit.recruit.co.jp/hadoop/conference2011fall/SES000000001?pno=1">公式QAサイト</a>。後日録画していたセッションがアップされるそうです
　<a href="http://d.hatena.ne.jp/okachimachiorz/touch/20110927/1317076207">Hadoop Conferene Japan Fall 2011 - 急がば回れ、選ぶなら近道</a>
　<a href="http://itpro.nikkeibp.co.jp/article/NEWS/20110926/369421/?ST=cloud&amp;P=1">Hadoopカンファレンスが開催、本格普及を見据えた支援サービスや先進事例が充実 - ニュース：ITpro</a>
　<a href="http://infra-engineer.com/hadoop/hadoop-conference-japan-2011-fall%E3%81%A7%E4%BD%BF%E7%94%A8%E3%81%95%E3%82%8C%E3%81%9F%E8%B3%87%E6%96%99%E3%82%84%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8D-hcj11f/">Hadoop Conference Japan 2011 fallで使用された資料 #hcj11f | インフラエンジニアのつぶやき</a>（スライドをまとめてくれてます。）</p>
</content:encoded>
    </item>
    
    <item>
      <title>Hadoopを中心とした分散環境での開発方法論・モデリング・設計手法等についての座談会(第5回）に参加しました。(Jugemより移植)</title>
      <link>https://blog.johtani.info/blog/2011/06/29/hadoop%E3%82%92%E4%B8%AD%E5%BF%83%E3%81%A8%E3%81%97%E3%81%9F%E5%88%86%E6%95%A3%E7%92%B0%E5%A2%83%E3%81%A7%E3%81%AE%E9%96%8B%E7%99%BA%E6%96%B9%E6%B3%95%E8%AB%96%E3%83%A2%E3%83%87%E3%83%AA%E3%83%B3%E3%82%B0%E8%A8%AD%E8%A8%88%E6%89%8B%E6%B3%95%E7%AD%89%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E3%81%AE%E5%BA%A7%E8%AB%87%E4%BC%9A-%E7%AC%AC5%E5%9B%9E%E3%81%AB%E5%8F%82%E5%8A%A0%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F/</link>
      <pubDate>Wed, 29 Jun 2011 23:10:00 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2011/06/29/hadoop%E3%82%92%E4%B8%AD%E5%BF%83%E3%81%A8%E3%81%97%E3%81%9F%E5%88%86%E6%95%A3%E7%92%B0%E5%A2%83%E3%81%A7%E3%81%AE%E9%96%8B%E7%99%BA%E6%96%B9%E6%B3%95%E8%AB%96%E3%83%A2%E3%83%87%E3%83%AA%E3%83%B3%E3%82%B0%E8%A8%AD%E8%A8%88%E6%89%8B%E6%B3%95%E7%AD%89%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E3%81%AE%E5%BA%A7%E8%AB%87%E4%BC%9A-%E7%AC%AC5%E5%9B%9E%E3%81%AB%E5%8F%82%E5%8A%A0%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F/</guid>
      <description>「Hadoopを中心とした分散環境での開発方法論・モデリング・設計手法等についての座談会(第5回）」に参加しました。300名入るイベントルー</description>
      <content:encoded><p>「<a href="http://www.zusaar.com/event/agZ6dXNhYXJyDAsSBUV2ZW50GNc_DA">Hadoopを中心とした分散環境での開発方法論・モデリング・設計手法等についての座談会(第5回）</a>」に参加しました。300名入るイベントルームでしたが、後ろの方まで人が埋まっていました。<br />
ということで、主に自分用ですが、メモを取ったので。<br />
※二次会行きたかった。。。<br />
<br />
<br />
1.「鉄道システムへの誘い」<br />
　@ayasehiro（本名無理w）<br />
　Hadoopの話はありません。<br />
<br />
　○鉄道系基幹システムの開発<br />
　　実態：<br />
　　　耐用年数：１０年以上<br />
　　　開発期間：数年～５年程度<br />
　　　開発規模：～10Mステップ、10k人月～<br />
<br />
　　ほとんどテスト、しかも異常系が主体。<br />
　　夜間に実際に鉄道を走らせて試験したり。<br />
<br />
　　開発サイクルが長い<br />
　　　人材育成が難しい、ノウハウがたまらない。<br />
<br />
　　開発自体はほとんど時間がなく、設計・製造・試験など新規技術の採用が難しい。<br />
　　開発４年前の調査・検証自体が２年程度。<br />
　　Hadoopも調査中。<br />
　　<br />
　○鉄道システム３大システム<br />
　　マルス（予約オンラインシステム）（1960～）<br />
　　コムトラック（運行管理システム）（1972～）<br />
　　ヤックス（ヤード自動化システム）（1968～1984）<br />
<br />
　○鉄道輸送システムとは<br />
　　用語：<br />
　　　運行を計画する=&gt;輸送計画<br />
　　　列車を運行する=&gt;運行管理<br />
<br />
　　需要想定＋営業施策＋その他（お召し列車など）＝列車ダイヤ作成<br />
　　　基本計画（長期）＋短期計画（数日～四半期程度）＝列車ダイヤ（重ねあわせてできあがり）<br />
<br />
　　ダイヤの計画（発車時刻など）と車両運用（車両自体の走る組み合わせ（仮の車両））の作成<br />
　　＋乗務員運用（乗務員の運用計画）<br />
<br />
　　運行管理：<br />
　　　なにも起きなければすることなし。（車両故障、天候、人身事故などによる整合性を取る作業）<br />
　　　＝事前に計画した輸送計画をすべて見直し<br />
　　　遅延の検知は？<br />
　　　　昔：人による伝令<br />
　　　　今：システムによる検知（レールに電流流して検知）<br />
<br />
　　　運転整理（実際に遅れた）：<br />
　　　　部分運休、折り返し駅の変更などにより対応<br />
　　　　元の計画になるべく近づく形で修正していく。<br />
<br />
　　　新幹線、山手線、京浜東北線などは速度信号という信号が表示される。<br />
　　　線路上に信号はないらしい。<br />
<br />
　○鉄道システムを取り巻く情勢<br />
　　少子高齢化・人口減少のため凋落産業となっている。<br />
　　社会インフラの責務＝動くのが当たり前<br />
　　2007年問題（ベテランの引退）＝スジ屋さんは最近いないらしい。<br />
　　高度な判断支援をするシステムが必要<br />
　　　連続稼動＝分散技術を適用できない？<br />
　　　関係各所との情報共有<br />
　　　計画立案のための情報支援＝最適化技術を適用できない？<br />
　　<br />
　○分散処理技術の適用<br />
　　個人的な感想<br />
　　　可用性（連続稼動）のための仕組み<br />
　　　バッチ処理<br />
<br />
　○分散技術の適用<br />
　　・連続稼動<br />
　　　active-active構成がメイン<br />
　　　　主系の出力だけを行う。問題が出れば副系の出力。<br />
　　　3系統の出力を比較器にて出力もある<br />
　　　　magiシステム<br />
　<br />
　　　問題点：<br />
　　　　ハードが高い（H社）<br />
　　　　ソフトウェアの作り込みが複雑＝テストが前パターンできない<br />
　　　解決案：<br />
　　　　汎用的なハードが使いたい。<br />
　　　　作り込みも減らしたい<br />
　　・バッチ処理：<br />
　　　Asakusa使えないかなーw<br />
<br />
　○最適化技術の採用<br />
　　コンピュータ技術の発展<br />
　　2007年問題<br />
　　　職人に言わせれば最適化はいらない、俺の言うことを聞けｗ<br />
<br />
　　・車両運用のモデリング<br />
　　　車両数大=&gt;組み合わせ大<br />
　　　制約条件が多い<br />
　　　車両運用の場合、走行累積キロの条件もある<br />
　　　-&gt;有向グラフにモデル化される。（ただし、グラフ化するまでが大変）<br />
　　・乗務員運用のモデリング<br />
　　　車両と違い、乗務員は1回で2人とか運べる（運転士＋移動する人とか）<br />
<br />
　　・車両割当のモデリング<br />
　　　やはり、グラフ化が可能<br />
<br />
　　・乗務員交番のモデリング。。。など<br />
<br />
　　結構一般的なモデルに落とし込める。ただし、落し込みが大変。<br />
　　机上研究だったものが、コンピュータの発展により実証研究になりつつある。<br />
　　<br />
　○まとめ<br />
　　鉄道システムはまだまだ未到の領域が残っている。<br />
　　開発サイクルが長いため、保守的な開発になる（35年前の設計思想からあまり変わってなかったりする）<br />
　　しかし業務要件やシステム利用者の意識は変化している<br />
　　<br />
　　興味を持たれた方は、ぜひ、我社に！（社名は2次会でｗ）<br />
<br />
　○Q&amp;A<br />
　　Q：鉄道システムのカルチャーってイケイケ？保守的？（@okachimachiorgさん）<br />
　　A：最新技術も知らないとだめじゃないかという人が出てきている。<br />
　　　 コア部分（安全第一なところ）＋周辺領域（ある程度融通が効きそうな部分）と考えることができるんじゃないかって人も出てきている。<br />
　　　 JR九○＝先進的<br />
　　　 JR四○、北○道＝お金ない<br />
　　　 JR○海＝超保守（企業的に超保守）<br />
　　　 JR東、西＝うーむ？<br />
　　　 東京メト○（運行計画）、阪○＝先進的<br />
　　　 京○急行＝基本人間で進路制御w<br />
　　　基本的には新しいものには興味をもつ人たちでは。<br />
　　Q：Su○caとかで分散処理は利用出来るんでは？<br />
　　A：匿名なので外側から見ていると分散処理はいろいろ使えるんでは？<br />
　　　 ログデータからいろいろできるんじゃないの？活かすべきでないの？<br />
　　　 使いどころはいっぱいある。<br />
　　Q：鉄道システムでどうしようもなくなったことはあるか？<br />
　　A：保守体制が一番気になる。<br />
　　　 OSSとかならまだ調べられる。ミドルウェアなどの保守契約が必要。<br />
　　　 保守体制が確立されてればある程度の保守費用は飲み込む。<br />
　　　 どうしようもないことはないが、今すごく困ってることは<br />
　　　 Excelで帳票を出したいとかいわれること。（ちょっと前に作ったシステムでExcel2003。バージョンあげると速度が遅くなったりするｗ）<br />
　　　 ilog社のものを使ってたが、IBMに買収されて保守費用があがってこまってるｗ<br />
　　　 保守が10年と長いため、サポートなどの折衝が必要。<br />
　　Q：最適化の適用範囲は？<br />
　　A：走行順序（どこで追い抜くか）の算出に活用。ほぼ完成でユーザ教育中。<br />
　　　 1列車の波及がかなり影響が出る。ダイヤだけ見ると列車だけだが、乗務員も関係しており、大変。<br />
　　　 ある時点から終電までを最適化の対象としたりして割り切っている。<br />
　　　 また、不足分について算出が出来れば、そこで打ち切ったりもする。<br />
<br />
2.「九州電力におけるHadoopの取り組みについて」<br />
　株式会社キューデンインフォコム e－ビジネス部　@hisashi_yano<br />
　概要：2年間関係したOSSをメインにしたシステムの話。<br />
<br />
　○九州電力の概要<br />
　　現在風当たりが強い業界。<br />
　　東電の1/10くらい<br />
　　部門ごとに大手ベンダーが関わってる。<br />
<br />
　○Hadoop採用の経緯<br />
　　部門ごとに個別最適なシステムを導入していてベンダーロックインされてる。<br />
<br />
　　　　・ホストのリプレース<br />
　　・両現用センター構成への対応<br />
　　・スマートグリッドへの対応<br />
<br />
　　問題点<br />
　　・コスト削減<br />
　　・技術革新への中の人の対応（内部でも問題を理解できるように）<br />
　　・商用パッケージのカスタマイズの限界<br />
　　・脱ベンダーロックイン（実は楽なんだけど。。。）<br />
<br />
<br />
　○過去2年間の研究内容<br />
　　・H21年度の結果<br />
　　　テーマ：クラウドの要素技術の研究<br />
　　　　KVM、Eucalyptus、wakame、hadoop　　　<br />
　　　<br />
　　　性能比較：VMWareとKVM-&gt;ベンチマーク比較<br />
　　　　　結論：性能的にあまり問題なし。<br />
　　　MapReduceの耐障害性など<br />
　　　　　ダミーデータにより台数増加による影響を検証<br />
　　　　　結論：台数大-&gt;性能向上<br />
　　　　　　　　ストリーミングは性能劣化する<br />
　　　　　　　　スループットはリニアに向上<br />
　　　　　信頼性は？<br />
　　　　　　実行中にノードを抜いたりして検証。<br />
　　　　　結論：問題なし。<br />
　　　クラウド環境におけるシステム管理手法<br />
　　　　複数ハードで1アプリという構成になる。<br />
　　　　監視対象が膨大になる。<br />
　　　　障害発生時の切り離しや監視対象も膨大。<br />
　　　　データセンター自体を監視する仕組みが必要では？というところで終了。<br />
<br />
　　・H22年度の結果<br />
　　　分散に特化した研究<br />
　　　前年度の課題<br />
　　　　サーバの仮想化・管理に関する課題<br />
　　　　分散処理に関する課題<br />
　　　　分散処理環境の運用監視に関する課題<br />
　　　目的：<br />
　　　　Hadoopを本番への適用（実際にはダミーデータ＋本番の仕組み）<br />
　　　<br />
　　　柔軟なサーバ統合基盤（サーバを起動-&gt;バッチを起動-&gt;回す仕組み）＝MonkeyMagic<br />
　　　　libvirtを使ってる<br />
　　　　<br />
　　　50台の仮想サーバの起動が10数分で完了。<br />
<br />
　　運用監視基盤（monkey magic）<br />
　　　仮想、実サーバ混在の監視<br />
　　　監視状況（サーバの状況）から判断して制御する仕組みを構築<br />
　　　DSLにてルール（判断＋制御）を指定<br />
　　　・ジョブの監視<br />
　　　・ジョブの実行管理<br />
　　　・構成管理の省力化<br />
　　　　volanteと連携が可能＝AmazonWebServiceとも連携可能<br />
　　　・サーバリソース＋アプリケーションの一括監視が可能<br />
　　分散バッチ処理の概要<br />
　　　RDBからKV形式にして抽出し、MRで回してRDBに戻すという研究<br />
　　　対象：<br />
　　　　配電部門（電柱の設備情報の目視検査）のデータの月間バッチ処理<br />
　　　現状：<br />
　　　　19時間程度かかってる。<br />
　　　テスト環境：<br />
　　　　実サーバ2台（仮想10台）<br />
　　　　MySQL、Javaで実装<br />
　　　処理内容<br />
　　　　電柱104万本<br />
　　　　巨大バッチを分割して実装<br />
　　　結果<br />
　　　　MySQL1台では15日以上かかる処理（現行システムで19時間）<br />
　　　　処理が32分で終了！他でも効果でるよね。<br />
　　　バッチ短縮の理由は？<br />
　　　　1.データアクセスが分散された<br />
　　　　2.処理の並列化（多重化出来る部分がうまくできた）<br />
　　　<br />
　　分散処理を書くのに2名死亡。。。<br />
<br />
　　適用基準の策定、開発ガイドライン、フレームワーク整備などが必要。<br />
<br />
　・H23年度は？<br />
　　Asakusaの適用など。<br />
<br />
　・さらに今後は？<br />
　　スマートグリッドへの適用<br />
　　　-&gt;メーターの交換が必要だが、10年くらいかかる<br />
　　　-&gt;スパンが長い（10年）ので商用製品だときつい？<br />
　　　データ量も半端ない。<br />
　　　テネシー州とClouderaでOpenPDCってのやってるらしい。<br />
　　<br />
　　電力と気温の関係は密接な関係あり。<br />
　　　エアコンが割合を占めてるから。<br />
　　　過去実績と予想気温データから分析するのにHadoop使える！<br />
　　　<br />
　・2年間やってきて思うこと<br />
　　将来目指すべき理想像を掲げるのが重要<br />
　　新技術導入は段階を踏むことが必要<br />
　　コミュニケーション大切！<br />
<br />
　○Q&amp;A<br />
　　Q：仮想化環境のオーバヘッドは？（I/O）<br />
　　A：台数を増やしたときにどうなるか？というのを検証したかった。<br />
　　　アプリ配布も考えていたので、物理サーバに縛られたくなかった。<br />
　　Q：仮想化に関して気をつけたM/RのPGで気をつけたことありますか？<br />
　　A：まったくないです。<br />
　　Q：日本でスマートグリッドははやるの？<br />
　　A：電力会社的にはやりたくない。費用対効果があまりない。<br />
　　Q：今後のスケジュールは？<br />
　　A：文書管理システムの組織名変更などの処理時間が540時間とかでてくるらしい。<br />
　　　これをHadoopで対応してみようかと思ってる。<br />
　　Q：Asakusaをどう評価していくのか？<br />
　　A：開発効率性があがるか？は検証する予定。1/3くらい楽になるんじゃないかなぁ？byのぐちさん<br />
　　　バッチの種類などにもよると思うが、標準化も指標にする予定。<br />
　　　結果はまたこの場で報告する予定。<br />
　　Q：Asakusa＋MonkeyMagicの連携はどんなこと考えてる？<br />
　　A：MonkeyMagicを運用基盤として行く予定。合意が取れればだけど。<br />
　　※MonkeyMagicもOSSにするよー<br />
<br /></p>
<h3 id="まとめbr-">まとめ<br /></h3>
<p>Hadoopから少しずつ離れつつありますが、やはり興味があるので、非常に楽しく話を聞けました。<br />
また、今回はインフラ分野のシステムということで、システムに要求されるレベルや<br />
運用周りにも気を配っている話が聞けたのが収穫でした。保守期間が長いため、テストが長い＝<br />
運用もしっかりと考慮を入れた設計、実装が必要になるというのは最もだと思います。<br />
ただ、少しずつ修正が入るアジャイルなども同様かと。<br />
<br />
MonkeyMagicが出来上がってきた背景の話を聞いて、さらに興味が湧いてきたところです。<br />
今後もかかわりが少ないかもしれないですが、ウォッチしていきたいと思いました。<br />
<br />
ただ、興味あるモノが多すぎるので、優先度をつけつつこなして行かないと。。。<br />
少しずつでも身につけていきたいと思う今日このごろです。<br />
<br />
<br />
※追記：Twitterでコメントを頂いたので、忘れないように追記。<br />
コメントを貰えるだけでもうれしい。やはり、アウトプットしたらフィードバック貰いたいし。<br />
ありがとうございます！<br />
<br />
<a href="http://twitter.com/#!/cocoatomo/status/86124705140047872">Twitter / @cocoatomo: あの質問をまとめるとこうなるのかぁ…… 最適化そのも &hellip;</a><br />
<br />
<a href="http://twitter.com/#!/cocoatomo/status/86236412344680448">Twitter / @cocoatomo: @johtani すみません, コメントはコメント欄 &hellip;</a><br />
<br />
<a href="http://twitter.com/#!/cocoatomo/status/86236865174323200">Twitter / @cocoatomo: @johtani そこらへんの理論って最後には計算量 &hellip;</a><br />
<br />
<a href="http://twitter.com/#!/cocoatomo/status/86281140184432641">Twitter / @cocoatomo: @johtani あの話し振りだとどうもまだ本格的に &hellip;</a><br />
<br />
あと、まとめも出来ていたので、ついでに。<br />
<a href="http://togetter.com/li/155628">Togetter - 「2011/06/29_Hadoopを中心とした分散環境での開発方法論・モデリング・設計手法等についての座談会(第5回） #hadoopmodeling」<a/><br />
<br />
関連するブログも見つけたので。<br />
<br />
<a href="http://blog.goo.ne.jp/hishidama/e/a6c5ae00a7a1bacbc88e023691a2eb0c">第5回Hadoop座談会の感想 - ひしだまの変更履歴</a><br />
<br />
<a href="http://d.hatena.ne.jp/torazuka/20110629/hadoop">Hadoopモデリング座談会（第5回）へ行ってきました - 虎塚</a></p>
</content:encoded>
    </item>
    
  </channel>
</rss>
