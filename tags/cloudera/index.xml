<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cloudera on @johtaniの日記 3rd</title>
    <link>https://blog.johtani.info/tags/cloudera/</link>
    <description>Recent content in Cloudera on @johtaniの日記 3rd</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Thu, 07 Nov 2013 10:11:00 +0900</lastBuildDate><atom:link href="https://blog.johtani.info/tags/cloudera/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cloudera World Tokyo 2013に参加しました！ #cwt2013 </title>
      <link>https://blog.johtani.info/blog/2013/11/07/cloudera-world-tokyo-2013/</link>
      <pubDate>Thu, 07 Nov 2013 10:11:00 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2013/11/07/cloudera-world-tokyo-2013/</guid>
      <description>Cloudera World Tokyo 2013に参加してきました。 午前中はあいにくの雨でしたが、それでも結構な人数が最初の基調講演から参加されてました。 私が参加したセッショ</description>
      <content:encoded>&lt;p&gt;&lt;a href=&#34;http://www.cloudera.co.jp/jpevents/cwt2013/index.html&#34;&gt;Cloudera World Tokyo 2013&lt;/a&gt;に参加してきました。&lt;/p&gt;
&lt;p&gt;午前中はあいにくの雨でしたが、それでも結構な人数が最初の基調講演から参加されてました。
私が参加したセッションは大盛況な感じでした。&lt;/p&gt;
&lt;p&gt;おみやげとしてカステラも頂いちゃいました！&lt;/p&gt;

&lt;link rel=&#34;stylesheet&#34; href=&#34;https://blog.johtani.info/css/hugo-easy-gallery.css&#34; /&gt;
&lt;div class=&#34;box&#34; style=&#34;max-width:300&#34;&gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://blog.johtani.info/images/entries/20131107/kasutera.jpg&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://blog.johtani.info/images/entries/20131107/kasutera.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;また、色々なセッションに現れたこんなメッセージ画像も見つけました！&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p&gt;昨日の写真データの整理をしていたら、こんなものが・・・ &lt;a href=&#34;https://twitter.com/shiumachi&#34;&gt;@shiumachi&lt;/a&gt; さんよ・・・ &lt;a href=&#34;https://twitter.com/search?q=%23cwt2013&amp;amp;src=hash&#34;&gt;#cwt2013&lt;/a&gt; &lt;a href=&#34;http://t.co/S0JsxSYXIx&#34;&gt;pic.twitter.com/S0JsxSYXIx&lt;/a&gt;&lt;/p&gt;&amp;mdash; Kenichiro HAMANO (@hamaken) &lt;a href=&#34;https://twitter.com/hamaken/statuses/398613935399510016&#34;&gt;November 8, 2013&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;!-- more --&gt;
&lt;p&gt;やっぱり、スーツの人が多いなという印象。&lt;/p&gt;
&lt;p&gt;名刺を毎回回収されるのはちょっとつらかったです。なにか、いい方法ないですかねぇ。&lt;/p&gt;
&lt;p&gt;以下はいつもの個人メモです。&lt;/p&gt;
&lt;h2 id=&#34;ビッグデータプラットフォームとして進化するhadoop&#34;&gt;「ビッグデータプラットフォームとして進化するHadoop」&lt;/h2&gt;
&lt;h4 id=&#34;cloudera株式会社代表取締役ジュセッペ小林氏&#34;&gt;Cloudera株式会社　代表取締役　ジュセッペ小林氏&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Costcoなどの写真を元にビッグデータを可視化&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bigdataとhadoopの関係&#34;&gt;BigDataとHadoopの関係&lt;/h3&gt;
&lt;p&gt;検索、SQL、機会学習、数理処理、データ管理などにもHadoopの活用されつつある。
セキュリティ、データ管理、クラスタ上でのツールの実行なども増えてきてる。&lt;/p&gt;
&lt;p&gt;「今日ビッグデータは明日のスモールデータ」&lt;/p&gt;
&lt;h4 id=&#34;アーキテクチャとしてのビッグデータ&#34;&gt;アーキテクチャとしてのビッグデータ&lt;/h4&gt;
&lt;p&gt;多種多様なデータを一箇所に集約し、生データを直接活用できる。
OSSとしての責任も。&lt;/p&gt;
&lt;h3 id=&#34;データサイエンス&#34;&gt;データサイエンス&lt;/h3&gt;
&lt;p&gt;Opsだけでないデータ解析にも活用&lt;/p&gt;
&lt;h2 id=&#34;clouderaのビッグデータプラットフォーム戦略仮&#34;&gt;「Clouderaのビッグデータプラットフォーム戦略」（仮）&lt;/h2&gt;
&lt;h4 id=&#34;講師cloudera-inc-cto-dramr-awadallah&#34;&gt;講師：Cloudera, Inc. CTO Dr.Amr Awadallah&lt;/h4&gt;
&lt;p&gt;レガシーな情報アーキテクチャ→スケールできない、可視化の限界、硬直したスキーマなどなど。&lt;/p&gt;
&lt;p&gt;エンタープライズデータハブとしてのHadoopとか。&lt;/p&gt;
&lt;h2 id=&#34;ビッグデータの歴史と将来展望&#34;&gt;ビッグデータの歴史と将来展望&lt;/h2&gt;
&lt;h4 id=&#34;講師国立情報学研究所アーキテクチャ科学研究系教授佐藤一郎氏&#34;&gt;講師：国立情報学研究所　アーキテクチャ科学研究系　教授　佐藤一郎氏&lt;/h4&gt;
&lt;h3 id=&#34;ビッグデータの歴史的経緯とか&#34;&gt;ビッグデータの歴史的経緯とか&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;最初の事例はアメリカの1880年国勢調査。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;「ビッグデータがコンピュータを生み出した」。コンピュータがビッグデータを生み出したんじゃない。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;少量データにもHadoopを&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;バッチ処理のリアルタイム化とか（一晩から10分へ）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;原点は検索データのインデクシング&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hadoopを使うのが目的じゃないんだから、構築には手を掛けないのがいいよね。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;プラットフォームと発展している&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;分散システム研究者から見たhadoop&#34;&gt;分散システム研究者から見たHadoop&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;分散ししテムの難しさを、処理範囲を限定することで巧みに回避&lt;/li&gt;
&lt;li&gt;データの近くで処理&lt;/li&gt;
&lt;li&gt;研究レベルではリアルタイム化や逐次処理化が活発&lt;/li&gt;
&lt;li&gt;全工程で逐次・リアルタイムが必要とは限らない&lt;/li&gt;
&lt;li&gt;聞いてばかりじゃなくて、動かしてみましょう。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;データサイエンス超並列分散処理を活用した新たなビジネス価値の創出&#34;&gt;データサイエンス：超並列分散処理を活用した新たなビジネス価値の創出&lt;/h2&gt;
&lt;h4 id=&#34;講師アクセンチュア株式会社工藤卓哉氏&#34;&gt;講師：アクセンチュア株式会社　工藤卓哉氏&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;「日経BPのビッグデータ総覧2013」に記事書いてる。&lt;/li&gt;
&lt;li&gt;多様化するデータ（社外のデータも）をどうやってうまく活用していくか。&lt;/li&gt;
&lt;li&gt;データが教えてくれたこと→まず、データありき、まずデータためましょう。それから解析とかすればいいのでは？というはなし？&lt;/li&gt;
&lt;li&gt;競合他社さんはNGだけど、ブースでデモ？実機？が見れますと。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hadoopデータプラットフォーム&#34;&gt;Hadoopデータプラットフォーム&lt;/h2&gt;
&lt;h4 id=&#34;cloudera株式会社嶋内翔氏&#34;&gt;Cloudera株式会社　嶋内　翔氏&lt;/h4&gt;
&lt;h3 id=&#34;まずは宣伝&#34;&gt;まずは宣伝&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cloudera Implaraのフリーブックの日本語版&lt;/li&gt;
&lt;li&gt;Hadoop Operationの書籍でるよ&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;プラットフォームを構成するもの&#34;&gt;プラットフォームを構成するもの&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Flume&lt;/li&gt;
&lt;li&gt;Sqoop&lt;/li&gt;
&lt;li&gt;HBase&lt;/li&gt;
&lt;li&gt;Hive&lt;/li&gt;
&lt;li&gt;Impala&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;データ登録してbiアナリストのお仕事にどうやって役立てる&#34;&gt;データ登録してBIアナリストのお仕事にどうやって役立てる？&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;外部テーブル：Hiveからはテーブルのように見える仕組み。元ファイルは消えない&lt;/li&gt;
&lt;li&gt;SerDe（さーでぃー）：データをHiveレコードに変換する仕組み&lt;/li&gt;
&lt;li&gt;生データを少し加工しましょう
&lt;ul&gt;
&lt;li&gt;圧縮したりファイル結合したりはしときましょう。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hadoop活用のポイント
&lt;ul&gt;
&lt;li&gt;富豪的プログラミング。リソースケチるな。&lt;/li&gt;
&lt;li&gt;ローカルでできることはローカル。むりにHadoopでやんなくてもいいですよねと。バランス重要&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;スケジューリング実行などはOozie使うと便利。（日次集計とか）&lt;/li&gt;
&lt;li&gt;Cloudera Searchで元データにインデックス貼れるぞと。検索しながら分析ができる&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;クラスタ管理とか&#34;&gt;クラスタ管理とか&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cloudera manager便利ですよ&lt;/li&gt;
&lt;li&gt;ストレージリソースの管理。
&lt;ul&gt;
&lt;li&gt;声掛け、管理者が容量チェック、Cloudera Managerのレポート&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;少数精鋭でHadoop使おう＝手が回らなくなる。&lt;/li&gt;
&lt;li&gt;みんなで使おう＝Kerberos認証とか管理をちゃんと考えないと。けど、文化が根付けば強力。Sentry、Cloudera Navigatorとか。&lt;/li&gt;
&lt;li&gt;Hadoopシステムの全体構成図。データの流れと各製品のつながり。&lt;/li&gt;
&lt;li&gt;We are hiring!ということで、興味のある方は@shiumachiさんにコンタクトをとりましょうとのこと。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sqlで実現するバッチ処理とストリーム処理&#34;&gt;SQLで実現するバッチ処理とストリーム処理&lt;/h2&gt;
&lt;h4 id=&#34;line株式会社田籠-聡氏&#34;&gt;LINE株式会社　田籠 聡氏&lt;/h4&gt;
&lt;p&gt;資料：&lt;a href=&#34;http://www.slideshare.net/tagomoris/batch-and-stream-processing-with-sql&#34;&gt;Batch and Stream processing with SQL&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;LINEのキャラがちらほら出てきた。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SQL好きですか？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ログの量とか。2.1TB/Day&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;バッチ処理とストリーム&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;速い集計のためにHadoopが重要&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;エラー系のログとかはストリームで処理したい&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;アーキテクチャ説明&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;データ解析する人って色々。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;管理者&lt;/li&gt;
&lt;li&gt;プログラマ&lt;/li&gt;
&lt;li&gt;サービスディレクタ&lt;/li&gt;
&lt;li&gt;経営陣&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;みんなが集計用処理を理解、編集ができるほうがいい。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;顔あげたらHiveアイコンだらけだったｗ&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shibとか。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;なんでHiveに限るの？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hiveに着目したバージョンアップだけを考えれば良くなる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;スケジュールクエリが増えてきて、つらい。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TimeWindowを固定して集計処理をすることで、回避できる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;norikra&#34;&gt;Norikra!!&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;スキーマレス&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OSS。Esperベース。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;インストールが楽&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;クエリの動作のお話。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://norikra.github.io&#34;&gt;http://norikra.github.io&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We Are Hiring!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hadoop-コミュニティと-yarn-の現状&#34;&gt;Hadoop コミュニティと YARN の現状&lt;/h2&gt;
&lt;h4 id=&#34;日本電信電話株式会社小沢-健史氏&#34;&gt;日本電信電話株式会社　小沢 健史氏&lt;/h4&gt;
&lt;h3 id=&#34;なんでhadoop&#34;&gt;なんでHadoop？&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;PostgreSQLでやってたけど、大きなデータにはHadoopを使おうという感じになってきた。&lt;/li&gt;
&lt;li&gt;なんで使い分けるの？
&lt;ul&gt;
&lt;li&gt;スキーマ後付け&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NTTDocomoのモバイル位置情報の統計処理とか？&lt;/li&gt;
&lt;li&gt;技術的な話をするので、HiveTに着替えます！ｗ&lt;/li&gt;
&lt;li&gt;YARNのなにが嬉しいの？
&lt;ul&gt;
&lt;li&gt;ImpalaとMapReduceが同時に動くような環境の時に、リソースをうまく管理できないのがV1&lt;/li&gt;
&lt;li&gt;そこでYARN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Apache Mesosとだいたい一緒。&lt;/li&gt;
&lt;li&gt;Apache MesosとYARNの比較&lt;/li&gt;
&lt;/ul&gt;
</content:encoded>
    </item>
    
    <item>
      <title>『プログラミング Hive』 『Hadoop 第3版』刊行記念セミナーに参加しました！ #oreilly0724</title>
      <link>https://blog.johtani.info/blog/2013/07/25/hadoop-hive-publication-party/</link>
      <pubDate>Thu, 25 Jul 2013 02:11:00 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2013/07/25/hadoop-hive-publication-party/</guid>
      <description>Hadoopとか離れちゃってるし、Hive触ったこと無いにもかかわらず参加しました！ （たまたま近くにいるからって理由なのは内緒で） 玉川さんの</description>
      <content:encoded>&lt;p&gt;Hadoopとか離れちゃってるし、Hive触ったこと無いにもかかわらず参加しました！&lt;br&gt;
（たまたま近くにいるからって理由なのは内緒で）&lt;br&gt;
玉川さんの四方山話を聞くのが主目的で参加しました。（ちょっと翻訳が気になってるので）&lt;/p&gt;
&lt;p&gt;イベントページは&lt;a href=&#34;http://connpass.com/event/2944/&#34;&gt;こちら&lt;/a&gt;&lt;br&gt;
刊行記念イベントにも関わらず、想像以上の人の入りでびっくりしました。Hadoop、Hive界隈はまだまだ人気なんだなぁと。&lt;br&gt;
プレゼントじゃんけん大会もあったのですが、そうそうに負けてしまったのが悔やまれます。。。&lt;br&gt;
Team Geek欲しかったなぁ。もちろん、懇親会まで参加しました。&lt;/p&gt;
&lt;p&gt;以下、いつものメモです。&lt;/p&gt;
&lt;!--  more --&gt;
&lt;h2 id=&#34;hiveの正しい使い方cloudera-嶋内さん&#34;&gt;Hiveの正しい使い方（Cloudera 嶋内さん）&lt;/h2&gt;
&lt;p&gt;残念ながら、マサカリは持ってなかったです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;スライドの各所に本の章番号が書いてあるのがうれしい。&lt;/li&gt;
&lt;li&gt;Hiveロゴが回ってたのでスライドの時に集中できなかったｗ&lt;/li&gt;
&lt;li&gt;Impalaの話も出てきた。
&lt;ul&gt;
&lt;li&gt;速いけど、色々足りない。Hiveの置き換えじゃないよと。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hiveとimpalaのおいしいとこ取りセラン須田さん&#34;&gt;HiveとImpalaのおいしいとこ取り（セラン　須田さん）&lt;/h2&gt;
&lt;p&gt;スライド：&lt;a href=&#34;http://www.slideshare.net/sudabon/20130724-oreilly-org&#34;&gt;http://www.slideshare.net/sudabon/20130724-oreilly-org&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;オンプレだとCDH便利だよと教えてもらう&lt;/li&gt;
&lt;li&gt;いくつかSlideshareにImpalaの性能評価の資料を上げてある（必要になったら検索で。。。）&lt;/li&gt;
&lt;li&gt;リリースされたその日に性能評価やってレポート書くとかすごすぎ！&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;翻訳の四方山話玉川さん&#34;&gt;翻訳の四方山話（玉川さん）&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;翻訳＝写経です&lt;/li&gt;
&lt;li&gt;締め切り駆動勉強法ｗ&lt;/li&gt;
&lt;li&gt;4page/day&lt;/li&gt;
&lt;li&gt;自分から電突してオライリーさんに翻訳させてくださいと。&lt;/li&gt;
&lt;li&gt;他の方の本が読めない（チェックしちゃうのでｗ）&lt;/li&gt;
&lt;li&gt;動機があるから読めるってのはあるだろうなぁ。&lt;/li&gt;
&lt;li&gt;選び方：わくわくするもの、仕事に活きるもの&lt;/li&gt;
&lt;li&gt;今年もあと2冊やる予定（Hadoop Operations、Vagrantを翻訳中）&lt;/li&gt;
&lt;li&gt;来年の候補（Chefとか）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;高可用性hdfsのご紹介cloudera-小林さん&#34;&gt;高可用性HDFSのご紹介（Cloudera 小林さん）&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;スライドにどの版で書いてあったかがわかりやすく書いてある。&lt;/li&gt;
&lt;li&gt;3段階の開発フェーズを経てる&lt;/li&gt;
&lt;li&gt;QJMのお話&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cloudera-universityとhadoop認定試験cloudera-川崎さん&#34;&gt;Cloudera UniversityとHadoop認定試験（Cloudera 川崎さん）&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Clouderaデータアナリスト向けトレーニング（3日間、10月日本語で開催予定）
&lt;ul&gt;
&lt;li&gt;Hive、Pig、Impalaなど&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Science入門コースも準備中&lt;/li&gt;
&lt;li&gt;出版記念！
&lt;ul&gt;
&lt;li&gt;8月管理者向け先着20 or 30名にHadoop第3版贈呈予定&lt;/li&gt;
&lt;li&gt;先着20名にプログラミングHive贈呈予定&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content:encoded>
    </item>
    
    <item>
      <title>Cloudera Searchのモジュールたち</title>
      <link>https://blog.johtani.info/blog/2013/06/05/cloudera-search-modules/</link>
      <pubDate>Wed, 05 Jun 2013 15:12:00 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2013/06/05/cloudera-search-modules/</guid>
      <description>Cloudera Searchは次のようなモジュールから構成されています。 これはCloudera Searchのモジュールで、さらにこれらがSolrとかを使っ</description>
      <content:encoded>&lt;p&gt;Cloudera Searchは次のようなモジュールから構成されています。
これはCloudera Searchのモジュールで、さらにこれらがSolrとかを使ってるみたいですね。pom.xmlを見たら何を使ってるかがわかるかな。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cdk-morphlines&lt;/li&gt;
&lt;li&gt;search-contrib&lt;/li&gt;
&lt;li&gt;search-core&lt;/li&gt;
&lt;li&gt;search-flume&lt;/li&gt;
&lt;li&gt;search-mr&lt;/li&gt;
&lt;li&gt;search-solrcell&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;てきとーに、README.mdみながらメモを残してみました。ソースとかはまだ読んでないです。
ざっと眺めたけど、インデキシング処理の話がメインで、検索側がどうやって動くかってのがわからなかったなぁ。
&lt;a href=&#34;http://www.cloudera.com/content/cloudera-content/cloudera-docs/Search/latest/PDF/Cloudera-Search-User-Guide.pdf&#34;&gt;ユーザガイド（注：PDF）&lt;/a&gt;ってのがあるから、これを読んでみるか。。。&lt;/p&gt;
&lt;p&gt;各モジュールについては、以下。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;cdk-morphlinescloudera-morphlines&#34;&gt;cdk-morphlines（Cloudera Morphlines）&lt;/h2&gt;
&lt;p&gt;Cloudera Morphlinesという名前みたい。
検インデキシングアプリの構築、変更をラクにするためのフレームワーク。
ETLの処理チェインを簡単にCloudera Searchにデータを入れる設定（Extract/Transform/Load処理）がかけると。
バッチ処理、Near Real Timeのために使えるみたい。検索結果をさらに入れるとかもできるんかなぁ。？&lt;/p&gt;
&lt;p&gt;Unixパイプラインのの進化版みたいなもので、一般的なレコードに対するStream処理から、Flueme、MapReduce、Pig、Hie、SqoopのようなHadoopコンポーネントも使えるみたい。&lt;/p&gt;
&lt;p&gt;Hadoop ETLアプリケーションのプロトタイピングにも使えて、リアルタイムで複雑なStreamやイベント処理やログファイル解析とかに使えるの？&lt;/p&gt;
&lt;p&gt;設定ファイルのフォーマットは&lt;a href=&#34;https://github.com/typesafehub/config/blob/master/HOCON.md&#34;&gt;HOCONフォーマット&lt;/a&gt;。AkkaやPlayで使われてる。&lt;/p&gt;
&lt;h3 id=&#34;cdk-morphlines-core&#34;&gt;cdk-morphlines-core&lt;/h3&gt;
&lt;p&gt;Cloudera Morphlinesのコンパイラ、実行環境、コマンドのライブラリを含んでる。
ログファイル解析やsingle-lineレコード、multi-lineレコード、CSVファイル、正規表現パターンマッチ、フィールドごとの比較とか条件分岐とか、文字列変換とか色々なコマンドを含んでる。&lt;/p&gt;
&lt;h3 id=&#34;cdk-morphlines-avro&#34;&gt;cdk-morphlines-avro&lt;/h3&gt;
&lt;p&gt;Avroファイルやオブジェクトの抽出、変換、読み込み処理コマンド&lt;/p&gt;
&lt;h3 id=&#34;cdk-morphlines-tika&#34;&gt;cdk-morphlines-tika&lt;/h3&gt;
&lt;p&gt;バイナリデータからMIMEタイプを検出して、解凍するコマンド。Tikaに依存&lt;/p&gt;
&lt;h4 id=&#34;雑感&#34;&gt;雑感&lt;/h4&gt;
&lt;p&gt;Cloudera Searchへのデータの流し込みを設定ファイルに記述して実行するとデータの変換処理とかが記述できるって感じかな？
Morphlinesのコマンドとして独自処理や使えそうな処理を作ることで、いろんな処理ができるって感じかなぁ。&lt;/p&gt;
&lt;h2 id=&#34;search-core&#34;&gt;search-core&lt;/h2&gt;
&lt;p&gt;Solrに対するMorphlineコマンドの上位モジュール&lt;/p&gt;
&lt;h3 id=&#34;search-solrcell&#34;&gt;search-solrcell&lt;/h3&gt;
&lt;p&gt;Tikaパーサを使ったSolrCellを使うためのMorphlineコマンド。
HTML、XML、PDF、Wordなど、Tikaがサポートしてるものがサポート対象。&lt;/p&gt;
&lt;h3 id=&#34;search-flume&#34;&gt;search-flume&lt;/h3&gt;
&lt;p&gt;Flueme Morphline Solr Sink。
Apache Flumeのイベントから検索ドキュメントを抽出、変換し、SolrにNearRealTimeで読み込むためのコマンド&lt;/p&gt;
&lt;h3 id=&#34;search-mr&#34;&gt;search-mr&lt;/h3&gt;
&lt;p&gt;HDFSに保存されたファイルに含まれる大量データをMapReduceで処理してHDFS上の検索インデックスに焼きこむモジュール。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;MapReduceIndexerTool&lt;/code&gt;は入力ファイルの集合からSolrのインデックスシャードの集合を作るためのmorphlineのタスクで、MapReduceのバッチジョブドライバー。
HDFSにインデックスを書き込む。
動作してるSolrサーバに対して出力されたデータをマージするのもサポートしてる。&lt;/p&gt;
&lt;p&gt;とりあえず、Near Real Time検索するにはFlueme使って、バッチ処理でインデックス焼くのはMapReduceIndexerToolみたいだなぁ。&lt;/p&gt;
</content:encoded>
    </item>
    
    <item>
      <title>Cloudera Searchってのが出たらしい（とりあえず、雑感？）</title>
      <link>https://blog.johtani.info/blog/2013/06/05/what-is-cloudera-search/</link>
      <pubDate>Wed, 05 Jun 2013 15:05:00 +0900</pubDate>
      
      <guid>https://blog.johtani.info/blog/2013/06/05/what-is-cloudera-search/</guid>
      <description>AWS Summitに来ていたのですが、TLでは、Cloudera Searchが賑わってました。 ということで、軽くどんなものか読んだり調べたりした</description>
      <content:encoded>&lt;p&gt;AWS Summitに来ていたのですが、TLでは、Cloudera Searchが賑わってました。
ということで、軽くどんなものか読んだり調べたりしたメモを残しとこうかと。
英語力はあやしいので、おかしいとこがあったらツッコミを。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;cloudera-searchとは&#34;&gt;Cloudera Searchとは？&lt;/h2&gt;
&lt;p&gt;CDH4.3に対応したCDHユーザ向けの検索システム（beta版）なのかな？
CDHに統合された検索フレームワークなのかな？&lt;/p&gt;
&lt;p&gt;基本はLucene/Solr 4.3でHadoopのペタバイトデータを検索することができるようになるみたいです。&lt;/p&gt;
&lt;h2 id=&#34;どんな仕組み&#34;&gt;どんな仕組み？&lt;/h2&gt;
&lt;p&gt;次のものを利用しているようです。（GithubのREADMEから。）&lt;/p&gt;
&lt;h4 id=&#34;使ってるもの&#34;&gt;使ってるもの&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Apache Solr(4.3.0＋α？)
&lt;ul&gt;
&lt;li&gt;Apache Lucene（Solrつかってるからね）&lt;/li&gt;
&lt;li&gt;Apache SolrCloud（うーん、Solrに含まれるのに別に出してるのなんで？）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Apache Flume&lt;/li&gt;
&lt;li&gt;Apache Hadoop MapReduce &amp;amp; HDFS&lt;/li&gt;
&lt;li&gt;Apache Tika
&lt;ul&gt;
&lt;li&gt;SolrCellとしてSolrにも組み込まれてる、いろんな文書（WordとかHTMLなどなど）からメタデータと本文データとかを取り出せるライブラリラッパー。実際にはさらにpdfboxとかを使って各文書からのデータを取り出してる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;何ができるの&#34;&gt;何ができるの？&lt;/h4&gt;
&lt;p&gt;HBaseやHDFSの用にZookeeperを使ってインデックスのシャーディングや高可用性ができる。（SolrCloudがZookeeperを使ってるからね。）
MapReduceのジョブの出力から自動的にSolrのインデックスにデータをマージできるらしい。
Cloudera Managerを使って、デプロイ、設定モニタリングなどが可能。&lt;/p&gt;
&lt;p&gt;Flumeのフィードをつかって、ストリーミングしてインデックスを作れる。FluemeがデータをSolrに流しこむのかな？
将来的にはHiveやHBaseのテーブルをインデックスすることも可能になるらしい。Impalaクエリの結果もフィードできるのか？&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://incubator.apache.org/blur/how_it_works.html&#34;&gt;Apache Blur&lt;/a&gt;ってキーワードも出てきた。HDFSのデータからLuceneのインデックス作るのかな？
NGDataのチームがSolr/HBaseの統合とかしてるみたい。&lt;/p&gt;
&lt;h3 id=&#34;参考url&#34;&gt;参考URL&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.cloudera.com/blog/2013/06/cloudera-search-the-newest-hadoop-framework-for-cdh-users-and-developers/&#34;&gt;Cloudera社のブログ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cloudera.com/content/cloudera-content/cloudera-docs/Search/latest/PDF/Cloudera-Search-Frequently-Asked-Questions.pdf&#34;&gt;Cloudera SearchのFAQ（注：PDF）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudera/search&#34;&gt;Githubのリポジトリ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content:encoded>
    </item>
    
  </channel>
</rss>
