---
layout: post
title: "第2回 データ構造と情報検索と言語処理勉強会に参加しました(Jugemより移植)"
slug: 第2回-データ構造と情報検索と言語処理勉強会に参加しました
author: johtani
date: 2011-12-11T00:04:35+09:00
comments: true
tags: []
---
ということで、懲りずに[#DSIRNLP](http://partake.in/events/92c72f87-6717-43ee-a358-413d63badf57)に参加してきました。
基礎的な部分をおろそかにしたくないけど、TokyoNLPとかWebMiningではついていけないので。。。
今回もしがみつくのが精一杯かもしれないと思いつつ、聞いて来ました。

```

0. DSIRNLPについて　@overlast
　講演者が可能なら実装に関して言及する。
　「こうやって作って結果を出す」系の発表をしましょう。
　開催に際して協力してくださったみなさんへの感謝の辞。

1.自然言語処理はじめました　@phyllo
　資料：http://www.slideshare.net/phyllo/ngram-10539181
　ブログ：http://d.hatena.ne.jp/jetbead/20111210/1323499634
　某Web企業の新入社員！（すごい）
　で、入って自然言語処理をはじめたらしい。
　N-Gramの説明

　Perl？
　　1.ナイーブな方法
　　　Perlでハッシュ使って数えてみたよ。これでOK？
　　　いやいや、Nが大きくなったりデータが大きくなるとキツイでしょ
　　2.SuffixArrayを使う
　　　ということで、Suffix Arrayを使ってみた。
　　　SuffixArrayのデータを作ってから、上からN文字数えれば数えられる！
　　　（数式出てきたけど目も取れなかったｗ）
　　　これでいいじゃん？いやいや、更に大規模だとどーすんの。1TBのメモリ
　　3.近似カウント法
　　　いくつかある中からLossy Countingを説明します。
　　　ストリームデータから数えてみよう。
　　　C++の実装？
　　4.分散処理を使う方法
　　　近似じゃダメ！正確な頻度が欲しい！
　　　＝＞Hadoopつかえ！
　色々やってみた感想が良かった。

　SuffixArrayのメモリ使用量という話がありましたが、ディスクを使う方法もあります。 by ?

　新人から自然言語やり始めたというが、自分が新人の頃にはこんなに出来なかった気がするなぁ。
　発表とかもってのほかだったし。

2.AI で AI 創ってみた（LT）　@uchumik
　資料：
　Luaプログラミングが出てきたので、
　多クラスロジスティック回帰とListNetを書いて見ました。（ただし、本は読んでないよ。）
　学習器のお話。
　ラグナロクオンラインのAIがLuaでかけることを思い出した。
　動画の途中で終了ｗ
　GitHubにあげなさい。ブログ書きなさい。動画もあげなさい。 by @overlast

　資料の割に時間がｗ　

2.5.CMコーナー
　技評の方からWEB+DBのCM！（ただし、商品なし）
　読者層の95%が男性ｗ
　総集編買ってね！WEB+DB plusシリーズも買ってね！
　書いてor買ってね。

　技評さんつぎはオライリーさんに負けないように賞品持ってきてねｗ

3.Mahout にパッチを送ってみた　@issay
　資料：http://www.slideshare.net/issaymk2/mahout-10539755
　人がやめていく会社で検索やHadoopやってます。
　※今日は皆既月食です。
　機械学習関連
　SGDはMapReduceでの分散に対応していないので、パッチを送ってみた。
　MapReduce、Shuffleなどの説明
　これをベースにナイーブベイズの説明をあわせて実装を見てみる。
　　・単語ｗのカテゴリｃにおける確率
　　・文書ｄのカテゴリｃにおける確率
　　　-文書ｄに出てくる単語ｗの確率の積と定義
　　単語の相関を見ない。
　　ゼロ頻度問題の解説
　　文書頻度の逆数（IDF）
　　カテゴリ毎の文書数のばらつきに対応するために、Complement Naive Bayes
　　BayesFeatureDriver
　次はランダムフォレスト
　　決定木とは？
　　ランダムフォレストとは？
　　ここでは素性。
　　Mahoutでの実装は？
　　　決定木の数だけ処理分散が可能。
　　　Reducerは使ってない。＝Mapperで計算が終わっちゃうから？
　次はロジスティクス回帰
　　尤度関数、損失関数、確率的勾配降下法（SGD）
　　先程まではオンライン。バッチ学習もある。
　　Mahoutでの実装はオンラインで、MapReduceに向いてない！
　　Adaptive Logistic Regrettion（アダプティブロジスティクス回帰）というのも実装されてる。
　送ったパッチの概要
　　Iterative Parameter Mixisngというのがあるので、それをSGDに適用するパッチ
　今後
　　MapReduce以外も増えるかも。
　
　Q:パッチがはいったバージョンはいつでる？A:3日前に送ったのでまだです
　Q:ナイーブベイズのMapReduceが一段ムダでは？（文書数のカウントは同時に出来るよね）A:そうですね、ぜひパッチを送ってみてください。
　Q:Mahout、Hadoopの未来は明るいんでしょうか？A:HDFSのデータをMapReduce以外のフレームワークで使えるといい。
　Q:Hadoopのパッチ送るの大変ですか？どのくらいかかりました？A:4,5ヶ月かかりました。

　すみません、途中から頭がパンクしてしまいました。。。
　ただ、MahoutがHadoopに乗っかってるからといって、MapReduce活用できてるわけじゃないという話がわかりました。


4.GraphDBのデータ構造　@kimuras
　資料：http://www.slideshare.net/skimura/graphdatabase-data-structure
　LTみたいな資料にになっちゃいました。すみません。
　mixiではMySQLだけど、いろんなDB触ってます。
　なので、GraphDBに興味持ちました。
　Luceneを教科書的に読んでます。
　Neo4jモダンな作りでよかった。　　http://www.slideshare.net/skimura/ss-8787632
　ノードデータの構造
　　NodeManagerというのがいて、Cache系を管理してる。
　　プロパティのインデックス、トランザクションManagerもいて、PersistenceManager
　　ここからNodeにアクセス（探索、）。
　キャッシュとかいいね。
　Soft LRU Cacheってのもあるよ。
　その他色々ｗ

　Q:トランザクション周りでLRUのキャッシュはどうなるんでしょうか@kumagi A:きちんとロックしてました。
　Q:分散はネットワーク、HDDどちらがキツイ？A:HDDがかなりきつい
　Q:プロパティもキャッシュに乗ってたほうがいい？A:プロパティも必要なら載せたほうがいい。メモリのしてはできたはず。

　Luceneがほめられてました。Neo４Jの

5.冬のLock-free祭り　@kumagi
　資料：https://docs.google.com/viewer?a=v&pid=explorer&chrome=true&srcid=0B72X9w6tG5q0NzMyODgwNDYtNjY4Yy00ZDgwLTliZDMtMjQwYmViMWE5NGU5&hl=en_US
　※資料がうまく見れないのは、アニメーションガチガチって話だからかな？
　http://twitter.com/#!/kumagi/status/145363169718697984

　辻Lock-free活動してます。
　　Lock-freeとツイートすると補足されるらしい。
　CPUの系譜のおさらい
　　ポラックの系譜
　　最新のIntelManyCoreとか東大とかに配られてるらしい。
　なんで、マルチコアのCPUがTSUKUMOとかで売ってないの？
　　僕らが使いこなせてないから。＝マルチスレッドの対応がうまくできてないから。
　CAS＝Compare And Swap
　まずは、Lock-free stack
　　ABA問題？
　Lock-free Queue
　　QueueのEnqueueの場合は2回のCASが必要になる。
　　不変条件を守る。ロックだと守りやすい。
　　2回のCAS処理の間が危険領域
　Lock-free List
　　色々なロックの説明。
　Lock-free hash map
　　これも気が狂ってるアルゴリズム？
　　ConcurrentHashMapなども話が出てきたが、説明しない＝Lock-freeじゃないからｗ
　Lock-free SkipList
　　SkipList：
　　　順序関係のあるデータをO(log n)で検索・挿入・削除ができるデータ構造（2分木ともろかぶり）
　　DougLea先生がjava.util.concurrentに入っています。
　Lock-free Btree
　　論文ないんですよ。簡単すぎて。
　SoftwareTransactionalMemory
　The Art of Multiprocessor Programmingを読みましょう！
　論文のお話。
　　http://labs.gree.jp/Top/OpenSource/Flare.html
　　を利用しているらしい。
　The Art of Multiprocessor Programming関連サイト
　http://www.cs.brown.edu/courses/cs176/lectures.shtml
　
　すごくわかりやすかった。資料をもっと見たいなぁ。
　Q:STMはメモリ使用量が2倍になる？A:
　Q:STM（Clojure）使ってみたけど残念な性能しか出なかったけど、なんで？A:Clojureのものはロックベース。でうーむ。。。

6.機械学習と最適化の基礎（仮）　@tkng
　PFIの徳永さん
　日本語入力を支える技術（技評）2012年2月発売予定
　最適化の話、機械学習の話、学習率の話。
　大域的最適、局所的最適の説明。（言いにくそう、大域的最適ｗ）
　凸最適化問題＝最適解が1つしかない？
　　大域的最適解＝局所的最適解
　機械学習なはなし。
　スパムメールの例で説明

　淡々と語られてましたが、わかりやすい説明でした。もっと昔にこんな形で数学の説明聞きたかった。。。
　
7.機械学習・言語処理技術を用いた誤り検出・訂正（LT）　@mamoruk
　資料：
　スペル誤り訂正とかに機械学習とか使われてます。

8.神の言語による自然言語処理（LT）　@AntiBayes
　資料：http://www.slideshare.net/AntiBayesian/ss-10539347#
　Lispさいこー
　Clojureさいこー
　lucene-gosenもいいよーｗ

9.言語判定へのいざない（LT）　@shuyo
　資料：
　Solrで採用されたlanguage-detection libraryの紹介。
　アゼルバイジャン語とか大変みたい。

12.作ろう！簡潔ビットベクトル　@echizen_tm
　資料：http://www.scribd.com/doc/73565169/Lets-Impl-Sbv
　入門編：
　　簡潔データ構造
　　　データサイズをほぼ情報量的下限にまで小さくしたデータ構造
　　　データは小さいし、速度速いというのがこれ。
　　実用化されてる。
　　　mozc（LOUDSが使われてます）
　　　Sedue（圧縮接尾辞配列（デフォルトではなくなった by @tkng））
　　種類：
　　　ビット列：ここの説明がこのあと
　　　木構造：トライ木をLOUDSが結構で実装するケースが多い。データサイズが小さくなる
　　　文字列：ウェーブレット木が有名。全文検索、転置インデックスにウェーブレット木を使う研究が多い。
　中級編
　　簡潔ビットベクトル：
　　rank(i)関数：i番目より前の立っているビットの数。
　　　疎なデータ列の効率的な実装に使える。検索結果が少ない場合のFacetとかに使える？
　　select(i)関数：？
　　　可変長データ列の効率的な実装
　上級編
　　ダメでした。。。ごめんなさい。。。

　体力的に厳しかったです。。。けど面白いし、わかりやすい。どういった所でこれらを使うべきかを取捨選択するのがすこし難しそうです。Luceneとかの内部ソース見ると実はこのあたりで実装されてる部分があったりするのかも。

11.類似文字列検索の仕組み　@overlast
　資料：
　使い所のはなし
　　例：辞書メンテナンスコストを軽減したい
　　架空の事例から類似検索を適用できるというストーリー
　　既存データが活用されるうれしさの例？
　　Apporoのデータ構造とかの話かな？

11.5.審査委員長から賞品持って帰る人の発表
　@kumagi
　@tkng
　@echizen_tm
　の方たちでしたー

12.懇親会
```

いやぁ、前回も感じましたが、基礎ができてないなぁと実感できた勉強会です。
そして幅も広い。やはり、数学的な要素が時々出てくるのでその部分をもっと身につけないといけないなぁと。。。
ついていけなかったところも多々ありましたが、頭の中にキーワードが入ってればなんとかなるかなぁと。
Neo4jやLuceneのソースコードリーディングをやるのが仕事に役立ちそうなので、少しずつでもやろう。
これから懇親会なので、とりあえず、このへんで。
あとで、見返しながら、リンク貼り直したりすると思います。
