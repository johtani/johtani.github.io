---
layout: post
title: "辞書の外部化とLucene/Solr3.4対応(Jugemより移植)"
slug: 辞書の外部化とlucene-solr3-4対応
author: johtani
date: 2011-10-26T01:12:00+09:00
comments: true
tags: [lucene-gosen]
---
[すぐやりますと言いつつ](http://johtani.jugem.jp/?eid=22?PHPSESSID=744a73e2820c6e94289eb9ba777c1ff2)、はや1ヶ月。。。
腰が重い、ダメエンジニアですね。。。

すみませんでした。。。
ようやくtrunkにコミットしました。
すぐにリリース版を用意すると思います。

1ヶ月もあいてしまったので、追加した機能に関するまとめと、
用途別の利用方法を記載しておきます。
（lucene-gosenのWikiにもそろそろ書かないとなぁ。日本語でもいいから。）

**追加した機能**
<hr>
これまでのlucene-gosenはjarに辞書を含む形でライブラリを提供していました。
ただ、この場合、カスタム辞書を利用している環境ではカスタム辞書を修正し、ビルドしなおすたびに、
jarファイルを作成しなければなりません。
また、jarファイルをSolrなどに配布する必要も出てきます。
この手間を考慮して、辞書を外部ディレクトリで指定することができるようにしたものが
今回の修正になります。
また、修正の過程で同一VM内で異なる辞書を使えるようにする機能も副産物として生まれました。
今回追加した機能は次のようなものになります。

* 辞書を含まないjarのビルドおよび提供
* ディレクトリ指定による辞書の指定
* 同一VM内での複数辞書の利用
* 辞書リビルド用のAntターゲットの追加
* Lucene/Solr jarファイルの最新化（3.4.0対応）


ディレクトリ指定による辞書の指定ですが、以下のような形になります。
まずは、LuceneのTokenizerでの指定方法です。
「辞書のディレクトリ」という引数が追加になっています。
ここに、辞書ディレクトリ（*.senファイルが存在するディレクトリ）を相対/絶対パスで指定します。
```

...
Tokenizer tokenizer = new JapaneseTokenizer(reader, null, "辞書のディレクトリ");
...
```

つぎは、Solrでの設定の方法です。
schema.xmlにて次のような設定を行います。
```

...
<fieldType name="text_ja" ...>
  <analyzer>
    ...
    &lt;tokenizer class="solr.JapaneseTokenizerFactory" compositePOS="compositePOS.txt" dictionaryDir="辞書のディレクトリ"/&gt;
    ...
  </analyzer>
</fieldType>
...  
```

schema.xmlの設定については、[example/schema.xml.snippet](https://code.google.com/p/lucene-gosen/source/browse/trunk/example/schema.xml.snippet)にも説明がありますので、こちらもあわせて参考に。
なお、Solrの設定については、先ほどのLuceneでの辞書のディレクトリの指定方法（絶対/相対パス）に加えて、
<em>$SOLR_HOME/conf</em> からの相対パスでの指定も可能になっています。


**Antのターゲットについて**
<hr>
辞書なしjarファイルを作成するターゲットなどを追加しています。
実際に追加したターゲットは以下のとおりです。

<table class="list_view">
<thead>
<tr>
<th>ターゲット名</th>
<th>説明</th>
</tr>
</thead>
<tbody>
<tr class="spec">
<td>nodic-jar</td>
<td>辞書なしのjarファイルを生成するためのターゲット。辞書のダウンロード、コンパイルは行いません。</td>
</tr>
<tr class="specalt">
<td class="alt">rebuild-dic</td>
<td class="alt">lucene-gosenのビルド済み辞書（.senファイル）を削除してから辞書のコンパイル（ビルド）を行います。-Ddictypeにより辞書のタイプ（ipadic|naist-chasen）の指定が必要です。また、-Dcustom.dicsによりカスタム辞書の指定もあわせて可能です。</td>
</tr>
<tr class="spec">
<td>build-dic-ipadic</td>
<td>テスト用に追加。-Ddictype=ipadicを指定してbuild-dicを実行。</td>
</tr>
<tr class="specalt">
<td class="alt">build-dic-naist-chasen</td>
<td class="alt">ついでに追加。-Ddictype=naist-chasenを指定してbuild-dicを実行。</td>
</tr>

</tbody>
</table>

最後の２つはあまり関係ありません。内部的に有ると便利だったため、作りました。
重要なのは最初の２つです。
ひとつめの「nodic-jar」は辞書を含まないjarファイルをビルドします。
このjarファイル＋辞書の入ったディレクトリを利用することで、辞書の外部化が可能となります。

そして、「rebuild-dic」です。こちらは、[以前記事に書きました](http://johtani.jugem.jp/?eid=4)が、カスタム辞書のコンパイルが思いの外面倒だったので、ターゲットを追加しました。
次のように指定することで、辞書のリビルドが可能です。
```

$ ant -Ddictype=naist-chasen -Dcustom.dcs="custom1.csv custom2.csv" rebuild-dic
```


**提供されるjarファイルについて**<hr>

提供されるjarファイルは次のようになる予定です。
1番目のjarファイルが今回追加になる、辞書なしのjarファイルになります。
* lucene-gosen-1.x.x.jar
* lucene-gosen-1.x.x-ipadic.jar
* lucene-gosen-1.x.x-naist-chasen.jar



**用途別の利用方法**<hr>
利用用途別に利用するjarファイルやantのターゲットを利用シーンを交えて想定を書いてみます。
Solrでの利用シーンを想定します。

<em>**お手軽に使う。辞書ありjarファイルで一発インストール。**</em>
これまでどおりの使い方になります。
辞書込みのjarファイルを利用すれば、すぐに利用可能になります。


<em>**カスタム辞書を使い倒す。定期的に辞書をメンテナンス。**</em>
定期的にシステム固有の単語が増える（例：製品名、新語など）場合です。
* 利用するjar：lucene-gosen-1.x.x.jar
* 辞書のコンパイル＋配置：ant -Ddictype=naist-chasen -Dcustom.dics="custom1.csv" rebuild-dir
* Solrの該当コアのRELOAD


Solrのマルチコア環境を利用します。なお、sharedLib設定にlucene-gosen-1.x.x.jarを配置すると、辞書の再読み込みができないので注意してください。
設定は、上記のようにTokenizerFactoryの設定でdictionaryDirにて辞書のディレクトリを設定しておきます。
カスタム辞書に単語を追加後、antにて、辞書のリビルドを行います。
リビルドした辞書ファイルを必要に応じて対象の辞書ディレクトリにコピーします。（ビルド後のディレクトリをそのまま利用している場合はコピーの必要はないです。）
最後に、Solrの該当コアのリロードを行います。（リロードの仕方は[こちらを参考に](http://wiki.apache.org/solr/CoreAdmin?PHPSESSID=d9edccf00e1c13655f96b005f36819c4)。）
コアのリロードにより、辞書の再読み込みが行われるので、リロード後から新しい辞書が適用されます。


<em>**異なる辞書を使い倒す。TokenizerごとにdictionaryDir設定するぞ**</em>
1つのSolrで異なる辞書を使ったフィールドを使いたい場合です。
ipadicとnaist-chasenといった異なる場合はあまり想定できないですが、カスタム辞書の部分が異なるという形が想定できるでしょうか。（例：製品名のフィールド、企業名のフィールド。。。など）
* 利用するjar：lucene-gosen-1.x.x.jar
* 設定：schema.xmlに異なるdictionaryDirを設定したTokenizerFactoryを設定


上記、カスタム辞書の定期更新も一緒に行うことも可能です。コアをリロードすれば、リロードしたコアで利用している
辞書がすべてリロードされます。

**最後に**<hr>
遅くなってしまいましたが、ようやく、trunkにコミットしました。
できるだけ速く、リリースしますので、もう少々お待ちを。

Solrのconfディレクトリからの指定については、[＠shinobu_aoki](http://twitter.com/shinobu_aoki)さんにパッチを提供してもらいました。
また、trunkにコミットしていないパッチを適用して記事を書いてくれた方もいらっしゃいました。こちらもあわせて参考に。私より説明が上手です。
[Java製形態素解析ライブラリ「lucene-gosen」を試してみる](http://www.mwsoft.jp/programming/munou/lucene_gosen.html)
