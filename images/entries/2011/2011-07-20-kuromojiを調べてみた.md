---
layout: post
title: "Kuromojiを調べてみた(Jugemより移植)"
slug: kuromojiを調べてみた
author: johtani
date: 2011-07-20T12:29:00+09:00
comments: true
tags: [形態素解析]
---
以前から[春山さんのブログ（リンク）](http://blog.livedoor.jp/haruyama_seigo/archives/51806436.html)や勉強会で耳にはしていたのですがソースは読んでいませんでした。
先日、[Luceneにcontributeされた（リンク）](https://issues.apache.org/jira/browse/LUCENE-3305)ので軽くソースを読んでみました。

[公式サイトはこちら](http://atilika.org/)

まずはMeCabのページにある[比較表（リンク）](http://mecab.sourceforge.net/#diff)を基準に特徴を調べてみました。せっかくなので、lucene-gosenも隣に。

<table class="list_view">
<thead>
<tr>
<th>&nbsp;</th>
<th>Kuromoji</th>
<th>lucene-gosen</th>
</tr>
</thead>
<tbody>
<tr class="spec">
<td>解析モデル</td>
<td>なし（学習機能なし）</td>
<td>なし（学習機能なし）</td>
</tr>
<tr class="specalt">
<td class="alt">コスト推定</td>
<td class="alt">なし（学習機能なし）</td>
<td class="alt">なし（学習機能なし）</td>
</tr>
<tr class="spec">
<td>学習モデル</td>
<td>なし（学習機能なし）</td>
<td>なし（学習機能なし）</td>
</tr>
<tr class="specalt">
<td class="alt">辞書引きアルゴリズム</td>
<td class="alt">Double Array Trie</td>
<td class="alt">Double Array Trie</td>
</tr>
<tr class="spec">
<td>解探索アルゴリズム</td>
<td>Viterbi</td>
<td>Viterbi</td>
</tr>
<tr class="specalt">
<td class="alt">連接表の実装</td>
<td class="alt">2次元 Table</td>
<td class="alt">3次元 Table</td>
</tr>
<tr class="spec">
<td>品詞の階層</td>
<td>無制限多階層品詞？ipadic、unidic形式に対応</td>
<td>無制限多階層品詞</td>
</tr>
<tr class="specalt">
<td class="alt">未知語処理</td>
<td class="alt">字種 (動作定義を変更可能)（おそらく。）</td>
<td class="alt">字種（変更不可能）</td>
</tr>
<tr class="spec">
<td>制約つき解析</td>
<td>たぶん、不可？</td>
<td>たぶん、不可？</td>
</tr>
<tr class="specalt">
<td class="alt">N-best解</td>
<td class="alt">不可能</td>
<td class="alt">不可能</td>
</tr>
</tbody>
</table>

こうやって比較してみるとlucene-gosen（Sen）とあまりかわりはありませんが、lucene-gosenが少し古いのがわかりますね。。。

Kuromojiで利用出来る辞書は現時点ではMeCab IPADIC、UNIDICの2種類のようです。

ソースを読んでの感想ですが、やはりMeCabが偉大だということがよくわかりました。
Senよりも新しいMeCabの処理に似ている点が多いです。解探索アルゴリズムや連接コスト表が特に。
MeCab向けの辞書を利用しているためというのもあるかと思います。

Kuromojiが特徴的なのは「searchモード」と呼ばれるモードが用意されていることです。
公式サイトにある例ですと、「関西国際空港」が「関西」「国際」「空港」というTokenで出力されます。
ソースを見たところViterbiアルゴリズムで辞書を探索しているときに特定の条件でコストをカサ増しすることで、結果を変えるという処理を行っているようです。
* 全て漢字の単語：3文字以上の場合に「(単語の長さ-3)*10000」をコストに加算
* その他の単語：7文字以上の場合に「(単語の長さ-7)*10000」をコストに加算


このようにコストを変化させることで「空港」でも「関西国際空港」という文字を含む文章が検索できる仕組みになっています。
また、「拡張searchモード」と呼ばれるモードも存在し、こちらは、未知語をuni-gramで区切って出力を行うようです。

ソース上で確認しただけで、未確認ですが、GraphvizFormatterというクラスがあるので、Graphvizで読み込める形式で形態素解析の結果が出力されるかもしれません。（すみません、確認してなくて。）

未知語の処理やsearchモードなど面白い機能があるので、試してみるのもいいかもしれません。lucene-gosenを考えていく上でも参考になりそうです。

最後に余談ですが、[FAQのページ（リンク）](http://atilika.org/confluence/display/KUROMOJI/FAQ)が面白いです。。。
