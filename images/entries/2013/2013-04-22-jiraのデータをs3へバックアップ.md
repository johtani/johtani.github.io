---
layout: post
title: "JIRAのデータをS3へバックアップ(Jugemより移植)"
slug: jiraのデータをs3へバックアップ
author: johtani
date: 2013-04-22T23:07:28+09:00
comments: true
tags: [備忘録]
---
だいぶ、ブログを書くペースが落ちてきてて、危機感を感じている今日このごろです。。。
今回は、個人的に利用しているJIRAのバックアップについて、ブログに残しておこうかと。

さくらVPSのサーバを借りてJIRAを運用しています。
運用といっても、自分の備忘録のためというのが大半の理由です。
タスクを忘れないように管理するのと合わせて、その作業を行ったときのメモも残したいなと。

バックアップといっても、同じサーバ内に保存しても意味がない＋AWSを触ると言いつつ1年以上経ってしまったので、
このへんで本腰を入れるという意味も込めてAWSのS3（ゆくゆくはGlacier）にバックアップを取る仕組みを作りました。
「作りました」というと凄そうですが、Cronとシェルだけで終わりました、なんて便利な世の中。
ということで、以下は作業の備忘録です。

<span style="font-size:large;">1.AWSのアカウント作成
___
アカウントを作ってください。ここは特に説明しなくてもいいかと。。。クレジットカードの登録が必要なのが注意点でしょうか。
アカウント作成後の1年間は[無料枠](http://aws.amazon.com/jp/free/)と呼ばれる仕組みが用意されており、いろんなことが無料で行えます。
（まだ、S3しか使ってないので、他にももっと使わないと。。。）

<span style="font-size:large;">2.S3のバケット作成
___
AWSのアカウントが作成できたら、[Amazon S3（Simple Storage Service）](http://aws.amazon.com/jp/s3/)のバケットと呼ばれる、データの保存先を作成します。
作成手順はこちらの[公式入門ドキュメント（英語）](http://docs.aws.amazon.com/AmazonS3/latest/gsg/GetStartedWithS3.html?r=8046)をそのまま行いました。
簡単な手順はこちら
1. AWS Management Consoleと呼ばれるところから、S3のコンソールにアクセス
1. 「Create Bucket」ボタンをクリック
1. 「Bucket Name」を入力し、リージョンを選択したら「Create」ボタンをクリック

以上でバケットが作成されました。これだけです。WebのConsoleからファイルをアップロードすることも可能です。
ただ、今回はさくらVPSから定期的にバックアップしたいのでシェルでアクセスできるようにします。

<span style="font-size:large;">3.AWSのアクセスキーとシークレットアクセスキーの取得
___
次に紹介するs3cmdというツールを利用するのに、AWSのアクセスキーとシークレットキーが必要になります。
取得方法は[こちら](http://www.atmarkit.co.jp/fwin2k/operation/aec2s3_1/aec2s3_1_04.html)を参考にしましたが、今は日本語のページが用意されています。
セキュリティ証明書（Security Credentials）のページで、「アクセス証明書」というタブで、「新しいアクセスキーを作成する」リンクをクリックしてください。
アクセスキーIDが新しく表示されます。このアクセスキーIDとシークレットアクセスキー（表示リンククリック後に表示される）をメモしておきます。

<span style="font-size:large;">4.s3cmdのインストール
___
世の中には便利なものを作ってくれる方がいるもので。
[s3cmd](http://s3tools.org/s3cmd)と呼ばれるS3へアクセスできるコマンドラインツールが存在します。
ということで、こちらをインストール。これまた、便利なもので[インストール手順を書いてくれれてるブログ](http://understeer.hatenablog.com/entry/2012/07/23/124402)もありました。（あれ、なんか、見たことある名前がURLにはいってるなぁ）
インストールはこちら。
```

# yum -y --enablerepo epel install s3cmd
```
インストール後に、先ほど取得したアクセスキーIDを設定します。
```

$ s3cmd --configure
Access Key: xxxx
Secret Key: xxxx
```
以上で、s3cmdが使えるようになりました。

<span style="font-size:large;">5.バックアップスクリプトの作成
___
つぎは、本題のJIRAのバックアップです。
バックアップ方法は[こちら](http://doc.go2group.jp/pages/viewpage.action?pageId=34865916)を参考にしました。ちょっと古いみたいですが。
おもなデータは「JIRAのXMLバックアップユーティリティ」にてバックアップするか、「データベースのバックアップツール」を利用する方法があります。
推奨は「データベースのバックアップツール」のようなので、私の場合は「pg_dump」にてJIRAのデータベースをまるごとバックアップすることにしています。
また、データベースには添付ファイルが保存されていないようなので、別途「/var/atlassian/application-data/jira/data」というディレクトリをtarコマンドで圧縮して保存すようにしました。
あとは、pg_dumpの結果と添付ファイルの保存先の圧縮したデータをまとめてディレクトリに保存して圧縮します。
さいごは、S3にアップロードすればおしまいです。
一応、ファイルが連綿と残り続けるのは嫌だなぁということで、ファイル数で世代管理することにもしました。
これまた、ググって見つけてきた[サイトを参考](http://d.hatena.ne.jp/nigogonigo/20121003/1349272523)にしただけですが。。。
ということで、こんなかんじのスクリプトを日時でcronに設定して動かしてます。

```

#!/bin/sh
TODAY=`date +%Y%m%d`
BACKUP_HOME="/var/atlassian/backups"
S3SYNC_DIR="/var/atlassian/backups/s3sync"
AGE=7

mkdir -p ${BACKUP_HOME}/${TODAY}/
/usr/bin/pg_dump -U postgres -Fc jiradb > ${BACKUP_HOME}/${TODAY}/jiradb_backup.dump
tar zcvf ${BACKUP_HOME}/${TODAY}/attachment.tgz /var/atlassian/application-data/jira/data
tar zcvf ${S3SYNC_DIR}/jira_backup_${TODAY}.tgz ${BACKUP_HOME}/${TODAY}
rm -rf ${BACKUP_HOME}/${TODAY}
NUM=`ls ${S3SYNC_DIR} | wc -l`
while [ ${NUM} -ge ${AGE} ]
do
  DEL_FILE=`ls -lt ${S3SYNC_DIR} | tail -1 | awk '{print $9}'`
  rm -r ${S3SYNC_DIR}/${DEL_FILE}
  NUM=`ls ${S3SYNC_DIR} | wc -l`
done

s3cmd sync --delete-removed ${S3SYNC_DIR}/* s3://my_jira_backup/s3sync/
```
そこへんだよとかあれば、ツッコミを。
今のところ、S3へのsyncだけなので、このあとは、月1くらいでGlacierに落とすとかの仕組みも考えるかなぁ。これまた何かあるんだろうけど。
あとは、この応用で家のNASに溜まっている写真をS3経由もしくは直接Glacierにバックアップする仕組みを考える予定です。


