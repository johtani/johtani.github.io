<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[@johtaniの日記 2nd]]></title>
  <link href="http://blog.johtani.info/atom.xml" rel="self"/>
  <link href="http://blog.johtani.info/"/>
  <updated>2014-12-25T18:07:53+09:00</updated>
  <id>http://blog.johtani.info/</id>
  <author>
    <name><![CDATA[johtani]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 2.0系のIssueの紹介]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/25/pickup-elasticsearch-2-0-0-labels/"/>
    <updated>2014-12-25T15:53:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/25/pickup-elasticsearch-2-0-0-labels</id>
    <content type="html"><![CDATA[<p>この記事は<a href="http://qiita.com/advent-calendar/2014/elasticsearch">Elasticsearch Advent Calndar 2014</a>の25日目のエントリです。</p>

<p>あっという間に最終日です。来年につなげるという意味で、Elasticsearchの2系のIssueをいくつかピックアップして紹介してみます。</p>

<!-- more -->


<p>現在、ElasticsearchのGitHubリポジトリは、大きく3つのブランチで作業しています。
<code>master</code>、<code>1.x</code>、<code>1.4</code>です。<code>master</code>と<code>1.x</code>の大きな違いとしては、<code>master</code>はLuceneの5.x系を採用している点です。</p>

<p>なお、これから紹介するIssueは現在、確定していない項目も含んでいます。実際に2.0がリリースされるタイミングでは
採用されない場合もあります。</p>

<h2>Upgrade master to lucene 5.0 snapshot #8347 (closed)</h2>

<p><a href="https://github.com/elasticsearch/elasticsearch/pull/8347">https://github.com/elasticsearch/elasticsearch/pull/8347</a></p>

<p>先ほど書きましたが、Luceneの5に対応するためのPRです。
Lucene 5に関してはLuceneのコミッターのMikeさんの<a href="http://blog.mikemccandless.com/2014/11/apache-lucene-500-is-coming.html">ブログ記事</a>も参考になります。</p>

<p>Lucene 5に変更することで、BitSetに関する改善が多く含まれることになります。
メモリの利用量、圧縮などの改善が多く含まれています。
もう1点大事な点としては、Lucene 5系ではLucene 3系のインデックスを読み込むことができなくなる点です。
Luceneの下位互換の範囲は1つ前のメジャーバージョン（5.x系の場合は4.xまでが対象）となっています。</p>

<h2>Filter cache: add a <code>_cache: auto</code> option and make it the default.（closed）</h2>

<p><a href="https://github.com/elasticsearch/elasticsearch/pull/8573">https://github.com/elasticsearch/elasticsearch/pull/8573</a></p>

<p>Filter cacheは、<code>true</code>もしくは<code>false</code>の設定が利用できますが、filterの種類にも依存します。
その辺りの条件を加味しつつ、よしなにCacheをコントロールしてくれます。</p>

<h2>Remove and/or/not in favour of <code>bool</code> filter #8960（open / discuss）</h2>

<p><a href="https://github.com/elasticsearch/elasticsearch/issues/8960">https://github.com/elasticsearch/elasticsearch/issues/8960</a></p>

<p>似ているが少し異なる<code>and</code>、<code>or</code>、<code>not</code>フィルタと<code>bool</code>フィルタが存在しています。
これらをわかりやすくするために、<code>bool</code>フィルタに統一しましょうという話し合いをしています。</p>

<h2>Input validation #9059（open / discuss）</h2>

<p><a href="https://github.com/elasticsearch/elasticsearch/issues/9059">https://github.com/elasticsearch/elasticsearch/issues/9059</a></p>

<p>色々な入力に関するチェックを追加しようというIssueです。
たとえば、ディレクトリ名やファイル名、URLのパスやクエリストリング、フィールドのパスやスクリプトなどです。
Validationがあると、変な設定をして頭をかかえることもなくなるかなぁと。</p>

<h2>Refactor analysis framework #8961（open）</h2>

<p><a href="https://github.com/elasticsearch/elasticsearch/issues/8961">https://github.com/elasticsearch/elasticsearch/issues/8961</a></p>

<p>新しくAnalyzerを作った場合に、色々な場所に登録必要があったりします。インデックスレベルとノードレベルです。（Kuromojiプラグインなどが参考になります。）
また、インデックスごとにカスタムのAnalyzerを設定するので、1つのノードに同じAnalyzerを何度も設定しないといけません。
よりシンプルにするために、Analyzerをノード単位で設定しようという提案です。</p>

<h2>Remove possibility for conflicting field definitions and ambiguous field resolution #8870（open）</h2>

<p><a href="https://github.com/elasticsearch/elasticsearch/issues/8870">https://github.com/elasticsearch/elasticsearch/issues/8870</a></p>

<p>同じインデックスに、異なるtypeで、同じフィールド名があった場合、いろいろと良くないことがあったりします。
たとえば、フィールドのタイプがintegerとstringと異なる場合に、インデックスレベルで検索を行うとうまく検索できなかったりと。
この問題を解消するために、より明確にしようというIssueです。
たとえば、フィールド名を指定するためには、フルパスで記述をするだとか、フィールドマッピングに関してはインデックスレベルで内部で保持をするなど。</p>

<h2>Validation of mappings request to reject unsupported fields #7205（closed）</h2>

<p><a href="https://github.com/elasticsearch/elasticsearch/issues/7205">https://github.com/elasticsearch/elasticsearch/issues/7205</a></p>

<p>1.xでも取り込まれますが、嬉しい機能なので紹介します。
これまでは、mappingsでスペルミスをした場合（たとえば、field設定で&#8221;indexx&#8221;といったミス）には、その項目は単に無視されるだけでした。
これが、v1.xでは、エラーに</p>

<h2>まとめ</h2>

<p>ということで、簡単ですが、v2.0.0に向けたIssueをピックアップして紹介してみました。
上記以外にも多くの改善、提案が2.0に向けて行われています。
興味のある方は、<a href="https://github.com/elasticsearch/elasticsearch/issues?q=is%3Aopen+is%3Aissue+label%3Av2.0.0">v2.0.0</a>ラベルでIssueを検索してみてはいかがでしょうか？</p>

<p>今年もあとわずかとなりました。
今年の2月にElasticsearchの1.0がリリースされ、あっという間に1.4なりました。まだまだ改善しています。</p>

<p>来年もElasticsearchに興味をもっていただければ嬉しいです。
<a href="http://www.elasticon.com/">Elasticsearch初のユーザカンファレンスのサイトもオープン</a>しました。
Elasticsearchに関するいろいろな話が聞ける機会だと思います。登録をお待ちしています。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Marvel 1.3.0リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/18/marvel-1-3-0-released-ja/"/>
    <updated>2014-12-18T17:06:48+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/18/marvel-1-3-0-released-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/marvel-1-3-0-released/">marvel 1.3.0 released</a></p>

<p>12/17に、<strong>Elasticsearch Marvel 1.3.0</strong>をリリースしました。
Marvelの以前のリリースから、Elasticsearchでは様々なことがありました（Elasticsearch 1.4のリリースなど）。
このバージョンでは、モニタリングにクエリキャッシュや新しいcircuit breakerなどのような機能を追加してあります。
Senseのナレッジベースは最新のAPIを含むものに拡張されています。
また、<a href="http://www.elasticsearch.org/overview/shield/">Shield</a>のリリースに向けた準備として、HTTPsのサポートも追加しました。</p>

<p>アップグレードのために、Elasticsearchの全てのノードに最新版のMarvelプラグインをインストールする必要があります。
また、他のJavaプラグインと同様に、Marvelの新バージョンを有効にするために、各ノードを（1台ずつ）リスタートする必要があるでしょう。
アップグレードプロセスについての詳細は、<a href="http://www.elasticsearch.org/guide/en/marvel/current/upgrade.html#upgrade">Marvelドキュメント</a>をごらんください。</p>

<!-- more -->


<p>まとめとして、ここに本リリースに関する改善点をいかにリストアップしておきます。</p>

<h3>agent</h3>

<ul>
<li>追加：

<ul>
<li>httpsのサポート</li>
<li>デフォルトのMarvelの設定（以前は常に9200）ではなく、ローカルノードのポートを自動的に検出</li>
</ul>
</li>
<li>改善：

<ul>
<li>marvelインデックステンプレートに関するエラーチェックと耐障害性(それに対するチェックと追加時のチェック)</li>
<li>エラーログに関するくり返しの抑制</li>
<li>URLパラメータによるインデックス名を指定する_bulk exportコマンド。これは、<code>rest.action.multi.allow_explicit_index</code>がfalseに設定されているときに有用</li>
</ul>
</li>
<li>修正：

<ul>
<li>ES 1.4.0のtribe nodeがMarvelのインストール時に初期化されない問題</li>
</ul>
</li>
<li>削除：

<ul>
<li>UIで表示されないoptional shard level statsを除去</li>
</ul>
</li>
</ul>


<h3>monitoring ui</h3>

<ul>
<li>追加：

<ul>
<li>ES 1.4.0で導入された新しいcircuit breakerを追加</li>
<li>circuit breakerのlimitをグラフにプロット</li>
<li>QueryCacheのグラフを追加</li>
<li>index throttlingのグラフの追加</li>
<li>Index writerとバージョンのmapのメモリ使用量のグラフの追加</li>
</ul>
</li>
<li>修正：

<ul>
<li>Network Transport Bytes Receivedグラフに実際の送信量を表示</li>
<li>Node Statsダッシュボードでいくつかのスレッドプールの不足</li>
</ul>
</li>
</ul>


<h3>sense</h3>

<ul>
<li>追加：

<ul>
<li>mappingsをインデックスでオートコンプリートするしないの設定を可能に</li>
<li>Cluster Reroute API</li>
<li>Search APIのQuery Cacheパラメータ</li>
<li>Analyze API</li>
<li>Validate Query API</li>
<li>Put Percolator API</li>
<li>cluster.routing.allocation.*設定</li>
<li>Function Scoreクエリのweightパラメータ</li>
<li>Flush API</li>
<li>Terms Aggregationのshow_term_doc_count_errorパラメータ</li>
<li>Update API</li>
<li>_geo_distanceソートオプション</li>
<li>Significant Terms aggregationを1.4.0にアップデート</li>
<li>Mapping APIにメタデータフィールドを追加</li>
<li>Get Index API</li>
<li>Scripted Metric Aggregation</li>
<li>simple_query_stringクエリ</li>
<li>More Like Thisクエリを1.4.0にアップデート</li>
<li>has_childクエリ/フィルタのmin_childrenとmax_childrenオプション</li>
<li>terms aggs/significant terms aggsのヒントオプション</li>
<li>Mappings APIのtransform</li>
<li>インデックスされたscriptとtemplate</li>
<li>Geo Bounds aggregation</li>
<li>Top Hits aggregation</li>
<li>Terms aggregationのcollect_modeオプション</li>
<li>Percentiles Rank aggregation</li>
<li>Disk Threshold Allocator設定</li>
</ul>
</li>
<li>修正：

<ul>
<li>URLオートコンプリートの挙動（プロトコルとホストのような組み合わせ）</li>
<li>nested typeマッピングのinclude_in_parentとinclude_in_rootの不足</li>
<li>Rangeフィルタでのgt、gte、lt、lte</li>
<li>Existsフィルタのオートコンプリート</li>
<li>Snapshot、Restore APIのリポジトリ設定の時オートコンプリートの失敗</li>
</ul>


<p>いつものように、Elasticsearch Marvelを改善するために、フィードバックをお待ちしています。
<a href="https://groups.google.com/forum/?fromgroups#!forum/elasticsearch">ElasticsearchユーザML</a>や<a href="http://www.twitter.com/elasticsearch">Twitter</a>に質問や意見お送りください。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 1.4.2および1.3.7リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/18/elasticsearch-1-4-2-released-ja/"/>
    <updated>2014-12-18T14:26:14+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/18/elasticsearch-1-4-2-released-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-2-released/">elasticsearch 1.4.2 and 1.3.7 released</a></p>

<p>本日、<strong>Lucene 4.10.2</strong>をベースにした<strong>Elasticsearch 1.4.2</strong>と、バグフィックスリリースである、<strong>Elasticsearch 1.3.7</strong>をリリースしました。
ダウンロードおよび変更リストはそれぞれ次のリンクからアクセスできます。</p>

<ul>
<li>最新ステーブルリリース：<a href="http://www.elasticsearch.org/downloads/1-4-2">Elasticsearch 1.4.2</a></li>
<li>1.3.x系バグフィックス：<a href="http://www.elasticsearch.org/downloads/1-3-7">Elasticsearch 1.3.7</a></li>
</ul>


<p>過去のリリースに関するブログ（公式）はこちら。</p>

<ul>
<li>1.4:<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-1-released/">1.4.1</a>,
<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-released/">1.4.0</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-beta-released/">1.4.0.Beta1</a></li>
<li>1.3:<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-1-released/">1.3.6</a>,
<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-released/">1.3.5</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-4-released/">1.3.4</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-3-released/">1.3.3</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-2-released/">1.3.2</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-1-released/">1.3.1</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-0-released/">1.3.0</a>.</li>
</ul>


<p>すべての変更については<a href="http://www.elasticsearch.org/downloads/1-4-2">1.4.2のリリースノート</a>および<a href="http://www.elasticsearch.org/downloads/1-3-7">1.3.7のリリースノート</a>をごらんください。
以下では、重要な変更について紹介します。</p>

<!-- more -->


<h2>bug fixes</h2>

<p>Elasticsearchに対して広範囲にわたってランダムなテストを行っています。以下の問題を見つけ、修正するのに役立っています。</p>

<ul>
<li>プライマリシャードを持つnodeがレプリカシャードをプライマリから復旧している間に、リスタートした場合に、プライマリ上のトランザクションログが削除されデータをロスする(<a href="https://github.com/elasticsearch/elasticsearch/pull/8917">#8917</a>)</li>
<li>scriptインデックスが普及した場合に、ScriptService全体がデッドロック(<a href="https://github.com/elasticsearch/elasticsearch/pull/8901">#8901</a>)</li>
<li>Index Writerのロックを強制的に解放することによるシャードの破損(<a href="https://github.com/elasticsearch/elasticsearch/pull/8892">#8892</a>)</li>
</ul>


<h2>パフォーマンス改善</h2>

<p>複雑な設定をもつ大きめのクラスタをもつユーザは、小さなスケールではわからない性能ボトルネックに直面します。
彼らの報告が次の改善をもたらす助けとなりました。</p>

<ul>
<li>使用可能なディスク空間に基づいてシャードの配置を決定する、disk allocation deciderの速度改善とクラスタリスタート後のリカバリ速度の改善(<a href="https://github.com/elasticsearch/elasticsearch/pull/8803">#8803</a>)</li>
<li>以前よりも高速な共有ファイルシステムでのSnapshot生成(<a href="https://github.com/elasticsearch/elasticsearch/pull/8749">#8749</a>)</li>
<li>不要なクラスタ状態変更の削減とそれによるネットワークトラフィックの削減およびリカバリの速度向上(<a href="https://github.com/elasticsearch/elasticsearch/pull/8933">#8933</a>, <a href="https://github.com/elasticsearch/elasticsearch/pull/8413">#8413</a>)</li>
<li>index stats APIはシャードリカバリによるブロックしない(<a href="https://github.com/elasticsearch/elasticsearch/pull/8910">#8910</a>)</li>
</ul>


<h2>試してみてください。</h2>

<p>ぜひ、<a href="http://www.elasticsearch.org/downloads/1-4-2">Elasticsearch 1.4.2</a>をダウンロードして、試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/elasticsearch/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JJUG ナイトセミナーでLuceneの簡単な紹介をしてきました。#JJUG]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/17/jjug-night-seminar-dec-2014/"/>
    <updated>2014-12-17T18:41:54+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/17/jjug-night-seminar-dec-2014</id>
    <content type="html"><![CDATA[<p><a href="http://jjug.doorkeeper.jp/events/18378">「【東京】JJUG ナイト・セミナー「機械学習・自然言語処理特集！」12/17（水）開催」</a>でLuceneの話をしてきました。
本当にごく簡単な入門です。
Luceneをさわるきっかけにしてもらえたら嬉しいです。</p>

<p>そのほかにも面白い話が聞けましたので、簡単ですがメモを。</p>

<!-- more -->


<h2>JJUGの2014年振り返り</h2>

<ul>
<li>だいたい、毎月ナイトセミナーかCCCを開催</li>
<li>イベント系に、のべ3100名が参加</li>
</ul>


<h2>Java でカジュアルにはじめる機械学習</h2>

<h3>小宮 篤史さん(スマートニュース株式会社)</h3>

<p>スライド：<a href="https://speakerdeck.com/komiya_atsushi/number-jjug-java-dekaziyuarunihazimeruji-jie-xue-xi">#JJUG - Java でカジュアルにはじめる機械学習</a><br/>
ブログ：<a href="http://blog.k11i.biz/2014/12/jjug-java.html">#JJUG ナイトセミナー「機械学習・自然言語処理特集！」で Java でカジュアルに機械学習する話をしてきました</a></p>

<ul>
<li>ガチの人は寝ててください。</li>
<li>機械学習でできること

<ul>
<li>分類・識別</li>
<li>予測・回帰</li>
<li>パターンマイニング・アソシエーションルール</li>
<li>クラスタリング</li>
</ul>
</li>
<li>上2つは教師あり学習/下2つは教師なし学習</li>
<li>データとしては、日構造では扱えないので、「特徴量」を抽出して「特徴ベクトル」を作って、処理をするのが機械学習</li>
</ul>


<p>得られた結果の正しさの測定などなど</p>

<ul>
<li>機械学習の実装は辛いので、車輪の再発明をやめましょう！</li>
</ul>


<p>Javaで使える機械学習
* Weka：とりあえず使ってみるならこれ？
* MLlib：Sparkで使われてる
* Mahout：オワコン？
* SAMOA：Stormの上で利用できる
* Jubatus：Javaクライアントあり。
* h2o：Deep learningをJavaでやるなら、これ。
* ほかにもあったけど、スライド見ていただければ。</p>

<p>機械学習をはじめるのに使えるデータセット
* UCI Machine learning repository
  * Iris（アヤメデータ）は機械学習界のHello world</p>

<ul>
<li>Wekaを使ったサンプルコード</li>
</ul>


<h2>Spark/MLlibではじめるスケーラブルな機械学習</h2>

<h3>猿田 浩輔さん(株式会社エヌ・ティ・ティ・データ)</h3>

<p>スライド：（後日、リンクがあれば更新予定）</p>

<ul>
<li><p>Spark+MLlibを語る上で外せない話題</p>

<ul>
<li>Hadoopとの違い？</li>
</ul>
</li>
<li><p>まずはHadoopの話</p></li>
<li>HadoopによるK-meansのデモ</li>
<li><p>Hadoopの問題点に対するSparkの解決策</p></li>
<li><p>Spark 1.0系からJava8で書ける</p></li>
</ul>


<p>QA：</p>

<p>Q： データをキャッシュできるという話でしたが、キャッシュするということは、ジョブが途中で失敗した場合は最初からやり直しになるのでしょうか？
A： キャッシュしたデータが残っている場合は、途中から再開出来ます。キャッシュしたデータを持ったマシンがこけたら、最初からやり直しです。</p>

<h2>Luceneと日本語の検索</h2>

<h3>自分</h3>

<p>スライド：<a href="https://speakerdeck.com/johtani/lucenetori-ben-yu-falsejian-suo">Luceneと日本語の検索</a>
サンプルのリポジトリ：<a href="https://github.com/johtani/jjug-example">jjug-example</a></p>

<p>自然言語処理にからめて何か話をしてくださいと話を受けていたのですが、自然言語処理については「形態素解析」くらいしか出てこなかったですけど。。。
Luceneがどんなものかを超概要で話をしてみました。少しでもLuceneがどんなものかをわかってもらえたら嬉しいです。</p>

<p>もっと詳しく知りたい方は、スライドにある参考資料などを見ていただければと。</p>

<p>Javaで書くのもいいんですが、もっと簡単に検索したい場合はElasticsearchを使うのが便利ですよ！で締めくくりたかったのですが、発表では失敗してしまいました。。。
Elasticsearchの起動からデータ登録、検索までは<a href="https://speakerdeck.com/johtani/elasticsearch-and-kibana">こちらのスライド</a>を見ていただければ簡単さがわかると思います。</p>

<p>また、Kuromojiを利用した時に、Tokenizerなどが出力するTokenの品詞情報を見たい場合に便利な<a href="https://github.com/johtani/elasticsearch-extended-analyze">Elasticsearch用プラグイン</a>も作っています。
こちらも、Elasticsearchと一緒に使ってみてください。</p>

<h2>まとめ</h2>

<p>機械学習に関していろんなツールがあるのだなぁと。
懇親会でもちょっと話しましたが、アルゴリズムの選定とか、アルゴリズムに適したデータの作成など、前処理のノウハウとかが大変そうだなぁといつも思います。
機械学習はいつもぼやーっとしか理解してないので。。。</p>

<p><a href="https://www.youtube.com/channel/UCZ5gDYmqI0tOeg-fEkCD2CQ">JJUGさんはYouTubeの動画</a>もあるようなので、過去の面白そうなセミナーも合わせてみてみると面白いと思います。</p>

<p>毎度のことですが、なんでも良いので、発表した後のフィードバックをいただけるとうれしいです。
今後の励みや改善につながるので。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[コーヒーブレイク]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/16/a-coffee-break/"/>
    <updated>2014-12-16T12:01:32+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/16/a-coffee-break</id>
    <content type="html"><![CDATA[<p>たまには、他愛のないブログを。</p>

<p>仕事しながら、コーヒーを飲んでます。</p>

<!-- more -->


<p>最近は、サムライズムさんのオフィスに入り浸って仕事してます。
オフィスには、コーヒーミル付きのコーヒーメーカーがあるんです。</p>

<p>↓こんな感じ（現物は違うけど）</p>

<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?t=johtani-22&o=9&p=8&l=as1&asins=B00O7HUQWE&nou=1&ref=qf_sp_asin_til&fc1=000000&IS2=1&lt1=_blank&m=amazon&lc1=0000FF&bc1=000000&bg1=FFFFFF&f=ifr" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>


<p>で、近所のコーヒー問屋で豆を買ってきてます。
そこのマスターに、いつもサジェストされるんです。</p>

<p>「この豆は、日が経つにつれて、細かく挽いて飲んでください。」</p>

<p>「この豆は、細かめに挽いて飲むのがオススメです。」</p>

<p>などなど。
オススメされるんですが、全自動のコーヒーメーカーは残念ながらここまでやってくれません。</p>

<p>ということで、手動のミルを買ってみました。家でも使えるし。</p>

<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?t=johtani-22&o=9&p=8&l=as1&asins=B0044ZA066&nou=1&ref=qf_sp_asin_til&fc1=000000&IS2=1&lt1=_blank&m=amazon&lc1=0000FF&bc1=000000&bg1=FFFFFF&f=ifr" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>


<p>ちょっと考え事しながらとか、頭の切り替えに、ミルを回すのもいいかなと。
気持ち、美味しいコーヒーな気がします（気のせいかも）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logstashプラグインのエコシステムの変更（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/14/plugin-ecosystem-changes/"/>
    <updated>2014-12-14T01:00:40+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/14/plugin-ecosystem-changes</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/plugin-ecosystem-changes/">exciting logstash plugin ecosystem changes</a></p>

<p>Logstash 1.5.0 Beta 1(<a href="http://www.elasticsearch.org/overview/logstash/download/">お試しはこちら</a>)のリリースで、
プラグインのインストール、管理、公開の方法を変更しています。
ユーザやコミュニティからフィードバックをもらいました。
その目的は、プラグインの利用や開発をより簡単にすることです。
このプロジェクトは始まったばかりです。プラグインのコミュニティを探し、
共有するためのワンストップソリューションを提供するこのアイデアを改善していく予定です。
このブログで、この決定を行った理由を説明し、新しいワークフローをと今後のロードマップを説明します。</p>

<!-- more -->


<h2>プラグインがあります！</h2>

<p>Logstashは、プラグイン（input、filter、output、codec）が豊富にあります。
これらは、Elasticsearchにより開発されたものと、コミュニティからコントリビュートされたものです。
Logstashの主な特長の1つは、これらのプラグインの有効性と動作を拡張するプラグインを追加するのが簡単なことです。
現在、165以上のプラグインがエコシステムにあり、これらは、2つのプロジェクトに分かれています。</p>

<ul>
<li><code>logstash-core</code>は最もよく使われるプラグインで、Logstashにデフォルトで含まれます</li>
<li><code>logstash-contrib</code>はコミュニティにより開発されたプラグインを含み、別途ダウンロードできます</li>
</ul>


<h2>新プラグインエコシステムの変更</h2>

<p>1.5.0では、全てのプラグインは、Logstashコアから分離され、rubygemsを使って個別にパッケージングされます。
rubygemsを選択したのは、依存関係のあるライブラリの配布とパッケージングがパワフルで一般的なものだからです。
さらに、<a href="http://rubygems.org/">rubygems.org</a>プラットフォームは配布や探索に影響があります。
また、Logstashにプラグインをインストール、アップデート、削除するのが簡単な基盤も追加しました。
<code>contrib</code>プロジェクトは徐々に終了します。全てのプラグインは個別のプロジェクトになります。</p>

<h2>プラグインエコシステム変更の理由</h2>

<p>多数のプラグインをもっていると、配布と公開に関して難題が出てきます。
私たちが変更するに至った理由は次のようなものです。</p>

<ul>
<li>現在は、プラグインの更新に伴い、Logstashの新バージョンのリリースが必要</li>
<li>開発者は、Logstashのリリース間隔とは別に、新バージョンをリリースをしたい</li>
<li>プラグイン開発者は、外部依存を記述できるようにしたい</li>
<li>Logstashコアの配布パッケージのダウンロードサイズを小さくし、ユーザは必要なプラグインのみインストール</li>
<li><code>logstash-contrib</code>を1つのリポジトリとして管理するのは難しい</li>
</ul>


<h2>詳細：</h2>

<h3>ソースコードの場所</h3>

<p>Logstashのソースコードは、今後も<a href="https://github.com/elasticsearch/logstash">現在のGitHubのリポジトリ</a>のままです。
しかし、プラグインに関するコードやテストコードは含まなくなります。
この分離により、個別のプラグインの改善と同様にコアの改善に集中できます。
これにより、Logstashプロジェクトの全体の品質も向上します。</p>

<p>全プラグインのソースコードは、新しいGitHub organization、<a href="https://github.com/logstash-plugins">logstash-plugins</a>にて管理します。
各プラグインは個別のリポジトリとして、ここに配置されます。
一見すると、これはメンテナンスが難しくなるように思えます。しかし、テスト、Issue、依存関係を明確にすることができます。
私たちの目的は、テスト、ドキュメント、gemの公開の自動化であり、これを簡単にするためのツールを追加します。</p>

<p>しかし、プラグインの開発者はプラグインのソースコードソースコードをlogstash-pluginsに置く必要はありません。
 ー コミュニティで利用可能にするために、<a href="http://rubygems.org/">rubygems.org</a>でそれを公開するだけで良いです。</p>

<h2>ワークフロー</h2>

<p>ここで、新プラグインエコシステムのやりとり/ワークフローについて、いくつかの観点から説明します。</p>

<h3>logstashユーザ:</h3>

<p>ユーザは、これまでのリリース同様にLogstashのバイナリをダウンロードします。
Logstash 1.5.0は、1.4.2でパッケージされていたプラグインと同等のものが含まれています。
新しいシステムに簡単に移行できるようにです。
そして、ユーザは、最初のデプロイの後に、Logstashプラグインのをインストール、アップグレードできるようになります。</p>

<p><code>$LS_HOME/bin/plugin</code>スクリプトがプラグイン操作に関連するコマンドになります。</p>

<h5>プラグインのインストール</h5>

<p>プラグインのほとんどはgemとして<a href="http://rubygems.org/">rubygems.org</a>にアップロードされます。
例えば、もしユーザが<a href="https://github.com/logstash-plugins/logstash-output-kafka">Apache Kafka outputプラグイン</a>をインストールする場合、次のコマンドを実行します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin install logstash-output-kafka</span></code></pre></td></tr></table></div></figure>


<p>または、ファイルをダウンロード済みの場合は次のコマンドとなります。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin install /path/to/logstash-output-kafka-1.0.0.gem</span></code></pre></td></tr></table></div></figure>


<h5>プラグインの削除</h5>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin uninstall logstash-output-kafka</span></code></pre></td></tr></table></div></figure>


<h5>1つまた全プラグインのアップデート</h5>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin update</span></code></pre></td></tr></table></div></figure>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin update logstash-output-kafka</span></code></pre></td></tr></table></div></figure>


<h5>プラグインのリストアップ</h5>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin list</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin list elasticsearch ( List all plugins containing a name )</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin list --group output ( list all outputs )</span></code></pre></td></tr></table></div></figure>


<h4>ドキュメント</h4>

<p>プラグインが個別に管理されても、<a href="http://www.elasticsearch.org/guide/en/logstash/current/index.html">全プラグインのドキュメントは1カ所</a>です。</p>

<h3>logstash plugin開発者:</h3>

<p>プラグイン開発者と作者は、Logstashエコシステムのためにプラグインを公開することができます。
プラグインは、gemやJavaライブラリの依存関係を宣言できます。
より重要なのは、Logstashのリリース間隔に関係なく、プラグインの改善版をリリースできます。</p>

<p>Rubygemsテクノロジはパッケージングシステム、依存関係管理、ホスティングのために選択されてきました。
Rubyのgemを公開することに慣れている開発者は、Logstashプラグインを簡単に公開することができます。
Elasticsearchはこれらの機能に関して開発者を支援するために、ツールを提供、メンテナンスします。</p>

<h4>開発およびローカルでのテスト</h4>

<p>JRuby <code>1.7.16</code>がプラグインを開発するための唯一の前提条件です。
プラグインにパッチを提供するのは以前と同様です。
例えば、<code>logstash-output-kafka</code>にパッチを送るのは次のようになります。</p>

<ol>
<li><code>git clone https://github.com/logstash-plugins/logstash-output-kafka.git</code></li>
<li>変更</li>
<li>プラグインをローカルでテスト

<ul>
<li><code>bundle install</code></li>
<li><code>bundle exec rspec</code></li>
<li>Logstashの他のバージョンもしくはローカルでテストする場合、Gemfileを編集し、    次のように別のロケーションを加えます。<code>gem "logstash", :github =&gt; "elasticsearch/logstash", :ref =&gt; "master"</code></li>
</ul>
</li>
<li>新しいPull Requestを<code>logstash-output-kafka</code>に対して作成</li>
<li>コミュニティでコードレビューを受け、Elasticsearchがパッチを受け入れ</li>
</ol>


<h4>バージョン</h4>

<p>バージョン情報は、それぞれのプラグインの<code>.gemspec</code>で管理します。
例えば、Apache Kafka outputのgemspecは<a href="https://github.com/logstash-plugins/logstash-output-kafka/blob/master/logstash-output-kafka.gemspec">こちら</a>です。
バージョニングは<a href="http://semver.org/">semantic versioning</a>のルールに従い、
Logstashのバージョニングとは別に、プラグインの開発者によって管理されます。
Logstash 1.5.0がリリースされると、マイルストーン1のプラグインはバージョン1.0.0となり、マイルストーン2のプラグインはバージョン2.0.0となるでしょう。</p>

<h4>公開</h4>

<p>開発者が変更を加えプラグインを公開したいと思った時、<code>.gemspec</code>のバージョン番号を変更します。
全テストが成功した時、Elasticsearchはrubygems.orgにプラグインを手動で公開します。
もし、テストが失敗した場合、プラグインは公開されません。
長期的には、プラグインの公開の自動化を行いたいと思っています。
この変更は新しいため、公開の自動化を提供する前に、自動化についてより理解し、プラグインのテスト基盤を改良したいと思っています。</p>

<h4>Issue</h4>

<p>Issueは、各プラグインのGitHubリポジトリに対してオープンなければなりません。
Logstashコアのリポジトリは、コアのパイプラインや共通的な機能に関連するIssueについて扱います。</p>

<h4>ドキュメント</h4>

<p>プラグインのドキュメントはソースコード自体から生成されます。
それぞれのプラグインのドキュメントは、そのプラグインのリポジトリに含まれます。
Elasticsearchは
<a href="http://www.elasticsearch.org/guide">elasticsearch.org/guide</a>に全てのプラグインのドキュメントを集め生成できる基盤を提供します。</p>

<h4>移行</h4>

<p>全ての新しいpull requestとissueは<a href="https://github.com/logstash-plugins">logstash-plugin</a> organisation配下にある各プラグインのリポジトリに対してオープンする必要があります。</p>

<h5>すでにあるPRはどうすれば良いですか？</h5>

<p>気にしないでください。すでにあるpull requestは開発者によって移行する必要はありません。
LogstashチームがLogstashコアリポジトリに対してのPRを、個別の関連するプラグインのリポジトリに対してマージします。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone … # clone the specific plugin repo
</span><span class='line'># now apply the patch
</span><span class='line'>curl -s https://github.com/elasticsearch/logstash/pull/XXXX | git am --3way
</span><span class='line'>git push</span></code></pre></td></tr></table></div></figure>


<p><strong>Note:このプロセスはすでにあるPRに対してgit historyを管理します</strong></p>

<h5>GitHub Issue</h5>

<p>現在、LogstashリポジトリにオープンされているIssueは、それぞれのプラグインのリポジトリに移行します。
Logstashチームがgithub.com APIを利用してこの処理を自動的に行います。
安心してください。私たちが個別のプラグインに対する既存のIssueを移行します。</p>

<h2>今後のロードマップ</h2>

<p>これは、最初のステップであり、これらの変更は、ユーザや開発者に対してエコシステムをよりよくするために、
しっかりとした基盤を提供します。</p>

<p>短期的には、開発者のためにpull requestのフィードバックでテスト自動化を提供する基盤を追加していきます。
プラグインリポジトリのブートストラップや管理のためのツールも提供していきます。</p>

<p>長期的には、すべてのLogstashプラグインを探し、公開するためのコミュニティポータルを提供したいと思っています。
このアイデアは、Puppet ForgeやAWS marketplaceのようなものです。</p>

<p><a href="http://www.elasticsearch.org/blog/logstash-1-5-0-beta1-released/">Logstash 1.5.0 Beta 1</a>をリリースし、これは新しいエコシステムを提供します。
ぜひ、試していただき、これらの変更に関して感じたことを教えてください。
あなたのフィードバック(<a href="http://twitter.com/elasticsearch">Twitter</a>もしくは<a href="https://github.com/elasticsearch/logstash/issues/new">GitHub</a>)はとても貴重です！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logstash 1.5.0 Beta1リリース(日本語訳)]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/12/logstash-1-5-0-beta1-released-ja/"/>
    <updated>2014-12-12T17:17:26+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/12/logstash-1-5-0-beta1-released-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/logstash-1-5-0-beta1-released/">logstash 1.5.0.beta1 released</a></p>

<p>Logstash 1.5.0 Beta1をリリースしました。<a href="http://www.elasticsearch.org/overview/logstash/download/">こちらのページ</a>からダウンロードできます。</p>

<p><strong>Note: ベータリリースです。本番環境では使用しないでください。</strong></p>

<!-- more -->


<h2>1.5.0の主な変更点は？</h2>

<p>1.5.0の主なテーマはプラグイン管理、パフォーマンス改善、<a href="http://kafka.apache.org/">Apache Kafka</a>インテグレーションです。Logstashの主な特徴の1つは
プラグインを利用できることであり、パイプラインの動作を拡張するためにプラグインを追加するのが簡単なことです。
このリリースで、プラグインの開発、管理、公開がより簡単になります。
また、Logstashの速度をより良くしたため、より多くのデータを短時間に処理することができます。
興味ありませんか？では、詳細を見ていきましょう。</p>

<h2>plugin ecosystemの変更</h2>

<p>Logstashは165ものプラグイン(inputs、filters、outputs、codecs)を持っており、
これらはElasticsearchとコミュニティからのコントリビュートで開発されています。
多くのプラグインを管理することは、使いやすさと素早さの間のトレードオフがあります。
Logstashの全てのプラグインをまとめることは使いやすさがある一方、プラグインの更新を取り込むために
Logstashの新しいリリースを待ってもらうことになります。
Logstashからプラグインを分離して個別に配布する場合、更新は簡単になりますが、使いやすさ（特に新しいユーザに）に影響が出ます。</p>

<p>私たちは、プロジェクトを前進させるために、これらのバランスをとることを考えました。
これまで、全ての利用可能なプラグインは’core’と&#8217;contrib&#8217;の2つに分割していました。
&lsquo;core&#8217;にあるよく使われるプラグインは、Logstashに含めていました。
コミュニティによりコントリビュートされたプラグインは&#8217;contrib&#8217;パッケージとして分離して配布していました。
1.5.0のリリースで、ユーザに対してより良いプラグイン管理をできるように変更しました。
全てのプラグインは、それ自身によるパッケージに移行しました。
パッケージングフレームワークとしてrubygemsを使い、<a href="http://rubygems.org/">rubygem.org</a>経由でこれらのプラグインを配布、公開します。
また、Logstashにプラグインのインストール、更新、削除を簡単にするための構造も追加しました。</p>

<p>例えば、S3 output pluginをインストールするには、以下のコマンドを実行します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$LS_HOME/bin/plugin install logstash-output-s3</span></code></pre></td></tr></table></div></figure>


<p>それだけです！Logstashがgemと依存するgemをrubygems.orgからダウンロードし、インストールします。
あなたは、S3にデータを送ることができるようになります。</p>

<p>ダウンロード可能なLogstashリリースはプラグインをまだ多く含んでいますが、
いつでも、個別にプラグインをアップグレードし、インストールすることができます。
プラグインエコシステムの変更に関する詳細のブログ記事をお待ち下さい。</p>

<h2>パフォーマンス改善</h2>

<p>Logstash 1.5.0はより高速になっています。パフォーマンスが改善された2カ所について説明します。</p>

<h3>grok filter</h3>

<p>Grok filterはLogstashで、構造化データを抽出するためにパターンを記述するのに使われます。
本リリースで、人気のある幾つかのパターンのgrok filterのスループットを100%に改善しました。
言い換えると、grok filterを使うときに、Logstashを通してより多くのデータを処理することができます。</p>

<p>私たちのベンチマークテストで、1.5.0と1.4.2のスループットの比較をしました。
利用したデータは690万件のApache Webアクセスlogで、<code>COMBINEDAPACHELOG</code>のgrok patternです。
1.5.0で、スループットは34,000 event per sec(eps)から50,000 epsに増加しました。
両方のテストを8コアのマシンでLogstashで8つのワーカーを実行しました。
これらのテストで、一つのgrok filterを実行し、
<code>stdin</code>と<code>stdout</code>を使ったパイプラインでイベントのスループットを計測しました。
全体的なパフォーマンスは、様々なハードウェアやLogstashのコンフィグによって変化することに注意してください。</p>

<h3>json serialization / deserialization</h3>

<p>JSONのシリアライズ/でシリアライズを<a href="https://github.com/guyboertje/jrjackson">JrJackson</a>ライブラリを利用して実装しました。
これにより、100%以上のスループットの改善がありました。
先ほど説明したパフォーマンステストにおいて、1.3KBのサイズの500,00 JSONイベントを送信し、
16,000 epsから30,000 epsにスループットが改善しました。
45,000サイズのイベントで、850 epsから3500 epsにスループットが増加しました。
すばらしいです。</p>

<h2>apache kafka integration</h2>

<p>いまでは、Apache Kafkaが大規模スケールデータ処理システムでよく利用されます。
Logstashの配備のスケーリングにおいて、Kafkaもまた、shippingインスタンスとindexingインスタンス間の
データを保存するための中間メッセージバッファとして使うことができます。</p>

<p>1.5.0で、Logstash Kafkaのinputとoutputのプラグインのビルトインサポートを追加しました。
これは、<a href="https://github.com/joekiller/logstash-kafka">Joseph Lawson</a>によって最初に開発されました。
私たちは、これらのプラグインにインテグレーションテストとドキュメントを追加することにより改良し、
新しいKafkaの機能を開発し続けます。
また、<a href="http://avro.apache.org/">Apache Avro</a> codecを追加することで、Kafkaに保存されたイベントを
簡単に取得でき、ELKスタックを使ってそれらを解析できるようにしました。</p>

<p>Kafka inputを追加するのは次のコマンドです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$LS_HOME/bin/plugin install logstash-input-kafka</span></code></pre></td></tr></table></div></figure>


<p>Kafka outputは次のコマンドです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$LS_HOME/bin/plugin install logstash-output-kafka</span></code></pre></td></tr></table></div></figure>


<h2>セキュリティに関する改善</h2>

<p>認証と経路暗号化のサポートを追加し、Elasticsearchのoutput、input、filterのセキュリティを改良しました。
例えば、HTTPプロトコルでSSL/TLSにより暗号化を有効にでき、
HTTPベーシック認証をユーザ名とパスワードをリクエストに与えることで設定できます。
これらの機能は、時期にリリースされる<a href="http://www.elasticsearch.org/overview/shield/">Elasticsearch Shield</a>セキュリティプロダクトとLogstashを統合できます。</p>

<h2>ドキュメント</h2>

<p>これまで、Logstashのドキュメントは[logstash.net])(<a href="http://logstash.net/">http://logstash.net/</a>)に置いてあり、
他のELKスタックと一緒に動かす時に、情報を探すのが厄介でした。
1.5.0および、今後のバージョンのドキュメントはelasticsearch.orgの<a href="http://www.elasticsearch.org/guide/en/logstash/current/index.html">Logstash Guide</a>に移行します。
この移行で<a href="http://elasticsearch.org/guide">elasticsearch.org/guide</a>にELKスタックを利用、
学習するためにドキュメントが1つになりました。
このベータリリースのイテレーションで、私たちはプレゼンテーションとドキュメントの品質を改善することに活発に取り組んでいきます。
(過去のLogstashのドキュメントの全てはいままでの<a href="http://logstash.net/docs/1.4.2/">logstash.net</a>で引き続き公開していく予定です。)</p>

<h2>バグフィックスと改善</h2>

<p>ここまでの新しい機能に加えて、Logstash 1.5.0では、多くのバグフィックスと多くの機能改善があります。
ここで、これらのいくつかを紹介します。</p>

<ul>
<li>出力しない&#8217;metadata&#8217;をイベントに格納可能に。これは、例えば、date filterに使う中間フィールドのために必要。(<a href="https://github.com/elasticsearch/logstash/issues/1834">#1834</a>,<a href="https://logstash.jira.com/browse/LOGSTASH-1798"> #LOGSTASH-1798</a>)</li>
<li>HTTPを利用しているときのファイルデスクリプタリークの修正。Logstashがストールするのを防ぎ、OOMエラーからクラッシュするケースも防ぎます。(<a href="https://github.com/elasticsearch/logstash/issues/1604">#1604</a>)</li>
<li>Twitter input:<code>full_tweet</code>オプションの追加、Twitter rate limitingエラーのハンドリング(<a href="https://github.com/elasticsearch/logstash/issues/1471">#1471</a>)</li>
<li>イベントを生成するfilter(multiline、clone、split、metrics)により、
後続の条件文にこれらのイベントを正しく伝搬(<a href="https://github.com/elasticsearch/logstash/issues/1431">#1431</a>)</li>
<li>Elasticsearch output:Logstashはデフォルトで<code>message.raw</code>フィールドを作成しない。messageフィールドはElasticsearch
により<code>not_analyzed</code>でマルチフィールドとして追加される。マルチフィールドはディスクスペースが2倍必要だが、利点がない。</li>
<li>bin/logstashの複数のサブコマンドを除去(<a href="https://github.com/elasticsearch/logstash/issues/1797">#1797</a>)</li>
</ul>


<p>これらの機能、改善、バグフィックスについては、Logstash 1.5.0.Beta1 の<a href="https://github.com/elasticsearch/logstash/blob/master/CHANGELOG">changelog</a>をごらんください。</p>

<h2>試してみてください！</h2>

<p>ぜひ、Logstash 1.5.0 Beta 1をダウンロードして試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/logstash/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2014年のElasticsearch]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/01/about-elasticsearch-in-2014/"/>
    <updated>2014-12-01T18:05:48+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/01/about-elasticsearch-in-2014</id>
    <content type="html"><![CDATA[<p>早いもので、師走です。今年もあと少しとなりました。ということで、Advent Calendarの季節が始まりました。</p>

<p>この記事は<a href="http://qiita.com/advent-calendar/2014/elasticsearch">Elasticsearch Advent Calndar 2014</a>の1日目のエントリです。</p>

<p>1日目ということで、簡単に今年の変遷を振り返りつつ、今年導入された新機能についてピックアップしてみようかと思います。</p>

<!-- more -->


<h2>1.0リリース(Lucene 4.6.0)</h2>

<p>今年一番の目玉と思いますが、1月にRCが公開されて、1.0.0が2月にリリースされました。
（ElasticSearch Serverの翻訳が昨年末に終わってレビューをしていた段階での発表だったので個人的にはきついタイミングでした）
1.0の主な変更点はこちら。</p>

<h3>Elasticsearch（Sが小文字に）</h3>

<p>1.0からSが小文字になりました。(<a href="https://github.com/elasticsearch/elasticsearch/issues/4634">#4634</a>)
0.90以前のバージョンについては、Sが大文字になっています。
ややこしいですが、今年の3月に出版された黒い<a href="http://www.amazon.co.jp/dp/4048662023/ref=as_sl_pc_tf_lc?tag=johtani-22&amp;camp=243&amp;creative=1615&amp;linkCode=as1&amp;creativeASIN=4048662023&amp;adid=0YAE2J8RE36SX7N3R06Z&amp;&amp;ref-refURL=http%3A%2F%2Fblog.johtani.info%2F">ElasticSearch Server日本語版</a>は原著が0.20で日本語版にするタイミングで0.90に対応しました。
このため、こちらの書籍のタイトルはSが大文字となっています。
（なお、<a href="https://www.packtpub.com/big-data-and-business-intelligence/elasticsearch-server-second-edition">原著の2nd Edition</a>は小文字になっています）</p>

<h3>Snapshot/Restoreの導入とGatewayの廃止</h3>

<p>0.90以前のバージョンでは、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/0.90/modules-gateway.html#modules-gateway">gatewayというモジュール</a>で、S3などにインデックスのメタデータなどを保存する機能がありました。
この機能は、0.20からlocal以外はdeprecatedとなりました。</p>

<p>インデックスのバックアップ、リストアのために、1.0で実装されたのが<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-snapshots.html#modules-snapshots">Snapshot/Restore</a>です。
Snapshot/Restoreでは、インデックスごと、もしくはクラスタ全体をリモートにあるリポジトリにスナップショットを取ることが可能となりました。
初期リリースの段階では、共有ファイルシステムのみでしたが、現在は、S3やHDFSなどに保存が可能となっています。</p>

<h3>Aggregation</h3>

<p>Facetをより強力にしたものです。Facetでは、指定したフィールドの集計のみでした。
データの解析などを行うには、独自で集計する必要がありました。
この機能をより柔軟に行えるように実装したのが<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations.html">Aggregation</a>です。</p>

<p>たとえば、アクセスログを日毎に集計し、さらに日毎の集計に対して国別の集計やユーザエージェントごとの集計をさらに行うといった感じです。
Facetの場合は、日毎の検索結果に対して個別に集計するのみでしたが、Aggregationを使うことで、1週間の検索結果に対して、
日毎に国別の集計を行うといったことが可能になっっています。</p>

<h3>cat API</h3>

<p>&ldquo;=^.^=&#8221;猫が出てくるAPIです。(違う)</p>

<p>Elasticsearchでは、クラスタの状態などが全てREST APIで取得でき、JSONで結果が帰ってきていました。
JSONはプログラムなどで処理を行う場合は便利ですが、コンソールで確認したり、管理系のツールでメールで通知する場合などは見にくいことがあります。
これを解消したのが<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/cat.html"><code>_cat</code> API</a>です。（<a href="http://www.elasticsearch.org/blog/introducing-cat-api/">公式の紹介ブログはこちら</a>）</p>

<h3>Circuit Breaker</h3>

<p>OOMが発生しそうなfielddataの読み込みを検知して、事前に防ぐ機構になります。
初期段階ではFielddataに対してのものから実装されました。</p>

<h2>1.1リリース(Lucene 4.6.1)</h2>

<p>3月にリリースされました。Elasticsearchはまだまだ発展しているため、リリースのサイクルが短いのが特徴です。</p>

<p>1.x系では、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-upgrade.html#setup-upgrade">Rolling Upgrade</a>が導入されました。このため、クラスタ全体を停止することなく、クラスタのアップグレードが可能になりました。</p>

<h3>search templates</h3>

<p>検索クエリをテンプレートとして登録することができる<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-template.html#search-template">search templates</a>です。
JSONでクエリを記述できるのは便利ですが、毎回組み立てるのは大変かもしれません。
特に、固定のクエリをプログラムから利用するような場合などです。
テンプレートとして登録しておくことで、検索時に値を埋め込むだけで検索ができるようになりました。</p>

<h3>Aggregationの強化</h3>

<p>Aggregationの種類が増えました。</p>

<ul>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-metrics-cardinality-aggregation.html#search-aggregations-metrics-cardinality-aggregation">cardinality</a>：ユニークユーザ数の集計などが行えるaggregationです。HyperLogLog++アルゴリズムを利用した実装になっています。</li>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-bucket-significantterms-aggregation.html">significant_terms</a>：単語の数による集計ではなく、コレクション全体に対する単語の頻度と、検索結果に対する単語の頻度を計算することで、重要度を計ることができます。</li>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-metrics-percentile-aggregation.html#search-aggregations-metrics-percentile-aggregation">percentiles</a>：パーセンタイル値を計算できます。</li>
</ul>


<h2>1.2リリース(Lucene 4.8系)</h2>

<h3>Java 7必須</h3>

<p>利用しているLuceneがJava 7必須となったためです。また、Java 6のEOLも切れてますし。</p>

<h3>dynamic scriptingがデフォルトオフ</h3>

<p>採用していたMVELがサンドボックス化に対応していないため、危険を回避するためにオフとなりました。</p>

<h3>インデキシングとマージング</h3>

<p>インデキシングとマージ処理に関するさまざまな改善。</p>

<ul>
<li>flushのthreasholdを操作回数ではなく、サイズや時間によるものに変更</li>
<li>デフォルトをConcurrentMergeSchedulerに変更</li>
</ul>


<h2>1.3リリース(Lucene 4.9.0系)</h2>

<h3>セキュリティ関連</h3>

<ul>
<li>JSONPのデフォルトオフ</li>
<li>MVELの非推奨化（1.4で削除）＋<code>script.disable_dynamic</code>のデフォルト値が<code>sandbox</code></li>
</ul>


<h3>aggregationの強化</h3>

<ul>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-metrics-top-hits-aggregation.html#search-aggregations-metrics-top-hits-aggregation">top hits</a>：Field Collapsing/combiningと呼ばれる機能です。たとえば、いくつかのサイトのHTMLを収集して検索機能を提供する場合に、ドメインごとに1件ずつ検索結果に出したい場合などに利用できる機能です。</li>
</ul>


<p>その他にも以下のaggregationが追加されています。
* <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-metrics-percentile-rank-aggregation.html">percentile ranks</a>
* <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-metrics-geobounds-aggregation.html">geo bounds</a></p>

<h3>mappingのtransform</h3>

<p>Mappingに<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-transform.html#mapping-transform">transform</a>機能が追加されました。
mappingにドキュメントの値を元に、インデキシング時に変換処理を記述できます。
たとえば、特定のフィールドにある値がある場合にだけ、あるフィールドに値を入れるなどといったことが可能になります。</p>

<h3>ディスク関連</h3>

<ul>
<li>disk based shard allocation deciderが導入されました。ノードのディスクの使用率を元に、シャードを配置しても良いかといった決定を行う機構です。</li>
<li>チェックサムによるファイルのチェック（Lucene4.9で導入されたコードへの切り替え）</li>
</ul>


<h2>1.4リリース(Lucene 4.10系)</h2>

<p>ベータ版が出されるほど、多くの改善が入っています。</p>

<h3>resiliency</h3>

<ul>
<li><a href="#memory-mgmt">メモリ使用量の低下</a>によるノードの安定性向上

<ul>
<li>DocValues、リクエストごとのcircuit breakerなど</li>
</ul>
</li>
<li>discoveryアルゴリズムの改善による<a href="#cluster-stability">クラスタの安定性</a>向上</li>
<li><a href="#checksums">チェックサム</a>の導入による破損したデータの検知</li>
</ul>


<h3>セキュリティ関連</h3>

<ul>
<li>CORSをデフォルト無効</li>
<li>Groovyがデフォルトのスクリプト言語に。</li>
</ul>


<h3>Aggregationの強化</h3>

<p>以下のaggregationが追加されています。
* <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-filters-aggregation.html#search-aggregations-bucket-filters-aggregation">filter</a>、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-children-aggregation.html#search-aggregations-bucket-children-aggregation">children</a>、<a href="%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88">scripted_metric</a></p>

<h3>Upgrade API</h3>

<p>インデックスを最新のバージョンのものにアップグレードするためのAPIです。
Luceneは下位互換を保ってくれているため、古いバージョンのインデックスも読み込むことが可能です。
ただ、最新バージョンで使える機能が制限されていたりということもあります。
クラスタにあるインデックスをアップグレードするのにかかる時間や必要かどうかといったことを取得できる仕組みも提供します。</p>

<p>また、Lucene自体は、1つ前のメジャーバージョン（4.x系だと3.x系まで）までの互換性は提供していますが、
2つ前のメジャーバージョンの互換性がなくなります。
Luceneも5.x系のブランチが作成されており、5系のリリースにより、3系との互換性がなくなります。
5系のリリースに対応する場合にも、こちらのAPIが助けになるかと。</p>

<h3>1.4.1</h3>

<p>11/27に<a href="http://blog.johtani.info/blog/2014/11/27/elasticsearch-1-4-1-released-ja/">1.4.1がリリース</a>されました。
シャードの配置やparent/child、nestedドキュメントの改善などが行われています。</p>

<h2>まとめ</h2>

<p>ということで、駆け足で、1月から11月までのElasticsearchの流れを追ってみました。
1.0で大きな機能追加、改善が行われ、その後も活発に開発が行われています。
要望などがあれば、MLで聞いてみたりやGitHubに登録するなどを行っていただければと。</p>

<p>あと、今年から来年にかけての大きなイベントとして、
<a href="http://www.elasticon.com/">Elasticsearch初のユーザカンファレンスのサイトがオープン</a>しました。
Elasticsearchに関するいろいろな話が聞ける機会だと思うので、興味のある方は見ていただければと。</p>

<p>では、また次のAdvent Calendarで！（最終日の予定ですが、空きがあるのでなにか書くかも）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 1.4.1および1.3.6リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/27/elasticsearch-1-4-1-released-ja/"/>
    <updated>2014-11-27T11:43:32+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/27/elasticsearch-1-4-1-released-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-1-released/">elasticsearch 1.4.1 and 1.3.6 released</a></p>

<p>本日、<strong>Lucene 4.10.2</strong>をベースにした<strong>Elasticsearch 1.4.1</strong>と、バグフィックスリリースである、<strong>Elasticsearch 1.3.6</strong>をリリースしました。
ダウンロードおよび変更リストはそれぞれ次のリンクからアクセスできます。</p>

<ul>
<li>最新ステーブルリリース：<a href="http://www.elasticsearch.org/downloads/1-4-1">Elasticsearch 1.4.1</a></li>
<li>1.3.x系バグフィックス：<a href="http://www.elasticsearch.org/downloads/1-3-6">Elasticsearch 1.3.6</a></li>
</ul>


<p>過去のリリースに関するブログ（公式）はこちら。</p>

<ul>
<li>1.4:<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-released/">1.4.0</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-beta-released/">1.4.0.Beta1</a></li>
<li>1.3:<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-released/">1.3.5</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-4-released/">1.3.4</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-3-released/">1.3.3</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-2-released/">1.3.2</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-1-released/">1.3.1</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-0-released/">1.3.0</a>.</li>
</ul>


<p>すべての変更については<a href="http://www.elasticsearch.org/downloads/1-4-1">1.4.1のリリースノート</a>および<a href="http://www.elasticsearch.org/downloads/1-3-6">1.3.6のリリースノート</a>をごらんください。
以下では、重要な変更について紹介します。</p>

<!-- more -->


<h2>shard allocation</h2>

<p>Elasticsearch 1.3.0で、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-allocation.html#disk">disk based shard allocation</a>が
デフォルトで有効になっています。
もし、ノードのディスクの使用量が<code>law</code>で指定された値（85%）を超えた場合、ノードにはシャードが配置されません。
また、<code>high</code>で指定された値（90%）を超えた場合、シャードを他のノードへ移動します。</p>

<p>Elasticsearch 1.4.1では、disk based shard allocationに3つの改良が追加されました。</p>

<ul>
<li>ディスク使用量のチェックはシャードがクラスタに配置されるタイミングでのみ実施していた。現在は60秒ごとに使用量をチェック。(<a href="https://github.com/elasticsearch/elasticsearch/pull/8270">#8270</a>)</li>
<li>ディスクフルメッセージは<code>DEBUG</code>レベルでログに出力されていました。なぜ、新しいシャードが配置されないのかを説明するのが困難でした。現在は<code>WARN</code>レベルで30秒ごとにログに出力されます。(<a href="https://github.com/elasticsearch/elasticsearch/pull/8382">#8382</a>)</li>
<li>以前は、シャードをもう一つのノードへ動かすべきかどうか決めるとき、allocation deciderはノードにあるシャードのサイズを考慮するだけでした。現在は、動かされるシャードのサイズも考慮します。これにより、必要最小限のシャードの移動量となります。(<a href="https://github.com/elasticsearch/elasticsearch/pull/8569">#8569</a>)</li>
</ul>


<h2>parent/child and nested documents</h2>

<p>Elasticsearch 1.4.0で、parent/childとnestedドキュメントに対して（新しいセグメントを開くときに）固定長ビットセットフィルタを構築しキャッシュしました。クエリ、フィルタおよびAggregationを常に速くするためにです。
多くの<code>nested</code>フィールドを持つユーザにとっては、以前のバージョンよりもヒープの使用量が大きくなってしまいました。</p>

<p><code>nested</code> aggregationによって処理されるドキュメントの順序を変更すること(<a href="https://github.com/elasticsearch/elasticsearch/pull/8454">#8454</a>)によって、固定長ビットセットフィルタが子のドキュメントに対して必要でなくなりました。
現在は、親のドキュメント（つまり、nested<strong>ではない</strong>ドキュメント）を表すフィルタのみをキャッシュしています。これにより必要なキャッシュ空間のサイズを減少しました。(<a href="https://github.com/elasticsearch/elasticsearch/pull/8414">#8414</a>、<a href="https://github.com/elasticsearch/elasticsearch/pull/8440">#8440</a>)</p>

<h2>date ranges</h2>

<p>2つの日付範囲に関する問題がこのリリースで修正されました。
1つ目は、日付を丸めるかというものです。例えば、<code>timestamp</code>フィールドに1秒の解像度の値があるとします。
<code>{"lt": "2014/11/26||/d"}</code>という<code>range</code>フィルタは<code>2014/11/26 00:00:00</code>未満のタイムスタンプのデータを結果として返しました。
しかし、<code>lt</code>を<code>lte</code>に変更した場合、<code>2014/11/27 00:00:00</code>以外の値も含めたいです。</p>

<p>以前は、<code>lte</code>は<code>2014/11/27 00:00:00</code>のタイムスタンプも含めてしまっていました。現在は、想定通りの動作をします。(<a href="https://github.com/elasticsearch/elasticsearch/pull/8556">#8556</a>)</p>

<p>2つ目のバグは日付の範囲条件に<code>now()</code>を利用したaliasとpercolatorフィルタです。
<code>now()</code>の値を、フィルタが作成したタイミングで決定していました。フィルタが実行されるたびに更新せずにです。
<a href="https://github.com/elasticsearch/elasticsearch/pull/8534">#8534</a>で、<code>now()</code>はaliasとpercolatorで想定通りの動作をします。</p>

<h2>試してみてください。</h2>

<p>ぜひ、<a href="http://www.elasticsearch.org/downloads/1-4-1">Elasticsearch 1.4.1</a>をダウンロードして、試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/elasticsearch/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[インデックステンプレートとLogstash]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/25/import-apache-accesslog-using-logstash-2/"/>
    <updated>2014-11-25T16:25:46+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/25/import-apache-accesslog-using-logstash-2</id>
    <content type="html"><![CDATA[<p>前回の「<a href="http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash/">Logstashを利用したApacheアクセスログのインポート</a>」の続きです。
前回の記事では、Logstashの設定ファイルについて説明しました。
今回は「Elasticsearchに設定するインデックステンプレート」について説明します。</p>

<!-- more -->


<h2>テンプレートの設定</h2>

<p>Elasticsearchでは、登録するデータの特性に合わせてMappingを定義する方がデータを効率良く扱うことができる場合があります。
この場合、通常ですと、インデックス作成時にMappingを指定します。</p>

<p>ただ、今回は、<a href="http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash#output-elasticsearch">インデックス名に「年」を含める形</a>で指定してあります。
「年」はLogstashで処理したデータによって決まります。このため、あらかじめMappingを指定してインデックスを作成するのは難しいです。</p>

<p>このような場合に便利な機能として、「<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-templates.html#indices-templates">インデックステンプレート</a>」があります。</p>

<h3>インデックステンプレートとは</h3>

<p>実際のテンプレートの説明に入る前に、少しだけ説明を。
インデックステンプレートとは、インデックスが作成されるタイミングで自動的に適用される設定をテンプレートとして登録できる機能のことです。
実際にテンプレートが適用されるかどうかは、インデックス名で判断されます。</p>

<p>例えば、大して重要でもなく、データ量も少ないインデックス用のテンプレートとして、シャード数が1、レプリカ数が0、&#8221;_source&#8221;を保存しない設定のテンプレートを登録する場合、
次のようになります。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">curl -XPUT localhost:9200/_template/template_1 -d &#39;</span>
</span><span class='line'><span class="l-Scalar-Plain">{</span>
</span><span class='line'>  <span class="l-Scalar-Plain">&quot;template&quot;</span> <span class="p-Indicator">:</span> <span class="s">&quot;te*&quot;</span><span class="err">,</span>
</span><span class='line'>  <span class="s">&quot;settings&quot;</span> <span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;number_of_shards&quot;</span> <span class="p-Indicator">:</span> <span class="nv">1</span><span class="p-Indicator">,</span>
</span><span class='line'>    <span class="s">&quot;number_of_replicas&quot;</span> <span class="p-Indicator">:</span> <span class="nv">0</span>
</span><span class='line'>  <span class="p-Indicator">}</span><span class="err">,</span>
</span><span class='line'>  <span class="s">&quot;mappings&quot;</span> <span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;type1&quot;</span> <span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;_source&quot;</span> <span class="p-Indicator">:</span> <span class="p-Indicator">{</span> <span class="s">&quot;enabled&quot;</span> <span class="p-Indicator">:</span> <span class="nv">false</span> <span class="p-Indicator">}</span>
</span><span class='line'>    <span class="p-Indicator">}</span>
</span><span class='line'>  <span class="p-Indicator">}</span>
</span><span class='line'><span class="err">}</span>
</span><span class='line'><span class="s">&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>_template</code>がインデックステンプレートを登録するためのエンドポイントです。
<code>template_1</code>がこのテンプレートのIDです。削除などについては、このIDを利用します。</p>

<p>そして、重要なのは、&#8221;<code>template</code>&ldquo;の設定です。
&rdquo;<code>template</code>&ldquo;には、このテンプレートが適用されるべきインデックス名を記載します。
上記サンプルでは<code>te*</code>となっているため、<code>te</code>で始まる名前のインデックスを作成した場合にテンプレートにある設定が適用されます。</p>

<h3>今回利用するテンプレート</h3>

<p>私がJJUG CCCや第7回Elasticsearch勉強会のKibana4のデモで利用したインデックスのテンプレートは次のものになります。
&ldquo;<code>template</code>&#8220;には、<a href="http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash/#output-elasticsearch">前回の記事で紹介したoutput/elasticsearchの設定</a> に合致する<code>new_demo_access_log-*</code>を指定しています。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">curl -XPUT localhost:9200/_template/new_access_log_for_demo -d &#39;</span>
</span><span class='line'><span class="l-Scalar-Plain">{</span>
</span><span class='line'>  <span class="l-Scalar-Plain">&quot;template&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;new_demo_access_log-*&quot;</span><span class="err">,</span>
</span><span class='line'>  <span class="s">&quot;settings&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;number_of_shards&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;2&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>    <span class="s">&quot;number_of_replicas&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;0&quot;</span>
</span><span class='line'>  <span class="p-Indicator">}</span><span class="err">,</span>
</span><span class='line'>  <span class="s">&quot;mappings&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;_default_&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;dynamic_templates&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">[</span>
</span><span class='line'>        <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;string_template&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>            <span class="s">&quot;mapping&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">},</span>
</span><span class='line'>            <span class="s">&quot;match_mapping_type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>            <span class="s">&quot;match&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;*&quot;</span>
</span><span class='line'>          <span class="p-Indicator">}</span>
</span><span class='line'>        <span class="p-Indicator">}</span>
</span><span class='line'>      <span class="p-Indicator">],</span>
</span><span class='line'>      <span class="s">&quot;properties&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>        <span class="s">&quot;path&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;multi_field&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>          <span class="s">&quot;fields&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>            <span class="s">&quot;no_analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">},</span>
</span><span class='line'>            <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">}</span>
</span><span class='line'>          <span class="p-Indicator">}</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;referer&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;multi_field&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>          <span class="s">&quot;fields&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>            <span class="s">&quot;no_analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">},</span>
</span><span class='line'>            <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">}</span>
</span><span class='line'>          <span class="p-Indicator">}</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;agent&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;multi_field&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>          <span class="s">&quot;fields&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>            <span class="s">&quot;no_analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">},</span>
</span><span class='line'>            <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">}</span>
</span><span class='line'>          <span class="p-Indicator">}</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;geoip&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;object&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>          <span class="s">&quot;properties&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>            <span class="s">&quot;location&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;geohash&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;geohash_precision&quot;</span><span class="p-Indicator">:</span> <span class="nv">10</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;geo_point&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;lat_lon&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;geohash_prefix&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span>
</span><span class='line'>            <span class="p-Indicator">}</span>
</span><span class='line'>          <span class="p-Indicator">}</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;response&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;copy_to&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;response_int&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;bytes&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;long&quot;</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;response_int&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;integer&quot;</span>
</span><span class='line'>        <span class="p-Indicator">}</span>
</span><span class='line'>      <span class="p-Indicator">}</span>
</span><span class='line'>    <span class="p-Indicator">}</span>
</span><span class='line'>  <span class="p-Indicator">}</span>
</span><span class='line'><span class="err">}</span>
</span><span class='line'><span class="s">&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<h4>settings設定</h4>

<p>デモ用であり、手元で2台のノードを起動するということもあり、<code>number_of_shards</code>に<code>2</code>を、<code>number_of_replicas</code>に<code>0</code>を指定してあります。</p>

<h4>mappings設定</h4>

<h5>インデックスのタイプ</h5>

<p>Mappingsの指定は通常、特定の<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/glossary.html#glossary-type">タイプ</a>を指定します。
今回のデモでは、1種類しかないのですが、タイプ名を特に意識しないために、<code>_default_</code>を使用しました。
この場合、任意のタイプに適用されることとなります。
タイプを指定してMappingの設定を行う場合は<code>_default_</code>の部分に特定のタイプ名を記入します。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="s">&quot;mappings&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;_default_&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="nv">...</span>
</span></code></pre></td></tr></table></div></figure>


<h5>ダイナミックテンプレート</h5>

<p>次は<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-root-object-type.html#_dynamic_templates">ダイナミックテンプレート</a>です。
インデックステンプレートはインデックスの設定をテンプレート化しました。ダイナミックテンプレートはフィールドに対してテンプレートを設定できます。</p>

<p>以下のダイナミックテンプレートでは、<code>string</code>タイプのフィールドのデフォルト設定を変更しています。
通常、<code>string</code>タイプのフィールドは<code>analyzed</code>となりますが、<code>not_analyzed</code>に変更してあります。
詳しく検索したいフィールドの方が少ないためです。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="nn">...</span>
</span><span class='line'><span class="s">&quot;dynamic_templates&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">[</span>
</span><span class='line'>  <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;string_template&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;mapping&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>        <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>        <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>      <span class="p-Indicator">},</span>
</span><span class='line'>      <span class="s">&quot;match_mapping_type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;match&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;*&quot;</span>
</span><span class='line'>    <span class="p-Indicator">}</span>
</span><span class='line'>  <span class="p-Indicator">}</span>
</span><span class='line'><span class="p-Indicator">]</span><span class="err">,</span>
</span><span class='line'><span class="nn">...</span>
</span></code></pre></td></tr></table></div></figure>


<h5>multi_field指定</h5>

<p>検索もしたいし、Terms Aggregationでも利用したいフィールドについては、<code>multi_field</code>を利用して、
<code>analyzed</code>と<code>not_analyzed</code>の2種類のフィールドを用意しています。
<code>multi_field</code>設定を用いることで、1つのJSONのデータから、異なる形のフィールドを用意することが可能です。</p>

<p>今回のテンプレートでは、<code>path</code>、<code>referer</code>、<code>agent</code>に<code>multi_field</code>を指定しました。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="nn">...</span>
</span><span class='line'><span class="s">&quot;path&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;multi_field&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>  <span class="s">&quot;fields&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;no_analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>    <span class="p-Indicator">},</span>
</span><span class='line'>    <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>    <span class="p-Indicator">}</span>
</span><span class='line'>  <span class="p-Indicator">}</span>
</span><span class='line'><span class="p-Indicator">}</span><span class="err">,</span>
</span><span class='line'><span class="nn">...</span>
</span></code></pre></td></tr></table></div></figure>


<p>例えば、上記の設定の場合、入力のJSONは<code>path</code>というデータのみですが、インデックス上には<code>path.no_analyzed</code>と
<code>path.analyzed</code>というフィールドができあがります。
実際に検索する場合は、<code>path.analyzed:検索したい文字列</code>という形で検索をすることで、いわゆる部分一致のような検索が可能です。
また、完全一致をしたい場合は<code>path.no_analyzed:検索したい文字列</code>という指定になります。
用途を考えると、<code>request</code>も指定したほうが良いかもしれません。</p>

<h5>geoip</h5>

<p><a href="http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash#filter-geoip">Logstashでgeoipデータ</a>を付与していました。
このgeoipのデータをKibana4で利用するために、geoデータとして登録する必要があります。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="s">&quot;geoip&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;object&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>  <span class="s">&quot;properties&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;location&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;geohash&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;geohash_precision&quot;</span><span class="p-Indicator">:</span> <span class="nv">10</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;geo_point&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;lat_lon&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;geohash_prefix&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span>
</span><span class='line'>    <span class="p-Indicator">}</span>
</span><span class='line'>  <span class="p-Indicator">}</span>
</span><span class='line'><span class="p-Indicator">}</span><span class="err">,</span>
</span></code></pre></td></tr></table></div></figure>


<p>上記の設定がgeoデータの指定です。
<code>type</code>に<code>object</code>が指定してありますが、これは、geoipのデータがネストしているためです。
geoipオブジェクトのうち、緯度経度のデータは<code>location</code>に入っているため、こちらに緯度経度関係の設定を指定します。</p>

<ul>
<li><code>"type": "geo_point"</code>：<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-geo-point-type.html#mapping-geo-point-type"><code>geo_point</code></a>タイプであることを指定</li>
<li><code>"geohash": true</code>：緯度経度のデータをもとに、geohashの値もインデックス</li>
<li><code>"geohash_precision": 10</code>：geohashの精度の指定</li>
<li><code>"lat_lon": true</code>：緯度経度を個別の<code>.lat</code>、<code>.lon</code>というフィールドにもインデックス</li>
<li><code>"geohash_prefix": true</code>：該当するgeohashのみでなく、その親にあたるgeohashについてもインデックスする</li>
</ul>


<h5>response、response_int、bytes</h5>

<p>最後は、response、response_int、bytesです。</p>

<p>responseには、HTTPステータスコードが入ります。
文字列としても扱いたいですが、integerとして、Renge Aggregationなどを行いたいので、
response_intというフィールドにも値を入れています。
<code>multi_field</code>でも可能ですが、ここでは、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-core-types.html#copy-to"><code>copy_to</code></a>を利用しました。
<code>copy_to</code>を用いることで、異なるフィールドに値をコピーすることができます。</p>

<p>bytesについては、longで扱いたいとういう理由だけです。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="s">&quot;response&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;copy_to&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;response_int&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>  <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'><span class="p-Indicator">}</span><span class="err">,</span>
</span><span class='line'><span class="s">&quot;bytes&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;long&quot;</span>
</span><span class='line'><span class="p-Indicator">}</span><span class="err">,</span>
</span><span class='line'><span class="s">&quot;response_int&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;integer&quot;</span>
</span><span class='line'><span class="p-Indicator">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>まとめ</h2>

<p>今回はデモに利用したインデックスてプレートについて説明しました。
前回の、Logstashの設定とこのインデックステンプレートを用いることで、Kibanaで解析するデータの準備ができます。
実際の操作などについては、また次回の記事で説明しようかと思います。</p>

<p>不明な点、誤植などありましたら、コメント欄へお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logstashを利用したApacheアクセスログのインポート]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash/"/>
    <updated>2014-11-21T17:30:39+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash</id>
    <content type="html"><![CDATA[<p>JJUG CCCや第7回Elasticsearch勉強会のKibana4のデモにアクセスログを利用しました。</p>

<p>ただ、セッションでは、どうやってElasticsearchに投入したのかという詳しい話をしていませんでした。
本記事では、データ取り込み時に利用したLogstashの設定ファイルについて説明します。</p>

<!-- more -->


<p>Logstashの設定の説明に入る前に、全体の流れを。
「ApacheアクセスログをKibana4により可視化」です。</p>

<h2>材料の準備</h2>

<p>「ApacheアクセスログをKibana4により可視化」に必要な材料は次の通りです。
（今回は起動するところまでいかないので、実際に必要なのは次回以降になります。）</p>

<ul>
<li>Java 7（u55以上を1つ）</li>
<li>Logstash 1.4.2（1つ）</li>
<li>Elasticsearch 1.4.0（1つ）</li>
<li>Kibana4 Beta2（1つ）</li>
<li>Apacheのアクセスログ（適量）</li>
</ul>


<p>Apacheのアクセスログ以外は、公式サイトからダウンロードできます。
それぞれをダウンロードして、起動できるようにしておきましょう。</p>

<p>※1台のマシン上で行う場合は、アクセスログの量を少なめにするなどの対策をとりましょう。
※今回は、1台のマシン（Mac）上で、VMなどを利用せず、それぞれ直接起動するものとします。</p>

<h2>可視化の手順と流れ</h2>

<p>可視化の流れとしては、</p>

<ol>
<li>Logstashでファイルを読み込み、各種処理（パースしたり、情報を追加したり、切り出したり）</li>
<li>Elasticsearchに保存</li>
<li>Kibanaでグラフを作ったり、検索してみたり</li>
</ol>


<p>です。</p>

<p>今回は、1のLogstashでファイルを読み込んだりする設定ファイルの説明です。</p>

<h3>Logstashの設定</h3>

<h4>Logstashの基本</h4>

<p>まずは、Logstashの設定ですが、簡単にLogstashの説明を。
Logstashは大きく3つのパーツに分かれています。</p>

<ol>
<li>input：データの入力処理</li>
<li>filter：inputで読み込んだデータに対する操作など</li>
<li>output：データの出力処理</li>
</ol>


<p>inputでデータを読み込み（複数可）、filterでデータに対して各種処理を行い、outputでデータを指定されたところに出力（複数可）します。</p>

<h4>アクセスログの読み込み設定</h4>

<p>アクセスログの読み込み処理は大まかに次のようなものとなります。</p>

<ol>
<li>アクセスログを読み込む（input/file）</li>
<li>読み取ったアクセスログを各フィールド（IPアドレス、ユーザエージェントなど）に分割（filter/grok）</li>
<li>日付のパース（filter/date）</li>
<li>クライアントIPアドレスにgeoipの情報を付加（filter/geoip）</li>
<li>リクエストのパスの第1階層の抽出（filter/grok）</li>
<li>ユーザエージェントのパース（filter/useragent）</li>
<li>Elasticsearchへの出力（output/elasticsearch）</li>
</ol>


<p>設定ファイルは次のようなものになります。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">input</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">file</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">path</span> <span class="o">=&gt;</span> <span class="s2">&quot;/Users/johtani/demo_access_log/*/*.log&quot;</span>
</span><span class='line'>    <span class="n">start_position</span> <span class="o">=&gt;</span> <span class="s2">&quot;beginning&quot;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">filter</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">grok</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">match</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="s2">&quot;message&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;%{COMBINEDAPACHELOG}&quot;</span> <span class="p">}</span>
</span><span class='line'>    <span class="n">break_on_match</span> <span class="o">=&gt;</span> <span class="kp">false</span>
</span><span class='line'>    <span class="n">tag_on_failure</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;_message_parse_failure&quot;</span><span class="o">]</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="n">date</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">match</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;timestamp&quot;</span><span class="p">,</span> <span class="s2">&quot;dd/MMM/YYYY:HH:mm:ss Z&quot;</span><span class="o">]</span>
</span><span class='line'>    <span class="n">locale</span> <span class="o">=&gt;</span> <span class="n">en</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="n">geoip</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">source</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;clientip&quot;</span><span class="o">]</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="n">grok</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">match</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="s2">&quot;request&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;^/%{WORD:first_path}/%{GREEDYDATA}$&quot;</span> <span class="p">}</span>
</span><span class='line'>    <span class="n">tag_on_failure</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;_request_parse_failure&quot;</span><span class="o">]</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="n">useragent</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;agent&quot;</span>
</span><span class='line'>    <span class="n">target</span> <span class="o">=&gt;</span> <span class="s2">&quot;useragent&quot;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">output</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">elasticsearch</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">host</span> <span class="o">=&gt;</span> <span class="s2">&quot;localhost&quot;</span>
</span><span class='line'>    <span class="n">index</span> <span class="o">=&gt;</span> <span class="s2">&quot;new_demo_access_log-%{year}&quot;</span>
</span><span class='line'>    <span class="n">cluster</span> <span class="o">=&gt;</span> <span class="s2">&quot;demo_cluster&quot;</span>
</span><span class='line'>    <span class="n">protocol</span> <span class="o">=&gt;</span> <span class="s2">&quot;http&quot;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h5>1. アクセスログを読み込む（input/file）</h5>

<p>inputの<a href="http://logstash.net/docs/1.4.2/inputs/file">fileモジュール(a)</a>を使用してアクセスログのファイルを読み込みます。
<code>path</code>でアクセスログのファイルのパスを指定します。
今回利用したアクセスログは<code>demo_access_log/2010/access20100201.log</code>といった日毎のファイルに分割されていたため、
<code>*</code>を利用してファイルのパスを指定しました。
また、今回は既存のファイルの読み込みだけのため、<code>start_position</code>に<code>beginning</code>を指定してあります。
デフォルトでは<code>end</code>が指定されるため、Logstashを起動後に追記されたログから対象になってしまうためです。
その他の設定については、公式ガイドをご覧ください。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">input</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">file</span> <span class="p">{</span> <span class="c1"># a</span>
</span><span class='line'>    <span class="n">path</span> <span class="o">=&gt;</span> <span class="s2">&quot;/Users/johtani/demo_access_log/*/*.log&quot;</span> <span class="c1"># b</span>
</span><span class='line'>    <span class="n">start_position</span> <span class="o">=&gt;</span> <span class="s2">&quot;beginning&quot;</span> <span class="c1"># c</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<blockquote><p>Logstashでは、ファイルをどこまで読み込んだかという情報を保持するために、<a href="http://logstash.net/docs/1.4.2/inputs/file#sincedb_path">sincedb</a>を利用しています。
設定変更後に同じファイルを最初から読み込みたい場合などは、こちらのファイルを一旦削除するなどの対応が必要です。</p></blockquote>

<p>ちなみに、読み込んだデータは次のようなJSONになっています。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;message&quot;</span><span class="p">:</span> <span class="s2">&quot;読み込んだアクセスログ&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;@version&quot;</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;@timestamp&quot;</span><span class="p">:</span><span class="s2">&quot;2014-11-21T06:16:21.644Z&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;host&quot;</span><span class="p">:</span><span class="s2">&quot;jupiter.local&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="s2">&quot;/Users/johtani/demo_access_log/2010/access20100201.log&quot;</span><span class="p">}</span>
</span><span class='line'><span class="err">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>特に指定がない場合は、<code>message</code>に読み込んだデータが入ってきます。
<code>@timestamp</code>がLogstashが読み込んだ時刻、<code>host</code>はLogstashが動作しているホスト名です。
<code>path</code>はfileモジュールが読み込んだファイルのパスを設定しています。
この後の処理で、どこの項目に対して処理を行うかといったことが重要になるので、</p>

<h5>2. 読み取ったアクセスログを各フィールド（IPアドレス、ユーザエージェントなど）に分割（filter/grok）</h5>

<p>2.〜6.の処理は、inputで読み込んだ1アクセスログに対する処理となります。</p>

<p>ここでは、<a href="http://logstash.net/docs/1.4.2/filters/grok">grokフィルタ</a>を使用して
Apacheのアクセスログを各フィールドに分割します。
Logastashでは、簡単に使えるようにいくつかの<a href="https://github.com/elasticsearch/logstash/tree/v1.4.2/patterns">パターン</a>が用意されています。
Apacheのログのために、<a href="https://github.com/elasticsearch/logstash/blob/v1.4.2/patterns/grok-patterns#L91"><code>COMBINEDAPACHELOG</code></a>というのが用意されています。
今回はこちらを使用しています。その他にも日付などパターンが用意されているので、試してみてください。</p>

<p><code>message</code>にアクセスログが入っているので、こちらの項目に対して<code>COMBINEDAPACHELOG</code>のパターンを
<code>match</code>で適用してフィールドに抜き出します。
<code>tag_on_failure</code>は、<code>match</code>でパースに失敗した場合に、<code>tag</code>というフィールドに指定した文字列を出力する機能になります。
デフォルトだと<code>_grokparsefailure</code>が付与されますが、ここでは、どの処理で失敗したがを判別するために文字列を変更しています。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">filter</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">grok</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">match</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="s2">&quot;message&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;%{COMBINEDAPACHELOG}&quot;</span> <span class="p">}</span>
</span><span class='line'>    <span class="n">break_on_match</span> <span class="o">=&gt;</span> <span class="kp">false</span>
</span><span class='line'>    <span class="n">tag_on_failure</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;_message_parse_failure&quot;</span><span class="o">]</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="o">.</span><span class="n">.</span><span class="o">.</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>clientip</code>、<code>ident</code>、<code>auth</code>、<code>timestamp</code>、<code>verb</code>、<code>request</code>、<code>httpversion</code>、<code>response</code>、<code>bytes</code>、<code>referrer</code>、<code>agent</code>がgrokフィルタにより抜き出された項目です。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="s2">&quot;アクセスログ&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;@version&quot;</span><span class="p">:</span><span class="s2">&quot;1&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;@timestamp&quot;</span><span class="p">:</span><span class="s2">&quot;2014-11-21T07:20:54.387Z&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;host&quot;</span><span class="p">:</span><span class="s2">&quot;jupiter.local&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="s2">&quot;/Users/johtani/demo_access_log/2010/access20100201.log&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;clientip&quot;</span><span class="p">:</span><span class="s2">&quot;クライアントのIPアドレス&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;ident&quot;</span><span class="p">:</span><span class="s2">&quot;-&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;auth&quot;</span><span class="p">:</span><span class="s2">&quot;-&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;timestamp&quot;</span><span class="p">:</span><span class="s2">&quot;01/Feb/2010:00:00:26 +0900&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;verb&quot;</span><span class="p">:</span><span class="s2">&quot;GET&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;request&quot;</span><span class="p">:</span><span class="s2">&quot;/images/favicon.ico&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;httpversion&quot;</span><span class="p">:</span><span class="s2">&quot;1.1&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;response&quot;</span><span class="p">:</span><span class="s2">&quot;200&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;bytes&quot;</span><span class="p">:</span><span class="s2">&quot;318&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;referrer&quot;</span><span class="p">:</span><span class="s2">&quot;\&quot;-\&quot;&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;agent&quot;</span><span class="p">:</span><span class="s2">&quot;\&quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; ja; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7 (.NET CLR 3.5.30729)\&quot;&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h5>3. 日付のパース（filter/date）</h5>

<p>Logstashは特に指定がない場合、inputでデータを取り出した日付が<code>@timestamp</code>となります。
そして、このフィールドが特に指定がない場合は、Elasticsearchのデータの日付となり、Kibanaで利用する日付となります。</p>

<p>リアルタイムにアクセスログを読み込む場合は、読み込んだ日時でもほぼ問題はありませんが、過去データの場合はそうもいきません。
そこで、<a href="http://logstash.net/docs/1.4.2/filters/date"><code>dateフィルタ</code></a>を使用して、<code>@timestamp</code>の値を書き換えます。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">date</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">match</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;timestamp&quot;</span><span class="p">,</span> <span class="s2">&quot;dd/MMM/YYYY:HH:mm:ss Z&quot;</span><span class="o">]</span>
</span><span class='line'>  <span class="n">locale</span> <span class="o">=&gt;</span> <span class="n">en</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>上記では、<code>timestamp</code>という項目に対して<code>dd/MMM/YYYY:HH:mm:ss Z</code>という日付パターンの場合に値を書き換える設定となります。
なお、日付の月の部分が<code>Feb</code>となっているため、<code>locale</code>に<code>en</code>を指定しています。Logstashが動作するマシンの<code>locale</code>が<code>ja</code>などの場合にパースに失敗するためです。</p>

<h5><a name="filter-geoip">4. クライアントIPアドレスにgeoipの情報を付加（filter/geoip）</a></h5>

<p>どの国からのアクセスかなどを判別したいので、IPアドレスを元にgeoipを利用してより詳細な情報を付与します。
Logstashでもこの機能が用意されており、簡単に利用ができます。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">geoip</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">source</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;clientip&quot;</span><span class="o">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>これだけです。対象とするIPアドレスのフィールドを指定しているだけです。
<code>geoip</code>というフィールドが追加され、次のような情報が付与されます。
国名、緯度経度、タイムゾーンなどです。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="err">...</span>
</span><span class='line'>  <span class="nt">&quot;geoip&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;ip&quot;</span><span class="p">:</span> <span class="s2">&quot;IPアドレス&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;country_code2&quot;</span><span class="p">:</span> <span class="s2">&quot;JP&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;country_code3&quot;</span><span class="p">:</span> <span class="s2">&quot;JPN&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;country_name&quot;</span><span class="p">:</span> <span class="s2">&quot;Japan&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;continent_code&quot;</span><span class="p">:</span> <span class="s2">&quot;AS&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;latitude&quot;</span><span class="p">:</span> <span class="mi">36</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;longitude&quot;</span><span class="p">:</span> <span class="mi">138</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;timezone&quot;</span><span class="p">:</span> <span class="s2">&quot;Asia/Tokyo&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;location&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>      <span class="mi">138</span><span class="p">,</span>
</span><span class='line'>      <span class="mi">36</span>
</span><span class='line'>    <span class="p">]</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="err">...</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h5>5. リクエストのパスの第1階層の抽出（filter/grok）</h5>

<p>リクエストされたURLは<code>request</code>フィールドにありますが、個別のURLだと、大まかな集計が大変です。
もちろん、クエリで処理することもできますが、Logstashで処理するついでに、第1階層のディレクトリ名を抽出しておくことで、
検索や集計を行いやすくしておきます。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">grok</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">match</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="s2">&quot;request&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;^/%{WORD:first_path}/%{GREEDYDATA}$&quot;</span> <span class="p">}</span>
</span><span class='line'>  <span class="n">tag_on_failure</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;_request_parse_failure&quot;</span><span class="o">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>また、grokフィルタの登場です。
今回は、<code>WORD:first_path</code>という記述方法で、<code>WORD</code>パターンにマッチした文字列を<code>first_path</code>というフィールドに展開する指定をしています。</p>

<p>例えば、サイトのスクリプトなどが<code>scripts</code>というディレクトリにある場合は、<code>first_path</code>の値を利用して、
後続のフィルタでログデータを出力しないといった処理にも使えます。</p>

<h5>6. ユーザエージェントのパース（filter/useragent）</h5>

<p>Logstashではユーザエージェントの文字列から、いくつかの情報を付与するフィルタも用意されています。
<a href="http://logstash.net/docs/1.4.2/filters/useragent"><code>useragent</code>フィルタです。</a></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">useragent</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;agent&quot;</span>
</span><span class='line'>  <span class="n">target</span> <span class="o">=&gt;</span> <span class="s2">&quot;useragent&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>agent</code>というフィールドにユーザエージェントの文字列があるので、このフィールドに対してフィルタを適用します。
元の文字列も取っておきたいので、<code>useragent</code>という別のフィールドに出力するように指定してあります。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="s2">&quot;useragent&quot;</span><span class="err">:</span> <span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Firefox&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;os&quot;</span><span class="p">:</span> <span class="s2">&quot;Windows XP&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;os_name&quot;</span><span class="p">:</span> <span class="s2">&quot;Windows XP&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;Other&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;major&quot;</span><span class="p">:</span> <span class="s2">&quot;17&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;minor&quot;</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span>
</span><span class='line'><span class="p">}</span><span class="err">,</span>
</span></code></pre></td></tr></table></div></figure>


<p>このように、OS名やバージョン名などが抽出できます。</p>

<h5><a name="output-elasticsearch">7. Elasticsearchへの出力（output/elasticsearch）</a></h5>

<p>最後は、<a href="http://logstash.net/docs/1.4.2/outputs/elasticsearch">Elasticsearchへのデータの出力設定</a>です。</p>

<p><code>index</code>にて、出力するindex名を指定してあります。
また、年毎のインデックス名にするために<code>%{year}</code>を利用しています。
<a href="http://logstash.net/docs/1.4.2/configuration#sprintf">sprintf format</a>です。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">elasticsearch</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">host</span> <span class="o">=&gt;</span> <span class="s2">&quot;localhost&quot;</span>
</span><span class='line'>  <span class="n">index</span> <span class="o">=&gt;</span> <span class="s2">&quot;new_demo_access_log-%{year}&quot;</span>
</span><span class='line'>  <span class="n">cluster</span> <span class="o">=&gt;</span> <span class="s2">&quot;demo_cluster&quot;</span>
</span><span class='line'>  <span class="n">protocol</span> <span class="o">=&gt;</span> <span class="s2">&quot;http&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>まとめ</h2>

<p>ということで、今回はアクセスログをLogstashにて読み込む時の設定について説明してきました。
次回は、実際にLogstashを起動してElasticsearchにデータを登録するところまでを説明します。</p>

<p>JJUG CCCや勉強会のデモに用いたデータは、
Elasticsearchにデータを登録する前にテンプレートも設定してありました。こちらについても、次回説明しようと思います。</p>

<p>不明な点、誤植などありましたら、コメント欄へお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第7回Elasticsearch勉強会を開催しました。#elasticsearchjp]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/19/hold-on-7th-elasticsearch-jp/"/>
    <updated>2014-11-19T11:19:07+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/19/hold-on-7th-elasticsearch-jp</id>
    <content type="html"><![CDATA[<p><a href="http://elasticsearch.doorkeeper.jp/events/16837">第7回Elsticsearch勉強会</a>を開催しました。
スタッフの皆さん、スピーカーの皆さん、開場提供していただいた<a href="http://recruit-tech.co.jp">リクルートテクノロジーズさん</a>、ありがとうございました！
次回もよろしくお願いします！参加していただき盛り上げていただいた参加者の皆さんもありがとうございました。</p>

<p>昨日も紹介しましたが、<a href="http://qiita.com/advent-calendar/2014/elasticsearch">Elasticsearch Advent Calendar 2014</a>を用意してみました。まだ、空きがありますので、登録お待ちしております！</p>

<!-- more -->


<p>今回は出足が好調で、早々に180人の枠を超えるという嬉しい事態でした。
最終的な参加人数は130名程度で、懇親会参加者が50名弱といったところです。</p>

<h2>「Kibana4」</h2>

<h3>Elasticsearch Inc. Jun Ohtani @johtani</h3>

<p>スライド：<a href="https://speakerdeck.com/johtani/kibana4">Kibana4</a></p>

<p>ということで、Kibana4の紹介と、Kibana4のBeta2を利用したデモを行いました。
デモの開始のところで少し環境がうまく動いてなくて手間取ってしまいましたが。。。</p>

<p>発表で1点だけ修正があります。JRubyを選択しているのがElasticsearchのライブラリを使用するためという説明をしましたが、
こちらは、Logstashに関する話でした。Kibana4は現時点では、ElasticsearchへのProxyとしての動作が主なものとなります。Rubyでも動作可能です。
bin/kibanaについてはJavaを使った起動になります。
参考：<a href="https://github.com/elasticsearch/kibana/tree/master/src/server">https://github.com/elasticsearch/kibana/tree/master/src/server</a></p>

<p>発表でも主張しましたが、ダウンロードして、Elasticsearchを用意すれば簡単に動作させることが可能です。
ぜひ、ローカルで試して見てもらえればと思います。
今回のデモのデータを入れるのに利用したLogstashの設定などについては、ブログで記事を書こうと思います。</p>

<h2>niconicoの検索を支えるElasticsearch</h2>

<h3>株式会社ドワンゴ 伊藤 祥 さん</h3>

<p>スライド：<a href="https://speakerdeck.com/shoito/niconico-elasticsearch">niconicoの検索を支えるElasticsearch</a></p>

<ul>
<li>リアルタイム検索の実現、新しい検索への対応</li>
<li>検索のアーキテクチャとか。</li>
<li>Capistranoでデプロイとかを管理</li>
<li>1.4.1が出たら、クラスタを更新予定</li>
</ul>


<p>ということで、実際に導入した話から、現在の運用の仕方、クラスタのアップグレードなど多岐にわたる内容でおもしろかったです。
遭遇した問題点とかもあったので。
Marvel便利なのでぜひ導入を検討してもらえればw</p>

<h2>Elasticsearch at CrowdWorks </h2>

<h3>株式会社クラウドワークス 九岡 佑介 さん @mumoshu</h3>

<p>スライド：<a href="http://www.slideshare.net/mumoshu/20141118-es">Elasticsearch at CrowdWorks</a></p>

<ul>
<li>会社の紹介</li>
<li>仕事が検索対象</li>
<li>検索時間が1桁減少！</li>
<li>Graceful Degradationで失敗したら、InnoDB FTSで代替：<a href="https://github.com/crowdworks/gracefully">Gracefully</a></li>
<li><a href="http://www.found.no">found.no</a>のサービスを利用</li>
<li>elasticsearch-modelの拡張を作成してOSSとして公開：<a href="https://github.com/crowdworks/elasticsearch-model-extensions">elasticsearch-model-extensions</a></li>
</ul>


<p>Gracefullyで切り替えとかは面白いなと思いました。
検索での利用の話でしたが、他のシーンでも使えそうですよね。
日本にFoundユーザがいるのも初めて知りました。
彼らの開発者ブログも質の良い情報が載っているので、参考になりますよね。</p>

<p>次は、どんなMappingで運用しているのかとか、どういった工夫をしているかといった点を詳しく聞きたいなと思いました。
またお待ちしております。</p>

<h2>1分で作るElasticsearchプラグイン</h2>

<h3>株式会社エヌツーエスエム 菅谷 信介 さん</h3>

<p>スライド：<a href="http://www.slideshare.net/shinsuke/plugins-ates7">Elasticsearchプラグインの作り方</a></p>

<ul>
<li>プラグインの作り方とか。</li>
<li>十数個のプラグインの紹介。プラグインはこちらで公開中。<a href="https://github.com/codelibs/">https://github.com/codelibs/</a></li>
<li>実際に、業務で必要なものから作成</li>
<li>まだまだ作りたいものがある</li>
</ul>


<p>コミュニティ還元できるものはPR送ってもらえるとうれしいです。
前よりは体制も増えてるので、PRも目にとまるようになってるはずです。</p>

<p>あとは、使ってみたいと思う方も多数いると思うので、ぜひ、OSSなので、貢献しましょう！
フィードバックがあるだけで、OSS活動やってるものにとってはやる気につながると思いますし。</p>

<h2>LT：GISとして活用するElasticsearch </h2>

<h3>船戸 隆さん</h3>

<p>スライド：<a href="https://speakerdeck.com/tfunato/gistositehuo-yong-suruelasticsearch">GISとして活用するElasticsearch </a></p>

<ul>
<li>java-jaからIngressの青（Registance）の勧誘に来られた方w</li>
<li>APIをハックして、情報を取得し、Kibanaで可視化</li>
<li>残念ながら、APIが変更されて見れなくなったらしい。</li>
</ul>


<p>Ingress実際にやったことはないのですが、おもしろそうでした。
発表される方の会社の採用紹介ではなく、Ingressの勧誘をされるとは想定外でしたw</p>

<p>興味のあるデータをKibanaで可視化するのも面白い例だと思うので、活用してもらえればと思います。</p>

<h2>その他、感想などのブログ</h2>

<p>適当に見つけたブログを列挙してあります。これもあるよ！などあれば、教えてください。</p>

<ul>
<li><a href="http://blog.yoslab.com/entry/2014/11/18/203159">勉強会メモ - 第7回elasticsearch勉強会</a></li>
<li><a href="http://qiita.com/t-sato/items/940ccfa9e4a668b91967">第7回elasticsearch勉強会 #elasticsearch #elasticsearchjp</a></li>
</ul>


<h2>まとめ</h2>

<p>JJUGの時とは違い、Elasticsearch勉強会ではさすがに、企業としてのElasticsearchの知名度が高かったのはありがたいことでした。
自分の発表のために始めた勉強会でもありますが、まだまだ、発表するときは緊張しますし、分かりにくいんじゃないかなぁと思うことも多々あります。
この辺がわかりにくかった、この辺をもっと知りたいなど、フィードバックをお待ちしております。</p>

<p>冒頭にも書きましたが、<a href="http://qiita.com/advent-calendar/2014/elasticsearch">Elasticsearch Advent Calendar 2014</a>の登録をお待ちしております。どんなことでも歓迎なので、Elasticsearch、Kibana、Logstashなどについて書いてもらえるとうれしいです。</p>

<p>次回ももちろん2ヶ月後くらいに行います。 スピーカー募集中ですので、コメント、メール、ツイートなど、コンタクトしていただければと思います。 よろしくお願いいたします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 1.4.0および1.3.5リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/06/elasticsearch-1-4-0-ja/"/>
    <updated>2014-11-06T01:30:33+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/06/elasticsearch-1-4-0-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-released/">elasticsearch-1.4.0 and 1.3.5 released</a></p>

<p>本日、<strong>Lucene 4.10.2</strong>をベースにした<strong>Elasticsearch 1.4.0</strong>と、バグフィックスリリースである、<strong>Elasticsearch 1.3.5</strong>をリリースしました。
ダウンロードおよび変更リストはそれぞれ次のリンクからアクセスできます。</p>

<ul>
<li>最新ステーブルリリース：<a href="http://www.elasticsearch.org/downloads/1-4-0">Elasticsearch 1.4.0</a></li>
<li>1.3.x系バグフィックス：<a href="http://www.elasticsearch.org/downloads/1-3-5">Elasticsearch 1.3.5</a></li>
</ul>


<p>1.3ブランチに関する過去のリリースについてのブログは次のとおりです：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-4-released/">1.3.4</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-3-released/">1.3.3</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-2-released/">1.3.2</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-1-released/">1.3.1</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-0-released/">1.3.0</a>.</p>

<!-- more -->


<p>Beta1リリースでも言及しましたが、1.4.0の主なテーマは<em>resiliency(復元性、弾力性)</em>です。
Elasticsearchをより安定し信頼性のあるものにし、メモリ管理を改善し、ディスカバリアルゴリズムを改善し、破損したデータの検知を改善しました。
Beta1リリースからのハイライトも含んでいます。</p>

<ul>
<li>Doc values (インデックス時にディスクに保存される<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/fielddata-formats.html#fielddata-formats">fielddata</a>)がヒープ利用率を激減</li>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-fielddata.html#request-circuit-breaker">Request circuit breaker</a>:
メモリを消費しすぎる検索リクエストの中断</li>
<li>Bloom filterの<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-update-settings.html#codec-bloom-load">デフォルト無効</a>、高速なインデキシングのためにもはや必要とされないため。</li>
<li>ノードディスカバリ、シャードリカバリの数多くのバグフィックス及び改善</li>
<li>データ破損の早期検知のためのチェックサムのさらなる利用</li>
<li>GroovyをMVELの代わりに<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/modules-scripting.html#modules-scripting">デフォルトスクリプト言語に</a></li>
<li>CORSを<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/modules-http.html#_settings_2">デフォルト無効</a>に。XSS攻撃防止の為。</li>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-shard-query-cache.html#index-modules-shard-query-cache">クエリキャッシュ</a>、変更されていないシャードからすぐにaggregation結果を返す</li>
<li>新しいAggregation：<code>filter</code>(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-filters-aggregation.html#search-aggregations-bucket-filters-aggregation">ドキュメント</a>)、<code>children</code>(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-children-aggregation.html#search-aggregations-bucket-children-aggregation">ドキュメント</a>)、<code>scripted_metric</code>(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-metrics-scripted-metric-aggregation.html#search-aggregations-metrics-scripted-metric-aggregation">ドキュメント</a>)</li>
<li>新しい<code>GET /index</code>API。インデックスのsettings、mappings、warmers、aliasesを1回のリクエストで返却(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-get-index.html#indices-get-index">ドキュメント</a>)</li>
<li>自動付与ドキュメントIDのためのFlake ID。プライマリキーの探索パフォーマンスの改善。</li>
<li>ドキュメントに変更のない更新によるドキュメントの再インデックスの防止</li>
<li><code>function_score</code>クエリの関数で<code>weight</code>パラメータによる個別の改善を可能に。(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/query-dsl-function-score-query.html#_weight">ドキュメント</a>)</li>
</ul>


<p>詳細については<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-beta-released/">1.4.0.Beta1のブログ(英語)</a>(<a href="http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja/">日本語訳</a>)をご覧ください。</p>

<p>Beta1以降の1.4.0の変更の全てについては、<a href="http://www.elasticsearch.org/downloads/1-4-0">1.4.0 release notes</a>でご覧いただけます。
以下では、2つの主な変更について紹介します。</p>

<h2>HTTP Pipelining</h2>

<p>HTTP pipeliningは複数のリクエストを1回のコネクションで、関連するレスポンスを待つことなく送信することができます。
そして、レスポンスは、受け取ったリクエストと同じ順序で返却されます。
HTTP/1.1の仕様で、pipeliningのサポートが必要です。ElasticsearchはHTTP/1.1であるとしてきましたが、pipeliningはサポートしていませんでした。この問題は.NETユーザで問題を引き起こしました。</p>

<p>現在、HTTP pipeliningは公式にサポート済みで、デフォルトで利用できます。<a href="https://github.com/elasticsearch/elasticsearch/pull/8299">#8299</a>をご覧ください。</p>

<h2>Upgrade API</h2>

<p>Luceneのすべてのリリースではバグフィックスや最適化が提供されます。しかし、多くのユーザは古いバージョンのLuceneで作成されたインデックスを持っており、より最新の改善による利点を利用できないことがあります。
新しい<code>upgrade</code>APIは、あなたのインデックスすべてもしくは一部を最新のLuceneフォーマットに透過的にアップグレードできます。</p>

<p><code>GET _upgrade</code>リクエストは、インデックスのアップグレードが必要かどうかを提示し、アップグレードに必要なセグメントのサイズをリポートすることによって、どのくらいの時間が必要かの目安を提供します。
<code>POST _upgrade</code>コマンドはバックグラウンドでインデックスを最新のLuceneフォーマットに書き換えます。</p>

<p>より詳しい情報は<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-upgrade.html"><code>upgrade</code>APIドキュメント</a>をご覧ください。</p>

<h2>試してみてください。</h2>

<p>Beta1リリースを利用し、経験・体験を報告していただいたベータテスターの方々に感謝します。
1.4.0がこれまでの最高のリリースになると確信しています。
ぜひ、<a href="http://www.elasticsearch.org/downloads/1-4-0">Elasticsearch 1.4.0</a>をダウンロードして、試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/elasticsearch/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[validate APIの利用]]></title>
    <link href="http://blog.johtani.info/blog/2014/10/27/how-to-use-validate-api/"/>
    <updated>2014-10-27T18:42:31+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/10/27/how-to-use-validate-api</id>
    <content type="html"><![CDATA[<p>久しぶりに翻訳ではないブログを。書こうと思いながらかけてなかったので。。。</p>

<p>今回は<a href="http://www.elasticsearch.org/guide/ep/elasticsearch/reference/current/search-validate.html">validate API</a>の紹介です。</p>

<!-- more -->


<h2>背景</h2>

<p>Elasticsearchのクエリは<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl.html">Query DSL</a>というJSONで
クエリを定義できるものを提供しています。
これは、様々な<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl-queries.html">クエリ</a>、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl-filters.html">フィルタ</a>を定義するために必要です。</p>

<p>自分の望んでいる条件を記述するために、JSONのネストと格闘することも必要となります。。。
また、クエリ、フィルタには様々なパラメータが用意されています。
これらのパラメータをすべて覚えるのは無理でしょうし、タイプミスなどもありますよね。
タイプミスやカッコのミスマッチなどで格闘して1時間が経過してしまったなどもあると思います。</p>

<p>そんな時に便利なAPIとして用意されているのが<a href="http://www.elasticsearch.org/guide/ep/elasticsearch/reference/current/search-validate.html">validate API</a>です。</p>

<h2>利用方法</h2>

<p>APIが用意されています。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>http://ホスト名:ポート番号/インデックス名/タイプ名/_validate/query</span></code></pre></td></tr></table></div></figure>


<p><code>インデックス名</code>や<code>タイプ名</code>は省略可能ですが、マッピングが異なると思うので、タイプ名まで指定するほうが良いと思います。
上記のAPIに対してクエリを送信するだけです。</p>

<h3>クエリの確認</h3>

<p>たとえば、<a href="https://gist.github.com/johtani/08dee5fb4da62037ef9e">こちらのGist</a>にあるようなマッピングのインデックスに対して
検索クエリを組み立てていて、エラーが出るとします。
※このクエリは<code>match_all</code>のところを<code>match_al</code>と、<code>l</code>が1文字足りないクエリになっています。</p>

<p><strong><em>検索クエリのリクエスト（エラーあり）</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_search
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "match_al": {}
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>実行結果のレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "error": "SearchPhaseExecutionException[Failed to execute phase [query], all shards failed; shardFailures {[rwkb01chTZq2V7FD0Tlwrw][pref_aggs][0]: SearchParseException[[pref_aggs][0]: from[-1],size[-1]: Parse Failure [Failed to parse source [{\n  \"query\": {\n    \"match_al\": { }\n  }\n}\n]]]; nested: QueryParsingException[[pref_aggs] No query registered for [match_al]]; }{[rwkb01chTZq2V7FD0Tlwrw][pref_aggs][1]: SearchParseException[[pref_aggs][1]: from[-1],size[-1]: Parse Failure [Failed to parse source [{\n  \"query\": {\n    \"match_al\": { }\n  }\n}\n]]]; nested: QueryParsingException[[pref_aggs] No query registered for [match_al]]; }]",
</span><span class='line'>   "status": 400
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>とこんなかんじで、エラーが帰っては来るのですが、非常に読みづらいです。</p>

<p>そこで、<code>validate API</code>を利用します。
リクエスト先を<code>/_search</code>から<code>/_validate/query</code>に変更します。</p>

<p><strong><em>validate API</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_validate/query
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "match_al": {}
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": false,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>すると、非常にシンプルな結果が返ってきます。
<code>"valid": false</code>となっているため、クエリに問題があることがわかります。</p>

<h3>エラーの詳細</h3>

<p>問題がある事自体はわかりましたが、エラーの内容も知りたいですよね？
その場合は、<code>explain</code>というパラメータを追加します。
（正しくは<code>explain=true</code>を追加しますが、<code>=true</code>を省略可能です。）</p>

<p><strong><em>validate API(explainあり、クエリ自体は省略)</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_validate/query?explain
</span><span class='line'>{...}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": false,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "pref_aggs",
</span><span class='line'>         "valid": false,
</span><span class='line'>         "error": "org.elasticsearch.index.query.QueryParsingException: [pref_aggs] No query registered for [match_al]"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><code>explanations</code>という項目が追加されました。
ここに<code>error</code>という項目として、エラーの詳細が返ってきます。<code>_search</code>の時よりも見やすいですね。
今回のエラーは、<code>match_all</code>が正しいクエリですの、<em><code>match_al</code>というクエリは登録されていないというエラー</em>でした。
では、クエリを修正して実行しましょう。</p>

<p><strong><em>validate API(エラー無し)</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_validate/query?explain
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "match_all": {}
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": true,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "pref_aggs",
</span><span class='line'>         "valid": true,
</span><span class='line'>         "explanation": "ConstantScore(*:*)"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>今度はクエリに問題はありません。<code>"valid": true</code>です。
そして、<code>explanations</code>の項目には、<code>error</code>の代わりに<code>explanation</code>という項目が返ってきました。
これが、実際にElasticsearch内部で実行されるクエリになります。</p>

<h3>実際のクエリに利用される単語の確認</h3>

<p>この機能はこの他に、クエリの解析にも利用できます。
思ったとおりに検索にヒットしない場合があって、困ったことはないですか？
フィールドに指定されたアナライザによっては、単語を変形したりするものが存在します。</p>

<p><strong><em>サンプルマッピング</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>PUT /validate_sample
</span><span class='line'>{
</span><span class='line'>  "mappings": {
</span><span class='line'>    "several_analyzer": {
</span><span class='line'>      "properties": {
</span><span class='line'>        "title": {"type": "string"},
</span><span class='line'>        "body_ja": {"type": "string", "analyzer": "kuromoji"},
</span><span class='line'>        "body_en": {"type": "string", "analyzer": "english"}
</span><span class='line'>      }
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>例えば、このように<code>kuromoji</code>、<code>english</code>、デフォルト(<code>standard</code>)アナライザを利用したマッピングがあるとします。
このフィールドに対して<code>powerful</code>という単語で検索したとします。</p>

<p><strong><em>validate API</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET /validate_sample/_validate/query?explain
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "multi_match": {
</span><span class='line'>      "fields": ["body_en","body_ja","title"],
</span><span class='line'>      "query": "powerful"
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>この場合、レスポンスは次のとおりです。</p>

<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": true,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "validate_sample",
</span><span class='line'>         "valid": true,
</span><span class='line'>         "explanation": "(title:powerful | body_en:power | body_ja:powerful)"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><code>title</code>、<code>body_ja</code>については入力された単語がそのままクエリとして利用されています。
<code>body_en</code>については、<code>power</code>という単語に変換されて実行されています。
これは、<code>english</code>アナライザがステミングを行った結果がクエリとして利用されるという意味です。
また、<code>powerful</code>を<code>秋葉原</code>といった日本語に変更して実行すると次のようになります。
日本語は<code>standard</code>アナライザなどでは、1文字ずつ区切られてしまうことがわかります。</p>

<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": true,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "validate_sample",
</span><span class='line'>         "valid": true,
</span><span class='line'>         "explanation": "((title:秋 title:葉 title:原) | (body_en:秋 body_en:葉 body_en:原) | ((body_ja:秋葉 body_ja:秋葉原) body_ja:原))"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>このように、クエリの単語がどのような単語に変換されてクエリに利用されているかなども知ることが可能です。</p>

<p>また、クエリを組み立てて、ヒットするはずが、0件となってしまうという場合にも、どのようなクエリが組み立てられているかを確認するという点で、
<code>validate API</code>が役立ちます。
検索がヒットするが、望んだクエリになっていないのでは？という場合は<code>_search API</code>の<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-request-explain.html"><code>explain</code>パラメータ</a>を
利用すれば、クエリの構成がわかるのですが、検索結果が0件の場合はクエリの構成は表示されません。</p>

<h2>解決できない問題は？</h2>

<p>便利なvalidate APIですが、以下の問題に対しては残念ながら確認できません。</p>

<ul>
<li><code>query</code>以外の項目のvalidate不可

<ul>
<li>たとえば、<code>_search API</code>の<code>size</code>などの項目についてはチェックできないです。</li>
</ul>
</li>
<li>存在しないフィールドの指定

<ul>
<li>上記<code>validate_sample</code>のマッピングの例でクエリに<code>body_eng</code>という存在しないフィールドを指定してもエラーとはなりません。</li>
</ul>
</li>
</ul>


<h2>まとめ</h2>

<p>書いたクエリがうまく動かない、JSONのタグがおかしいといった場合は、
まずはこの<code>validate API</code>で確認してみるのがオススメです。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sonatypeのバージョン番号で困ったので]]></title>
    <link href="http://blog.johtani.info/blog/2014/10/15/versioning-of-sonatype/"/>
    <updated>2014-10-15T15:26:08+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/10/15/versioning-of-sonatype</id>
    <content type="html"><![CDATA[<p><a href="http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja/">Elasticsearch 1.4.0.Beta1がリリース</a>されました。</p>

<p>個人で<a href="https://github.com/johtani/elasticsearch-extended-analyze">elasticsearch-extended-analyze</a>というプラグインを開発してます。
こちらも1.4.0.Beta1に対応するべく作業をしてて、少し戸惑ったことがあったので、メモをば。</p>

<!-- more -->


<p>ここ最近はプラグインのバージョン番号をElasticsearchのバージョン番号と同じものを利用していました。
（プラグインの機能追加をサボってる？？）
その時に、<code>1.4.0.Beta1</code>という番号を指定したのですが、意味不明なエラーに悩まされてしまいまして。</p>

<p>プラグインのリリースでは、以下のコマンドを実行します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ mvn release:prepare
</span><span class='line'>$ mvn release:perform</span></code></pre></td></tr></table></div></figure>


<p>最初のコマンド（prepare）で、パッケージングを実施し、Githubにリリースタグを打ったバージョンがpushされます。
次のコマンド（perform）で、パッケージングされたzipファイルがsonatypeのサイトに公開するためにアップロードされます。</p>

<p><code>1.4.0.Beta1</code>というバージョン文字列を利用した場合、prepareは問題なく実行できたのですが、
performで以下の様なエラーが返ってきました。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Return code is: 401, ReasonPhrase: Unauthorized.</span></code></pre></td></tr></table></div></figure>


<p>バージョン番号が<code>1.3.0</code>では特に問題はなかったのですが、、、
結局、バージョン番号を<code>1.4.0-beta1</code>に変更すると問題なくリリースが完了しました。</p>

<p>mike_neckさんと話をしていて、<a href="http://semver.org">Semantic Versioning</a>に関係しているのかなぁという話にはなったのですが、
詳しく調べていません。。。</p>

<p>そのうち調べようかなぁ。。。。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[elasticsearch 1.4.0.Beta1のリリース]]></title>
    <link href="http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja/"/>
    <updated>2014-10-02T19:14:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja</id>
    <content type="html"><![CDATA[<p>※この記事は次のブログを翻訳したものになります。</p>

<p>原文：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-beta-released/">elasticsearch 1.4.0.beta1 released</a></p>

<p>本日、<em>Lucene 4.10.1</em>をベースにした、<em>Elasticsearch 1.4.0.Beta1</em>をリリースしました。
<a href="http://www.elasticsearch.org/downloads/1-4-0-Beta1">Elasticsearch 1.4.0.Beta1</a>からダウンロードできます。
また、すべての変更点に関してもこちらをご覧ください。</p>

<!-- more -->


<p>1.4.0のテーマは<em>resiliency(復元性、弾力性)</em>です。
<em>resiliency</em>とはElasticsearchをより安定し信頼性のあるものにすることを意味します。
すべての機能が正常に機能している場合は信頼することは簡単です。
予想外のことが発生した時に難しくなります：ノードでout of memoryの発生、スローGCや重いI/O、ネットワーク障害、不安定なデータの送信によるノードのパフォーマンス低下など。</p>

<p>本ベータリリースは、resiliencyの主な3つの改善を含んでいます。</p>

<ul>
<li><a href="#memory-mgmt">メモリ使用量の低下</a>によるノードの安定性向上</li>
<li>discoveryアルゴリズムの改善による<a href="#cluster-stability">クラスタの安定性</a>向上</li>
<li><a href="#checksums">チェックサム</a>の導入による破損したデータの検知</li>
</ul>


<p>分散システムは複雑です。
決して想像できないような状況をシミュレーションするために、ランダムなシナリオを作成する広範囲なテストスイートを持っています。
しかし、無数のエッジケース(特殊なケース)があることも認識しています。
1.4.0.Beta1はこれまで私たちが行ってきた改善のすべてを含んでいます。
これらの変更を実際にテストしていただき、<a href="https://github.com/elasticsearch/elasticsearch/issues">何か問題があった場合は私たちに教えてください</a>。</p>

<h2><a name="memory-mgmt">メモリ管理</a></h2>

<p>ヒープ空間は限られたリソースです。
上限を32GBとし、利用可能なRAMの50%をヒープの上限にすることを推奨します。
この上限を超えた場合、JVMは圧縮したポインタを使用することができず、GCが非常に遅くなります。
ノードの不安定性の主な原因は遅いGCです。それは、次のようなことから発生します。</p>

<ul>
<li>メモリプレッシャー</li>
<li>スワップ(参照：<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/setup-configuration.html#setup-configuration-memory">memory settings</a>)</li>
<li>非常に大きなヒープ</li>
</ul>


<p>本リリースは、メモリ管理の改善し、（結果として）ノードの安定性を改善するいくつかの変更を含んでいます。</p>

<h3>doc values</h3>

<p>メモリの利用の最も大きなものの1つは<strong>fielddata</strong>です
aggregation、ソート、スクリプトがフィールドの値に素早くアクセスするために、フィールドの値をメモリにロードして保持します。
ヒープは貴重なため、1ビットも無駄にしないためにメモリ内のデータは高度な圧縮と最適化を行っています。
これは、ヒープスペース以上のデータをもつまでは、非常によく動作します。
これは、多くのノードを追加することによって常に解決できる問題です。
しかし、CPUやI/Oが限界に達してしまうずっと前に、ヒープ空間の容量に到達します。</p>

<p>最近のリリースは、<strong>doc values</strong>によるサポートがあります。
基本的に、doc valuesはin-memory fielddataと同じ機能を提供します。
doc valuesの提供する利点は、それらが、非常に少量のヒープ空間しか使用しない点です。
doc valuesはメモリからではなく、ディスクから読み込まれます。
ディスクアクセスは遅いですが、doc valuesはカーネルのファイルシステムキャッシュの利点を得られます。
ファイルシステムキャッシュはJVMヒープとはことなり、32GBの制限による束縛がありません。
ヒープからファイルシステムキャッシュにfielddataを移行することによって、より小さなヒープを使うことができます。これは、GCがより早くなり、ノードが更に安定することを意味します。</p>

<p>本リリースより前は、doc valuesはin-memory fielddataよりもかなり遅かったです。
本リリースに含まれる変更は、パフォーマンスをかなり向上させ、in-memory fielddataとほぼ同じくらいの速度になっています。</p>

<p>in-memory fielddataの代わりにdoc valuesを利用するために必要なことは、次のように新しいフィールドをマッピングすることです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>PUT /my_index
</span><span class='line'>{
</span><span class='line'>  "mappings": {
</span><span class='line'>    "my_type": {
</span><span class='line'>      "properties": {
</span><span class='line'>        "timestamp": {
</span><span class='line'>          "type":       "date",
</span><span class='line'>          "doc_values": true
</span><span class='line'>        }
</span><span class='line'>      }
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>このマッピングで、このフィールドに対するfielddataの利用は、メモリにフィールドをロードする代わりに、自動的にディスクからdoc valuesを利用します。
<em>注意：</em>現時点で、doc valuesはanalyzedな<code>string</code>フィールドはサポートしていません。</p>

<h3>request circuit breaker</h3>

<p>fielddata circuit breakerはfielddataによって利用されるメモリの上限を制限するために追加され、OOMEの最も大きな原因の1つを防ぎました。
そして、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-fielddata.html#request-circuit-breaker">リクエストレベルのcircuit-breaker</a>を提供するために、コンセプトを拡張しました。
これは、単一のリクエストによって使用されるメモリの上限を制限します。</p>

<h3>bloom filters</h3>

<p><a href="http://en.wikipedia.org/wiki/Bloom_filter">Bloom filters</a> はインデキシング(前のバージョンのドキュメントが存在するかどうかのチェックのため)や、
IDによるドキュメントの検索(ドキュメントを含むセグメントがどれかを決定するため)に関する重要な性能最適化を提供しました。
しかし、もちろんそれらはコスト（メモリ）を必要とします。
現在の改善は、bloom filterの必要性を取り除きました。
現在では、Elasticsearchはまだ、インデックス時にそれらを構築します(実世界の経験がテストシナリオにそぐわない場合に備えて)。
しかし、デフォルトではメモリにはロードされません。
すべてが予定通りに運べば、将来のバージョンで完全にこれらは除去します。</p>

<h2><a name="cluster-stability">クラスタの安定性</a></h2>

<p>クラスタの安定性向上のために私たちができる最も大きなことは、ノードの安定性の向上です。
もし、ノードが安定しておりタイミングよく反応すれば、クラスタが不安定になる可能性が大いに減少します。
私たちは不完全な世界に住んでいます。- 物事は予想外にうまく行きません。クラスタはデータを失うことなくこのような状況から回復できる必要があります。</p>

<p>私たちは、<code>improve_zen</code>ブランチ上で、Elasticsearchの障害からの復旧するための能力の向上に数ヶ月費やしてきました。
まず、複雑なネットワークレベルの障害を繰り返すためのテストを追加しました。
次に、各テストのための修正を追加しました。
そこには、より多くの行うことが存在します。しかし、私たちは、<a href="https://github.com/elasticsearch/elasticsearch/issues/2488">issue #2488</a>(&ldquo;分割が交差している場合、minimum_master_nodesはsplit-brainを防げない&rdquo;)に含まれる、ユーザが経験してきた大部分の問題を私たちは解決しました。</p>

<p>私たちはクラスタのresiliencyを非常に真剣に取り組んでいます。
私たちは、Elasticsearchが何ができるか、その上で何が弱点であるかを理解してほしいと思っています。
これを考慮して、私たちは<a href="http://www.elasticsearch.org/guide/en/elasticsearch/resiliency/current/index.html">Resiliency Status Document</a>を作成しました。
このドキュメントは、私たち(または私たちユーザ)が遭遇したresiliencyの問題の、何が修正済みで、何が修正されないまま残っているかを記録します。
このドキュメントを慎重に読み、あなたのデータを保護するために適切な方法を選択してください。</p>

<h2><a name="checksums">データ破損の検知</a></h2>

<p>ネットワークをまたいだシャードリカバリのチェックサムは、圧縮ライブラリのバグを発見する助けとなりました。
それは、バージョン1.3.2で修正済みです。
それ以来、私たちはElasticsearchのいたるところにチェックサムとチェックサムの確認を追加しました。</p>

<ul>
<li>マージ中に、あるセグメント内すべてのチェックサムの確認(<a href="https://github.com/elasticsearch/elasticsearch/issues/7360">#7360</a>)</li>
<li>インデックス再オープン時に、あるセグメント内の最も小さなファイルの完全な確認と、より大きなファイルの軽量な打ち切りチェック(<a href="https://issues.apache.org/jira/browse/LUCENE-5842">LUCENE-5842</a>)</li>
<li>トランザクションログからイベントを再生するとき、各イベントはチェックサムを確認される(<a href="https://github.com/elasticsearch/elasticsearch/issues/6554">#6554</a>)</li>
<li>シャードのリカバリ中もしくは、スナップショットからのリストア中にElasticsearchはローカルファイルとリモートのコピーが同一であるか確認する必要がある。ファイルの長さとチェックサムのみを使うのは不十分であることが確認された。このため、現在はセグメントのすべてのファイルの同一性を確認(<a href="https://github.com/elasticsearch/elasticsearch/issues/7159">#7159</a>)</li>
</ul>


<h2>その他のハイライト</h2>

<p><a href="http://www.elasticsearch.org/downloads/1-4-0-Beta1">Elasticsearch 1.4.0.Beta1のchangelog</a>に本リリースの多くの機能、改善、バグフィックスについて読むことができます。
ここでは、特筆すべきいくつかの変更について述べます。</p>

<h3>groovyによるmvelの置き換え</h3>

<p>Groovyは現在、デフォルトのscripting languageです。
以前のデフォルトはMVELで、古くなってきており、サンドボックス内で実行できないという事実は、セキュリティ問題でした。
Groovyはサンドボックスであり(それは、ボックスの外へは許可が必要)、メンテナンスされており、速いです！
詳しくは<a href="http://www.elasticsearch.org/blog/scripting/">scriptingについてのブログ記事</a>をご覧ください。</p>

<h3>デフォルトでcorsはオフ</h3>

<p>Elasticsearchのデフォルト設定はクロスサイトスクリプティングに対して脆弱でした。
私たちはデフォルトで<a href="http://en.wikipedia.org/wiki/Cross-origin_resource_sharing">CORS</a>をオフにすることで修正しました。
Elasticsearchにインストールされたサイトプラグインはこれまで同様に機能します。
しかし、CORSを再度オンにすることがない限り、外部のウェブサイトがリモートのクラスタにアクセスすることはできません。
ウェブサイトがあなたのクラスタにアクセス可能に制御できるように、さらに<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/modules-http.html#_settings_2">CORS settings</a>を追加しました。
詳しくは<a href="http://www.elasticsearch.org/community/security">security page</a>をご覧ください。</p>

<h3>クエリキャッシュ</h3>

<p>新しい試験的な<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-shard-query-cache.html">shardレベルのクエリキャッシュ</a>は、静的なインデックスのアグリゲーションをほとんど即座に反応できます。
ウエブサイトのアクセスの日毎のページビュー数を見るダッシュボードを持っていると想像してみてください。
これらの数値は古いインデックスでは変更がありません。しかし、アグリゲーションはダッシュボードのリフレッシュのたびに再計算されます。
新しいクエリキャッシュを利用すると、シャードのデータが変更されない限り、アグリゲーションの結果はキャッシュから直接返却されます。
キャッシュから古い結果を決して取得することはありません。それは、常に、キャッシュされていないリクエストと同じ結果を返します。</p>

<h3>新しいaggregations</h3>

<p>3つの新しいaggregationsがあります。</p>

<ul>
<li><p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-filters-aggregation.html"><code>filters</code></a></p>

<ul>
<li>これは<code>filter</code> aggregationの拡張です。複数のバケットを定義し、バケット毎に異なるフィルタを利用できます。</li>
</ul>
</li>
<li><p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-children-aggregation.html"><code>children</code></a></p>

<ul>
<li><code>nested</code>アグリゲーションの親子版。<code>children</code> aggは親のドキュメントに属する子のドキュメントを集計できる</li>
</ul>
</li>
<li><p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-metrics-scripted-metric-aggregation.html"><code>scripted_metric</code></a></p>

<ul>
<li>このaggregationは、データによって計算されたメトリックを完全にコントロールできます。これは、初期化フェーズ、ドキュメント収集フェーズ、shardレベル結合フェーズ、global reduceフェーズを提供します。</li>
</ul>
</li>
</ul>


<h3>get /index api</h3>

<p>以前、ある1つのインデックスのaliases、mappings、settings、warmersを取得出来ました。しかし、それらを個別にです。
<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-get-index.html"><code>get-index</code> API</a> はこれらのすべてもしくは一部を、複数もしくはひとつのインデックスに対して一緒に取得できます。
これは、既存のインデックスと同一もしくはほぼ同一であるインデックスを作成したいときに非常に役に立ちます。</p>

<h3>登録と更新</h3>

<p>ドキュメントの登録と更新にいくつかの改善があります。</p>

<ul>
<li>現在、ドキュメントIDの自動生成のために<a href="http://boundary.com/blog/2012/01/12/flake-a-decentralized-k-ordered-unique-id-generator-in-erlang">Flake ID</a>を使用しています。これは、プライマリキー探索時に素晴らしい性能向上を提供します。</li>
<li><code>detect_noop</code>に<code>true</code>を設定すると、ドキュメントに変更を与えない更新が軽量になります。この設定を有効にすると、<code>_source</code>フィールドのコンテンツを変更する更新リクエストだけ、ドキュメントの新しいバージョンを書き込みます。</li>
<li>更新はスクリプトから完全に操作できます。以前は、スクリプトはドキュメントがすでに存在しているときだけ実行可能で、それ以外は、<code>upsert</code>ドキュメントで登録しました。<code>script_upsert</code>パラメータでスクリプトから直接ドキュメントの作成が操作できます。</li>
</ul>


<h3>function score</h3>

<p>すでに非常に便利な<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/query-dsl-function-score-query.html"><code>function_score</code>クエリ</a>が、新しく<code>weight</code>パラメータをサポートします。
これは、それぞれの指定された関数の影響をチューニングするのに使われます。
これは、人気度よりも更新日時により重みをかけたり、地理情報よりも価格により重みをかけるといったことを可能にします。
また、<code>random_score</code>機能はセグメントマージによる影響を受けません。これにより、より一貫した順序が提供されます。</p>

<h2>試してみてください。</h2>

<p>ぜひ、<a href="http://www.elasticsearch.org/downloads/1-4-0-Beta1">Elasticsearch 1.4.0.Beta1</a>をダウンロードして、試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/elasticsearch/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第6回Elasticsearch勉強会を開催しました。#elasticsearchjp]]></title>
    <link href="http://blog.johtani.info/blog/2014/09/17/hold-on-6th-elasticsearch-jp/"/>
    <updated>2014-09-17T13:22:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/09/17/hold-on-6th-elasticsearch-jp</id>
    <content type="html"><![CDATA[<p><a href="http://elasticsearch.doorkeeper.jp/events/13917">第6回Elsticsearch勉強会</a>を開催しました。
スタッフの皆さん、スピーカーの皆さん、開場提供していただいた<a href="http://recruit-tech.co.jp">リクルートテクノロジーズさん</a>、ありがとうございました！
次回もよろしくお願いします！参加していただき盛り上げていただいた参加者の皆さんもありがとうございました。
今回は、スタッフが私を含めて3，4名ということで、ドタバタしてしまってスミマセンでした。</p>

<!-- more -->


<p>今回はキャンセルが多く、最終的には90人弱の参加となりましたが、今回も多数の方にお集まりいただきありがとうございました。
同じ日に他の勉強会もあった影響でしょうか？</p>

<h2>「Aggregationあれこれ」Elasticsearch Inc. Jun Ohtani @johtani</h2>

<p>スライド：<a href="https://speakerdeck.com/johtani/aggregationarekore">Aggregationあれこれ</a></p>

<ul>
<li>ちょっと長かったですかね。。。</li>
<li>Aggregationの概要、内部動作、種類などを簡単に紹介してみました。</li>
<li>個々のAggregationもいろいろなオプションなどがあるので、色々と試してみていただければと思います。</li>
<li>アニメーション入りのスライドになってましたが、UpしてあるスライドはPDF版になります。</li>
</ul>


<h2>「秒間3万の広告配信ログをElasticSearchでリアルタイム集計してきた戦いの記録」 株式会社サイバーエージェント　山田直行さん　@satully</h2>

<p>スライド：<a href="http://www.slideshare.net/Satully/elasticsearch-study6threaltime20140916">秒間3万の広告配信ログをElasticSearchでリアルタイム集計してきた戦いの記録</a></p>

<ul>
<li>ディスプレイ広告配信DSPの話</li>
<li>システム: Fluentd、S3、Elasticsearch、Redis、MySQL</li>
<li>7月に秒間3万〜4万のリクエストをさばいている。</li>
<li>なぜElasticsearchを選んだのか、今の構成など</li>
<li>実際に苦労された点なども交えて話していただき面白かったです。</li>
<li>7月時点のお話ということで、現時点ではまた違う構成っぽかったので、また話を聞きたいなぁ。</li>
</ul>


<h2>「Elasticsearch 日本語スキーマレス環境構築と、ついでに多言語対応」ナレッジワークス株式会社　木戸国彦さん @9215</h2>

<p>スライド：<a href="https://speakerdeck.com/kunihikokido/elasticsearch-ri-ben-yu-sukimaresuhuan-jing-gou-zhu-to-tuideniduo-yan-yu-dui-ying">Elasticsearch 日本語スキーマレス環境構築と、ついでに多言語対応</a></p>

<ul>
<li>Dynamic TemplateやIndex Templateの説明</li>
<li>日本語や多言語化するときのMappingのサンプルになりそうなものがゴロゴロ紹介されてました。</li>
<li>いくつかの例があって、後で見直したいなと。</li>
<li>途中で出てきた、fielddata（インデックスに入っている単語区切りのデータ）を見るのに使ってたクエリは<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-request-fielddata-fields.html">field data fields</a>だったかな。</li>
</ul>


<h2>「elasticsearchソースコードを読みはじめてみた」@furandon_pig さん</h2>

<p>スライド：<a href="http://www.slideshare.net/furandon_pig/elasticsearch-39175134">elasticsearchソースコードを読みはじめてみた</a></p>

<ul>
<li>リクエストを受けて検索してる部分から読むといいって言われたらしいが、起動スクリプトから読み始めてみた。</li>
<li>時間かかりそうｗ</li>
<li>ただ、人がどんな感じでソースを読んだり理解してるかがわかりやすかったので面白かったです。</li>
<li>定期的に続きを聞いてみたいです。</li>
</ul>


<h2>LT</h2>

<h3>「reroute APIを使用してシャード配置を制御する」 株式会社富士通ソフトウェアテクノロジーズ 滝田聖己さん @pisatoshi</h3>

<p>スライド：<a href="https://speakerdeck.com/pisatoshi/elasticsearch-rerouteapiwoshi-tutasiyadopei-zhi-falsezhi-yu">reroute APIを使用してシャード配置を制御する</a></p>

<ul>
<li>シャードの再配置が自動で行われるので、それをオフにしないと、せっかく移動しても無駄になることがというあるあるネタ</li>
<li>Bonsaiロゴを作成するLT</li>
<li>実際にいくら掛かったのかが知りたかった。</li>
</ul>


<h3>「検索のダウンタイム0でバックアップからIndexをリストアする方法」株式会社ドワンゴモバイル 西田和史さん</h3>

<p>スライド：<a href="http://www.slideshare.net/kbigwheel/0index-39143333">検索のダウンタイム0でバックアップからIndexをリストアする方法</a></p>

<ul>
<li>擬似無停止のやりかた。</li>
<li>aliasを活用して、かつ、Restoreで再構築するという方法。</li>
<li>aliasまで一緒にリストアされるので注意が必要っていうのは、実際にやってみたからわかることという感じですね。</li>
</ul>


<h2>その他、感想などのブログ</h2>

<p>適当に見つけたブログを列挙してあります。これもあるよ！などあれば、教えてください。</p>

<ul>
<li><a href="http://s-wool.blog.jp/archives/1009404632.html">第6回elasticsearch勉強会に行ってきましたのでそのメモ</a></li>
<li><a href="http://arika.hateblo.jp/entry/2014/09/17/100921">elasticsearch 勉強会 第6回</a></li>
</ul>


<h3>まとめ</h3>

<p>今回も、ためになる話がいっぱい聞けたかなと。
個人的な印象としては、いつものメンバーよりも新しい方が多かった印象です。
また、ほとんどの方が、Elasticsearchをご存知でした。
そこそこ知名度は上がってきているようで嬉しい限りです。（東京以外での知名度なども知りたいかなと。）</p>

<p>あと、懇親会の部屋の案内が遅くなってしまってスミマセンでした。
さすがにスタッフ3名はきつかったです。。。</p>

<p>19時半開始にしてみましたが、懇親会の時間がやはり短めになってしまうなぁという印象でした。</p>

<p>次回ももちろん2ヶ月後くらいに行います。
スピーカー募集中ですので、コメント、メール、ツイートなど、コンタクトしていただければと思います。
よろしくお願いいたします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[elasticsearch.もうちょっと入門という話をしてきました #gihyo_efk]]></title>
    <link href="http://blog.johtani.info/blog/2014/09/16/book-publication-event/"/>
    <updated>2014-09-16T13:21:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/09/16/book-publication-event</id>
    <content type="html"><![CDATA[<p>先日2014年9月9日(火)に<a href="http://eventdots.jp/event/137658">『サーバ/インフラエンジニア養成読本 ログ収集〜可視化編』　出版記念！執筆者が語る大講演会！</a>で、
<a href="https://speakerdeck.com/johtani/elasticsearchmoutiyotutoru-men">「elasticsearch.もうちょっと入門」</a>というタイトルで発表してきました。
会場のGMOのみなさま、Treasure Data、技術評論社のみなさま、どうもありがとうございました。</p>

<p>書籍に興味のある方は、右のリンクから購入してもらえるとうれしいです。Kindle版も用意されています。</p>

<!-- more -->


<p>提供のTDの方に目をつぶってもらいながらLogstashについての発表となってしまいましたが、楽しんでいただけたかなぁと。
書籍では主にKibana3をメインにしたElasticsearchの使い方だったので、それ以外の機能ということで、Aggregationについて説明してみました。</p>

<p>そのあとは、おそらく初めてですが、パネルディスカッションにも参加しました。
<a href="https://twitter.com/naoya_ito">@naoya_ito</a>さんをモデレーターに、rebuild.fm風に進めていただき、話しやすかったかなと。
（少なくとも私は楽しめました！）
ただ、私だけバックグラウンドが少し異なることもあり、話をうまく繋げられなかったかもと気にしていたりもしますが。。。</p>

<p>パネルディスカッションでもありましたが、エンジニアが「趣味」で入れて試してみるのにはもってこいのツール群だと思います。
ちょっと入れてみて、可視化をしてみるといろいろと発見があると思います。
何かを発見するためにもまず試してみるのが何事も重要かなと最近思ってるのもあるので、気軽に試してみてもらえればと。</p>

<p>不明点などあれば、著者陣に気軽に聞いていただけると良いかと思います（いいですよね、みなさんｗ）。
Fluentd（もちろん、Logstashも）、Elasticsearch、Kibanaを利用して、データについて試行錯誤してもらって、
システムやビジネスに必要なものを探索して見てください。</p>

<h3>参考</h3>

<p>他の方々のブログをメモとして。</p>

<ul>
<li><a href="http://suzuken.hatenablog.jp/entry/2014/09/11/210059">サービス改善とログデータ解析について発表してきました</a></li>
<li><a href="http://blog.harukasan.jp/entry/2014/09/12/144217">Kibanaではじめるダッシュボードについて発表してきました #gihyo_efk</a></li>
<li><a href="http://y-ken.hatenablog.com/entry/fluentd-system-design-pattern">Fluentdのお勧めシステム構成パターンについて発表しました</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearchのインデキシングに関するパフォーマンス検討]]></title>
    <link href="http://blog.johtani.info/blog/2014/09/09/performance-considerations-for-elasticsearch-indexing/"/>
    <updated>2014-09-09T17:11:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/09/09/performance-considerations-for-elasticsearch-indexing</id>
    <content type="html"><![CDATA[<p>Elasticsearchのインデキシングに関するパフォーマンス検討</p>

<p>原文：<a href="http://www.elasticsearch.org/blog/performance-considerations-elasticsearch-indexing/">performance considerations for elasticsearch indexing</a></p>

<p>Elasticsearchユーザは様々な楽しいユースケースを持っています。小さなログを追加することから、Webスケールの大きなドキュメントの集合をインデキシングするようなことまでです。また、インデキシングのスループットを最大化することが重要で一般的な目標となります。
「典型的な」アプリケーションに対して良いデフォルト値を設定するようにしていますが、次のちょっとした簡単なベストプラクティスによってインデキシングのパフォーマンスをすぐに改善することができます。それらについて記述します。</p>

<!-- more -->


<p>第一に、制御できないならば、巨大なJavaヒープを使用しない：必要なサイズ（マシンの持つRAMの半分以下）のheapだけを設定しましょう。Elasticsearchの利用方法のために必要な全体量を設定します。これは、OSにIOキャッシュを制御するためのRAMを残すことを意味します。OSが<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-configuration.html">javaプロセスをスワップアウト</a>していないことも確認しましょう。</p>

<p>最新バージョン（<a href="http://www.elasticsearch.org/downloads/1-3-2/">現時点では1.3.2</a>）のElasticsearchにアップグレードしましょう：多数のインデキシングに関連する問題点が最新リリースで修正されています。</p>

<p>詳細に入る前に警告：ここで述べるすべての情報は現時点での最新（<a href="http://www.elasticsearch.org/downloads/1-3-2/">1.3.2</a>）の情報です。しかし、Elasticsearchの更新は日々行われています。この情報をあなたが見た時点では最新ではなく、正確ではなくなっているかもしれません。自信がない場合は<a href="http://www.elasticsearch.org/community">ユーザメーリングリスト</a>で質問してください。</p>

<p>クラスタのインデキシングスループットをチューニングする場合、<a href="http://www.elasticsearch.org/overview/marvel">Marvel</a>は非常に有用なツールです：ここで述べている各設定を継続的に試し、変更の影響がクラスタの挙動をどのように変更されたかを簡単に可視化することが可能です。</p>

<h2>クライアントサイド</h2>

<p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/docs-bulk.html">bulk API</a>を常に使いましょう。1リクエストで複数のドキュメントをインデキシングでき、各バルクリクエストで送るのに良いドキュメント数を試しましょう。最適なサイズは多くの要因に依存しますが、最適サイズからずれるならば多すぎるよりも少なすぎる方が良いでしょう。クライアントサイドのスレッドで並列にbulkリクエストを使うか、個別の非同期リクエストを使ってください。</p>

<p>インデキシングが遅いと結論付ける前に、クラスタのハードウェアの性能を引き出せているかを確認して下さい：すべてのノードでCPUやIOが溢れていないかを確認するために<code>iostat</code>や<code>top</code>、<code>ps</code>といったツールを使いましょう。もし、溢れていなければ、より多くの並列なリクエストが必要です。しかし、javaクライアントからの<code>EsRejectedExecutionException</code>や、RESTリクエストのHTTPレスポンスとして<code>TOO_MANY_REQUESTS (429)</code>が返ってきた場合は並列リクエストを多く送りすぎています。もし<a href="http://www.elasticsearch.org/overview/marvel">Marvel</a>を利用しているなら、<a href="http://www.elasticsearch.org/guide/en/marvel/current/#_node_amp_index_statistics">Node Statistics Dashboard</a>の<code>THREAD POOLS - BULK</code>にリジェクトされた数が表示されます。bulkスレッドプールサイズ（デフォルト値はコア数）を増やすのは得策ではありません。インデキシングスループットを減少させるでしょう。クライアントサイドの並列度を下げるか、ノードを増やすのが良い選択です。</p>

<p>ここでは、1シャードに対してインデキシングスループットを最大化する設定に注目します。1つのLuceneインデックスのドキュメントの容量を測定するために、単一ノード（単一シャード、レプリカなし）で最初にテストをして最適化し、クラスタ全体にスケールする前にチューニングを繰り返します。これはまた、インデキシングスループットの要件を見つけるために、クラスタ全体にどのくらいのノードが必要かをラフに見積もるためのベースラインを与えてくれます。</p>

<p>単一シャードが十分機能したら、Elasticsearchのスケーラビリティの最大の利点や、クラスタでの複数ノードによるレプリカ数やシャード数の増加の利点が得られます。</p>

<p>結論を導き出す前に、ある程度の時間（60分）くらいクラスタ全体の性能を計測しましょう。このテストは、巨大なマージ、GCサイクル、シャードの移動、OSのIOキャッシュ、予期しないスワップの可能性などのイベントのライフサイクルをカバーできます。</p>

<h2>ストレージデバイス</h2>

<p>当然ながらインデックスを保存するストレージデバイスはインデキシングの性能に多大な影響を及ぼします：</p>

<ul>
<li>SSDを利用する：これらは最も速いHDDよりも速いです。ランダムアクセスのための消費電力が低いだけでなく、シーケンシャルIOアクセスも高いです。また、同時に発生するインデキシング、マージや検索のための並列的なIOも高速です。</li>
<li>インデックスをリモートマウントされたファイルシステム（例：<a href="http://en.wikipedia.org/wiki/Network_File_System">NFS</a>や<a href="http://en.wikipedia.org/wiki/Server_Message_Block">SMB/CIFS</a>）上に配置しない：代わりにローカルストレージを使う</li>
<li>仮想化されたストレージ（Amazonの<a href="http://aws.amazon.com/ebs/">Elastic Block Storage</a>など）に注意：仮想化されたストレージはElasticsearchで十分に動作します。また、十分早く簡単に用意できることから魅力的です。しかし、残念なことに、ローカルストレージと比較すると本質的に遅いです。最近の非公式なテストでは、<a href="http://aws.amazon.com/ebs/details/#PIOPS">最高の性能を持つプロビジョニングされたIOPSのSSDオプションのEBS</a>でさえ、ローカルインスタンスにあるSSDよりも遅いです。ローカルインスタンスにあるSSDは物理マシン上のすべての仮想マシンから共有されてアクセスされます。もし他の仮想マシンが急にIOが集中した場合に不可解なスローダウンとなることがあることを覚えておいてください。</li>
<li>複数のSSDを<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-dir-layout.html">複数の<code>path.data</code>ディレクトリ</a>にインデックスをストライピング（<a href="http://en.wikipedia.org/wiki/RAID_0#RAID_0">RAID0</a>のように）：2つは同様で、ファイルブロックレベルでストライピングする代わりに、個別にインデックスファイルレベルでElasticsearchの&#8221;stripes&#8221;となります。これらのアプローチは、いづれかのSSDの故障によりインデックスが壊れるという、1シャードが故障する(IO性能を高速化することとトレードオフ)というリスクを増加させることに注意してください。これは、一般的に行うのに良いトレードオフです：単一シャードで最大のパフォーマンスを最適化し、異なるノード間でレプリカを追加すると、ノードの故障への冗長化ができます。また、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-snapshots.html">snapshotやrestore</a>を使って保険のためにインデックスのバックアップを取ることもできます。</li>
</ul>


<h2>セグメントとマージ</h2>

<p>新しくインデキシングされたドキュメントは最初にLuceneの<code>IndexWriter</code>によってRAMに保存されます。RAMバッファがいっぱいになった時もしくは、Elasticsearchがflushもしくはrefreshを実行した時など定期的にこれらのドキュメントはディスクに新しいセグメントとして書き込まれます。最後に、セグメントが多くなった時に、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-merge.html">Merge PolicyとSucheduler</a>によってそれらがマージされます。このプロセスは連続的に生じます：マージされたセグメントはより大きなセグメントとなり、小さなマージが幾つか実行され、また、大きなセグメントにマージされます。これらがどのように動作するかを<a href="http://blog.mikemccandless.com/2011/02/visualizing-lucenes-segment-merges.html">わかりやすく可視化したブログはこちら</a>です。</p>

<p>マージ、特に大きなマージは非常に時間がかかります。これは、通常は問題ありません。そのようなマージはレアで全体のインデックスのコストと比べればささいなものです。しかし、マージすることがインデキシングについていけない場合、インデックスに非常に多くのセグメントがあるような深刻な問題を防ぐために、Elasticsearchはやってくるインデキシングリクエストを単一スレッド(1.2以降)に制限します。</p>

<p>もし、INFOレベルのログメッセージに<code>now throttling indexing</code>と表示されていたり、<a href="http://www.elasticsearch.org/guide/en/marvel/current">Marvel</a>でのセグメント数が増加しているを見た場合、マージが遅れているとわかります。Marvelは<a href="http://www.elasticsearch.org/guide/en/marvel/current/#_node_amp_index_statistics">Index Statistics dashboard</a>の<code>MANAGEMENT EXTENDED</code>の部分にセグメント数をプロットしており、それは、非常にゆっくりと指数対数的に増加しており、大きなマージが終了したところがのこぎりの歯のような形で見て取れます。</p>

<p><img src="http://www.elasticsearch.org/content/uploads/2014/09/segmentCounts.png" title="セグメント数" ></p>

<p>なぜマージが遅れるのでしょう？デフォルトでElasticsearchはすべてのマージの書き込みのバイト数をわずか20MB/secに制限しています。スピニングディスク（HDD）に対して、これはマージによって典型的なドライブのIOキャパシティを飽和させず、並列に検索を十分に実行させることを保証します。しかし、もし、インデキシング中に検索をしない場合や、検索性能がインデキシングのスループットよりも重要でない場合、インデックスの保存にSSDを使用している場合などは、<code>index.store.throttle.type</code>に<code>none</code>を設定して、マージの速度制限を無効化するべきです（詳細は<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-store.html">こちら</a>をご覧ください）。なおバージョン1.2以前には<a href="https://github.com/elasticsearch/elasticsearch/issues/6018">期待以上のマージIO制限の発生</a>といったバグが存在します。アップグレードを！</p>

<p>もし、不幸にもスピニングディスク（それはSSDと同等の並列なIOを扱えません）をまだ使っている場合、<code>index.merge.scheduler.max_thread_count</code>に<code>1</code>を設定しなければなりません。そうでない場合は、（SSDを支持する）デフォルト値が多くのマージを同時に実行させるでしょう。</p>

<p>活発に更新が行われているインデックスで<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-optimize.html"><code>optimize</code></a>を実行しないでください。それは、非常にコストの高い操作(すべてのセグメントをマージ)です。しかし、もし、インデックスにドキュメントを追加が終わった直後はオプティマイズのタイミングとしては良いタイミングです。それは、検索時のリソースを減らすからです。例えば、時間ベースのインデックスを持っており、新しいインデックスに日々のログを追加している場合、過去の日付のインデックスをオプティマイズするのは良い考えです。特に、ノードが多くの日付のインデックスを持っている場合です。</p>

<p>更にチューニングするための設定：</p>

<ul>
<li>実際に必要のないフィールドをオフにする。例えば<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-all-field.html"><code>_all</code>フィールドをオフ</a>。また、保持したいフィールドでは、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-core-types.html"><code>indexed</code>か<code>stored</code>かを検討する</a>。</li>
<li>もし、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-source-field.html"><code>_source</code>フィールドをオフ</a>にしたくなるかもしれないが、インデキシングコストは小さい(保存するだけで、インデキシングしない)、また、それは、将来の更新や、前のインデックスを再インデキシングするために非常に価値があり、それはディスク使用率の懸念事項がない限り、オフにする価値はあまりない。それは、ディスクが比較的安価であるので価値がない。</li>
<li>もし、インデックスされたドキュメントの検索までの遅延を許容できるなら、<code>index.refresh_interval</code>を<code>30s</code>に増やすか、<code>-1</code>を設定して、オフにする。これは、巨大なセグメントをフラッシュし、マージのプレッシャーを減らすことができる。</li>
<li><a href="http://www.elasticsearch.org/downloads/1-3-2/">Elasticsearch 1.3.2</a>(稀に、フラッシュ時に過度のRAMを使用するという<a href="https://github.com/elasticsearch/elasticsearch/issues/6443">問題</a>を<a href="https://github.com/elasticsearch/elasticsearch/issues/6379">修正した</a>)にアップグレードすることで、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-translog.html"><code>index.translog.flush_threshold_size</code></a>をデフォルト(200mb)から1gbに増加し、インデックスファイルのfsyncの頻度を減らす。
Marvelに<a href="http://www.elasticsearch.org/guide/en/marvel/current/#_node_amp_index_statistics"><code>Index Statistics dashboard</code></a>の<code>MANAGEMENT</code>にフラッシュの頻度がプロットされている。</li>
</ul>


<h2>インデックスバッファサイズ</h2>

<p>巨大なインデックスを構築中はレプリカ数を0にし、あとから、レプリカを有効にする。レプリカが0ということは、データを失った(ステータスがred)時に冗長性がないので、ノードの故障に注意すること。もし、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-optimize.html"><code>optimize</code></a>(ドキュメントの追加をすることがないので)を計画するなら、インデキシングが終わったあとで、レプリカを作成する前に実行するのが良いでしょう。レプリカはオプティマイズされたセグメントをコピーするだけになります。詳細は<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-update-settings.html">インデックス設定更新</a>を参照。</p>

<p>もし、ノードがヘビーなインデキシングを行っているだけなら、アクティブなシャードのインデキシングバッファに多くてい512MBを<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-indices.html">indices.memory.index_buffer_size</a>に与えてください。(超えてもインデキシングのパフォーマンスは一般的には改善されません。)Elasticsearchはその設定(Javaヒープのパーセンテージもしくはバイト数)を受けて、min_index_buffer_sizeとmax_index_buffer_sizeの値を前提にノードのアクティブシャードに均等に割り当てます；大きな値はLuceneが最初のセグメントをより大きくし、将来的なマージのプレッシャーを減らすことを意味します。</p>

<p>デフォルトは10%で、それで十分です；例えば、もし、5つのアクティブなシャードがノードにあり、ヒープが25GBの場合、各シャードは25GBの10%の1/5=512MB（すでに最大値）を持っています。ヘビーなインデキシングのあと、この設定をデフォルトに下げましょう。検索時のデータ構造のために十分なRAMを確保するために。この設定はまだ動的な設定変更はできません。<a href="https://github.com/elasticsearch/elasticsearch/issues/7045">Issueがここに</a>あります。</p>

<p>インデックスバッファによって現在利用されているバイト数は1.3.0の<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-stats.html">indices stats API</a>に追加されています。<code>indices.segments.index_writer_memory</code>の値を見ることができます。これはMarvelではまだプロットされていませんが、将来のバージョンで追加される予定です。しかし、自分でグラフに追加することもできます。(Marvelはデータは収集しています)</p>

<p>1.4.0では、<a href="https://github.com/elasticsearch/elasticsearch/issues/7440"><code>indices.segments.index_writer_max_memory</code></a>として、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-stats.html">indices stats API</a>にアクティブシャードにどのくらいのRAMバッファが割り当てられているかも表示されます。これらの値はインデックスのシャード事の値として見ることができ、<code>http://host:9200/&lt;indexName&gt;/_stats?level=shards</code>を使ってみることができます；これは、全シャードに対する合計と、各シャードごとのstatsを返すでしょう。</p>

<h2>オートIDの利用もしくは良いIDの利用</h2>

<p>もし、ドキュメントの<code>ID</code>がなんでも良い場合、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/docs-index_.html#_automatic_id_generation" title="">Elasticsearchで採番すること</a>ができます：これは、(1.2以降)ドキュメントIDをバージョンを探さずに保存できるように<a href="https://github.com/elasticsearch/elasticsearch/pull/5917">最適化</a>され、Elasticsearchの<a href="http://benchmarks.elasticsearch.org/">日毎のベンチマーク</a>で異なるパフォーマンスを見ることができます。(<code>Fast</code>と<code>FastUpdate</code>のグラフを比較)</p>

<p>もし、IDを自身が持っていて、自分の支配下で<a href="http://blog.mikemccandless.com/2014/05/choosing-fast-unique-identifier-uuid.html">Luceneに対して素早く選ぼうとしている</a>なら、1.3.2にアップグレードしましょう、IDのルックアップが<a href="https://github.com/elasticsearch/elasticsearch/issues/6212">さらにオプティマイズ</a>されています。Javaの<a href="http://docs.oracle.com/javase/7/docs/api/java/util/UUID.html">UUID.randomUUID()</a>はやめましょう。それは、セグメントに対してどのようにIDを割り当てるかという予測やパターン性がないため、最悪のケースで<a href="http://blog.mikemccandless.com/2014/05/choosing-fast-unique-identifier-uuid.html">セグメントごとのシーク</a>が発生します。</p>

<p><a href="http://boundary.com/blog/2012/01/12/flake-a-decentralized-k-ordered-unique-id-generator-in-erlang/">Flake IDs</a>を利用した時の<a href="http://www.elasticsearch.org/overview/marvel">Marvel</a>によるインデックス性能の違い：</p>

<p><img src="http://www.elasticsearch.org/content/uploads/2014/09/flakeIDsPerf.png" title="flakeIDsPerf" ></p>

<p>ランダムUUIDを利用した場合：</p>

<p><img src="http://www.elasticsearch.org/content/uploads/2014/09/uuidsPerf.png" title="uuidsPerf" ></p>

<p>次の1.4.0では、ElasticsearchのID自動採番を<a href="https://github.com/elasticsearch/elasticsearch/issues/5941">UUIDからFlake IDに変更</a>します。</p>

<p>もし、Luceneのローレベル操作がインデックスに対してなにをやっているかについて興味があるなら、<a href="https://github.com/elasticsearch/elasticsearch/issues/5891"><code>lucene.iw</code>をTRACEログレベルで出力できるように</a>してみましょう(1.2から利用可能)。これは、多くの出力がありますが、Luceneの<code>IndexWriter</code>レベルで何が起きているかを理解するのに非常に役に立ちます。出力は非常にローレベルです：<a href="http://www.elasticsearch.org/guide/en/marvel/current">Marvel</a>がインデックスに何が起きているかをよりリアルタイムにグラフを描画してくれます。</p>

<h2>スケールアウト</h2>

<p>我々は、単一シャード(Luceneインデックス)性能のチューニングに注目してきました。しかし、一旦それに満足できたならば、Elasticsearchはクラスタ全体にわたってインデキシングや検索を簡単にスケールアウトすることに長けています。シャード数(デフォルトでは5)を増やすのは可能です。それは、マシン全体に対して並列度、巨大なインデックスのサイズ、検索時のレイテンシの低下など得ることができます。また、レプリカを1位上にすることは、ハードウェア故障に対する冗長性を持つことを意味します。</p>

<p>最後に、このドキュメントを見ても問題解決しない場合は<a href="http://www.elasticsearch.org/community">コミュニティに参加</a>しましょう。例えば、<a href="https://groups.google.com/forum/?fromgroups#!forum/elasticsearch">ElasticsearchのユーザML</a>に投稿するなど。おそらく、修正すべきエキサイティングなバグがあるでしょう。(パッチも常に歓迎です！)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[サーバ/インフラエンジニア養成読本 ログ収集~可視化編 を手伝いました]]></title>
    <link href="http://blog.johtani.info/blog/2014/08/04/release-magazine-book-of-log-aggs-and-viz/"/>
    <updated>2014-08-04T21:54:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/08/04/release-magazine-book-of-log-aggs-and-viz</id>
    <content type="html"><![CDATA[<p>懲りずにまた、執筆してみました。みなさん「買って」から感想をいただけるとうれしいです！</p>

<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&nou=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=johtani-22&o=9&p=8&l=as1&m=amazon&f=ifr&ref=tf_til&asins=4774169838" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>




<!-- more -->


<h2>本書について</h2>

<p>共著者の方々のブログが詳しいので、そちらを読んでもらいつつ。
実際にログを収集して解析されている方々と一緒に書かせていただくことで色々と勉強させていただいています。</p>

<h3>共著者の方々のブログ</h3>

<ul>
<li><a href="https://twitter.com/suzu_v">@suzu_v</a>さん：<a href="http://suzuken.hatenablog.jp/entry/2014/07/18/084555">サーバ/インフラエンジニア養成読本 ログ収集~可視化編 を書きました</a></li>
<li><a href="https://twitter.com/yoshi_ken">@yoshi_ken</a>さん：<a href="http://y-ken.hatenablog.com/entry/published-elasticsearch-fluentd-kibana-book">ログ収集や可視化で話題のFluentd、Elasticsearch、Kibanaを徹底解説したムック本が発売となります</a></li>
<li><a href="https://twitter.com/harukasan">@harukasan</a>さん：<a href="http://blog.harukasan.jp/entry/2014/07/18/180351">書きました: サーバ/インフラエンジニア養成読本 ログ収集~可視化編</a></li>
</ul>


<h3>どの辺を書いたの？</h3>

<p>「特集３：Elasticsearch入門」（なんか、入門ばっかりだなぁ）を書かせていただきました。
データストア入門ということで、ほんとうに簡単な他のデータストアを説明し、Elasticsearchってどんなものかを単語の説明をしつつ紹介してみました。</p>

<p>Elasticsearch自体は多くの機能を持っており、それ単体で分厚い書籍がかけるので、ログ検索に関係ありそうな部分をピックアップしてみました。
あとは、運用時に気をつける点や便利なツール（Curatorなど）の紹介をしています。</p>

<p>また、Hadoopと合わせて利用してみたい、すでにHadoopにあるデータも活用してみたいという話もありそうだということで、<a href="https://github.com/elasticsearch/elasticsearch-hadoop">elasticsearch-hadoop</a>についても簡単ですが紹介してあります。</p>

<h2>その他感想</h2>

<p>個人的に、忙しい時期<a href="http://blog.johtani.info/blog/2014/07/01/join-elasticsearch/">（参考記事）</a>だったので、あんまり力になれてないので大変申し訳なく思っています。。。
ただ、素晴らしい出来（カラーでKibanaの解説が日本語で読めたり、Fluentdの逆引きのリストがあったり、ログを貯めて可視化する意義を説明してあったり）です。</p>

<p>ぜひ、読んだ感想をいただければと！</p>
]]></content>
  </entry>
  
</feed>
