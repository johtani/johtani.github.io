<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[@johtaniの日記 2nd]]></title>
  <link href="http://blog.johtani.info/atom.xml" rel="self"/>
  <link href="http://blog.johtani.info/"/>
  <updated>2014-12-14T02:24:30+09:00</updated>
  <id>http://blog.johtani.info/</id>
  <author>
    <name><![CDATA[johtani]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Logstashプラグインのエコシステムの変更（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/14/plugin-ecosystem-changes/"/>
    <updated>2014-12-14T01:00:40+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/14/plugin-ecosystem-changes</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/plugin-ecosystem-changes/">exciting logstash plugin ecosystem changes</a></p>

<p>Logstash 1.5.0 Beta 1(<a href="http://www.elasticsearch.org/overview/logstash/download/">お試しはこちら</a>)のリリースで、
プラグインのインストール、管理、公開の方法を変更しています。
ユーザやコミュニティからフィードバックをもらいました。
その目的は、プラグインの利用や開発をより簡単にすることです。
このプロジェクトは始まったばかりです。プラグインのコミュニティを探し、
共有するためのワンストップソリューションを提供するこのアイデアを改善していく予定です。
このブログで、この決定を行った理由を説明し、新しいワークフローをと今後のロードマップを説明します。</p>

<!-- more -->


<h2>プラグインがあります！</h2>

<p>Logstashは、プラグイン（input、filter、output、codec）が豊富にあります。
これらは、Elasticsearchにより開発されたものと、コミュニティからコントリビュートされたものです。
Logstashの主な特長の1つは、これらのプラグインの有効性と動作を拡張するプラグインを追加するのが簡単なことです。
現在、165以上のプラグインがエコシステムにあり、これらは、2つのプロジェクトに分かれています。</p>

<ul>
<li><code>logstash-core</code>は最もよく使われるプラグインで、Logstashにデフォルトで含まれます</li>
<li><code>logstash-contrib</code>はコミュニティにより開発されたプラグインを含み、別途ダウンロードできます</li>
</ul>


<h2>新プラグインエコシステムの変更</h2>

<p>1.5.0では、全てのプラグインは、Logstashコアから分離され、rubygemsを使って個別にパッケージングされます。
rubygemsを選択したのは、依存関係のあるライブラリの配布とパッケージングがパワフルで一般的なものだからです。
さらに、<a href="http://rubygems.org/">rubygems.org</a>プラットフォームは配布や探索に影響があります。
また、Logstashにプラグインをインストール、アップデート、削除するのが簡単な基盤も追加しました。
<code>contrib</code>プロジェクトは徐々に終了します。全てのプラグインは個別のプロジェクトになります。</p>

<h2>プラグインエコシステム変更の理由</h2>

<p>多数のプラグインをもっていると、配布と公開に関して難題が出てきます。
私たちが変更するに至った理由は次のようなものです。</p>

<ul>
<li>現在は、プラグインの更新に伴い、Logstashの新バージョンのリリースが必要</li>
<li>開発者は、Logstashのリリース間隔とは別に、新バージョンをリリースをしたい</li>
<li>プラグイン開発者は、外部依存を記述できるようにしたい</li>
<li>Logstashコアの配布パッケージのダウンロードサイズを小さくし、ユーザは必要なプラグインのみインストール</li>
<li><code>logstash-contrib</code>を1つのリポジトリとして管理するのは難しい</li>
</ul>


<h2>詳細：</h2>

<h3>ソースコードの場所</h3>

<p>Logstashのソースコードは、今後も<a href="https://github.com/elasticsearch/logstash">現在のGitHubのリポジトリ</a>のままです。
しかし、プラグインに関するコードやテストコードは含まなくなります。
この分離により、個別のプラグインの改善と同様にコアの改善に集中できます。
これにより、Logstashプロジェクトの全体の品質も向上します。</p>

<p>全プラグインのソースコードは、新しいGitHub organization、<a href="https://github.com/logstash-plugins">logstash-plugins</a>にて管理します。
各プラグインは個別のリポジトリとして、ここに配置されます。
一見すると、これはメンテナンスが難しくなるように思えます。しかし、テスト、Issue、依存関係を明確にすることができます。
私たちの目的は、テスト、ドキュメント、gemの公開の自動化であり、これを簡単にするためのツールを追加します。</p>

<p>しかし、プラグインの開発者はプラグインのソースコードソースコードをlogstash-pluginsに置く必要はありません。
 ー コミュニティで利用可能にするために、<a href="http://rubygems.org/">rubygems.org</a>でそれを公開するだけで良いです。</p>

<h2>ワークフロー</h2>

<p>ここで、新プラグインエコシステムのやりとり/ワークフローについて、いくつかの観点から説明します。</p>

<h3>logstashユーザ:</h3>

<p>ユーザは、これまでのリリース同様にLogstashのバイナリをダウンロードします。
Logstash 1.5.0は、1.4.2でパッケージされていたプラグインと同等のものが含まれています。
新しいシステムに簡単に移行できるようにです。
そして、ユーザは、最初のデプロイの後に、Logstashプラグインのをインストール、アップグレードできるようになります。</p>

<p><code>$LS_HOME/bin/plugin</code>スクリプトがプラグイン操作に関連するコマンドになります。</p>

<h5>プラグインのインストール</h5>

<p>プラグインのほとんどはgemとして<a href="http://rubygems.org/">rubygems.org</a>にアップロードされます。
例えば、もしユーザが<a href="https://github.com/logstash-plugins/logstash-output-kafka">Apache Kafka outputプラグイン</a>をインストールする場合、次のコマンドを実行します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin install logstash-output-kafka</span></code></pre></td></tr></table></div></figure>


<p>または、ファイルをダウンロード済みの場合は次のコマンドとなります。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin install /path/to/logstash-output-kafka-1.0.0.gem</span></code></pre></td></tr></table></div></figure>


<h5>プラグインの削除</h5>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin uninstall logstash-output-kafka</span></code></pre></td></tr></table></div></figure>


<h5>1つまた全プラグインのアップデート</h5>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin update</span></code></pre></td></tr></table></div></figure>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin update logstash-output-kafka</span></code></pre></td></tr></table></div></figure>


<h5>プラグインのリストアップ</h5>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin list</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin list elasticsearch ( List all plugins containing a name )</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/plugin list --group output ( list all outputs )</span></code></pre></td></tr></table></div></figure>


<h4>ドキュメント</h4>

<p>プラグインが個別に管理されても、<a href="http://www.elasticsearch.org/guide/en/logstash/current/index.html">全プラグインのドキュメントは1カ所</a>です。</p>

<h3>logstash plugin開発者:</h3>

<p>プラグイン開発者と作者は、Logstashエコシステムのためにプラグインを公開することができます。
プラグインは、gemやJavaライブラリの依存関係を宣言できます。
より重要なのは、Logstashのリリース間隔に関係なく、プラグインの改善版をリリースできます。</p>

<p>Rubygemsテクノロジはパッケージングシステム、依存関係管理、ホスティングのために選択されてきました。
Rubyのgemを公開することに慣れている開発者は、Logstashプラグインを簡単に公開することができます。
Elasticsearchはこれらの機能に関して開発者を支援するために、ツールを提供、メンテナンスします。</p>

<h4>開発およびローカルでのテスト</h4>

<p>JRuby <code>1.7.16</code>がプラグインを開発するための唯一の前提条件です。
プラグインにパッチを提供するのは以前と同様です。
例えば、<code>logstash-output-kafka</code>にパッチを送るのは次のようになります。</p>

<ol>
<li><code>git clone https://github.com/logstash-plugins/logstash-output-kafka.git</code></li>
<li>変更</li>
<li>プラグインをローカルでテスト

<ul>
<li><code>bundle install</code></li>
<li><code>bundle exec rspec</code></li>
<li>Logstashの他のバージョンもしくはローカルでテストする場合、Gemfileを編集し、    次のように別のロケーションを加えます。<code>gem "logstash", :github =&gt; "elasticsearch/logstash", :ref =&gt; "master"</code></li>
</ul>
</li>
<li>新しいPull Requestを<code>logstash-output-kafka</code>に対して作成</li>
<li>コミュニティでコードレビューを受け、Elasticsearchがパッチを受け入れ</li>
</ol>


<h4>バージョン</h4>

<p>バージョン情報は、それぞれのプラグインの<code>.gemspec</code>で管理します。
例えば、Apache Kafka outputのgemspecは<a href="https://github.com/logstash-plugins/logstash-output-kafka/blob/master/logstash-output-kafka.gemspec">こちら</a>です。
バージョニングは<a href="http://semver.org/">semantic versioning</a>のルールに従い、
Logstashのバージョニングとは別に、プラグインの開発者によって管理されます。
Logstash 1.5.0がリリースされると、マイルストーン1のプラグインはバージョン1.0.0となり、マイルストーン2のプラグインはバージョン2.0.0となるでしょう。</p>

<h4>公開</h4>

<p>開発者が変更を加えプラグインを公開したいと思った時、<code>.gemspec</code>のバージョン番号を変更します。
全テストが成功した時、Elasticsearchはrubygems.orgにプラグインを手動で公開します。
もし、テストが失敗した場合、プラグインは公開されません。
長期的には、プラグインの公開の自動化を行いたいと思っています。
この変更は新しいため、公開の自動化を提供する前に、自動化についてより理解し、プラグインのテスト基盤を改良したいと思っています。</p>

<h4>Issue</h4>

<p>Issueは、各プラグインのGitHubリポジトリに対してオープンなければなりません。
Logstashコアのリポジトリは、コアのパイプラインや共通的な機能に関連するIssueについて扱います。</p>

<h4>ドキュメント</h4>

<p>プラグインのドキュメントはソースコード自体から生成されます。
それぞれのプラグインのドキュメントは、そのプラグインのリポジトリに含まれます。
Elasticsearchは
<a href="http://www.elasticsearch.org/guide">elasticsearch.org/guide</a>に全てのプラグインのドキュメントを集め生成できる基盤を提供します。</p>

<h4>移行</h4>

<p>全ての新しいpull requestとissueは<a href="https://github.com/logstash-plugins">logstash-plugin</a> organisation配下にある各プラグインのリポジトリに対してオープンする必要があります。</p>

<h5>すでにあるPRはどうすれば良いですか？</h5>

<p>気にしないでください。すでにあるpull requestは開発者によって移行する必要はありません。
LogstashチームがLogstashコアリポジトリに対してのPRを、個別の関連するプラグインのリポジトリに対してマージします。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone … # clone the specific plugin repo
</span><span class='line'># now apply the patch
</span><span class='line'>curl -s https://github.com/elasticsearch/logstash/pull/XXXX | git am --3way
</span><span class='line'>git push</span></code></pre></td></tr></table></div></figure>


<p><strong>Note:このプロセスはすでにあるPRに対してgit historyを管理します</strong></p>

<h5>GitHub Issue</h5>

<p>現在、LogstashリポジトリにオープンされているIssueは、それぞれのプラグインのリポジトリに移行します。
Logstashチームがgithub.com APIを利用してこの処理を自動的に行います。
安心してください。私たちが個別のプラグインに対する既存のIssueを移行します。</p>

<h2>今後のロードマップ</h2>

<p>これは、最初のステップであり、これらの変更は、ユーザや開発者に対してエコシステムをよりよくするために、
しっかりとした基盤を提供します。</p>

<p>短期的には、開発者のためにpull requestのフィードバックでテスト自動化を提供する基盤を追加していきます。
プラグインリポジトリのブートストラップや管理のためのツールも提供していきます。</p>

<p>長期的には、すべてのLogstashプラグインを探し、公開するためのコミュニティポータルを提供したいと思っています。
このアイデアは、Puppet ForgeやAWS marketplaceのようなものです。</p>

<p><a href="http://www.elasticsearch.org/blog/logstash-1-5-0-beta1-released/">Logstash 1.5.0 Beta 1</a>をリリースし、これは新しいエコシステムを提供します。
ぜひ、試していただき、これらの変更に関して感じたことを教えてください。
あなたのフィードバック(<a href="http://twitter.com/elasticsearch">Twitter</a>もしくは<a href="https://github.com/elasticsearch/logstash/issues/new">GitHub</a>)はとても貴重です！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logstash 1.5.0 Beta1リリース(日本語訳)]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/12/logstash-1-5-0-beta1-released-ja/"/>
    <updated>2014-12-12T17:17:26+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/12/logstash-1-5-0-beta1-released-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/logstash-1-5-0-beta1-released/">logstash 1.5.0.beta1 released</a></p>

<p>Logstash 1.5.0 Beta1をリリースしました。<a href="http://www.elasticsearch.org/overview/logstash/download/">こちらのページ</a>からダウンロードできます。</p>

<p><strong>Note: ベータリリースです。本番環境では使用しないでください。</strong></p>

<!-- more -->


<h2>1.5.0の主な変更点は？</h2>

<p>1.5.0の主なテーマはプラグイン管理、パフォーマンス改善、<a href="http://kafka.apache.org/">Apache Kafka</a>インテグレーションです。Logstashの主な特徴の1つは
プラグインを利用できることであり、パイプラインの動作を拡張するためにプラグインを追加するのが簡単なことです。
このリリースで、プラグインの開発、管理、公開がより簡単になります。
また、Logstashの速度をより良くしたため、より多くのデータを短時間に処理することができます。
興味ありませんか？では、詳細を見ていきましょう。</p>

<h2>plugin ecosystemの変更</h2>

<p>Logstashは165ものプラグイン(inputs、filters、outputs、codecs)を持っており、
これらはElasticsearchとコミュニティからのコントリビュートで開発されています。
多くのプラグインを管理することは、使いやすさと素早さの間のトレードオフがあります。
Logstashの全てのプラグインをまとめることは使いやすさがある一方、プラグインの更新を取り込むために
Logstashの新しいリリースを待ってもらうことになります。
Logstashからプラグインを分離して個別に配布する場合、更新は簡単になりますが、使いやすさ（特に新しいユーザに）に影響が出ます。</p>

<p>私たちは、プロジェクトを前進させるために、これらのバランスをとることを考えました。
これまで、全ての利用可能なプラグインは’core’と&#8217;contrib&#8217;の2つに分割していました。
&lsquo;core&#8217;にあるよく使われるプラグインは、Logstashに含めていました。
コミュニティによりコントリビュートされたプラグインは&#8217;contrib&#8217;パッケージとして分離して配布していました。
1.5.0のリリースで、ユーザに対してより良いプラグイン管理をできるように変更しました。
全てのプラグインは、それ自身によるパッケージに移行しました。
パッケージングフレームワークとしてrubygemsを使い、<a href="http://rubygems.org/">rubygem.org</a>経由でこれらのプラグインを配布、公開します。
また、Logstashにプラグインのインストール、更新、削除を簡単にするための構造も追加しました。</p>

<p>例えば、S3 output pluginをインストールするには、以下のコマンドを実行します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$LS_HOME/bin/plugin install logstash-output-s3</span></code></pre></td></tr></table></div></figure>


<p>それだけです！Logstashがgemと依存するgemをrubygems.orgからダウンロードし、インストールします。
あなたは、S3にデータを送ることができるようになります。</p>

<p>ダウンロード可能なLogstashリリースはプラグインをまだ多く含んでいますが、
いつでも、個別にプラグインをアップグレードし、インストールすることができます。
プラグインエコシステムの変更に関する詳細のブログ記事をお待ち下さい。</p>

<h2>パフォーマンス改善</h2>

<p>Logstash 1.5.0はより高速になっています。パフォーマンスが改善された2カ所について説明します。</p>

<h3>grok filter</h3>

<p>Grok filterはLogstashで、構造化データを抽出するためにパターンを記述するのに使われます。
本リリースで、人気のある幾つかのパターンのgrok filterのスループットを100%に改善しました。
言い換えると、grok filterを使うときに、Logstashを通してより多くのデータを処理することができます。</p>

<p>私たちのベンチマークテストで、1.5.0と1.4.2のスループットの比較をしました。
利用したデータは690万件のApache Webアクセスlogで、<code>COMBINEDAPACHELOG</code>のgrok patternです。
1.5.0で、スループットは34,000 event per sec(eps)から50,000 epsに増加しました。
両方のテストを8コアのマシンでLogstashで8つのワーカーを実行しました。
これらのテストで、一つのgrok filterを実行し、
<code>stdin</code>と<code>stdout</code>を使ったパイプラインでイベントのスループットを計測しました。
全体的なパフォーマンスは、様々なハードウェアやLogstashのコンフィグによって変化することに注意してください。</p>

<h3>json serialization / deserialization</h3>

<p>JSONのシリアライズ/でシリアライズを<a href="https://github.com/guyboertje/jrjackson">JrJackson</a>ライブラリを利用して実装しました。
これにより、100%以上のスループットの改善がありました。
先ほど説明したパフォーマンステストにおいて、1.3KBのサイズの500,00 JSONイベントを送信し、
16,000 epsから30,000 epsにスループットが改善しました。
45,000サイズのイベントで、850 epsから3500 epsにスループットが増加しました。
すばらしいです。</p>

<h2>apache kafka integration</h2>

<p>いまでは、Apache Kafkaが大規模スケールデータ処理システムでよく利用されます。
Logstashの配備のスケーリングにおいて、Kafkaもまた、shippingインスタンスとindexingインスタンス間の
データを保存するための中間メッセージバッファとして使うことができます。</p>

<p>1.5.0で、Logstash Kafkaのinputとoutputのプラグインのビルトインサポートを追加しました。
これは、<a href="https://github.com/joekiller/logstash-kafka">Joseph Lawson</a>によって最初に開発されました。
私たちは、これらのプラグインにインテグレーションテストとドキュメントを追加することにより改良し、
新しいKafkaの機能を開発し続けます。
また、<a href="http://avro.apache.org/">Apache Avro</a> codecを追加することで、Kafkaに保存されたイベントを
簡単に取得でき、ELKスタックを使ってそれらを解析できるようにしました。</p>

<p>Kafka inputを追加するのは次のコマンドです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$LS_HOME/bin/plugin install logstash-input-kafka</span></code></pre></td></tr></table></div></figure>


<p>Kafka outputは次のコマンドです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$LS_HOME/bin/plugin install logstash-output-kafka</span></code></pre></td></tr></table></div></figure>


<h2>セキュリティに関する改善</h2>

<p>認証と経路暗号化のサポートを追加し、Elasticsearchのoutput、input、filterのセキュリティを改良しました。
例えば、HTTPプロトコルでSSL/TLSにより暗号化を有効にでき、
HTTPベーシック認証をユーザ名とパスワードをリクエストに与えることで設定できます。
これらの機能は、時期にリリースされる<a href="http://www.elasticsearch.org/overview/shield/">Elasticsearch Shield</a>セキュリティプロダクトとLogstashを統合できます。</p>

<h2>ドキュメント</h2>

<p>これまで、Logstashのドキュメントは[logstash.net])(<a href="http://logstash.net/">http://logstash.net/</a>)に置いてあり、
他のELKスタックと一緒に動かす時に、情報を探すのが厄介でした。
1.5.0および、今後のバージョンのドキュメントはelasticsearch.orgの<a href="http://www.elasticsearch.org/guide/en/logstash/current/index.html">Logstash Guide</a>に移行します。
この移行で<a href="http://elasticsearch.org/guide">elasticsearch.org/guide</a>にELKスタックを利用、
学習するためにドキュメントが1つになりました。
このベータリリースのイテレーションで、私たちはプレゼンテーションとドキュメントの品質を改善することに活発に取り組んでいきます。
(過去のLogstashのドキュメントの全てはいままでの<a href="http://logstash.net/docs/1.4.2/">logstash.net</a>で引き続き公開していく予定です。)</p>

<h2>バグフィックスと改善</h2>

<p>ここまでの新しい機能に加えて、Logstash 1.5.0では、多くのバグフィックスと多くの機能改善があります。
ここで、これらのいくつかを紹介します。</p>

<ul>
<li>出力しない&#8217;metadata&#8217;をイベントに格納可能に。これは、例えば、date filterに使う中間フィールドのために必要。(<a href="https://github.com/elasticsearch/logstash/issues/1834">#1834</a>,<a href="https://logstash.jira.com/browse/LOGSTASH-1798"> #LOGSTASH-1798</a>)</li>
<li>HTTPを利用しているときのファイルデスクリプタリークの修正。Logstashがストールするのを防ぎ、OOMエラーからクラッシュするケースも防ぎます。(<a href="https://github.com/elasticsearch/logstash/issues/1604">#1604</a>)</li>
<li>Twitter input:<code>full_tweet</code>オプションの追加、Twitter rate limitingエラーのハンドリング(<a href="https://github.com/elasticsearch/logstash/issues/1471">#1471</a>)</li>
<li>イベントを生成するfilter(multiline、clone、split、metrics)により、
後続の条件文にこれらのイベントを正しく伝搬(<a href="https://github.com/elasticsearch/logstash/issues/1431">#1431</a>)</li>
<li>Elasticsearch output:Logstashはデフォルトで<code>message.raw</code>フィールドを作成しない。messageフィールドはElasticsearch
により<code>not_analyzed</code>でマルチフィールドとして追加される。マルチフィールドはディスクスペースが2倍必要だが、利点がない。</li>
<li>bin/logstashの複数のサブコマンドを除去(<a href="https://github.com/elasticsearch/logstash/issues/1797">#1797</a>)</li>
</ul>


<p>これらの機能、改善、バグフィックスについては、Logstash 1.5.0.Beta1 の<a href="https://github.com/elasticsearch/logstash/blob/master/CHANGELOG">changelog</a>をごらんください。</p>

<h2>試してみてください！</h2>

<p>ぜひ、Logstash 1.5.0 Beta 1をダウンロードして試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/logstash/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2014年のElasticsearch]]></title>
    <link href="http://blog.johtani.info/blog/2014/12/01/about-elasticsearch-in-2014/"/>
    <updated>2014-12-01T18:05:48+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/12/01/about-elasticsearch-in-2014</id>
    <content type="html"><![CDATA[<p>早いもので、師走です。今年もあと少しとなりました。ということで、Advent Calendarの季節が始まりました。</p>

<p>この記事は<a href="http://qiita.com/advent-calendar/2014/elasticsearch">Elasticsearch Advent Calndar 2014</a>の1日目のエントリです。</p>

<p>1日目ということで、簡単に今年の変遷を振り返りつつ、今年導入された新機能についてピックアップしてみようかと思います。</p>

<!-- more -->


<h2>1.0リリース(Lucene 4.6.0)</h2>

<p>今年一番の目玉と思いますが、1月にRCが公開されて、1.0.0が2月にリリースされました。
（ElasticSearch Serverの翻訳が昨年末に終わってレビューをしていた段階での発表だったので個人的にはきついタイミングでした）
1.0の主な変更点はこちら。</p>

<h3>Elasticsearch（Sが小文字に）</h3>

<p>1.0からSが小文字になりました。(<a href="https://github.com/elasticsearch/elasticsearch/issues/4634">#4634</a>)
0.90以前のバージョンについては、Sが大文字になっています。
ややこしいですが、今年の3月に出版された黒い<a href="http://www.amazon.co.jp/dp/4048662023/ref=as_sl_pc_tf_lc?tag=johtani-22&amp;camp=243&amp;creative=1615&amp;linkCode=as1&amp;creativeASIN=4048662023&amp;adid=0YAE2J8RE36SX7N3R06Z&amp;&amp;ref-refURL=http%3A%2F%2Fblog.johtani.info%2F">ElasticSearch Server日本語版</a>は原著が0.20で日本語版にするタイミングで0.90に対応しました。
このため、こちらの書籍のタイトルはSが大文字となっています。
（なお、<a href="https://www.packtpub.com/big-data-and-business-intelligence/elasticsearch-server-second-edition">原著の2nd Edition</a>は小文字になっています）</p>

<h3>Snapshot/Restoreの導入とGatewayの廃止</h3>

<p>0.90以前のバージョンでは、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/0.90/modules-gateway.html#modules-gateway">gatewayというモジュール</a>で、S3などにインデックスのメタデータなどを保存する機能がありました。
この機能は、0.20からlocal以外はdeprecatedとなりました。</p>

<p>インデックスのバックアップ、リストアのために、1.0で実装されたのが<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-snapshots.html#modules-snapshots">Snapshot/Restore</a>です。
Snapshot/Restoreでは、インデックスごと、もしくはクラスタ全体をリモートにあるリポジトリにスナップショットを取ることが可能となりました。
初期リリースの段階では、共有ファイルシステムのみでしたが、現在は、S3やHDFSなどに保存が可能となっています。</p>

<h3>Aggregation</h3>

<p>Facetをより強力にしたものです。Facetでは、指定したフィールドの集計のみでした。
データの解析などを行うには、独自で集計する必要がありました。
この機能をより柔軟に行えるように実装したのが<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations.html">Aggregation</a>です。</p>

<p>たとえば、アクセスログを日毎に集計し、さらに日毎の集計に対して国別の集計やユーザエージェントごとの集計をさらに行うといった感じです。
Facetの場合は、日毎の検索結果に対して個別に集計するのみでしたが、Aggregationを使うことで、1週間の検索結果に対して、
日毎に国別の集計を行うといったことが可能になっっています。</p>

<h3>cat API</h3>

<p>&ldquo;=^.^=&#8221;猫が出てくるAPIです。(違う)</p>

<p>Elasticsearchでは、クラスタの状態などが全てREST APIで取得でき、JSONで結果が帰ってきていました。
JSONはプログラムなどで処理を行う場合は便利ですが、コンソールで確認したり、管理系のツールでメールで通知する場合などは見にくいことがあります。
これを解消したのが<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/cat.html"><code>_cat</code> API</a>です。（<a href="http://www.elasticsearch.org/blog/introducing-cat-api/">公式の紹介ブログはこちら</a>）</p>

<h3>Circuit Breaker</h3>

<p>OOMが発生しそうなfielddataの読み込みを検知して、事前に防ぐ機構になります。
初期段階ではFielddataに対してのものから実装されました。</p>

<h2>1.1リリース(Lucene 4.6.1)</h2>

<p>3月にリリースされました。Elasticsearchはまだまだ発展しているため、リリースのサイクルが短いのが特徴です。</p>

<p>1.x系では、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-upgrade.html#setup-upgrade">Rolling Upgrade</a>が導入されました。このため、クラスタ全体を停止することなく、クラスタのアップグレードが可能になりました。</p>

<h3>search templates</h3>

<p>検索クエリをテンプレートとして登録することができる<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-template.html#search-template">search templates</a>です。
JSONでクエリを記述できるのは便利ですが、毎回組み立てるのは大変かもしれません。
特に、固定のクエリをプログラムから利用するような場合などです。
テンプレートとして登録しておくことで、検索時に値を埋め込むだけで検索ができるようになりました。</p>

<h3>Aggregationの強化</h3>

<p>Aggregationの種類が増えました。</p>

<ul>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-metrics-cardinality-aggregation.html#search-aggregations-metrics-cardinality-aggregation">cardinality</a>：ユニークユーザ数の集計などが行えるaggregationです。HyperLogLog++アルゴリズムを利用した実装になっています。</li>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-bucket-significantterms-aggregation.html">significant_terms</a>：単語の数による集計ではなく、コレクション全体に対する単語の頻度と、検索結果に対する単語の頻度を計算することで、重要度を計ることができます。</li>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-metrics-percentile-aggregation.html#search-aggregations-metrics-percentile-aggregation">percentiles</a>：パーセンタイル値を計算できます。</li>
</ul>


<h2>1.2リリース(Lucene 4.8系)</h2>

<h3>Java 7必須</h3>

<p>利用しているLuceneがJava 7必須となったためです。また、Java 6のEOLも切れてますし。</p>

<h3>dynamic scriptingがデフォルトオフ</h3>

<p>採用していたMVELがサンドボックス化に対応していないため、危険を回避するためにオフとなりました。</p>

<h3>インデキシングとマージング</h3>

<p>インデキシングとマージ処理に関するさまざまな改善。</p>

<ul>
<li>flushのthreasholdを操作回数ではなく、サイズや時間によるものに変更</li>
<li>デフォルトをConcurrentMergeSchedulerに変更</li>
</ul>


<h2>1.3リリース(Lucene 4.9.0系)</h2>

<h3>セキュリティ関連</h3>

<ul>
<li>JSONPのデフォルトオフ</li>
<li>MVELの非推奨化（1.4で削除）＋<code>script.disable_dynamic</code>のデフォルト値が<code>sandbox</code></li>
</ul>


<h3>aggregationの強化</h3>

<ul>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-metrics-top-hits-aggregation.html#search-aggregations-metrics-top-hits-aggregation">top hits</a>：Field Collapsing/combiningと呼ばれる機能です。たとえば、いくつかのサイトのHTMLを収集して検索機能を提供する場合に、ドメインごとに1件ずつ検索結果に出したい場合などに利用できる機能です。</li>
</ul>


<p>その他にも以下のaggregationが追加されています。
* <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-metrics-percentile-rank-aggregation.html">percentile ranks</a>
* <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-aggregations-metrics-geobounds-aggregation.html">geo bounds</a></p>

<h3>mappingのtransform</h3>

<p>Mappingに<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-transform.html#mapping-transform">transform</a>機能が追加されました。
mappingにドキュメントの値を元に、インデキシング時に変換処理を記述できます。
たとえば、特定のフィールドにある値がある場合にだけ、あるフィールドに値を入れるなどといったことが可能になります。</p>

<h3>ディスク関連</h3>

<ul>
<li>disk based shard allocation deciderが導入されました。ノードのディスクの使用率を元に、シャードを配置しても良いかといった決定を行う機構です。</li>
<li>チェックサムによるファイルのチェック（Lucene4.9で導入されたコードへの切り替え）</li>
</ul>


<h2>1.4リリース(Lucene 4.10系)</h2>

<p>ベータ版が出されるほど、多くの改善が入っています。</p>

<h3>resiliency</h3>

<ul>
<li><a href="#memory-mgmt">メモリ使用量の低下</a>によるノードの安定性向上

<ul>
<li>DocValues、リクエストごとのcircuit breakerなど</li>
</ul>
</li>
<li>discoveryアルゴリズムの改善による<a href="#cluster-stability">クラスタの安定性</a>向上</li>
<li><a href="#checksums">チェックサム</a>の導入による破損したデータの検知</li>
</ul>


<h3>セキュリティ関連</h3>

<ul>
<li>CORSをデフォルト無効</li>
<li>Groovyがデフォルトのスクリプト言語に。</li>
</ul>


<h3>Aggregationの強化</h3>

<p>以下のaggregationが追加されています。
* <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-filters-aggregation.html#search-aggregations-bucket-filters-aggregation">filter</a>、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-children-aggregation.html#search-aggregations-bucket-children-aggregation">children</a>、<a href="%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88">scripted_metric</a></p>

<h3>Upgrade API</h3>

<p>インデックスを最新のバージョンのものにアップグレードするためのAPIです。
Luceneは下位互換を保ってくれているため、古いバージョンのインデックスも読み込むことが可能です。
ただ、最新バージョンで使える機能が制限されていたりということもあります。
クラスタにあるインデックスをアップグレードするのにかかる時間や必要かどうかといったことを取得できる仕組みも提供します。</p>

<p>また、Lucene自体は、1つ前のメジャーバージョン（4.x系だと3.x系まで）までの互換性は提供していますが、
2つ前のメジャーバージョンの互換性がなくなります。
Luceneも5.x系のブランチが作成されており、5系のリリースにより、3系との互換性がなくなります。
5系のリリースに対応する場合にも、こちらのAPIが助けになるかと。</p>

<h3>1.4.1</h3>

<p>11/27に<a href="http://blog.johtani.info/blog/2014/11/27/elasticsearch-1-4-1-released-ja/">1.4.1がリリース</a>されました。
シャードの配置やparent/child、nestedドキュメントの改善などが行われています。</p>

<h2>まとめ</h2>

<p>ということで、駆け足で、1月から11月までのElasticsearchの流れを追ってみました。
1.0で大きな機能追加、改善が行われ、その後も活発に開発が行われています。
要望などがあれば、MLで聞いてみたりやGitHubに登録するなどを行っていただければと。</p>

<p>あと、今年から来年にかけての大きなイベントとして、
<a href="http://www.elasticon.com/">Elasticsearch初のユーザカンファレンスのサイトがオープン</a>しました。
Elasticsearchに関するいろいろな話が聞ける機会だと思うので、興味のある方は見ていただければと。</p>

<p>では、また次のAdvent Calendarで！（最終日の予定ですが、空きがあるのでなにか書くかも）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 1.4.1および1.3.6リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/27/elasticsearch-1-4-1-released-ja/"/>
    <updated>2014-11-27T11:43:32+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/27/elasticsearch-1-4-1-released-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-1-released/">elasticsearch 1.4.1 and 1.3.6 released</a></p>

<p>本日、<strong>Lucene 4.10.2</strong>をベースにした<strong>Elasticsearch 1.4.1</strong>と、バグフィックスリリースである、<strong>Elasticsearch 1.3.6</strong>をリリースしました。
ダウンロードおよび変更リストはそれぞれ次のリンクからアクセスできます。</p>

<ul>
<li>最新ステーブルリリース：<a href="http://www.elasticsearch.org/downloads/1-4-1">Elasticsearch 1.4.1</a></li>
<li>1.3.x系バグフィックス：<a href="http://www.elasticsearch.org/downloads/1-3-6">Elasticsearch 1.3.6</a></li>
</ul>


<p>過去のリリースに関するブログ（公式）はこちら。</p>

<ul>
<li>1.4:<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-released/">1.4.0</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-beta-released/">1.4.0.Beta1</a></li>
<li>1.3:<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-released/">1.3.5</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-4-released/">1.3.4</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-3-released/">1.3.3</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-2-released/">1.3.2</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-1-released/">1.3.1</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-0-released/">1.3.0</a>.</li>
</ul>


<p>すべての変更については<a href="http://www.elasticsearch.org/downloads/1-4-1">1.4.1のリリースノート</a>および<a href="http://www.elasticsearch.org/downloads/1-3-6">1.3.6のリリースノート</a>をごらんください。
以下では、重要な変更について紹介します。</p>

<!-- more -->


<h2>shard allocation</h2>

<p>Elasticsearch 1.3.0で、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-allocation.html#disk">disk based shard allocation</a>が
デフォルトで有効になっています。
もし、ノードのディスクの使用量が<code>law</code>で指定された値（85%）を超えた場合、ノードにはシャードが配置されません。
また、<code>high</code>で指定された値（90%）を超えた場合、シャードを他のノードへ移動します。</p>

<p>Elasticsearch 1.4.1では、disk based shard allocationに3つの改良が追加されました。</p>

<ul>
<li>ディスク使用量のチェックはシャードがクラスタに配置されるタイミングでのみ実施していた。現在は60秒ごとに使用量をチェック。(<a href="https://github.com/elasticsearch/elasticsearch/pull/8270">#8270</a>)</li>
<li>ディスクフルメッセージは<code>DEBUG</code>レベルでログに出力されていました。なぜ、新しいシャードが配置されないのかを説明するのが困難でした。現在は<code>WARN</code>レベルで30秒ごとにログに出力されます。(<a href="https://github.com/elasticsearch/elasticsearch/pull/8382">#8382</a>)</li>
<li>以前は、シャードをもう一つのノードへ動かすべきかどうか決めるとき、allocation deciderはノードにあるシャードのサイズを考慮するだけでした。現在は、動かされるシャードのサイズも考慮します。これにより、必要最小限のシャードの移動量となります。(<a href="https://github.com/elasticsearch/elasticsearch/pull/8569">#8569</a>)</li>
</ul>


<h2>parent/child and nested documents</h2>

<p>Elasticsearch 1.4.0で、parent/childとnestedドキュメントに対して（新しいセグメントを開くときに）固定長ビットセットフィルタを構築しキャッシュしました。クエリ、フィルタおよびAggregationを常に速くするためにです。
多くの<code>nested</code>フィールドを持つユーザにとっては、以前のバージョンよりもヒープの使用量が大きくなってしまいました。</p>

<p><code>nested</code> aggregationによって処理されるドキュメントの順序を変更すること(<a href="https://github.com/elasticsearch/elasticsearch/pull/8454">#8454</a>)によって、固定長ビットセットフィルタが子のドキュメントに対して必要でなくなりました。
現在は、親のドキュメント（つまり、nested<strong>ではない</strong>ドキュメント）を表すフィルタのみをキャッシュしています。これにより必要なキャッシュ空間のサイズを減少しました。(<a href="https://github.com/elasticsearch/elasticsearch/pull/8414">#8414</a>、<a href="https://github.com/elasticsearch/elasticsearch/pull/8440">#8440</a>)</p>

<h2>date ranges</h2>

<p>2つの日付範囲に関する問題がこのリリースで修正されました。
1つ目は、日付を丸めるかというものです。例えば、<code>timestamp</code>フィールドに1秒の解像度の値があるとします。
<code>{"lt": "2014/11/26||/d"}</code>という<code>range</code>フィルタは<code>2014/11/26 00:00:00</code>未満のタイムスタンプのデータを結果として返しました。
しかし、<code>lt</code>を<code>lte</code>に変更した場合、<code>2014/11/27 00:00:00</code>以外の値も含めたいです。</p>

<p>以前は、<code>lte</code>は<code>2014/11/27 00:00:00</code>のタイムスタンプも含めてしまっていました。現在は、想定通りの動作をします。(<a href="https://github.com/elasticsearch/elasticsearch/pull/8556">#8556</a>)</p>

<p>2つ目のバグは日付の範囲条件に<code>now()</code>を利用したaliasとpercolatorフィルタです。
<code>now()</code>の値を、フィルタが作成したタイミングで決定していました。フィルタが実行されるたびに更新せずにです。
<a href="https://github.com/elasticsearch/elasticsearch/pull/8534">#8534</a>で、<code>now()</code>はaliasとpercolatorで想定通りの動作をします。</p>

<h2>試してみてください。</h2>

<p>ぜひ、<a href="http://www.elasticsearch.org/downloads/1-4-1">Elasticsearch 1.4.1</a>をダウンロードして、試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/elasticsearch/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[インデックステンプレートとLogstash]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/25/import-apache-accesslog-using-logstash-2/"/>
    <updated>2014-11-25T16:25:46+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/25/import-apache-accesslog-using-logstash-2</id>
    <content type="html"><![CDATA[<p>前回の「<a href="http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash/">Logstashを利用したApacheアクセスログのインポート</a>」の続きです。
前回の記事では、Logstashの設定ファイルについて説明しました。
今回は「Elasticsearchに設定するインデックステンプレート」について説明します。</p>

<!-- more -->


<h2>テンプレートの設定</h2>

<p>Elasticsearchでは、登録するデータの特性に合わせてMappingを定義する方がデータを効率良く扱うことができる場合があります。
この場合、通常ですと、インデックス作成時にMappingを指定します。</p>

<p>ただ、今回は、<a href="http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash#output-elasticsearch">インデックス名に「年」を含める形</a>で指定してあります。
「年」はLogstashで処理したデータによって決まります。このため、あらかじめMappingを指定してインデックスを作成するのは難しいです。</p>

<p>このような場合に便利な機能として、「<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-templates.html#indices-templates">インデックステンプレート</a>」があります。</p>

<h3>インデックステンプレートとは</h3>

<p>実際のテンプレートの説明に入る前に、少しだけ説明を。
インデックステンプレートとは、インデックスが作成されるタイミングで自動的に適用される設定をテンプレートとして登録できる機能のことです。
実際にテンプレートが適用されるかどうかは、インデックス名で判断されます。</p>

<p>例えば、大して重要でもなく、データ量も少ないインデックス用のテンプレートとして、シャード数が1、レプリカ数が0、&#8221;_source&#8221;を保存しない設定のテンプレートを登録する場合、
次のようになります。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">curl -XPUT localhost:9200/_template/template_1 -d &#39;</span>
</span><span class='line'><span class="l-Scalar-Plain">{</span>
</span><span class='line'>  <span class="l-Scalar-Plain">&quot;template&quot;</span> <span class="p-Indicator">:</span> <span class="s">&quot;te*&quot;</span><span class="err">,</span>
</span><span class='line'>  <span class="s">&quot;settings&quot;</span> <span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;number_of_shards&quot;</span> <span class="p-Indicator">:</span> <span class="nv">1</span><span class="p-Indicator">,</span>
</span><span class='line'>    <span class="s">&quot;number_of_replicas&quot;</span> <span class="p-Indicator">:</span> <span class="nv">0</span>
</span><span class='line'>  <span class="p-Indicator">}</span><span class="err">,</span>
</span><span class='line'>  <span class="s">&quot;mappings&quot;</span> <span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;type1&quot;</span> <span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;_source&quot;</span> <span class="p-Indicator">:</span> <span class="p-Indicator">{</span> <span class="s">&quot;enabled&quot;</span> <span class="p-Indicator">:</span> <span class="nv">false</span> <span class="p-Indicator">}</span>
</span><span class='line'>    <span class="p-Indicator">}</span>
</span><span class='line'>  <span class="p-Indicator">}</span>
</span><span class='line'><span class="err">}</span>
</span><span class='line'><span class="s">&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>_template</code>がインデックステンプレートを登録するためのエンドポイントです。
<code>template_1</code>がこのテンプレートのIDです。削除などについては、このIDを利用します。</p>

<p>そして、重要なのは、&#8221;<code>template</code>&ldquo;の設定です。
&rdquo;<code>template</code>&ldquo;には、このテンプレートが適用されるべきインデックス名を記載します。
上記サンプルでは<code>te*</code>となっているため、<code>te</code>で始まる名前のインデックスを作成した場合にテンプレートにある設定が適用されます。</p>

<h3>今回利用するテンプレート</h3>

<p>私がJJUG CCCや第7回Elasticsearch勉強会のKibana4のデモで利用したインデックスのテンプレートは次のものになります。
&ldquo;<code>template</code>&#8220;には、<a href="http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash/#output-elasticsearch">前回の記事で紹介したoutput/elasticsearchの設定</a> に合致する<code>new_demo_access_log-*</code>を指定しています。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">curl -XPUT localhost:9200/_template/new_access_log_for_demo -d &#39;</span>
</span><span class='line'><span class="l-Scalar-Plain">{</span>
</span><span class='line'>  <span class="l-Scalar-Plain">&quot;template&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;new_demo_access_log-*&quot;</span><span class="err">,</span>
</span><span class='line'>  <span class="s">&quot;settings&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;number_of_shards&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;2&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>    <span class="s">&quot;number_of_replicas&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;0&quot;</span>
</span><span class='line'>  <span class="p-Indicator">}</span><span class="err">,</span>
</span><span class='line'>  <span class="s">&quot;mappings&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;_default_&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;dynamic_templates&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">[</span>
</span><span class='line'>        <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;string_template&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>            <span class="s">&quot;mapping&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">},</span>
</span><span class='line'>            <span class="s">&quot;match_mapping_type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>            <span class="s">&quot;match&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;*&quot;</span>
</span><span class='line'>          <span class="p-Indicator">}</span>
</span><span class='line'>        <span class="p-Indicator">}</span>
</span><span class='line'>      <span class="p-Indicator">],</span>
</span><span class='line'>      <span class="s">&quot;properties&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>        <span class="s">&quot;path&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;multi_field&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>          <span class="s">&quot;fields&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>            <span class="s">&quot;no_analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">},</span>
</span><span class='line'>            <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">}</span>
</span><span class='line'>          <span class="p-Indicator">}</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;referer&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;multi_field&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>          <span class="s">&quot;fields&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>            <span class="s">&quot;no_analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">},</span>
</span><span class='line'>            <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">}</span>
</span><span class='line'>          <span class="p-Indicator">}</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;agent&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;multi_field&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>          <span class="s">&quot;fields&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>            <span class="s">&quot;no_analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">},</span>
</span><span class='line'>            <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>            <span class="p-Indicator">}</span>
</span><span class='line'>          <span class="p-Indicator">}</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;geoip&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;object&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>          <span class="s">&quot;properties&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>            <span class="s">&quot;location&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>              <span class="s">&quot;geohash&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;geohash_precision&quot;</span><span class="p-Indicator">:</span> <span class="nv">10</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;geo_point&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;lat_lon&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span><span class="p-Indicator">,</span>
</span><span class='line'>              <span class="s">&quot;geohash_prefix&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span>
</span><span class='line'>            <span class="p-Indicator">}</span>
</span><span class='line'>          <span class="p-Indicator">}</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;response&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;copy_to&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;response_int&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;bytes&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;long&quot;</span>
</span><span class='line'>        <span class="p-Indicator">},</span>
</span><span class='line'>        <span class="s">&quot;response_int&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>          <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;integer&quot;</span>
</span><span class='line'>        <span class="p-Indicator">}</span>
</span><span class='line'>      <span class="p-Indicator">}</span>
</span><span class='line'>    <span class="p-Indicator">}</span>
</span><span class='line'>  <span class="p-Indicator">}</span>
</span><span class='line'><span class="err">}</span>
</span><span class='line'><span class="s">&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<h4>settings設定</h4>

<p>デモ用であり、手元で2台のノードを起動するということもあり、<code>number_of_shards</code>に<code>2</code>を、<code>number_of_replicas</code>に<code>0</code>を指定してあります。</p>

<h4>mappings設定</h4>

<h5>インデックスのタイプ</h5>

<p>Mappingsの指定は通常、特定の<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/glossary.html#glossary-type">タイプ</a>を指定します。
今回のデモでは、1種類しかないのですが、タイプ名を特に意識しないために、<code>_default_</code>を使用しました。
この場合、任意のタイプに適用されることとなります。
タイプを指定してMappingの設定を行う場合は<code>_default_</code>の部分に特定のタイプ名を記入します。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="s">&quot;mappings&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;_default_&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="nv">...</span>
</span></code></pre></td></tr></table></div></figure>


<h5>ダイナミックテンプレート</h5>

<p>次は<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-root-object-type.html#_dynamic_templates">ダイナミックテンプレート</a>です。
インデックステンプレートはインデックスの設定をテンプレート化しました。ダイナミックテンプレートはフィールドに対してテンプレートを設定できます。</p>

<p>以下のダイナミックテンプレートでは、<code>string</code>タイプのフィールドのデフォルト設定を変更しています。
通常、<code>string</code>タイプのフィールドは<code>analyzed</code>となりますが、<code>not_analyzed</code>に変更してあります。
詳しく検索したいフィールドの方が少ないためです。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="nn">...</span>
</span><span class='line'><span class="s">&quot;dynamic_templates&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">[</span>
</span><span class='line'>  <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;string_template&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;mapping&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>        <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>        <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>      <span class="p-Indicator">},</span>
</span><span class='line'>      <span class="s">&quot;match_mapping_type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;match&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;*&quot;</span>
</span><span class='line'>    <span class="p-Indicator">}</span>
</span><span class='line'>  <span class="p-Indicator">}</span>
</span><span class='line'><span class="p-Indicator">]</span><span class="err">,</span>
</span><span class='line'><span class="nn">...</span>
</span></code></pre></td></tr></table></div></figure>


<h5>multi_field指定</h5>

<p>検索もしたいし、Terms Aggregationでも利用したいフィールドについては、<code>multi_field</code>を利用して、
<code>analyzed</code>と<code>not_analyzed</code>の2種類のフィールドを用意しています。
<code>multi_field</code>設定を用いることで、1つのJSONのデータから、異なる形のフィールドを用意することが可能です。</p>

<p>今回のテンプレートでは、<code>path</code>、<code>referer</code>、<code>agent</code>に<code>multi_field</code>を指定しました。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="nn">...</span>
</span><span class='line'><span class="s">&quot;path&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;multi_field&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>  <span class="s">&quot;fields&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;no_analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;not_analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>    <span class="p-Indicator">},</span>
</span><span class='line'>    <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;index&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;analyzed&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'>    <span class="p-Indicator">}</span>
</span><span class='line'>  <span class="p-Indicator">}</span>
</span><span class='line'><span class="p-Indicator">}</span><span class="err">,</span>
</span><span class='line'><span class="nn">...</span>
</span></code></pre></td></tr></table></div></figure>


<p>例えば、上記の設定の場合、入力のJSONは<code>path</code>というデータのみですが、インデックス上には<code>path.no_analyzed</code>と
<code>path.analyzed</code>というフィールドができあがります。
実際に検索する場合は、<code>path.analyzed:検索したい文字列</code>という形で検索をすることで、いわゆる部分一致のような検索が可能です。
また、完全一致をしたい場合は<code>path.no_analyzed:検索したい文字列</code>という指定になります。
用途を考えると、<code>request</code>も指定したほうが良いかもしれません。</p>

<h5>geoip</h5>

<p><a href="http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash#filter-geoip">Logstashでgeoipデータ</a>を付与していました。
このgeoipのデータをKibana4で利用するために、geoデータとして登録する必要があります。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="s">&quot;geoip&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;object&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>  <span class="s">&quot;properties&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>    <span class="s">&quot;location&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>      <span class="s">&quot;geohash&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;geohash_precision&quot;</span><span class="p-Indicator">:</span> <span class="nv">10</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;geo_point&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;lat_lon&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span><span class="p-Indicator">,</span>
</span><span class='line'>      <span class="s">&quot;geohash_prefix&quot;</span><span class="p-Indicator">:</span> <span class="nv">true</span>
</span><span class='line'>    <span class="p-Indicator">}</span>
</span><span class='line'>  <span class="p-Indicator">}</span>
</span><span class='line'><span class="p-Indicator">}</span><span class="err">,</span>
</span></code></pre></td></tr></table></div></figure>


<p>上記の設定がgeoデータの指定です。
<code>type</code>に<code>object</code>が指定してありますが、これは、geoipのデータがネストしているためです。
geoipオブジェクトのうち、緯度経度のデータは<code>location</code>に入っているため、こちらに緯度経度関係の設定を指定します。</p>

<ul>
<li><code>"type": "geo_point"</code>：<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-geo-point-type.html#mapping-geo-point-type"><code>geo_point</code></a>タイプであることを指定</li>
<li><code>"geohash": true</code>：緯度経度のデータをもとに、geohashの値もインデックス</li>
<li><code>"geohash_precision": 10</code>：geohashの精度の指定</li>
<li><code>"lat_lon": true</code>：緯度経度を個別の<code>.lat</code>、<code>.lon</code>というフィールドにもインデックス</li>
<li><code>"geohash_prefix": true</code>：該当するgeohashのみでなく、その親にあたるgeohashについてもインデックスする</li>
</ul>


<h5>response、response_int、bytes</h5>

<p>最後は、response、response_int、bytesです。</p>

<p>responseには、HTTPステータスコードが入ります。
文字列としても扱いたいですが、integerとして、Renge Aggregationなどを行いたいので、
response_intというフィールドにも値を入れています。
<code>multi_field</code>でも可能ですが、ここでは、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-core-types.html#copy-to"><code>copy_to</code></a>を利用しました。
<code>copy_to</code>を用いることで、異なるフィールドに値をコピーすることができます。</p>

<p>bytesについては、longで扱いたいとういう理由だけです。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="s">&quot;response&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;copy_to&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;response_int&quot;</span><span class="p-Indicator">,</span>
</span><span class='line'>  <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;string&quot;</span>
</span><span class='line'><span class="p-Indicator">}</span><span class="err">,</span>
</span><span class='line'><span class="s">&quot;bytes&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;long&quot;</span>
</span><span class='line'><span class="p-Indicator">}</span><span class="err">,</span>
</span><span class='line'><span class="s">&quot;response_int&quot;</span><span class="p-Indicator">:</span> <span class="p-Indicator">{</span>
</span><span class='line'>  <span class="s">&quot;type&quot;</span><span class="p-Indicator">:</span> <span class="s">&quot;integer&quot;</span>
</span><span class='line'><span class="p-Indicator">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>まとめ</h2>

<p>今回はデモに利用したインデックスてプレートについて説明しました。
前回の、Logstashの設定とこのインデックステンプレートを用いることで、Kibanaで解析するデータの準備ができます。
実際の操作などについては、また次回の記事で説明しようかと思います。</p>

<p>不明な点、誤植などありましたら、コメント欄へお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logstashを利用したApacheアクセスログのインポート]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash/"/>
    <updated>2014-11-21T17:30:39+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/21/import-apache-accesslog-using-logstash</id>
    <content type="html"><![CDATA[<p>JJUG CCCや第7回Elasticsearch勉強会のKibana4のデモにアクセスログを利用しました。</p>

<p>ただ、セッションでは、どうやってElasticsearchに投入したのかという詳しい話をしていませんでした。
本記事では、データ取り込み時に利用したLogstashの設定ファイルについて説明します。</p>

<!-- more -->


<p>Logstashの設定の説明に入る前に、全体の流れを。
「ApacheアクセスログをKibana4により可視化」です。</p>

<h2>材料の準備</h2>

<p>「ApacheアクセスログをKibana4により可視化」に必要な材料は次の通りです。
（今回は起動するところまでいかないので、実際に必要なのは次回以降になります。）</p>

<ul>
<li>Java 7（u55以上を1つ）</li>
<li>Logstash 1.4.2（1つ）</li>
<li>Elasticsearch 1.4.0（1つ）</li>
<li>Kibana4 Beta2（1つ）</li>
<li>Apacheのアクセスログ（適量）</li>
</ul>


<p>Apacheのアクセスログ以外は、公式サイトからダウンロードできます。
それぞれをダウンロードして、起動できるようにしておきましょう。</p>

<p>※1台のマシン上で行う場合は、アクセスログの量を少なめにするなどの対策をとりましょう。
※今回は、1台のマシン（Mac）上で、VMなどを利用せず、それぞれ直接起動するものとします。</p>

<h2>可視化の手順と流れ</h2>

<p>可視化の流れとしては、</p>

<ol>
<li>Logstashでファイルを読み込み、各種処理（パースしたり、情報を追加したり、切り出したり）</li>
<li>Elasticsearchに保存</li>
<li>Kibanaでグラフを作ったり、検索してみたり</li>
</ol>


<p>です。</p>

<p>今回は、1のLogstashでファイルを読み込んだりする設定ファイルの説明です。</p>

<h3>Logstashの設定</h3>

<h4>Logstashの基本</h4>

<p>まずは、Logstashの設定ですが、簡単にLogstashの説明を。
Logstashは大きく3つのパーツに分かれています。</p>

<ol>
<li>input：データの入力処理</li>
<li>filter：inputで読み込んだデータに対する操作など</li>
<li>output：データの出力処理</li>
</ol>


<p>inputでデータを読み込み（複数可）、filterでデータに対して各種処理を行い、outputでデータを指定されたところに出力（複数可）します。</p>

<h4>アクセスログの読み込み設定</h4>

<p>アクセスログの読み込み処理は大まかに次のようなものとなります。</p>

<ol>
<li>アクセスログを読み込む（input/file）</li>
<li>読み取ったアクセスログを各フィールド（IPアドレス、ユーザエージェントなど）に分割（filter/grok）</li>
<li>日付のパース（filter/date）</li>
<li>クライアントIPアドレスにgeoipの情報を付加（filter/geoip）</li>
<li>リクエストのパスの第1階層の抽出（filter/grok）</li>
<li>ユーザエージェントのパース（filter/useragent）</li>
<li>Elasticsearchへの出力（output/elasticsearch）</li>
</ol>


<p>設定ファイルは次のようなものになります。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">input</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">file</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">path</span> <span class="o">=&gt;</span> <span class="s2">&quot;/Users/johtani/demo_access_log/*/*.log&quot;</span>
</span><span class='line'>    <span class="n">start_position</span> <span class="o">=&gt;</span> <span class="s2">&quot;beginning&quot;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">filter</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">grok</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">match</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="s2">&quot;message&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;%{COMBINEDAPACHELOG}&quot;</span> <span class="p">}</span>
</span><span class='line'>    <span class="n">break_on_match</span> <span class="o">=&gt;</span> <span class="kp">false</span>
</span><span class='line'>    <span class="n">tag_on_failure</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;_message_parse_failure&quot;</span><span class="o">]</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="n">date</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">match</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;timestamp&quot;</span><span class="p">,</span> <span class="s2">&quot;dd/MMM/YYYY:HH:mm:ss Z&quot;</span><span class="o">]</span>
</span><span class='line'>    <span class="n">locale</span> <span class="o">=&gt;</span> <span class="n">en</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="n">geoip</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">source</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;clientip&quot;</span><span class="o">]</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="n">grok</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">match</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="s2">&quot;request&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;^/%{WORD:first_path}/%{GREEDYDATA}$&quot;</span> <span class="p">}</span>
</span><span class='line'>    <span class="n">tag_on_failure</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;_request_parse_failure&quot;</span><span class="o">]</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="n">useragent</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;agent&quot;</span>
</span><span class='line'>    <span class="n">target</span> <span class="o">=&gt;</span> <span class="s2">&quot;useragent&quot;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">output</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">elasticsearch</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">host</span> <span class="o">=&gt;</span> <span class="s2">&quot;localhost&quot;</span>
</span><span class='line'>    <span class="n">index</span> <span class="o">=&gt;</span> <span class="s2">&quot;new_demo_access_log-%{year}&quot;</span>
</span><span class='line'>    <span class="n">cluster</span> <span class="o">=&gt;</span> <span class="s2">&quot;demo_cluster&quot;</span>
</span><span class='line'>    <span class="n">protocol</span> <span class="o">=&gt;</span> <span class="s2">&quot;http&quot;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h5>1. アクセスログを読み込む（input/file）</h5>

<p>inputの<a href="http://logstash.net/docs/1.4.2/inputs/file">fileモジュール(a)</a>を使用してアクセスログのファイルを読み込みます。
<code>path</code>でアクセスログのファイルのパスを指定します。
今回利用したアクセスログは<code>demo_access_log/2010/access20100201.log</code>といった日毎のファイルに分割されていたため、
<code>*</code>を利用してファイルのパスを指定しました。
また、今回は既存のファイルの読み込みだけのため、<code>start_position</code>に<code>beginning</code>を指定してあります。
デフォルトでは<code>end</code>が指定されるため、Logstashを起動後に追記されたログから対象になってしまうためです。
その他の設定については、公式ガイドをご覧ください。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">input</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">file</span> <span class="p">{</span> <span class="c1"># a</span>
</span><span class='line'>    <span class="n">path</span> <span class="o">=&gt;</span> <span class="s2">&quot;/Users/johtani/demo_access_log/*/*.log&quot;</span> <span class="c1"># b</span>
</span><span class='line'>    <span class="n">start_position</span> <span class="o">=&gt;</span> <span class="s2">&quot;beginning&quot;</span> <span class="c1"># c</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<blockquote><p>Logstashでは、ファイルをどこまで読み込んだかという情報を保持するために、<a href="http://logstash.net/docs/1.4.2/inputs/file#sincedb_path">sincedb</a>を利用しています。
設定変更後に同じファイルを最初から読み込みたい場合などは、こちらのファイルを一旦削除するなどの対応が必要です。</p></blockquote>

<p>ちなみに、読み込んだデータは次のようなJSONになっています。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;message&quot;</span><span class="p">:</span> <span class="s2">&quot;読み込んだアクセスログ&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;@version&quot;</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;@timestamp&quot;</span><span class="p">:</span><span class="s2">&quot;2014-11-21T06:16:21.644Z&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;host&quot;</span><span class="p">:</span><span class="s2">&quot;jupiter.local&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="s2">&quot;/Users/johtani/demo_access_log/2010/access20100201.log&quot;</span><span class="p">}</span>
</span><span class='line'><span class="err">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>特に指定がない場合は、<code>message</code>に読み込んだデータが入ってきます。
<code>@timestamp</code>がLogstashが読み込んだ時刻、<code>host</code>はLogstashが動作しているホスト名です。
<code>path</code>はfileモジュールが読み込んだファイルのパスを設定しています。
この後の処理で、どこの項目に対して処理を行うかといったことが重要になるので、</p>

<h5>2. 読み取ったアクセスログを各フィールド（IPアドレス、ユーザエージェントなど）に分割（filter/grok）</h5>

<p>2.〜6.の処理は、inputで読み込んだ1アクセスログに対する処理となります。</p>

<p>ここでは、<a href="http://logstash.net/docs/1.4.2/filters/grok">grokフィルタ</a>を使用して
Apacheのアクセスログを各フィールドに分割します。
Logastashでは、簡単に使えるようにいくつかの<a href="https://github.com/elasticsearch/logstash/tree/v1.4.2/patterns">パターン</a>が用意されています。
Apacheのログのために、<a href="https://github.com/elasticsearch/logstash/blob/v1.4.2/patterns/grok-patterns#L91"><code>COMBINEDAPACHELOG</code></a>というのが用意されています。
今回はこちらを使用しています。その他にも日付などパターンが用意されているので、試してみてください。</p>

<p><code>message</code>にアクセスログが入っているので、こちらの項目に対して<code>COMBINEDAPACHELOG</code>のパターンを
<code>match</code>で適用してフィールドに抜き出します。
<code>tag_on_failure</code>は、<code>match</code>でパースに失敗した場合に、<code>tag</code>というフィールドに指定した文字列を出力する機能になります。
デフォルトだと<code>_grokparsefailure</code>が付与されますが、ここでは、どの処理で失敗したがを判別するために文字列を変更しています。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">filter</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">grok</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">match</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="s2">&quot;message&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;%{COMBINEDAPACHELOG}&quot;</span> <span class="p">}</span>
</span><span class='line'>    <span class="n">break_on_match</span> <span class="o">=&gt;</span> <span class="kp">false</span>
</span><span class='line'>    <span class="n">tag_on_failure</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;_message_parse_failure&quot;</span><span class="o">]</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="o">.</span><span class="n">.</span><span class="o">.</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>clientip</code>、<code>ident</code>、<code>auth</code>、<code>timestamp</code>、<code>verb</code>、<code>request</code>、<code>httpversion</code>、<code>response</code>、<code>bytes</code>、<code>referrer</code>、<code>agent</code>がgrokフィルタにより抜き出された項目です。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="s2">&quot;アクセスログ&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;@version&quot;</span><span class="p">:</span><span class="s2">&quot;1&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;@timestamp&quot;</span><span class="p">:</span><span class="s2">&quot;2014-11-21T07:20:54.387Z&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;host&quot;</span><span class="p">:</span><span class="s2">&quot;jupiter.local&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="s2">&quot;/Users/johtani/demo_access_log/2010/access20100201.log&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;clientip&quot;</span><span class="p">:</span><span class="s2">&quot;クライアントのIPアドレス&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;ident&quot;</span><span class="p">:</span><span class="s2">&quot;-&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;auth&quot;</span><span class="p">:</span><span class="s2">&quot;-&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;timestamp&quot;</span><span class="p">:</span><span class="s2">&quot;01/Feb/2010:00:00:26 +0900&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;verb&quot;</span><span class="p">:</span><span class="s2">&quot;GET&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;request&quot;</span><span class="p">:</span><span class="s2">&quot;/images/favicon.ico&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;httpversion&quot;</span><span class="p">:</span><span class="s2">&quot;1.1&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;response&quot;</span><span class="p">:</span><span class="s2">&quot;200&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;bytes&quot;</span><span class="p">:</span><span class="s2">&quot;318&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;referrer&quot;</span><span class="p">:</span><span class="s2">&quot;\&quot;-\&quot;&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;agent&quot;</span><span class="p">:</span><span class="s2">&quot;\&quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; ja; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7 (.NET CLR 3.5.30729)\&quot;&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h5>3. 日付のパース（filter/date）</h5>

<p>Logstashは特に指定がない場合、inputでデータを取り出した日付が<code>@timestamp</code>となります。
そして、このフィールドが特に指定がない場合は、Elasticsearchのデータの日付となり、Kibanaで利用する日付となります。</p>

<p>リアルタイムにアクセスログを読み込む場合は、読み込んだ日時でもほぼ問題はありませんが、過去データの場合はそうもいきません。
そこで、<a href="http://logstash.net/docs/1.4.2/filters/date"><code>dateフィルタ</code></a>を使用して、<code>@timestamp</code>の値を書き換えます。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">date</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">match</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;timestamp&quot;</span><span class="p">,</span> <span class="s2">&quot;dd/MMM/YYYY:HH:mm:ss Z&quot;</span><span class="o">]</span>
</span><span class='line'>  <span class="n">locale</span> <span class="o">=&gt;</span> <span class="n">en</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>上記では、<code>timestamp</code>という項目に対して<code>dd/MMM/YYYY:HH:mm:ss Z</code>という日付パターンの場合に値を書き換える設定となります。
なお、日付の月の部分が<code>Feb</code>となっているため、<code>locale</code>に<code>en</code>を指定しています。Logstashが動作するマシンの<code>locale</code>が<code>ja</code>などの場合にパースに失敗するためです。</p>

<h5><a name="filter-geoip">4. クライアントIPアドレスにgeoipの情報を付加（filter/geoip）</a></h5>

<p>どの国からのアクセスかなどを判別したいので、IPアドレスを元にgeoipを利用してより詳細な情報を付与します。
Logstashでもこの機能が用意されており、簡単に利用ができます。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">geoip</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">source</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;clientip&quot;</span><span class="o">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>これだけです。対象とするIPアドレスのフィールドを指定しているだけです。
<code>geoip</code>というフィールドが追加され、次のような情報が付与されます。
国名、緯度経度、タイムゾーンなどです。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="err">...</span>
</span><span class='line'>  <span class="nt">&quot;geoip&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;ip&quot;</span><span class="p">:</span> <span class="s2">&quot;IPアドレス&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;country_code2&quot;</span><span class="p">:</span> <span class="s2">&quot;JP&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;country_code3&quot;</span><span class="p">:</span> <span class="s2">&quot;JPN&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;country_name&quot;</span><span class="p">:</span> <span class="s2">&quot;Japan&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;continent_code&quot;</span><span class="p">:</span> <span class="s2">&quot;AS&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;latitude&quot;</span><span class="p">:</span> <span class="mi">36</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;longitude&quot;</span><span class="p">:</span> <span class="mi">138</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;timezone&quot;</span><span class="p">:</span> <span class="s2">&quot;Asia/Tokyo&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;location&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>      <span class="mi">138</span><span class="p">,</span>
</span><span class='line'>      <span class="mi">36</span>
</span><span class='line'>    <span class="p">]</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="err">...</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h5>5. リクエストのパスの第1階層の抽出（filter/grok）</h5>

<p>リクエストされたURLは<code>request</code>フィールドにありますが、個別のURLだと、大まかな集計が大変です。
もちろん、クエリで処理することもできますが、Logstashで処理するついでに、第1階層のディレクトリ名を抽出しておくことで、
検索や集計を行いやすくしておきます。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">grok</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">match</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="s2">&quot;request&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;^/%{WORD:first_path}/%{GREEDYDATA}$&quot;</span> <span class="p">}</span>
</span><span class='line'>  <span class="n">tag_on_failure</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">&quot;_request_parse_failure&quot;</span><span class="o">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>また、grokフィルタの登場です。
今回は、<code>WORD:first_path</code>という記述方法で、<code>WORD</code>パターンにマッチした文字列を<code>first_path</code>というフィールドに展開する指定をしています。</p>

<p>例えば、サイトのスクリプトなどが<code>scripts</code>というディレクトリにある場合は、<code>first_path</code>の値を利用して、
後続のフィルタでログデータを出力しないといった処理にも使えます。</p>

<h5>6. ユーザエージェントのパース（filter/useragent）</h5>

<p>Logstashではユーザエージェントの文字列から、いくつかの情報を付与するフィルタも用意されています。
<a href="http://logstash.net/docs/1.4.2/filters/useragent"><code>useragent</code>フィルタです。</a></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">useragent</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;agent&quot;</span>
</span><span class='line'>  <span class="n">target</span> <span class="o">=&gt;</span> <span class="s2">&quot;useragent&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>agent</code>というフィールドにユーザエージェントの文字列があるので、このフィールドに対してフィルタを適用します。
元の文字列も取っておきたいので、<code>useragent</code>という別のフィールドに出力するように指定してあります。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="s2">&quot;useragent&quot;</span><span class="err">:</span> <span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Firefox&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;os&quot;</span><span class="p">:</span> <span class="s2">&quot;Windows XP&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;os_name&quot;</span><span class="p">:</span> <span class="s2">&quot;Windows XP&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;Other&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;major&quot;</span><span class="p">:</span> <span class="s2">&quot;17&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;minor&quot;</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span>
</span><span class='line'><span class="p">}</span><span class="err">,</span>
</span></code></pre></td></tr></table></div></figure>


<p>このように、OS名やバージョン名などが抽出できます。</p>

<h5><a name="output-elasticsearch">7. Elasticsearchへの出力（output/elasticsearch）</a></h5>

<p>最後は、<a href="http://logstash.net/docs/1.4.2/outputs/elasticsearch">Elasticsearchへのデータの出力設定</a>です。</p>

<p><code>index</code>にて、出力するindex名を指定してあります。
また、年毎のインデックス名にするために<code>%{year}</code>を利用しています。
<a href="http://logstash.net/docs/1.4.2/configuration#sprintf">sprintf format</a>です。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">elasticsearch</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">host</span> <span class="o">=&gt;</span> <span class="s2">&quot;localhost&quot;</span>
</span><span class='line'>  <span class="n">index</span> <span class="o">=&gt;</span> <span class="s2">&quot;new_demo_access_log-%{year}&quot;</span>
</span><span class='line'>  <span class="n">cluster</span> <span class="o">=&gt;</span> <span class="s2">&quot;demo_cluster&quot;</span>
</span><span class='line'>  <span class="n">protocol</span> <span class="o">=&gt;</span> <span class="s2">&quot;http&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>まとめ</h2>

<p>ということで、今回はアクセスログをLogstashにて読み込む時の設定について説明してきました。
次回は、実際にLogstashを起動してElasticsearchにデータを登録するところまでを説明します。</p>

<p>JJUG CCCや勉強会のデモに用いたデータは、
Elasticsearchにデータを登録する前にテンプレートも設定してありました。こちらについても、次回説明しようと思います。</p>

<p>不明な点、誤植などありましたら、コメント欄へお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第7回Elasticsearch勉強会を開催しました。#elasticsearchjp]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/19/hold-on-7th-elasticsearch-jp/"/>
    <updated>2014-11-19T11:19:07+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/19/hold-on-7th-elasticsearch-jp</id>
    <content type="html"><![CDATA[<p><a href="http://elasticsearch.doorkeeper.jp/events/16837">第7回Elsticsearch勉強会</a>を開催しました。
スタッフの皆さん、スピーカーの皆さん、開場提供していただいた<a href="http://recruit-tech.co.jp">リクルートテクノロジーズさん</a>、ありがとうございました！
次回もよろしくお願いします！参加していただき盛り上げていただいた参加者の皆さんもありがとうございました。</p>

<p>昨日も紹介しましたが、<a href="http://qiita.com/advent-calendar/2014/elasticsearch">Elasticsearch Advent Calendar 2014</a>を用意してみました。まだ、空きがありますので、登録お待ちしております！</p>

<!-- more -->


<p>今回は出足が好調で、早々に180人の枠を超えるという嬉しい事態でした。
最終的な参加人数は130名程度で、懇親会参加者が50名弱といったところです。</p>

<h2>「Kibana4」</h2>

<h3>Elasticsearch Inc. Jun Ohtani @johtani</h3>

<p>スライド：<a href="https://speakerdeck.com/johtani/kibana4">Kibana4</a></p>

<p>ということで、Kibana4の紹介と、Kibana4のBeta2を利用したデモを行いました。
デモの開始のところで少し環境がうまく動いてなくて手間取ってしまいましたが。。。</p>

<p>発表で1点だけ修正があります。JRubyを選択しているのがElasticsearchのライブラリを使用するためという説明をしましたが、
こちらは、Logstashに関する話でした。Kibana4は現時点では、ElasticsearchへのProxyとしての動作が主なものとなります。Rubyでも動作可能です。
bin/kibanaについてはJavaを使った起動になります。
参考：<a href="https://github.com/elasticsearch/kibana/tree/master/src/server">https://github.com/elasticsearch/kibana/tree/master/src/server</a></p>

<p>発表でも主張しましたが、ダウンロードして、Elasticsearchを用意すれば簡単に動作させることが可能です。
ぜひ、ローカルで試して見てもらえればと思います。
今回のデモのデータを入れるのに利用したLogstashの設定などについては、ブログで記事を書こうと思います。</p>

<h2>niconicoの検索を支えるElasticsearch</h2>

<h3>株式会社ドワンゴ 伊藤 祥 さん</h3>

<p>スライド：<a href="https://speakerdeck.com/shoito/niconico-elasticsearch">niconicoの検索を支えるElasticsearch</a></p>

<ul>
<li>リアルタイム検索の実現、新しい検索への対応</li>
<li>検索のアーキテクチャとか。</li>
<li>Capistranoでデプロイとかを管理</li>
<li>1.4.1が出たら、クラスタを更新予定</li>
</ul>


<p>ということで、実際に導入した話から、現在の運用の仕方、クラスタのアップグレードなど多岐にわたる内容でおもしろかったです。
遭遇した問題点とかもあったので。
Marvel便利なのでぜひ導入を検討してもらえればw</p>

<h2>Elasticsearch at CrowdWorks </h2>

<h3>株式会社クラウドワークス 九岡 佑介 さん @mumoshu</h3>

<p>スライド：<a href="http://www.slideshare.net/mumoshu/20141118-es">Elasticsearch at CrowdWorks</a></p>

<ul>
<li>会社の紹介</li>
<li>仕事が検索対象</li>
<li>検索時間が1桁減少！</li>
<li>Graceful Degradationで失敗したら、InnoDB FTSで代替：<a href="https://github.com/crowdworks/gracefully">Gracefully</a></li>
<li><a href="http://www.found.no">found.no</a>のサービスを利用</li>
<li>elasticsearch-modelの拡張を作成してOSSとして公開：<a href="https://github.com/crowdworks/elasticsearch-model-extensions">elasticsearch-model-extensions</a></li>
</ul>


<p>Gracefullyで切り替えとかは面白いなと思いました。
検索での利用の話でしたが、他のシーンでも使えそうですよね。
日本にFoundユーザがいるのも初めて知りました。
彼らの開発者ブログも質の良い情報が載っているので、参考になりますよね。</p>

<p>次は、どんなMappingで運用しているのかとか、どういった工夫をしているかといった点を詳しく聞きたいなと思いました。
またお待ちしております。</p>

<h2>1分で作るElasticsearchプラグイン</h2>

<h3>株式会社エヌツーエスエム 菅谷 信介 さん</h3>

<p>スライド：<a href="http://www.slideshare.net/shinsuke/plugins-ates7">Elasticsearchプラグインの作り方</a></p>

<ul>
<li>プラグインの作り方とか。</li>
<li>十数個のプラグインの紹介。プラグインはこちらで公開中。<a href="https://github.com/codelibs/">https://github.com/codelibs/</a></li>
<li>実際に、業務で必要なものから作成</li>
<li>まだまだ作りたいものがある</li>
</ul>


<p>コミュニティ還元できるものはPR送ってもらえるとうれしいです。
前よりは体制も増えてるので、PRも目にとまるようになってるはずです。</p>

<p>あとは、使ってみたいと思う方も多数いると思うので、ぜひ、OSSなので、貢献しましょう！
フィードバックがあるだけで、OSS活動やってるものにとってはやる気につながると思いますし。</p>

<h2>LT：GISとして活用するElasticsearch </h2>

<h3>船戸 隆さん</h3>

<p>スライド：<a href="https://speakerdeck.com/tfunato/gistositehuo-yong-suruelasticsearch">GISとして活用するElasticsearch </a></p>

<ul>
<li>java-jaからIngressの青（Registance）の勧誘に来られた方w</li>
<li>APIをハックして、情報を取得し、Kibanaで可視化</li>
<li>残念ながら、APIが変更されて見れなくなったらしい。</li>
</ul>


<p>Ingress実際にやったことはないのですが、おもしろそうでした。
発表される方の会社の採用紹介ではなく、Ingressの勧誘をされるとは想定外でしたw</p>

<p>興味のあるデータをKibanaで可視化するのも面白い例だと思うので、活用してもらえればと思います。</p>

<h2>その他、感想などのブログ</h2>

<p>適当に見つけたブログを列挙してあります。これもあるよ！などあれば、教えてください。</p>

<ul>
<li><a href="http://blog.yoslab.com/entry/2014/11/18/203159">勉強会メモ - 第7回elasticsearch勉強会</a></li>
<li><a href="http://qiita.com/t-sato/items/940ccfa9e4a668b91967">第7回elasticsearch勉強会 #elasticsearch #elasticsearchjp</a></li>
</ul>


<h2>まとめ</h2>

<p>JJUGの時とは違い、Elasticsearch勉強会ではさすがに、企業としてのElasticsearchの知名度が高かったのはありがたいことでした。
自分の発表のために始めた勉強会でもありますが、まだまだ、発表するときは緊張しますし、分かりにくいんじゃないかなぁと思うことも多々あります。
この辺がわかりにくかった、この辺をもっと知りたいなど、フィードバックをお待ちしております。</p>

<p>冒頭にも書きましたが、<a href="http://qiita.com/advent-calendar/2014/elasticsearch">Elasticsearch Advent Calendar 2014</a>の登録をお待ちしております。どんなことでも歓迎なので、Elasticsearch、Kibana、Logstashなどについて書いてもらえるとうれしいです。</p>

<p>次回ももちろん2ヶ月後くらいに行います。 スピーカー募集中ですので、コメント、メール、ツイートなど、コンタクトしていただければと思います。 よろしくお願いいたします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 1.4.0および1.3.5リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/06/elasticsearch-1-4-0-ja/"/>
    <updated>2014-11-06T01:30:33+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/06/elasticsearch-1-4-0-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-released/">elasticsearch-1.4.0 and 1.3.5 released</a></p>

<p>本日、<strong>Lucene 4.10.2</strong>をベースにした<strong>Elasticsearch 1.4.0</strong>と、バグフィックスリリースである、<strong>Elasticsearch 1.3.5</strong>をリリースしました。
ダウンロードおよび変更リストはそれぞれ次のリンクからアクセスできます。</p>

<ul>
<li>最新ステーブルリリース：<a href="http://www.elasticsearch.org/downloads/1-4-0">Elasticsearch 1.4.0</a></li>
<li>1.3.x系バグフィックス：<a href="http://www.elasticsearch.org/downloads/1-3-5">Elasticsearch 1.3.5</a></li>
</ul>


<p>1.3ブランチに関する過去のリリースについてのブログは次のとおりです：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-4-released/">1.3.4</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-3-released/">1.3.3</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-2-released/">1.3.2</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-1-released/">1.3.1</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-0-released/">1.3.0</a>.</p>

<!-- more -->


<p>Beta1リリースでも言及しましたが、1.4.0の主なテーマは<em>resiliency(復元性、弾力性)</em>です。
Elasticsearchをより安定し信頼性のあるものにし、メモリ管理を改善し、ディスカバリアルゴリズムを改善し、破損したデータの検知を改善しました。
Beta1リリースからのハイライトも含んでいます。</p>

<ul>
<li>Doc values (インデックス時にディスクに保存される<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/fielddata-formats.html#fielddata-formats">fielddata</a>)がヒープ利用率を激減</li>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-fielddata.html#request-circuit-breaker">Request circuit breaker</a>:
メモリを消費しすぎる検索リクエストの中断</li>
<li>Bloom filterの<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-update-settings.html#codec-bloom-load">デフォルト無効</a>、高速なインデキシングのためにもはや必要とされないため。</li>
<li>ノードディスカバリ、シャードリカバリの数多くのバグフィックス及び改善</li>
<li>データ破損の早期検知のためのチェックサムのさらなる利用</li>
<li>GroovyをMVELの代わりに<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/modules-scripting.html#modules-scripting">デフォルトスクリプト言語に</a></li>
<li>CORSを<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/modules-http.html#_settings_2">デフォルト無効</a>に。XSS攻撃防止の為。</li>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-shard-query-cache.html#index-modules-shard-query-cache">クエリキャッシュ</a>、変更されていないシャードからすぐにaggregation結果を返す</li>
<li>新しいAggregation：<code>filter</code>(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-filters-aggregation.html#search-aggregations-bucket-filters-aggregation">ドキュメント</a>)、<code>children</code>(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-children-aggregation.html#search-aggregations-bucket-children-aggregation">ドキュメント</a>)、<code>scripted_metric</code>(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-metrics-scripted-metric-aggregation.html#search-aggregations-metrics-scripted-metric-aggregation">ドキュメント</a>)</li>
<li>新しい<code>GET /index</code>API。インデックスのsettings、mappings、warmers、aliasesを1回のリクエストで返却(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-get-index.html#indices-get-index">ドキュメント</a>)</li>
<li>自動付与ドキュメントIDのためのFlake ID。プライマリキーの探索パフォーマンスの改善。</li>
<li>ドキュメントに変更のない更新によるドキュメントの再インデックスの防止</li>
<li><code>function_score</code>クエリの関数で<code>weight</code>パラメータによる個別の改善を可能に。(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/query-dsl-function-score-query.html#_weight">ドキュメント</a>)</li>
</ul>


<p>詳細については<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-beta-released/">1.4.0.Beta1のブログ(英語)</a>(<a href="http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja/">日本語訳</a>)をご覧ください。</p>

<p>Beta1以降の1.4.0の変更の全てについては、<a href="http://www.elasticsearch.org/downloads/1-4-0">1.4.0 release notes</a>でご覧いただけます。
以下では、2つの主な変更について紹介します。</p>

<h2>HTTP Pipelining</h2>

<p>HTTP pipeliningは複数のリクエストを1回のコネクションで、関連するレスポンスを待つことなく送信することができます。
そして、レスポンスは、受け取ったリクエストと同じ順序で返却されます。
HTTP/1.1の仕様で、pipeliningのサポートが必要です。ElasticsearchはHTTP/1.1であるとしてきましたが、pipeliningはサポートしていませんでした。この問題は.NETユーザで問題を引き起こしました。</p>

<p>現在、HTTP pipeliningは公式にサポート済みで、デフォルトで利用できます。<a href="https://github.com/elasticsearch/elasticsearch/pull/8299">#8299</a>をご覧ください。</p>

<h2>Upgrade API</h2>

<p>Luceneのすべてのリリースではバグフィックスや最適化が提供されます。しかし、多くのユーザは古いバージョンのLuceneで作成されたインデックスを持っており、より最新の改善による利点を利用できないことがあります。
新しい<code>upgrade</code>APIは、あなたのインデックスすべてもしくは一部を最新のLuceneフォーマットに透過的にアップグレードできます。</p>

<p><code>GET _upgrade</code>リクエストは、インデックスのアップグレードが必要かどうかを提示し、アップグレードに必要なセグメントのサイズをリポートすることによって、どのくらいの時間が必要かの目安を提供します。
<code>POST _upgrade</code>コマンドはバックグラウンドでインデックスを最新のLuceneフォーマットに書き換えます。</p>

<p>より詳しい情報は<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-upgrade.html"><code>upgrade</code>APIドキュメント</a>をご覧ください。</p>

<h2>試してみてください。</h2>

<p>Beta1リリースを利用し、経験・体験を報告していただいたベータテスターの方々に感謝します。
1.4.0がこれまでの最高のリリースになると確信しています。
ぜひ、<a href="http://www.elasticsearch.org/downloads/1-4-0">Elasticsearch 1.4.0</a>をダウンロードして、試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/elasticsearch/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[validate APIの利用]]></title>
    <link href="http://blog.johtani.info/blog/2014/10/27/how-to-use-validate-api/"/>
    <updated>2014-10-27T18:42:31+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/10/27/how-to-use-validate-api</id>
    <content type="html"><![CDATA[<p>久しぶりに翻訳ではないブログを。書こうと思いながらかけてなかったので。。。</p>

<p>今回は<a href="http://www.elasticsearch.org/guide/ep/elasticsearch/reference/current/search-validate.html">validate API</a>の紹介です。</p>

<!-- more -->


<h2>背景</h2>

<p>Elasticsearchのクエリは<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl.html">Query DSL</a>というJSONで
クエリを定義できるものを提供しています。
これは、様々な<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl-queries.html">クエリ</a>、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl-filters.html">フィルタ</a>を定義するために必要です。</p>

<p>自分の望んでいる条件を記述するために、JSONのネストと格闘することも必要となります。。。
また、クエリ、フィルタには様々なパラメータが用意されています。
これらのパラメータをすべて覚えるのは無理でしょうし、タイプミスなどもありますよね。
タイプミスやカッコのミスマッチなどで格闘して1時間が経過してしまったなどもあると思います。</p>

<p>そんな時に便利なAPIとして用意されているのが<a href="http://www.elasticsearch.org/guide/ep/elasticsearch/reference/current/search-validate.html">validate API</a>です。</p>

<h2>利用方法</h2>

<p>APIが用意されています。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>http://ホスト名:ポート番号/インデックス名/タイプ名/_validate/query</span></code></pre></td></tr></table></div></figure>


<p><code>インデックス名</code>や<code>タイプ名</code>は省略可能ですが、マッピングが異なると思うので、タイプ名まで指定するほうが良いと思います。
上記のAPIに対してクエリを送信するだけです。</p>

<h3>クエリの確認</h3>

<p>たとえば、<a href="https://gist.github.com/johtani/08dee5fb4da62037ef9e">こちらのGist</a>にあるようなマッピングのインデックスに対して
検索クエリを組み立てていて、エラーが出るとします。
※このクエリは<code>match_all</code>のところを<code>match_al</code>と、<code>l</code>が1文字足りないクエリになっています。</p>

<p><strong><em>検索クエリのリクエスト（エラーあり）</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_search
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "match_al": {}
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>実行結果のレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "error": "SearchPhaseExecutionException[Failed to execute phase [query], all shards failed; shardFailures {[rwkb01chTZq2V7FD0Tlwrw][pref_aggs][0]: SearchParseException[[pref_aggs][0]: from[-1],size[-1]: Parse Failure [Failed to parse source [{\n  \"query\": {\n    \"match_al\": { }\n  }\n}\n]]]; nested: QueryParsingException[[pref_aggs] No query registered for [match_al]]; }{[rwkb01chTZq2V7FD0Tlwrw][pref_aggs][1]: SearchParseException[[pref_aggs][1]: from[-1],size[-1]: Parse Failure [Failed to parse source [{\n  \"query\": {\n    \"match_al\": { }\n  }\n}\n]]]; nested: QueryParsingException[[pref_aggs] No query registered for [match_al]]; }]",
</span><span class='line'>   "status": 400
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>とこんなかんじで、エラーが帰っては来るのですが、非常に読みづらいです。</p>

<p>そこで、<code>validate API</code>を利用します。
リクエスト先を<code>/_search</code>から<code>/_validate/query</code>に変更します。</p>

<p><strong><em>validate API</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_validate/query
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "match_al": {}
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": false,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>すると、非常にシンプルな結果が返ってきます。
<code>"valid": false</code>となっているため、クエリに問題があることがわかります。</p>

<h3>エラーの詳細</h3>

<p>問題がある事自体はわかりましたが、エラーの内容も知りたいですよね？
その場合は、<code>explain</code>というパラメータを追加します。
（正しくは<code>explain=true</code>を追加しますが、<code>=true</code>を省略可能です。）</p>

<p><strong><em>validate API(explainあり、クエリ自体は省略)</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_validate/query?explain
</span><span class='line'>{...}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": false,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "pref_aggs",
</span><span class='line'>         "valid": false,
</span><span class='line'>         "error": "org.elasticsearch.index.query.QueryParsingException: [pref_aggs] No query registered for [match_al]"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><code>explanations</code>という項目が追加されました。
ここに<code>error</code>という項目として、エラーの詳細が返ってきます。<code>_search</code>の時よりも見やすいですね。
今回のエラーは、<code>match_all</code>が正しいクエリですの、<em><code>match_al</code>というクエリは登録されていないというエラー</em>でした。
では、クエリを修正して実行しましょう。</p>

<p><strong><em>validate API(エラー無し)</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_validate/query?explain
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "match_all": {}
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": true,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "pref_aggs",
</span><span class='line'>         "valid": true,
</span><span class='line'>         "explanation": "ConstantScore(*:*)"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>今度はクエリに問題はありません。<code>"valid": true</code>です。
そして、<code>explanations</code>の項目には、<code>error</code>の代わりに<code>explanation</code>という項目が返ってきました。
これが、実際にElasticsearch内部で実行されるクエリになります。</p>

<h3>実際のクエリに利用される単語の確認</h3>

<p>この機能はこの他に、クエリの解析にも利用できます。
思ったとおりに検索にヒットしない場合があって、困ったことはないですか？
フィールドに指定されたアナライザによっては、単語を変形したりするものが存在します。</p>

<p><strong><em>サンプルマッピング</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>PUT /validate_sample
</span><span class='line'>{
</span><span class='line'>  "mappings": {
</span><span class='line'>    "several_analyzer": {
</span><span class='line'>      "properties": {
</span><span class='line'>        "title": {"type": "string"},
</span><span class='line'>        "body_ja": {"type": "string", "analyzer": "kuromoji"},
</span><span class='line'>        "body_en": {"type": "string", "analyzer": "english"}
</span><span class='line'>      }
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>例えば、このように<code>kuromoji</code>、<code>english</code>、デフォルト(<code>standard</code>)アナライザを利用したマッピングがあるとします。
このフィールドに対して<code>powerful</code>という単語で検索したとします。</p>

<p><strong><em>validate API</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET /validate_sample/_validate/query?explain
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "multi_match": {
</span><span class='line'>      "fields": ["body_en","body_ja","title"],
</span><span class='line'>      "query": "powerful"
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>この場合、レスポンスは次のとおりです。</p>

<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": true,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "validate_sample",
</span><span class='line'>         "valid": true,
</span><span class='line'>         "explanation": "(title:powerful | body_en:power | body_ja:powerful)"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><code>title</code>、<code>body_ja</code>については入力された単語がそのままクエリとして利用されています。
<code>body_en</code>については、<code>power</code>という単語に変換されて実行されています。
これは、<code>english</code>アナライザがステミングを行った結果がクエリとして利用されるという意味です。
また、<code>powerful</code>を<code>秋葉原</code>といった日本語に変更して実行すると次のようになります。
日本語は<code>standard</code>アナライザなどでは、1文字ずつ区切られてしまうことがわかります。</p>

<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": true,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "validate_sample",
</span><span class='line'>         "valid": true,
</span><span class='line'>         "explanation": "((title:秋 title:葉 title:原) | (body_en:秋 body_en:葉 body_en:原) | ((body_ja:秋葉 body_ja:秋葉原) body_ja:原))"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>このように、クエリの単語がどのような単語に変換されてクエリに利用されているかなども知ることが可能です。</p>

<p>また、クエリを組み立てて、ヒットするはずが、0件となってしまうという場合にも、どのようなクエリが組み立てられているかを確認するという点で、
<code>validate API</code>が役立ちます。
検索がヒットするが、望んだクエリになっていないのでは？という場合は<code>_search API</code>の<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-request-explain.html"><code>explain</code>パラメータ</a>を
利用すれば、クエリの構成がわかるのですが、検索結果が0件の場合はクエリの構成は表示されません。</p>

<h2>解決できない問題は？</h2>

<p>便利なvalidate APIですが、以下の問題に対しては残念ながら確認できません。</p>

<ul>
<li><code>query</code>以外の項目のvalidate不可

<ul>
<li>たとえば、<code>_search API</code>の<code>size</code>などの項目についてはチェックできないです。</li>
</ul>
</li>
<li>存在しないフィールドの指定

<ul>
<li>上記<code>validate_sample</code>のマッピングの例でクエリに<code>body_eng</code>という存在しないフィールドを指定してもエラーとはなりません。</li>
</ul>
</li>
</ul>


<h2>まとめ</h2>

<p>書いたクエリがうまく動かない、JSONのタグがおかしいといった場合は、
まずはこの<code>validate API</code>で確認してみるのがオススメです。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sonatypeのバージョン番号で困ったので]]></title>
    <link href="http://blog.johtani.info/blog/2014/10/15/versioning-of-sonatype/"/>
    <updated>2014-10-15T15:26:08+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/10/15/versioning-of-sonatype</id>
    <content type="html"><![CDATA[<p><a href="http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja/">Elasticsearch 1.4.0.Beta1がリリース</a>されました。</p>

<p>個人で<a href="https://github.com/johtani/elasticsearch-extended-analyze">elasticsearch-extended-analyze</a>というプラグインを開発してます。
こちらも1.4.0.Beta1に対応するべく作業をしてて、少し戸惑ったことがあったので、メモをば。</p>

<!-- more -->


<p>ここ最近はプラグインのバージョン番号をElasticsearchのバージョン番号と同じものを利用していました。
（プラグインの機能追加をサボってる？？）
その時に、<code>1.4.0.Beta1</code>という番号を指定したのですが、意味不明なエラーに悩まされてしまいまして。</p>

<p>プラグインのリリースでは、以下のコマンドを実行します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ mvn release:prepare
</span><span class='line'>$ mvn release:perform</span></code></pre></td></tr></table></div></figure>


<p>最初のコマンド（prepare）で、パッケージングを実施し、Githubにリリースタグを打ったバージョンがpushされます。
次のコマンド（perform）で、パッケージングされたzipファイルがsonatypeのサイトに公開するためにアップロードされます。</p>

<p><code>1.4.0.Beta1</code>というバージョン文字列を利用した場合、prepareは問題なく実行できたのですが、
performで以下の様なエラーが返ってきました。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Return code is: 401, ReasonPhrase: Unauthorized.</span></code></pre></td></tr></table></div></figure>


<p>バージョン番号が<code>1.3.0</code>では特に問題はなかったのですが、、、
結局、バージョン番号を<code>1.4.0-beta1</code>に変更すると問題なくリリースが完了しました。</p>

<p>mike_neckさんと話をしていて、<a href="http://semver.org">Semantic Versioning</a>に関係しているのかなぁという話にはなったのですが、
詳しく調べていません。。。</p>

<p>そのうち調べようかなぁ。。。。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[elasticsearch 1.4.0.Beta1のリリース]]></title>
    <link href="http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja/"/>
    <updated>2014-10-02T19:14:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja</id>
    <content type="html"><![CDATA[<p>※この記事は次のブログを翻訳したものになります。</p>

<p>原文：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-beta-released/">elasticsearch 1.4.0.beta1 released</a></p>

<p>本日、<em>Lucene 4.10.1</em>をベースにした、<em>Elasticsearch 1.4.0.Beta1</em>をリリースしました。
<a href="http://www.elasticsearch.org/downloads/1-4-0-Beta1">Elasticsearch 1.4.0.Beta1</a>からダウンロードできます。
また、すべての変更点に関してもこちらをご覧ください。</p>

<!-- more -->


<p>1.4.0のテーマは<em>resiliency(復元性、弾力性)</em>です。
<em>resiliency</em>とはElasticsearchをより安定し信頼性のあるものにすることを意味します。
すべての機能が正常に機能している場合は信頼することは簡単です。
予想外のことが発生した時に難しくなります：ノードでout of memoryの発生、スローGCや重いI/O、ネットワーク障害、不安定なデータの送信によるノードのパフォーマンス低下など。</p>

<p>本ベータリリースは、resiliencyの主な3つの改善を含んでいます。</p>

<ul>
<li><a href="#memory-mgmt">メモリ使用量の低下</a>によるノードの安定性向上</li>
<li>discoveryアルゴリズムの改善による<a href="#cluster-stability">クラスタの安定性</a>向上</li>
<li><a href="#checksums">チェックサム</a>の導入による破損したデータの検知</li>
</ul>


<p>分散システムは複雑です。
決して想像できないような状況をシミュレーションするために、ランダムなシナリオを作成する広範囲なテストスイートを持っています。
しかし、無数のエッジケース(特殊なケース)があることも認識しています。
1.4.0.Beta1はこれまで私たちが行ってきた改善のすべてを含んでいます。
これらの変更を実際にテストしていただき、<a href="https://github.com/elasticsearch/elasticsearch/issues">何か問題があった場合は私たちに教えてください</a>。</p>

<h2><a name="memory-mgmt">メモリ管理</a></h2>

<p>ヒープ空間は限られたリソースです。
上限を32GBとし、利用可能なRAMの50%をヒープの上限にすることを推奨します。
この上限を超えた場合、JVMは圧縮したポインタを使用することができず、GCが非常に遅くなります。
ノードの不安定性の主な原因は遅いGCです。それは、次のようなことから発生します。</p>

<ul>
<li>メモリプレッシャー</li>
<li>スワップ(参照：<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/setup-configuration.html#setup-configuration-memory">memory settings</a>)</li>
<li>非常に大きなヒープ</li>
</ul>


<p>本リリースは、メモリ管理の改善し、（結果として）ノードの安定性を改善するいくつかの変更を含んでいます。</p>

<h3>doc values</h3>

<p>メモリの利用の最も大きなものの1つは<strong>fielddata</strong>です
aggregation、ソート、スクリプトがフィールドの値に素早くアクセスするために、フィールドの値をメモリにロードして保持します。
ヒープは貴重なため、1ビットも無駄にしないためにメモリ内のデータは高度な圧縮と最適化を行っています。
これは、ヒープスペース以上のデータをもつまでは、非常によく動作します。
これは、多くのノードを追加することによって常に解決できる問題です。
しかし、CPUやI/Oが限界に達してしまうずっと前に、ヒープ空間の容量に到達します。</p>

<p>最近のリリースは、<strong>doc values</strong>によるサポートがあります。
基本的に、doc valuesはin-memory fielddataと同じ機能を提供します。
doc valuesの提供する利点は、それらが、非常に少量のヒープ空間しか使用しない点です。
doc valuesはメモリからではなく、ディスクから読み込まれます。
ディスクアクセスは遅いですが、doc valuesはカーネルのファイルシステムキャッシュの利点を得られます。
ファイルシステムキャッシュはJVMヒープとはことなり、32GBの制限による束縛がありません。
ヒープからファイルシステムキャッシュにfielddataを移行することによって、より小さなヒープを使うことができます。これは、GCがより早くなり、ノードが更に安定することを意味します。</p>

<p>本リリースより前は、doc valuesはin-memory fielddataよりもかなり遅かったです。
本リリースに含まれる変更は、パフォーマンスをかなり向上させ、in-memory fielddataとほぼ同じくらいの速度になっています。</p>

<p>in-memory fielddataの代わりにdoc valuesを利用するために必要なことは、次のように新しいフィールドをマッピングすることです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>PUT /my_index
</span><span class='line'>{
</span><span class='line'>  "mappings": {
</span><span class='line'>    "my_type": {
</span><span class='line'>      "properties": {
</span><span class='line'>        "timestamp": {
</span><span class='line'>          "type":       "date",
</span><span class='line'>          "doc_values": true
</span><span class='line'>        }
</span><span class='line'>      }
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>このマッピングで、このフィールドに対するfielddataの利用は、メモリにフィールドをロードする代わりに、自動的にディスクからdoc valuesを利用します。
<em>注意：</em>現時点で、doc valuesはanalyzedな<code>string</code>フィールドはサポートしていません。</p>

<h3>request circuit breaker</h3>

<p>fielddata circuit breakerはfielddataによって利用されるメモリの上限を制限するために追加され、OOMEの最も大きな原因の1つを防ぎました。
そして、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-fielddata.html#request-circuit-breaker">リクエストレベルのcircuit-breaker</a>を提供するために、コンセプトを拡張しました。
これは、単一のリクエストによって使用されるメモリの上限を制限します。</p>

<h3>bloom filters</h3>

<p><a href="http://en.wikipedia.org/wiki/Bloom_filter">Bloom filters</a> はインデキシング(前のバージョンのドキュメントが存在するかどうかのチェックのため)や、
IDによるドキュメントの検索(ドキュメントを含むセグメントがどれかを決定するため)に関する重要な性能最適化を提供しました。
しかし、もちろんそれらはコスト（メモリ）を必要とします。
現在の改善は、bloom filterの必要性を取り除きました。
現在では、Elasticsearchはまだ、インデックス時にそれらを構築します(実世界の経験がテストシナリオにそぐわない場合に備えて)。
しかし、デフォルトではメモリにはロードされません。
すべてが予定通りに運べば、将来のバージョンで完全にこれらは除去します。</p>

<h2><a name="cluster-stability">クラスタの安定性</a></h2>

<p>クラスタの安定性向上のために私たちができる最も大きなことは、ノードの安定性の向上です。
もし、ノードが安定しておりタイミングよく反応すれば、クラスタが不安定になる可能性が大いに減少します。
私たちは不完全な世界に住んでいます。- 物事は予想外にうまく行きません。クラスタはデータを失うことなくこのような状況から回復できる必要があります。</p>

<p>私たちは、<code>improve_zen</code>ブランチ上で、Elasticsearchの障害からの復旧するための能力の向上に数ヶ月費やしてきました。
まず、複雑なネットワークレベルの障害を繰り返すためのテストを追加しました。
次に、各テストのための修正を追加しました。
そこには、より多くの行うことが存在します。しかし、私たちは、<a href="https://github.com/elasticsearch/elasticsearch/issues/2488">issue #2488</a>(&ldquo;分割が交差している場合、minimum_master_nodesはsplit-brainを防げない&rdquo;)に含まれる、ユーザが経験してきた大部分の問題を私たちは解決しました。</p>

<p>私たちはクラスタのresiliencyを非常に真剣に取り組んでいます。
私たちは、Elasticsearchが何ができるか、その上で何が弱点であるかを理解してほしいと思っています。
これを考慮して、私たちは<a href="http://www.elasticsearch.org/guide/en/elasticsearch/resiliency/current/index.html">Resiliency Status Document</a>を作成しました。
このドキュメントは、私たち(または私たちユーザ)が遭遇したresiliencyの問題の、何が修正済みで、何が修正されないまま残っているかを記録します。
このドキュメントを慎重に読み、あなたのデータを保護するために適切な方法を選択してください。</p>

<h2><a name="checksums">データ破損の検知</a></h2>

<p>ネットワークをまたいだシャードリカバリのチェックサムは、圧縮ライブラリのバグを発見する助けとなりました。
それは、バージョン1.3.2で修正済みです。
それ以来、私たちはElasticsearchのいたるところにチェックサムとチェックサムの確認を追加しました。</p>

<ul>
<li>マージ中に、あるセグメント内すべてのチェックサムの確認(<a href="https://github.com/elasticsearch/elasticsearch/issues/7360">#7360</a>)</li>
<li>インデックス再オープン時に、あるセグメント内の最も小さなファイルの完全な確認と、より大きなファイルの軽量な打ち切りチェック(<a href="https://issues.apache.org/jira/browse/LUCENE-5842">LUCENE-5842</a>)</li>
<li>トランザクションログからイベントを再生するとき、各イベントはチェックサムを確認される(<a href="https://github.com/elasticsearch/elasticsearch/issues/6554">#6554</a>)</li>
<li>シャードのリカバリ中もしくは、スナップショットからのリストア中にElasticsearchはローカルファイルとリモートのコピーが同一であるか確認する必要がある。ファイルの長さとチェックサムのみを使うのは不十分であることが確認された。このため、現在はセグメントのすべてのファイルの同一性を確認(<a href="https://github.com/elasticsearch/elasticsearch/issues/7159">#7159</a>)</li>
</ul>


<h2>その他のハイライト</h2>

<p><a href="http://www.elasticsearch.org/downloads/1-4-0-Beta1">Elasticsearch 1.4.0.Beta1のchangelog</a>に本リリースの多くの機能、改善、バグフィックスについて読むことができます。
ここでは、特筆すべきいくつかの変更について述べます。</p>

<h3>groovyによるmvelの置き換え</h3>

<p>Groovyは現在、デフォルトのscripting languageです。
以前のデフォルトはMVELで、古くなってきており、サンドボックス内で実行できないという事実は、セキュリティ問題でした。
Groovyはサンドボックスであり(それは、ボックスの外へは許可が必要)、メンテナンスされており、速いです！
詳しくは<a href="http://www.elasticsearch.org/blog/scripting/">scriptingについてのブログ記事</a>をご覧ください。</p>

<h3>デフォルトでcorsはオフ</h3>

<p>Elasticsearchのデフォルト設定はクロスサイトスクリプティングに対して脆弱でした。
私たちはデフォルトで<a href="http://en.wikipedia.org/wiki/Cross-origin_resource_sharing">CORS</a>をオフにすることで修正しました。
Elasticsearchにインストールされたサイトプラグインはこれまで同様に機能します。
しかし、CORSを再度オンにすることがない限り、外部のウェブサイトがリモートのクラスタにアクセスすることはできません。
ウェブサイトがあなたのクラスタにアクセス可能に制御できるように、さらに<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/modules-http.html#_settings_2">CORS settings</a>を追加しました。
詳しくは<a href="http://www.elasticsearch.org/community/security">security page</a>をご覧ください。</p>

<h3>クエリキャッシュ</h3>

<p>新しい試験的な<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-shard-query-cache.html">shardレベルのクエリキャッシュ</a>は、静的なインデックスのアグリゲーションをほとんど即座に反応できます。
ウエブサイトのアクセスの日毎のページビュー数を見るダッシュボードを持っていると想像してみてください。
これらの数値は古いインデックスでは変更がありません。しかし、アグリゲーションはダッシュボードのリフレッシュのたびに再計算されます。
新しいクエリキャッシュを利用すると、シャードのデータが変更されない限り、アグリゲーションの結果はキャッシュから直接返却されます。
キャッシュから古い結果を決して取得することはありません。それは、常に、キャッシュされていないリクエストと同じ結果を返します。</p>

<h3>新しいaggregations</h3>

<p>3つの新しいaggregationsがあります。</p>

<ul>
<li><p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-filters-aggregation.html"><code>filters</code></a></p>

<ul>
<li>これは<code>filter</code> aggregationの拡張です。複数のバケットを定義し、バケット毎に異なるフィルタを利用できます。</li>
</ul>
</li>
<li><p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-children-aggregation.html"><code>children</code></a></p>

<ul>
<li><code>nested</code>アグリゲーションの親子版。<code>children</code> aggは親のドキュメントに属する子のドキュメントを集計できる</li>
</ul>
</li>
<li><p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-metrics-scripted-metric-aggregation.html"><code>scripted_metric</code></a></p>

<ul>
<li>このaggregationは、データによって計算されたメトリックを完全にコントロールできます。これは、初期化フェーズ、ドキュメント収集フェーズ、shardレベル結合フェーズ、global reduceフェーズを提供します。</li>
</ul>
</li>
</ul>


<h3>get /index api</h3>

<p>以前、ある1つのインデックスのaliases、mappings、settings、warmersを取得出来ました。しかし、それらを個別にです。
<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-get-index.html"><code>get-index</code> API</a> はこれらのすべてもしくは一部を、複数もしくはひとつのインデックスに対して一緒に取得できます。
これは、既存のインデックスと同一もしくはほぼ同一であるインデックスを作成したいときに非常に役に立ちます。</p>

<h3>登録と更新</h3>

<p>ドキュメントの登録と更新にいくつかの改善があります。</p>

<ul>
<li>現在、ドキュメントIDの自動生成のために<a href="http://boundary.com/blog/2012/01/12/flake-a-decentralized-k-ordered-unique-id-generator-in-erlang">Flake ID</a>を使用しています。これは、プライマリキー探索時に素晴らしい性能向上を提供します。</li>
<li><code>detect_noop</code>に<code>true</code>を設定すると、ドキュメントに変更を与えない更新が軽量になります。この設定を有効にすると、<code>_source</code>フィールドのコンテンツを変更する更新リクエストだけ、ドキュメントの新しいバージョンを書き込みます。</li>
<li>更新はスクリプトから完全に操作できます。以前は、スクリプトはドキュメントがすでに存在しているときだけ実行可能で、それ以外は、<code>upsert</code>ドキュメントで登録しました。<code>script_upsert</code>パラメータでスクリプトから直接ドキュメントの作成が操作できます。</li>
</ul>


<h3>function score</h3>

<p>すでに非常に便利な<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/query-dsl-function-score-query.html"><code>function_score</code>クエリ</a>が、新しく<code>weight</code>パラメータをサポートします。
これは、それぞれの指定された関数の影響をチューニングするのに使われます。
これは、人気度よりも更新日時により重みをかけたり、地理情報よりも価格により重みをかけるといったことを可能にします。
また、<code>random_score</code>機能はセグメントマージによる影響を受けません。これにより、より一貫した順序が提供されます。</p>

<h2>試してみてください。</h2>

<p>ぜひ、<a href="http://www.elasticsearch.org/downloads/1-4-0-Beta1">Elasticsearch 1.4.0.Beta1</a>をダウンロードして、試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/elasticsearch/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第6回Elasticsearch勉強会を開催しました。#elasticsearchjp]]></title>
    <link href="http://blog.johtani.info/blog/2014/09/17/hold-on-6th-elasticsearch-jp/"/>
    <updated>2014-09-17T13:22:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/09/17/hold-on-6th-elasticsearch-jp</id>
    <content type="html"><![CDATA[<p><a href="http://elasticsearch.doorkeeper.jp/events/13917">第6回Elsticsearch勉強会</a>を開催しました。
スタッフの皆さん、スピーカーの皆さん、開場提供していただいた<a href="http://recruit-tech.co.jp">リクルートテクノロジーズさん</a>、ありがとうございました！
次回もよろしくお願いします！参加していただき盛り上げていただいた参加者の皆さんもありがとうございました。
今回は、スタッフが私を含めて3，4名ということで、ドタバタしてしまってスミマセンでした。</p>

<!-- more -->


<p>今回はキャンセルが多く、最終的には90人弱の参加となりましたが、今回も多数の方にお集まりいただきありがとうございました。
同じ日に他の勉強会もあった影響でしょうか？</p>

<h2>「Aggregationあれこれ」Elasticsearch Inc. Jun Ohtani @johtani</h2>

<p>スライド：<a href="https://speakerdeck.com/johtani/aggregationarekore">Aggregationあれこれ</a></p>

<ul>
<li>ちょっと長かったですかね。。。</li>
<li>Aggregationの概要、内部動作、種類などを簡単に紹介してみました。</li>
<li>個々のAggregationもいろいろなオプションなどがあるので、色々と試してみていただければと思います。</li>
<li>アニメーション入りのスライドになってましたが、UpしてあるスライドはPDF版になります。</li>
</ul>


<h2>「秒間3万の広告配信ログをElasticSearchでリアルタイム集計してきた戦いの記録」 株式会社サイバーエージェント　山田直行さん　@satully</h2>

<p>スライド：<a href="http://www.slideshare.net/Satully/elasticsearch-study6threaltime20140916">秒間3万の広告配信ログをElasticSearchでリアルタイム集計してきた戦いの記録</a></p>

<ul>
<li>ディスプレイ広告配信DSPの話</li>
<li>システム: Fluentd、S3、Elasticsearch、Redis、MySQL</li>
<li>7月に秒間3万〜4万のリクエストをさばいている。</li>
<li>なぜElasticsearchを選んだのか、今の構成など</li>
<li>実際に苦労された点なども交えて話していただき面白かったです。</li>
<li>7月時点のお話ということで、現時点ではまた違う構成っぽかったので、また話を聞きたいなぁ。</li>
</ul>


<h2>「Elasticsearch 日本語スキーマレス環境構築と、ついでに多言語対応」ナレッジワークス株式会社　木戸国彦さん @9215</h2>

<p>スライド：<a href="https://speakerdeck.com/kunihikokido/elasticsearch-ri-ben-yu-sukimaresuhuan-jing-gou-zhu-to-tuideniduo-yan-yu-dui-ying">Elasticsearch 日本語スキーマレス環境構築と、ついでに多言語対応</a></p>

<ul>
<li>Dynamic TemplateやIndex Templateの説明</li>
<li>日本語や多言語化するときのMappingのサンプルになりそうなものがゴロゴロ紹介されてました。</li>
<li>いくつかの例があって、後で見直したいなと。</li>
<li>途中で出てきた、fielddata（インデックスに入っている単語区切りのデータ）を見るのに使ってたクエリは<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-request-fielddata-fields.html">field data fields</a>だったかな。</li>
</ul>


<h2>「elasticsearchソースコードを読みはじめてみた」@furandon_pig さん</h2>

<p>スライド：<a href="http://www.slideshare.net/furandon_pig/elasticsearch-39175134">elasticsearchソースコードを読みはじめてみた</a></p>

<ul>
<li>リクエストを受けて検索してる部分から読むといいって言われたらしいが、起動スクリプトから読み始めてみた。</li>
<li>時間かかりそうｗ</li>
<li>ただ、人がどんな感じでソースを読んだり理解してるかがわかりやすかったので面白かったです。</li>
<li>定期的に続きを聞いてみたいです。</li>
</ul>


<h2>LT</h2>

<h3>「reroute APIを使用してシャード配置を制御する」 株式会社富士通ソフトウェアテクノロジーズ 滝田聖己さん @pisatoshi</h3>

<p>スライド：<a href="https://speakerdeck.com/pisatoshi/elasticsearch-rerouteapiwoshi-tutasiyadopei-zhi-falsezhi-yu">reroute APIを使用してシャード配置を制御する</a></p>

<ul>
<li>シャードの再配置が自動で行われるので、それをオフにしないと、せっかく移動しても無駄になることがというあるあるネタ</li>
<li>Bonsaiロゴを作成するLT</li>
<li>実際にいくら掛かったのかが知りたかった。</li>
</ul>


<h3>「検索のダウンタイム0でバックアップからIndexをリストアする方法」株式会社ドワンゴモバイル 西田和史さん</h3>

<p>スライド：<a href="http://www.slideshare.net/kbigwheel/0index-39143333">検索のダウンタイム0でバックアップからIndexをリストアする方法</a></p>

<ul>
<li>擬似無停止のやりかた。</li>
<li>aliasを活用して、かつ、Restoreで再構築するという方法。</li>
<li>aliasまで一緒にリストアされるので注意が必要っていうのは、実際にやってみたからわかることという感じですね。</li>
</ul>


<h2>その他、感想などのブログ</h2>

<p>適当に見つけたブログを列挙してあります。これもあるよ！などあれば、教えてください。</p>

<ul>
<li><a href="http://s-wool.blog.jp/archives/1009404632.html">第6回elasticsearch勉強会に行ってきましたのでそのメモ</a></li>
<li><a href="http://arika.hateblo.jp/entry/2014/09/17/100921">elasticsearch 勉強会 第6回</a></li>
</ul>


<h3>まとめ</h3>

<p>今回も、ためになる話がいっぱい聞けたかなと。
個人的な印象としては、いつものメンバーよりも新しい方が多かった印象です。
また、ほとんどの方が、Elasticsearchをご存知でした。
そこそこ知名度は上がってきているようで嬉しい限りです。（東京以外での知名度なども知りたいかなと。）</p>

<p>あと、懇親会の部屋の案内が遅くなってしまってスミマセンでした。
さすがにスタッフ3名はきつかったです。。。</p>

<p>19時半開始にしてみましたが、懇親会の時間がやはり短めになってしまうなぁという印象でした。</p>

<p>次回ももちろん2ヶ月後くらいに行います。
スピーカー募集中ですので、コメント、メール、ツイートなど、コンタクトしていただければと思います。
よろしくお願いいたします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[elasticsearch.もうちょっと入門という話をしてきました #gihyo_efk]]></title>
    <link href="http://blog.johtani.info/blog/2014/09/16/book-publication-event/"/>
    <updated>2014-09-16T13:21:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/09/16/book-publication-event</id>
    <content type="html"><![CDATA[<p>先日2014年9月9日(火)に<a href="http://eventdots.jp/event/137658">『サーバ/インフラエンジニア養成読本 ログ収集〜可視化編』　出版記念！執筆者が語る大講演会！</a>で、
<a href="https://speakerdeck.com/johtani/elasticsearchmoutiyotutoru-men">「elasticsearch.もうちょっと入門」</a>というタイトルで発表してきました。
会場のGMOのみなさま、Treasure Data、技術評論社のみなさま、どうもありがとうございました。</p>

<p>書籍に興味のある方は、右のリンクから購入してもらえるとうれしいです。Kindle版も用意されています。</p>

<!-- more -->


<p>提供のTDの方に目をつぶってもらいながらLogstashについての発表となってしまいましたが、楽しんでいただけたかなぁと。
書籍では主にKibana3をメインにしたElasticsearchの使い方だったので、それ以外の機能ということで、Aggregationについて説明してみました。</p>

<p>そのあとは、おそらく初めてですが、パネルディスカッションにも参加しました。
<a href="https://twitter.com/naoya_ito">@naoya_ito</a>さんをモデレーターに、rebuild.fm風に進めていただき、話しやすかったかなと。
（少なくとも私は楽しめました！）
ただ、私だけバックグラウンドが少し異なることもあり、話をうまく繋げられなかったかもと気にしていたりもしますが。。。</p>

<p>パネルディスカッションでもありましたが、エンジニアが「趣味」で入れて試してみるのにはもってこいのツール群だと思います。
ちょっと入れてみて、可視化をしてみるといろいろと発見があると思います。
何かを発見するためにもまず試してみるのが何事も重要かなと最近思ってるのもあるので、気軽に試してみてもらえればと。</p>

<p>不明点などあれば、著者陣に気軽に聞いていただけると良いかと思います（いいですよね、みなさんｗ）。
Fluentd（もちろん、Logstashも）、Elasticsearch、Kibanaを利用して、データについて試行錯誤してもらって、
システムやビジネスに必要なものを探索して見てください。</p>

<h3>参考</h3>

<p>他の方々のブログをメモとして。</p>

<ul>
<li><a href="http://suzuken.hatenablog.jp/entry/2014/09/11/210059">サービス改善とログデータ解析について発表してきました</a></li>
<li><a href="http://blog.harukasan.jp/entry/2014/09/12/144217">Kibanaではじめるダッシュボードについて発表してきました #gihyo_efk</a></li>
<li><a href="http://y-ken.hatenablog.com/entry/fluentd-system-design-pattern">Fluentdのお勧めシステム構成パターンについて発表しました</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearchのインデキシングに関するパフォーマンス検討]]></title>
    <link href="http://blog.johtani.info/blog/2014/09/09/performance-considerations-for-elasticsearch-indexing/"/>
    <updated>2014-09-09T17:11:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/09/09/performance-considerations-for-elasticsearch-indexing</id>
    <content type="html"><![CDATA[<p>Elasticsearchのインデキシングに関するパフォーマンス検討</p>

<p>原文：<a href="http://www.elasticsearch.org/blog/performance-considerations-elasticsearch-indexing/">performance considerations for elasticsearch indexing</a></p>

<p>Elasticsearchユーザは様々な楽しいユースケースを持っています。小さなログを追加することから、Webスケールの大きなドキュメントの集合をインデキシングするようなことまでです。また、インデキシングのスループットを最大化することが重要で一般的な目標となります。
「典型的な」アプリケーションに対して良いデフォルト値を設定するようにしていますが、次のちょっとした簡単なベストプラクティスによってインデキシングのパフォーマンスをすぐに改善することができます。それらについて記述します。</p>

<!-- more -->


<p>第一に、制御できないならば、巨大なJavaヒープを使用しない：必要なサイズ（マシンの持つRAMの半分以下）のheapだけを設定しましょう。Elasticsearchの利用方法のために必要な全体量を設定します。これは、OSにIOキャッシュを制御するためのRAMを残すことを意味します。OSが<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-configuration.html">javaプロセスをスワップアウト</a>していないことも確認しましょう。</p>

<p>最新バージョン（<a href="http://www.elasticsearch.org/downloads/1-3-2/">現時点では1.3.2</a>）のElasticsearchにアップグレードしましょう：多数のインデキシングに関連する問題点が最新リリースで修正されています。</p>

<p>詳細に入る前に警告：ここで述べるすべての情報は現時点での最新（<a href="http://www.elasticsearch.org/downloads/1-3-2/">1.3.2</a>）の情報です。しかし、Elasticsearchの更新は日々行われています。この情報をあなたが見た時点では最新ではなく、正確ではなくなっているかもしれません。自信がない場合は<a href="http://www.elasticsearch.org/community">ユーザメーリングリスト</a>で質問してください。</p>

<p>クラスタのインデキシングスループットをチューニングする場合、<a href="http://www.elasticsearch.org/overview/marvel">Marvel</a>は非常に有用なツールです：ここで述べている各設定を継続的に試し、変更の影響がクラスタの挙動をどのように変更されたかを簡単に可視化することが可能です。</p>

<h2>クライアントサイド</h2>

<p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/docs-bulk.html">bulk API</a>を常に使いましょう。1リクエストで複数のドキュメントをインデキシングでき、各バルクリクエストで送るのに良いドキュメント数を試しましょう。最適なサイズは多くの要因に依存しますが、最適サイズからずれるならば多すぎるよりも少なすぎる方が良いでしょう。クライアントサイドのスレッドで並列にbulkリクエストを使うか、個別の非同期リクエストを使ってください。</p>

<p>インデキシングが遅いと結論付ける前に、クラスタのハードウェアの性能を引き出せているかを確認して下さい：すべてのノードでCPUやIOが溢れていないかを確認するために<code>iostat</code>や<code>top</code>、<code>ps</code>といったツールを使いましょう。もし、溢れていなければ、より多くの並列なリクエストが必要です。しかし、javaクライアントからの<code>EsRejectedExecutionException</code>や、RESTリクエストのHTTPレスポンスとして<code>TOO_MANY_REQUESTS (429)</code>が返ってきた場合は並列リクエストを多く送りすぎています。もし<a href="http://www.elasticsearch.org/overview/marvel">Marvel</a>を利用しているなら、<a href="http://www.elasticsearch.org/guide/en/marvel/current/#_node_amp_index_statistics">Node Statistics Dashboard</a>の<code>THREAD POOLS - BULK</code>にリジェクトされた数が表示されます。bulkスレッドプールサイズ（デフォルト値はコア数）を増やすのは得策ではありません。インデキシングスループットを減少させるでしょう。クライアントサイドの並列度を下げるか、ノードを増やすのが良い選択です。</p>

<p>ここでは、1シャードに対してインデキシングスループットを最大化する設定に注目します。1つのLuceneインデックスのドキュメントの容量を測定するために、単一ノード（単一シャード、レプリカなし）で最初にテストをして最適化し、クラスタ全体にスケールする前にチューニングを繰り返します。これはまた、インデキシングスループットの要件を見つけるために、クラスタ全体にどのくらいのノードが必要かをラフに見積もるためのベースラインを与えてくれます。</p>

<p>単一シャードが十分機能したら、Elasticsearchのスケーラビリティの最大の利点や、クラスタでの複数ノードによるレプリカ数やシャード数の増加の利点が得られます。</p>

<p>結論を導き出す前に、ある程度の時間（60分）くらいクラスタ全体の性能を計測しましょう。このテストは、巨大なマージ、GCサイクル、シャードの移動、OSのIOキャッシュ、予期しないスワップの可能性などのイベントのライフサイクルをカバーできます。</p>

<h2>ストレージデバイス</h2>

<p>当然ながらインデックスを保存するストレージデバイスはインデキシングの性能に多大な影響を及ぼします：</p>

<ul>
<li>SSDを利用する：これらは最も速いHDDよりも速いです。ランダムアクセスのための消費電力が低いだけでなく、シーケンシャルIOアクセスも高いです。また、同時に発生するインデキシング、マージや検索のための並列的なIOも高速です。</li>
<li>インデックスをリモートマウントされたファイルシステム（例：<a href="http://en.wikipedia.org/wiki/Network_File_System">NFS</a>や<a href="http://en.wikipedia.org/wiki/Server_Message_Block">SMB/CIFS</a>）上に配置しない：代わりにローカルストレージを使う</li>
<li>仮想化されたストレージ（Amazonの<a href="http://aws.amazon.com/ebs/">Elastic Block Storage</a>など）に注意：仮想化されたストレージはElasticsearchで十分に動作します。また、十分早く簡単に用意できることから魅力的です。しかし、残念なことに、ローカルストレージと比較すると本質的に遅いです。最近の非公式なテストでは、<a href="http://aws.amazon.com/ebs/details/#PIOPS">最高の性能を持つプロビジョニングされたIOPSのSSDオプションのEBS</a>でさえ、ローカルインスタンスにあるSSDよりも遅いです。ローカルインスタンスにあるSSDは物理マシン上のすべての仮想マシンから共有されてアクセスされます。もし他の仮想マシンが急にIOが集中した場合に不可解なスローダウンとなることがあることを覚えておいてください。</li>
<li>複数のSSDを<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-dir-layout.html">複数の<code>path.data</code>ディレクトリ</a>にインデックスをストライピング（<a href="http://en.wikipedia.org/wiki/RAID_0#RAID_0">RAID0</a>のように）：2つは同様で、ファイルブロックレベルでストライピングする代わりに、個別にインデックスファイルレベルでElasticsearchの&#8221;stripes&#8221;となります。これらのアプローチは、いづれかのSSDの故障によりインデックスが壊れるという、1シャードが故障する(IO性能を高速化することとトレードオフ)というリスクを増加させることに注意してください。これは、一般的に行うのに良いトレードオフです：単一シャードで最大のパフォーマンスを最適化し、異なるノード間でレプリカを追加すると、ノードの故障への冗長化ができます。また、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-snapshots.html">snapshotやrestore</a>を使って保険のためにインデックスのバックアップを取ることもできます。</li>
</ul>


<h2>セグメントとマージ</h2>

<p>新しくインデキシングされたドキュメントは最初にLuceneの<code>IndexWriter</code>によってRAMに保存されます。RAMバッファがいっぱいになった時もしくは、Elasticsearchがflushもしくはrefreshを実行した時など定期的にこれらのドキュメントはディスクに新しいセグメントとして書き込まれます。最後に、セグメントが多くなった時に、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-merge.html">Merge PolicyとSucheduler</a>によってそれらがマージされます。このプロセスは連続的に生じます：マージされたセグメントはより大きなセグメントとなり、小さなマージが幾つか実行され、また、大きなセグメントにマージされます。これらがどのように動作するかを<a href="http://blog.mikemccandless.com/2011/02/visualizing-lucenes-segment-merges.html">わかりやすく可視化したブログはこちら</a>です。</p>

<p>マージ、特に大きなマージは非常に時間がかかります。これは、通常は問題ありません。そのようなマージはレアで全体のインデックスのコストと比べればささいなものです。しかし、マージすることがインデキシングについていけない場合、インデックスに非常に多くのセグメントがあるような深刻な問題を防ぐために、Elasticsearchはやってくるインデキシングリクエストを単一スレッド(1.2以降)に制限します。</p>

<p>もし、INFOレベルのログメッセージに<code>now throttling indexing</code>と表示されていたり、<a href="http://www.elasticsearch.org/guide/en/marvel/current">Marvel</a>でのセグメント数が増加しているを見た場合、マージが遅れているとわかります。Marvelは<a href="http://www.elasticsearch.org/guide/en/marvel/current/#_node_amp_index_statistics">Index Statistics dashboard</a>の<code>MANAGEMENT EXTENDED</code>の部分にセグメント数をプロットしており、それは、非常にゆっくりと指数対数的に増加しており、大きなマージが終了したところがのこぎりの歯のような形で見て取れます。</p>

<p><img src="http://www.elasticsearch.org/content/uploads/2014/09/segmentCounts.png" title="セグメント数" ></p>

<p>なぜマージが遅れるのでしょう？デフォルトでElasticsearchはすべてのマージの書き込みのバイト数をわずか20MB/secに制限しています。スピニングディスク（HDD）に対して、これはマージによって典型的なドライブのIOキャパシティを飽和させず、並列に検索を十分に実行させることを保証します。しかし、もし、インデキシング中に検索をしない場合や、検索性能がインデキシングのスループットよりも重要でない場合、インデックスの保存にSSDを使用している場合などは、<code>index.store.throttle.type</code>に<code>none</code>を設定して、マージの速度制限を無効化するべきです（詳細は<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-store.html">こちら</a>をご覧ください）。なおバージョン1.2以前には<a href="https://github.com/elasticsearch/elasticsearch/issues/6018">期待以上のマージIO制限の発生</a>といったバグが存在します。アップグレードを！</p>

<p>もし、不幸にもスピニングディスク（それはSSDと同等の並列なIOを扱えません）をまだ使っている場合、<code>index.merge.scheduler.max_thread_count</code>に<code>1</code>を設定しなければなりません。そうでない場合は、（SSDを支持する）デフォルト値が多くのマージを同時に実行させるでしょう。</p>

<p>活発に更新が行われているインデックスで<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-optimize.html"><code>optimize</code></a>を実行しないでください。それは、非常にコストの高い操作(すべてのセグメントをマージ)です。しかし、もし、インデックスにドキュメントを追加が終わった直後はオプティマイズのタイミングとしては良いタイミングです。それは、検索時のリソースを減らすからです。例えば、時間ベースのインデックスを持っており、新しいインデックスに日々のログを追加している場合、過去の日付のインデックスをオプティマイズするのは良い考えです。特に、ノードが多くの日付のインデックスを持っている場合です。</p>

<p>更にチューニングするための設定：</p>

<ul>
<li>実際に必要のないフィールドをオフにする。例えば<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-all-field.html"><code>_all</code>フィールドをオフ</a>。また、保持したいフィールドでは、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-core-types.html"><code>indexed</code>か<code>stored</code>かを検討する</a>。</li>
<li>もし、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-source-field.html"><code>_source</code>フィールドをオフ</a>にしたくなるかもしれないが、インデキシングコストは小さい(保存するだけで、インデキシングしない)、また、それは、将来の更新や、前のインデックスを再インデキシングするために非常に価値があり、それはディスク使用率の懸念事項がない限り、オフにする価値はあまりない。それは、ディスクが比較的安価であるので価値がない。</li>
<li>もし、インデックスされたドキュメントの検索までの遅延を許容できるなら、<code>index.refresh_interval</code>を<code>30s</code>に増やすか、<code>-1</code>を設定して、オフにする。これは、巨大なセグメントをフラッシュし、マージのプレッシャーを減らすことができる。</li>
<li><a href="http://www.elasticsearch.org/downloads/1-3-2/">Elasticsearch 1.3.2</a>(稀に、フラッシュ時に過度のRAMを使用するという<a href="https://github.com/elasticsearch/elasticsearch/issues/6443">問題</a>を<a href="https://github.com/elasticsearch/elasticsearch/issues/6379">修正した</a>)にアップグレードすることで、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-translog.html"><code>index.translog.flush_threshold_size</code></a>をデフォルト(200mb)から1gbに増加し、インデックスファイルのfsyncの頻度を減らす。
Marvelに<a href="http://www.elasticsearch.org/guide/en/marvel/current/#_node_amp_index_statistics"><code>Index Statistics dashboard</code></a>の<code>MANAGEMENT</code>にフラッシュの頻度がプロットされている。</li>
</ul>


<h2>インデックスバッファサイズ</h2>

<p>巨大なインデックスを構築中はレプリカ数を0にし、あとから、レプリカを有効にする。レプリカが0ということは、データを失った(ステータスがred)時に冗長性がないので、ノードの故障に注意すること。もし、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-optimize.html"><code>optimize</code></a>(ドキュメントの追加をすることがないので)を計画するなら、インデキシングが終わったあとで、レプリカを作成する前に実行するのが良いでしょう。レプリカはオプティマイズされたセグメントをコピーするだけになります。詳細は<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-update-settings.html">インデックス設定更新</a>を参照。</p>

<p>もし、ノードがヘビーなインデキシングを行っているだけなら、アクティブなシャードのインデキシングバッファに多くてい512MBを<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-indices.html">indices.memory.index_buffer_size</a>に与えてください。(超えてもインデキシングのパフォーマンスは一般的には改善されません。)Elasticsearchはその設定(Javaヒープのパーセンテージもしくはバイト数)を受けて、min_index_buffer_sizeとmax_index_buffer_sizeの値を前提にノードのアクティブシャードに均等に割り当てます；大きな値はLuceneが最初のセグメントをより大きくし、将来的なマージのプレッシャーを減らすことを意味します。</p>

<p>デフォルトは10%で、それで十分です；例えば、もし、5つのアクティブなシャードがノードにあり、ヒープが25GBの場合、各シャードは25GBの10%の1/5=512MB（すでに最大値）を持っています。ヘビーなインデキシングのあと、この設定をデフォルトに下げましょう。検索時のデータ構造のために十分なRAMを確保するために。この設定はまだ動的な設定変更はできません。<a href="https://github.com/elasticsearch/elasticsearch/issues/7045">Issueがここに</a>あります。</p>

<p>インデックスバッファによって現在利用されているバイト数は1.3.0の<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-stats.html">indices stats API</a>に追加されています。<code>indices.segments.index_writer_memory</code>の値を見ることができます。これはMarvelではまだプロットされていませんが、将来のバージョンで追加される予定です。しかし、自分でグラフに追加することもできます。(Marvelはデータは収集しています)</p>

<p>1.4.0では、<a href="https://github.com/elasticsearch/elasticsearch/issues/7440"><code>indices.segments.index_writer_max_memory</code></a>として、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-stats.html">indices stats API</a>にアクティブシャードにどのくらいのRAMバッファが割り当てられているかも表示されます。これらの値はインデックスのシャード事の値として見ることができ、<code>http://host:9200/&lt;indexName&gt;/_stats?level=shards</code>を使ってみることができます；これは、全シャードに対する合計と、各シャードごとのstatsを返すでしょう。</p>

<h2>オートIDの利用もしくは良いIDの利用</h2>

<p>もし、ドキュメントの<code>ID</code>がなんでも良い場合、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/docs-index_.html#_automatic_id_generation" title="">Elasticsearchで採番すること</a>ができます：これは、(1.2以降)ドキュメントIDをバージョンを探さずに保存できるように<a href="https://github.com/elasticsearch/elasticsearch/pull/5917">最適化</a>され、Elasticsearchの<a href="http://benchmarks.elasticsearch.org/">日毎のベンチマーク</a>で異なるパフォーマンスを見ることができます。(<code>Fast</code>と<code>FastUpdate</code>のグラフを比較)</p>

<p>もし、IDを自身が持っていて、自分の支配下で<a href="http://blog.mikemccandless.com/2014/05/choosing-fast-unique-identifier-uuid.html">Luceneに対して素早く選ぼうとしている</a>なら、1.3.2にアップグレードしましょう、IDのルックアップが<a href="https://github.com/elasticsearch/elasticsearch/issues/6212">さらにオプティマイズ</a>されています。Javaの<a href="http://docs.oracle.com/javase/7/docs/api/java/util/UUID.html">UUID.randomUUID()</a>はやめましょう。それは、セグメントに対してどのようにIDを割り当てるかという予測やパターン性がないため、最悪のケースで<a href="http://blog.mikemccandless.com/2014/05/choosing-fast-unique-identifier-uuid.html">セグメントごとのシーク</a>が発生します。</p>

<p><a href="http://boundary.com/blog/2012/01/12/flake-a-decentralized-k-ordered-unique-id-generator-in-erlang/">Flake IDs</a>を利用した時の<a href="http://www.elasticsearch.org/overview/marvel">Marvel</a>によるインデックス性能の違い：</p>

<p><img src="http://www.elasticsearch.org/content/uploads/2014/09/flakeIDsPerf.png" title="flakeIDsPerf" ></p>

<p>ランダムUUIDを利用した場合：</p>

<p><img src="http://www.elasticsearch.org/content/uploads/2014/09/uuidsPerf.png" title="uuidsPerf" ></p>

<p>次の1.4.0では、ElasticsearchのID自動採番を<a href="https://github.com/elasticsearch/elasticsearch/issues/5941">UUIDからFlake IDに変更</a>します。</p>

<p>もし、Luceneのローレベル操作がインデックスに対してなにをやっているかについて興味があるなら、<a href="https://github.com/elasticsearch/elasticsearch/issues/5891"><code>lucene.iw</code>をTRACEログレベルで出力できるように</a>してみましょう(1.2から利用可能)。これは、多くの出力がありますが、Luceneの<code>IndexWriter</code>レベルで何が起きているかを理解するのに非常に役に立ちます。出力は非常にローレベルです：<a href="http://www.elasticsearch.org/guide/en/marvel/current">Marvel</a>がインデックスに何が起きているかをよりリアルタイムにグラフを描画してくれます。</p>

<h2>スケールアウト</h2>

<p>我々は、単一シャード(Luceneインデックス)性能のチューニングに注目してきました。しかし、一旦それに満足できたならば、Elasticsearchはクラスタ全体にわたってインデキシングや検索を簡単にスケールアウトすることに長けています。シャード数(デフォルトでは5)を増やすのは可能です。それは、マシン全体に対して並列度、巨大なインデックスのサイズ、検索時のレイテンシの低下など得ることができます。また、レプリカを1位上にすることは、ハードウェア故障に対する冗長性を持つことを意味します。</p>

<p>最後に、このドキュメントを見ても問題解決しない場合は<a href="http://www.elasticsearch.org/community">コミュニティに参加</a>しましょう。例えば、<a href="https://groups.google.com/forum/?fromgroups#!forum/elasticsearch">ElasticsearchのユーザML</a>に投稿するなど。おそらく、修正すべきエキサイティングなバグがあるでしょう。(パッチも常に歓迎です！)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[サーバ/インフラエンジニア養成読本 ログ収集~可視化編 を手伝いました]]></title>
    <link href="http://blog.johtani.info/blog/2014/08/04/release-magazine-book-of-log-aggs-and-viz/"/>
    <updated>2014-08-04T21:54:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/08/04/release-magazine-book-of-log-aggs-and-viz</id>
    <content type="html"><![CDATA[<p>懲りずにまた、執筆してみました。みなさん「買って」から感想をいただけるとうれしいです！</p>

<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&nou=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=johtani-22&o=9&p=8&l=as1&m=amazon&f=ifr&ref=tf_til&asins=4774169838" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>




<!-- more -->


<h2>本書について</h2>

<p>共著者の方々のブログが詳しいので、そちらを読んでもらいつつ。
実際にログを収集して解析されている方々と一緒に書かせていただくことで色々と勉強させていただいています。</p>

<h3>共著者の方々のブログ</h3>

<ul>
<li><a href="https://twitter.com/suzu_v">@suzu_v</a>さん：<a href="http://suzuken.hatenablog.jp/entry/2014/07/18/084555">サーバ/インフラエンジニア養成読本 ログ収集~可視化編 を書きました</a></li>
<li><a href="https://twitter.com/yoshi_ken">@yoshi_ken</a>さん：<a href="http://y-ken.hatenablog.com/entry/published-elasticsearch-fluentd-kibana-book">ログ収集や可視化で話題のFluentd、Elasticsearch、Kibanaを徹底解説したムック本が発売となります</a></li>
<li><a href="https://twitter.com/harukasan">@harukasan</a>さん：<a href="http://blog.harukasan.jp/entry/2014/07/18/180351">書きました: サーバ/インフラエンジニア養成読本 ログ収集~可視化編</a></li>
</ul>


<h3>どの辺を書いたの？</h3>

<p>「特集３：Elasticsearch入門」（なんか、入門ばっかりだなぁ）を書かせていただきました。
データストア入門ということで、ほんとうに簡単な他のデータストアを説明し、Elasticsearchってどんなものかを単語の説明をしつつ紹介してみました。</p>

<p>Elasticsearch自体は多くの機能を持っており、それ単体で分厚い書籍がかけるので、ログ検索に関係ありそうな部分をピックアップしてみました。
あとは、運用時に気をつける点や便利なツール（Curatorなど）の紹介をしています。</p>

<p>また、Hadoopと合わせて利用してみたい、すでにHadoopにあるデータも活用してみたいという話もありそうだということで、<a href="https://github.com/elasticsearch/elasticsearch-hadoop">elasticsearch-hadoop</a>についても簡単ですが紹介してあります。</p>

<h2>その他感想</h2>

<p>個人的に、忙しい時期<a href="http://blog.johtani.info/blog/2014/07/01/join-elasticsearch/">（参考記事）</a>だったので、あんまり力になれてないので大変申し訳なく思っています。。。
ただ、素晴らしい出来（カラーでKibanaの解説が日本語で読めたり、Fluentdの逆引きのリストがあったり、ログを貯めて可視化する意義を説明してあったり）です。</p>

<p>ぜひ、読んだ感想をいただければと！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[プロキシ環境でのpluginコマンドの実行]]></title>
    <link href="http://blog.johtani.info/blog/2014/08/01/plugin-using-under-proxy-env/"/>
    <updated>2014-08-01T15:24:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/08/01/plugin-using-under-proxy-env</id>
    <content type="html"><![CDATA[<p>Proxy環境で働いている方も結構いると思います。
Twitter上で、Elasticsearchのpluginコマンドでプラグインがインストールできなくて困っている方がいたので、
調べてみたのでメモしておきます。</p>

<!-- more -->


<h2>プラグインコマンド</h2>

<p>Elasticsearchでは、プラグインという形でいくつかの便利な機能が公開されています。
<a href="https://github.com/elasticsearch/elasticsearch-analysis-kuromoji">形態素解析ライブラリのKuromoji</a>を使うためのプラグインや、<a href="https://github.com/lmenezes/elasticsearch-kopf">クラスタの管理がGUIで可能なkopf</a>プラグインなどがあります。
公式、サードパーティいろいろです。</p>

<p>これらのプラグインをElasticsearchにインストールする場合、以下のコマンドを実行すれば
自動的にダウンロードして<code>plugins</code>ディレクトリにインストールしてくれます。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./bin/plugin -i elasticsearch/elasticsearch-analysis-kuromoji/2.3.0</span></code></pre></td></tr></table></div></figure>


<p>ここで、<code>elasticsearch/elasticsearch-analysis-kuromoji/2.3.0</code>がプラグインのパスになります（例では、<code>提供元/プラグイン名/プラグインバージョン</code>となっています。）。</p>

<p>この<code>plugin</code>コマンドがダウンロード元にアクセスに行くのですが、プロキシ環境だとプロキシの設定が必要になります。</p>

<h2>プロキシの指定（Mac/LinuxとWindowsでの違い）</h2>

<h3>Mac/Linux(shコマンド)</h3>

<p><a href="http://blog.johtani.info/blog/2013/09/03/ja-wikipedia-with-kuromoji/">以前の記事</a>でプロキシのポート番号などの指定方法を
以下のように説明していました。
（※昔の記事のため、kuromojiプラグインのバージョンが古いです）</p>

<p>ElasticsearchのpluginコマンドはJavaで実装されています。（org.elasticsearch.common.http.client.HttpDownloadHelper）
プラグインのダウンロードには、java.net.URL.openConnection()から取得URLConnectionを使用しています。</p>

<p>ですので、pluginのインストールを行う際に、Proxy環境にある場合は以下のようにコマンドを実行します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./bin/plugin -DproxyPort=ポート番号 -DproxyHost=ホスト名 -i elasticsearch/elasticsearch-analysis-kuromoji/1.5.0</span></code></pre></td></tr></table></div></figure>


<p>LinuxやMacの環境であれば、こちらのコマンドでプロキシの指定が可能です。
ただし、Windows環境ではうまくいきません。</p>

<p>Elasticsearchは、環境の違いにより、ダウンロードするファイルが異なります。
Windows環境の方は、zipファイルをダウンロードしてもらうようになっています。
elasticsearchコマンドおよびpluginコマンドがbat形式で提供されているのがzipファイルとなるからです。</p>

<h3>Windows(batコマンド)</h3>

<p>Windows環境では次のように指定します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>set JAVA_OPTS="-DproxyHost=ホスト名 -DproxyPort=ポート番号"
</span><span class='line'>bin\plugin -i elasticsearch/elasticsearch-analysis-kuromoji/2.3.0</span></code></pre></td></tr></table></div></figure>


<p>コマンドの実装方法が少し異なるために、このようになっています。</p>

<h2>まとめ</h2>

<p>プロキシ環境で利用される場合は、プラグインコマンドは上記のように実行していただければと。</p>

<p>公式ガイドには、これらの情報を追記するPRを送る予定です。
また、WindowsのコマンドでもMac/Linuxと同様にできたほうがいい気がするので、Issueをあげようと思います。</p>

<p>不明点などあれば、コメントいただければと。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 1.3.1 リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/07/29/elasticsearch-1-3-1-release/"/>
    <updated>2014-07-29T12:22:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/07/29/elasticsearch-1-3-1-release</id>
    <content type="html"><![CDATA[<p><a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-1-released/">原文：Elasticsearch 1.3.1 Released</a>を日本語に翻訳したものです。</p>

<p>バグフィックス版のElasticsearch 1.3.1をリリースしました。
ダウンロードおよび変更履歴は<a href="http://www.elasticsearch.org/downloads/1-3-1/">Elasticsearch 1.3.1</a>からお願いいたします。</p>

<!-- more -->


<p>このリリースはインデックスリカバリ時の後方互換性バグ（<a href="https://github.com/elasticsearch/elasticsearch/pull/7055">#7055</a>）への対応です。
このバグは<strong>データの欠損は起こりません。</strong> Elasticsearch 1.3.1へアップグレードすることで問題を回避できます。
このバグは、以下のElasticsearchのバージョンで作成されたセグメントを含むインデックスを1.3.0へアップグレードしようとすると発生します。</p>

<ul>
<li>Elasticsearch 0.90.7</li>
<li>Elasticsearch 0.90.2</li>
<li>Elasticsearch 0.90.0以前のバージョン</li>
</ul>


<p>このバグは、これらの古いインデックスをレプリカからリカバリできなくします。
これらのバージョンのセグメントを持つインデックスが、レプリカは可能ですが、
ステータスがYellowのままGreenに決してなりません。
ログには次のようなExceptionが発生します。</p>

<blockquote><p>IllegalArgumentException[No enum constant org.apache.lucene.util.Version.x.x.x]</p></blockquote>

<p>Luceneの特定のバージョンではLuceneのマイナーバージョンを含んでおらず、誤ったバージョン番号がセグメントに記録されました。
<a href="https://issues.apache.org/jira/browse/LUCENE-5850">LUCENE-5850</a>のチケットがこの問題に対処するためにオープンされています。
この問題は我々の後方互換テストで見つかるべき問題ですが、Luceneで不足しているため発見されませんでした。
テストスイートは今後の可能性のために改良されます。</p>

<p>このリリースはその他に、Aggregationのマイナーバグフィックスも含まれています。
詳細は<a href="http://www.elasticsearch.org/downloads/1-3-1/">リリースノート</a>をご覧ください</p>

<p><a href="http://www.elasticsearch.org/downloads/1-3-1/">Elasticsearch 1.3.1</a>をダウンロードし、試してください。
もし問題を見つけた場合は<a href="https://github.com/elasticsearch/elasticsearch/issues">GitHubのIssues</a>へご報告をお願いいたします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Curator 1.2および1.1について]]></title>
    <link href="http://blog.johtani.info/blog/2014/07/28/curator-2-0-and-1-1/"/>
    <updated>2014-07-28T14:19:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/07/28/curator-2-0-and-1-1</id>
    <content type="html"><![CDATA[<p><a href="http://www.elasticsearch.org/blog/curator-1-2-0-released/">Curatorの1.2.0がリリース</a>されました。</p>

<p><a href="http://blog.johtani.info/blog/2014/01/24/curator-tending-your-time-series-indices-in-japanese/">前回のCuratorの記事</a>が古くなってしまった（1.1.0からコマンドのI/Fが変更された）ので
1.1.0および1.2.0に関する記事を翻訳しておきます。</p>

<p>ちなみに、<a href="https://github.com/elasticsearch/curator/">Curator</a>とは、Elasticsearchに時系列のインデックス（例：LogstashやFluentdでログを保存）を保存している場合にそれらのインデックスを管理（削除したり、クローズしたり）するための便利なツールです。
Curatorの概要については、<a href="https://github.com/elasticsearch/curator/">GitHubリポジトリ</a>か<a href="http://blog.johtani.info/blog/2014/01/24/curator-tending-your-time-series-indices-in-japanese/">前回の記事</a>をご覧ください。</p>

<!-- more -->


<h1>Curator 1.1.0リリース (2014/06/13公開)<a name="curator_v110"/></h1>

<p>元記事：<a href="http://www.elasticsearch.org/blog/elasticsearch-curator-version-1-1-0-released/">elasticsearch curator - version 1.1.0 released</a></p>

<p>Elasticsearch 1.0.0がリリースされ、新しい機能、Snapshot &amp; Restoreが利用できるようになりました。
Snapshotはある時点でのインデックスの写真を撮るように、バックアップを作成することができます。
1.0.0が発表されてすぐに、この機能に関するリクエストが寄せられるようになりました。
「Curatorにスナップショットを追加して！」もしくは「いつCuratorでスナップショットが使えるようになる？」といった感じです。
これがあなたの要望なら、それはついに叶えられました。しかも他の追加機能も一緒にです。</p>

<h2>新機能</h2>

<p>Curatorの新機能は以下のとおりです。</p>

<ul>
<li>新CLI構造</li>
<li>スナップショット(Snapshot)</li>
<li>エイリアス(Aliases)</li>
<li>パターンによる除外インデックス指定</li>
<li>配置ルーティング(Allocation Routing)</li>
<li>インデックスとスナップショットの表示</li>
<li>リポジトリ管理(個別のスクリプトによる)</li>
<li><a href="https://github.com/elasticsearch/curator/wiki">ドキュメントWiki</a></li>
</ul>


<h3>新コマンドライン構造</h3>

<p><strong>注意</strong>：コマンドライン構造の変更とは、Curator 1.1.0以前のcron記述が動作しないことを意味します。Curator 1.1.0にアップグレードする場合はコマンドも修正が必要となるので注意してください。</p>

<p>シンプルにするために、<em>commands</em>という概念を追加しました。
また、ヘルプの出力もわかりやすくなっています。
前のバージョンと同じタスクをCuratorは実行できますが、異なるフォーマットを用いるようになりました。</p>

<p>旧コマンド：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator -d 30</span></code></pre></td></tr></table></div></figure>


<p>新コマンド：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator delete --older-than 30</span></code></pre></td></tr></table></div></figure>


<p>コマンドは、フラグとは異なりハイフンを前に付けないことに注意してください。
また、似たような名前のフラグがあることに気をつけてください。
例えば、<code>--older-than</code>フラグは多くのコマンドに利用できます。
指定される値は各ケースにおいて同一です。「指定された数よりも古いインデックス」となります。</p>

<p>新しいコマンドのリストは次のとおりです。</p>

<ul>
<li>alias</li>
<li>allocation</li>
<li>bloom</li>
<li>close</li>
<li>delete</li>
<li>optimize</li>
<li>show</li>
<li>snapshot</li>
</ul>


<p>コマンドのヘルプは次のコマンドで表示されます。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator [COMMAND] --help</span></code></pre></td></tr></table></div></figure>


<p>コマンドに関係あるフラグがすべて表示されます。</p>

<h3>スナップショット(snapshots)</h3>

<p><code>snapshot</code>コマンドで、存在しているリポジトリにインデックスのスナップショットを保存することができます。</p>

<p>Curatorはインデックス毎に1つのスナップショットを作成し、インデックスから名前をつけます。
例えば、インデックスの名前が<code>logstash-2014.06.10</code>の場合、スナップショットの名前は<code>logstash-2014.06.10</code>となります。
指定した条件を元に、シーケンシャルに、1つずつインデックスのスナップショットを作成していきます。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator snapshot --older-than 20 --repository REPOSITORY_NAME</span></code></pre></td></tr></table></div></figure>


<p>このコマンドは、20日以上古いインデックスすべてのスナップショットを作成し、<code>REPOSITORY_NAME</code>で指定されたリポジトリに保存します。</p>

<p><code>es_repo_mgr</code>と呼ばれるリポジトリ作成を支援するスクリプトがCuratorには含まれています。
ファイルシステムおよびS3タイプのリポジトリ両方の作成を支援します。</p>

<p>さらに、古いインデックスのスナップショットを取ることができることに加えて、Curatorは最新のインデックスをアップロードする方法も提供します。
これは、<a href="http://www.elasticsearch.org/overview/marvel/">Elasticsearch Marvel</a>のインデックスをアップロードするときに便利です。
トラブルシューティングを目的として、パフォーマンスデータを他の人に見せる場合などです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator snapshot --most-recent 3 --prefix .marvel- --repository REPOSITORY_NAME</span></code></pre></td></tr></table></div></figure>


<p>このコマンドでは、最新の3つのMarvelインデックスのスナップショットを指定されたリポジトリに保存できます。</p>

<h3>エイリアス(aliases)</h3>

<p>Curatorはすでに存在するエイリアスにインデックスを追加することも、削除することもできるようになりました。
ただし、エイリアスがすでに存在している必要があります。エイリアスの作成はできません。</p>

<p><code>last_week</code>という前の一週間のインデックスのエイリアスを保持していること想像してください。
この場合、次の2つのコマンドを利用することで、エイリアスを管理できます。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator alias --alias-older-than 7 --alias last_week
</span><span class='line'>curator alias --unalias-older-than 14 --alias last_week</span></code></pre></td></tr></table></div></figure>


<p>新しく作られたインデックスが<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-templates.html#indices-templates">インデックステンプレート</a>によって
自動的にエイリアスの一部となるようにElasticsearchに設定しておくと、さらに便利です。
この場合、新しいインデックスが自動的に<code>this_week</code>というエイリアスの一部になるようにしてあれば、以下のコマンドのみとなります。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator alias --unalias-older-than 7 --alias this_week</span></code></pre></td></tr></table></div></figure>


<p><code>this_week</code>と<code>last_week</code>のエイリアスのアップデートを保持できます。</p>

<h3>パターンによる除外(exclude pattern)</h3>

<p>時には、指定したインデックスを操作から除外したくなる場合もあるでしょう。
ここまでは、プレフィックスや日付によって選択されたインデックスのみを対象にしてきました。
そこで、<code>--exclude-pattern</code>オプションです。これは、指定したインデックスを除いて処理を行うことができます。</p>

<p><code>logstash-2014.06.11</code>というインデックスを決して削除したくないとします。
この場合、次のコマンドのようになります。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator delete --older-than 15 --exclude-pattern 2014.06.11</span></code></pre></td></tr></table></div></figure>


<p>Curatorはデフォルトで<code>logstash-</code>というプレフィックスにマッチしますが、<code>2014.06.11</code>というインデックスは対象外となります。</p>

<h3>配置ルーティング(allocation routing)</h3>

<p>Elasticsearchはノードにタグを付けることができます。
これらのタグはインデックスやシャードをクラスタのどこに配置するかをコントロールするために役立ちます。
一般的なユースケースだと、高性能なSSDドライブを持ったノードをインデキシングのために、ハードディスクを持った性能の低いマシンは検索頻度が低い古いインデックスを配置するといった場合です。
この場合、HDDノードには、<code>elasticsearch.yml</code>に<code>node.tag: hdd</code>、SSDノードには<code>node.tag: ssd</code>と設定されているべきです。
Curatorはこの時、インデックスをタグに基づいてオフピークの時間帯に再配置させることができます。</p>

<p>コマンド：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator allocation --older-than 2 --rule tag=hdd</span></code></pre></td></tr></table></div></figure>


<p><code>index.routing.allocation.require.tag=hdd</code>という設定が２日よりも古いインデックスに適用されます。
これは、インデックスのシャードが<code>node.tag: hdd</code>というノードに再配置される必要があると、Elasticsearchに伝えます。</p>

<h3>インデックスとスナップショットの表示(show indices and snapshots)</h3>

<p>これは、単にあなたの持っているインデックスやスナップショットがどんなものかを表示します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator show --show-indices</span></code></pre></td></tr></table></div></figure>


<p>これは、デフォルトプレフィックスの<code>logstash-</code>にマッチするすべてのインデックスを表示します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator show --show-snapshots --repository REPOSITORY_NAME</span></code></pre></td></tr></table></div></figure>


<p>これは、指定されたリポジトリにある、デフォルトプレフィックスの<code>logstash-</code>にマッチするすべてのスナップショットを表示します。</p>

<h3>リポジトリ管理(repository management)</h3>

<p>前に説明したとおり、<code>es_repo_mgr</code>と呼ばれるヘルパースクリプトをCuratorは含んでいます。
現時点では、<code>fs</code>と<code>s3</code>タイプをサポートしています。
リポジトリを作る前に利用したいタイプのドキュメントを読むようにしてください。
例えば、<code>fs</code>タイプのリポジトリを各ノードで使う場合は、同じ共有ファイルシステムに、同じパスでアクセスできなければなりません。
パスの指定は<code>--location</code>です。</p>

<p><code>fs</code>タイプリポジトリの作成</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>es_repo_mgr create_fs --location '/tmp/REPOSITORY_LOCATION' --repository REPOSITORY_NAME</span></code></pre></td></tr></table></div></figure>


<p>削除</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>es_repo_mgr delete --repository REPOSITORY_NAME</span></code></pre></td></tr></table></div></figure>


<h3>ドキュメントWiki</h3>

<p><a href="https://github.com/elasticsearch/curator/wiki">Curatorのドキュメント</a>が更新され、オンラインにWiki形式でだれでも更新できるようになっています。
コマンドやフラグのより詳細の情報はこちらで見つけることができます。また、もし、興味があれば、ドキュメントを追加することもできます。</p>

<h2>インストールと更新</h2>

<p>Curator 1.1.0は<a href="https://pypi.python.org/pypi?%3Aaction=pkg_edit&amp;name=elasticsearch-curator">PyPi</a>リポジトリにあります。
インストールは以下のとおりです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pip install elasticsearch-curator</span></code></pre></td></tr></table></div></figure>


<p>バージョン1.0.0からアップグレードする場合は以下のとおりです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pip uninstall elasticsearch-curator
</span><span class='line'>pip install elasticsearch-curator</span></code></pre></td></tr></table></div></figure>


<p>バージョン1.0.0よりも古いバージョンからのアップグレードは以下のとおりです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pip uninstall elasticsearch-curator
</span><span class='line'>pip uninstall elasticsearch
</span><span class='line'>pip install elasticsearch-curator</span></code></pre></td></tr></table></div></figure>


<p><code>pip uninstall elasticsearch</code>で、古いパイションモジュールをを削除します。
適切なバージョンが依存関係により再インストールされます。</p>

<h2>まとめ</h2>

<p>Curatorの新機能は素晴らしいです！このリリースは大きな改善です。
もし、トラブルや足りないものを見つけた場合は<a href="http://github.com/elasticsearch/curator/issues">GitHub Issue</a>に報告してください。
また、Curatorが便利だと思ったら、私たちに伝えてください。<code>#elasticsearch</code>タグを付けてツイートしてください！</p>

<p>Curatorはまだ、始まったばかりです。Curator 2.0のロードマップを作業中です。ここまで読んでいただきありがとうございます。
Happy Curating!</p>

<hr />

<h1>Curator 1.2.0リリース(2014/07/24)</h1>

<p>元記事：<a href="http://www.elasticsearch.org/blog/curator-1-2-0-released/">curator 1.2.0 released</a></p>

<p><a href="#curator_v110">Curator v1.1.0</a>のリリースから、数週間が経ちました。
私たちは、Curator 1.2.0をリリースしました。</p>

<h2>新機能(new features)</h2>

<ul>
<li>ユーザ指定の日付パターン：長い間リクエストされていた機能</li>
<li>ウィークリーインデックスのサポート：これも長い間リクエストされていた機能</li>
<li>複数の<a href="https://github.com/elasticsearch/curator/wiki/Logformat">ログフォーマット</a>オプション：Logstashフォーマットが利用可能</li>
</ul>


<p>これらの変更は<a href="https://github.com/elasticsearch/curator/wiki">Curatorドキュメント</a>にも記載されています。</p>

<h2>更新(updates)</h2>

<ul>
<li>ログ出力の整理：デフォルトのログ出力を整理しました。デバッグログはすべて表示されます。</li>
<li>ドライランのログ出力の詳細化：テスト実行時に何が起きたかをわかりやすくしました。</li>
</ul>


<h2>日付パターンと<code>--timestring</code>(date patterns and &ndash;timestring)</h2>

<p>前のリリースで、セパレータ文字を利用して、インデックス名のエレメントを分離することで、日付を計算しました。
この設計の決定は、プログラムが管理するために設計されたLogstashのインデックスを使うのには簡単でした。
しかし、Curatorは時系列インデックス管理に成長しています。これは、異なる命名規則のインデックスを意味しています。</p>

<p>また、インターバルによって、日付の計算が必要になる場合もあります。
<code>--time-unit</code>オプションが残っており、<code>weeks</code>という単位を指定することもできます。
デフォルトの<code>--timestring</code>オプションは、以前のコマンドと同様の動作をしなければなりません。次のようになります。</p>

<table>
<thead>
<tr>
<th> Time Unit </th>
<th> Timestring </th>
</tr>
</thead>
<tbody>
<tr>
<td> days      </td>
<td> <code>%Y.%m.%d</code></td>
</tr>
<tr>
<td> hours     </td>
<td> <code>%Y.%m.%d.%H</code></td>
</tr>
<tr>
<td> weeks     </td>
<td> <code>%Y.%W</code></td>
</tr>
</tbody>
</table>


<p>これが意味するものは、もし、単位に<code>hours</code>をした場合、<code>--timestring</code>を指定しなかった場合は<code>%Y.%m.%d.%H</code>となります。
これは、<a href="https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior">Pythonのstrftimeフォーマット</a>で&#8221;年.月.日.時&#8221;を意味します。
同様に、<code>weeks</code>を単位に指定した場合、Curatorはデフォルトの<code>--timestring</code>は<code>%Y.%W</code>となります。</p>

<p>この機能は、日付の間にセパレーター文字のないインデックスでも機能します。
例えば、<code>production-20140724</code>のような日時インデックスがある場合、2日よりも古いインデックスに対する<a href="https://github.com/elasticsearch/curator/wiki/Disable-Bloom-Filter-Cache">ブルームフィルタっキャッシュのオフ</a>のコマンドは次のようになります。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator bloom --prefix production- --older-than 2 --timestring %Y%m%d</span></code></pre></td></tr></table></div></figure>


<p>この例で、デフォルトの単位は<code>days</code>であることに注意してください。<code>hourly-2014072414</code>のような時間インデックスの場合は次のようになります。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator bloom --prefix hourly- --older-than 2 --time-unit hours --timestring %Y%m%d%H</span></code></pre></td></tr></table></div></figure>


<h2><code>--separator</code>の置き換え</h2>

<p>もし、Curatorの前のバージョンでカスタムセパレータ文字を利用していた場合、次のように変更すべきです。
前のコマンドで<code>cerberus-2014-07-24</code>のようなインデックスがある場合、コマンドを<code>--separator -</code>の用に置き換える必要があります。
新しいコマンドは次のとおりです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator delete --prefix cerberus- --older-than 30 --timestring %Y-%m-%d</span></code></pre></td></tr></table></div></figure>


<p>年(<code>％Y</code>)と月(<code>%m</code>)と日(&lsquo;%d&rsquo;)の間にセパレータ文字を置くだけです。</p>

<p>これは、また、Curatorで以前は不可能であったことをできるようにもします。
異なるセパレータ文字の混在です。
<code>logs-2014.07.24-14</code>というようなインデックスを処理するときに<code>--timestring</code>は<code>%Y.%m.%d-%H</code>のようになります.</p>

<p><code>--timestring</code>の詳細は<a href="https://github.com/elasticsearch/curator/wiki/Timestring">Curatorのドキュメント</a>をご覧ください。</p>

<h2>フィードバック</h2>

<p>これらの新しい機能はユーザのコメントやリクエストから来ています。もし、機能のリクエストやバグを発見したら、<a href="https://github.com/elasticsearch/curator/issues">こちら</a>まで連絡してください。</p>

<p>また、Twitterでもお待ちしています。私たちのTwitter IDは<code>@elasticsearch</code>です。</p>

<p>Happy Curating!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第5回Elasticsearch勉強会を開催しました。#elasticsearchjp]]></title>
    <link href="http://blog.johtani.info/blog/2014/07/19/hold-on-5th-elasticsearch-jp/"/>
    <updated>2014-07-19T21:52:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/07/19/hold-on-5th-elasticsearch-jp</id>
    <content type="html"><![CDATA[<p><a href="http://elasticsearch.doorkeeper.jp/events/12028">第5回Elasticsearch勉強会</a>を開催しました。
遅くなってしまいましたが、まとめてみました。</p>

<p>今回は、Elasticsearchに入って初の勉強会でした。タイミングが良いことに、Honza、Igor、Shayの3名がトレーニングのために
来日していたため、特別回ということにして、話をしてもらいました。</p>

<p>そして、<a href="http://samuraism.com/">サムライズム</a>の<a href="https://twitter.com/yusuke">@yusuke</a>さんにテキスト翻訳してもらいました。
早くて正確なタイピング＋翻訳、本当にありがとうございました。</p>

<p>開場提供していただいた<a href="http://recruit-tech.co.jp">リクルートテクノロジーズさん</a>、ありがとうございました！
次回もよろしくお願いします！
参加していただき盛り上げていただいた参加者の皆さんもありがとうございました。</p>

<blockquote class="twitter-tweet" lang="ja"><p>amazing turnout to the elasticsearch at Tokyo <a href="https://twitter.com/hashtag/elasticsearchjp?src=hash">#elasticsearchjp</a> <a href="http://t.co/Aa88eVf5dF">pic.twitter.com/Aa88eVf5dF</a></p>&mdash; Shay Banon (@kimchy) <a href="https://twitter.com/kimchy/statuses/488686274375843841">2014, 7月 14</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>




<!-- more -->


<p>動画があとで、アップされる予定です。お楽しみに。</p>

<h2>Honza&rsquo;s talk</h2>

<ul>
<li>djangoの開発者！であり、ElasticsearchのPythonクライアント、Curatorの開発者</li>
<li>Python Clientを利用しながら、ライブコーディングのような形で説明する方法が新鮮</li>
<li>Aggregationの便利さについての説明</li>
<li>Python Clientがクエリを組み立てるのにすごく便利そうだった</li>
<li>Pythonユーザが結構いたので助かりましたｗ</li>
</ul>


<h2>Igor&rsquo;s talk</h2>

<p>スライド：<a href="https://speakerdeck.com/imotov/elasticsearch-data">elasticsearch data/</a></p>

<ul>
<li>Snapshot/Restoreの開発などを行っている開発者</li>
<li>Elasticsearchのデータ、ディレクトリ構造に関するお話</li>
<li>シャードの話から、ディレクトリ構造、メタデータに関する説明</li>
<li>transaction logの挙動の説明</li>
<li>検索のフェーズの説明</li>
</ul>


<p>Igorは、実は私がElasticsearch社の人とコンタクトがとれた最初の人だと思います。
第1回Elasticsearch勉強会が開催する当日に帰国されるという不運だったのですが、1年越しでトークしてもらえました！</p>

<blockquote class="twitter-tweet" lang="ja"><p><a href="https://twitter.com/johtani">@johtani</a> I am so bummed! I am leaving Tokyo Thursday morning.</p>&mdash; Igor Motov (@imotov) <a href="https://twitter.com/imotov/statuses/372340973121986560">2013, 8月 27</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


<h2>QA</h2>

<p>ShayをメインにいくつかのQAをしてもらいました。
NetflixなどのMeetupの動画で見てたのですが、こんな形で日本でも実現できるとは。</p>

<ul>
<li>Q: なんで、ファイルデスクリプタの設定を大きくするの？

<ul>
<li>A: Luceneのインデックスは複数のセグメントから構成されている。メモリに作られたあと、ファイルにfsyncされる。</li>
</ul>
</li>
<li>Q: KibanaでAggregation使いたいんだけど？

<ul>
<li>A: Kibana 4で対応するよ！異なるフィールドの値を1つのグラフにすることも出来るよ！</li>
</ul>
</li>
<li>Q: なんでElasticsearch作ったの？

<ul>
<li>A: 暇だったからｗ奥さんのレシピ検索を作ってみようと思って作り始めて、Luceneを触って感動して。。。検索すげー、Compassってのを触ってこれもすごいと思いつつ、もっとLucene活用できるんじゃないかということでElasticsearch作ったんだ。奥さんのレシピ検索？まだ完成してないよｗ</li>
</ul>
</li>
<li>Q: 2000くらいスナップショット撮ったらパフォーマンスが悪くなっててなんで？

<ul>
<li>A: 差分でスナップショットを作るんだけど、差分の計算に昔のスナップショットを見るので、定期的に新しくしたほうがいい。もし、気になることがあったらIssue上げたりMLに投げてくれるとうれしい。<br/>
（あとでちょっと聞いたけど、古いスナップショットを消すのも有効っぽい。差分でスナップショットを作るけど、昔のを消した場合は、新しいスナップショットが利用しているファイルは残る仕組みになっているから。）</li>
</ul>
</li>
<li>Q: Relevancyのチューニングってどうすればいい？ドキュメントが少なくない？

<ul>
<li>A: ドキュメンテーションは頑張ってるので、応援してねｗあとは、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/guide/current/index.html">definitive guide</a>も参考になるよ。スコアはfunction_scoreクエリがすごいのでいろいろ使ってね。MVELをGroovyに帰る予定。性能もだけど、サンドボックス的な意味もあります。</li>
</ul>
</li>
<li>Q: 次のVisionは？現時点は検索だけど。（最後の質問がとてもナイスで、助かりましたｗ私がしたほうがいい気がするｗｗ）

<ul>
<li>A: 今後はアナリティクスのプラットフォームに向かってる。Aggregationとかね。メモリ効率よくしたりしてるよ。あとは、Field-collapsionも実装中だよ。あと、マシンラーニングとかもね。データを探索するための機能を色々作ってくよ。障害性にも。チェックサム機能をLuceneに入れて、ESにも入れていく予定。Zenの機能も改善している。</li>
</ul>
</li>
</ul>


<h2>まとめ</h2>

<p>今週は、トレーニングがあったり、いろいろな打ち合わせがあったりと、テンパってたので至らない点が多かったかもしれないですが。。。
楽しんでいただけと思います。
数日、Shay、Honza、Igorと行動を共にして、本当に情熱のあるチームでユーザのことを気にかけているなと感じることができました。
少しでもその片鱗を勉強会で感じてもらえたんじゃないかと。特に、QAでのShayによる情熱が伝わったんじゃないかと。</p>

<p>懇親会でも数人の方から、日本語のサポートを望んでいるという声も頂きました。
興味のある方は私までコンタクトいただければと。</p>

<p>あと、@yusukeさんのテキスト翻訳が素晴らしくて、参加してもらった方たちも絶賛してました。
次回も英語スピーカーの場合に助けてもらえると嬉しいです（私もそこまで出来るように頑張ります）</p>

<h2>その他のブログ</h2>

<p>ブログ記事ありがとうございます！</p>

<ul>
<li><a href="http://arika.hateblo.jp/entry/2014/07/15/011241">第5回elasticsearch勉強会にいってきました - はやさがたりない。</a></li>
<li><a href="http://blog.yoslab.com/entry/2014/07/15/073000">感想戦：aggrigation から見える検索エンジンの次 - 第5回 Elasticsearch勉強会 - よしだのブログ</a></li>
<li><a href="http://uchimanajet7.hatenablog.com/entry/2014/07/15/114632">「第5回elasticsearch勉強会 #elasticsearch #elasticsearchjp」（2014年07月14日）の参加メモ - uchimanajet7のメモ</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[転職しました]]></title>
    <link href="http://blog.johtani.info/blog/2014/07/01/join-elasticsearch/"/>
    <updated>2014-07-01T11:30:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/07/01/join-elasticsearch</id>
    <content type="html"><![CDATA[<p>ということで、転職しました。
どーしてもやりたいことが出てきたので、無理を言って転職することにしてみました。</p>

<!-- more -->


<p><a href="http://samuraism.com">サムライズム</a>ではなく、<a href="http://www.elasticsearch.com">Elasticsearch</a>にジョインします。（というか、しました。）</p>

<blockquote class="twitter-tweet" lang="ja"><p>初出社 <a href="https://twitter.com/hashtag/%E3%82%B5%E3%83%A0%E3%83%A9%E3%82%A4%E3%82%BA%E3%83%A0?src=hash">#サムライズム</a></p>&mdash; Jun Ohtani (@johtani) <a href="https://twitter.com/johtani/statuses/483793778541465600">2014, 7月 1</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>冗談でツイートしたのですが、その前に英語アカウントのツイートがRTされてしまっていまいちでした。。。</p>

<p><img src="http://blog.johtani.info/images/entries/20140701/schiphol.jpg" title="スキポール空港" ></p>

<p>先週、アムステルダムに行っていたのも退職前に休みをいただき、Elasticsearchの全社会議に参加していたためです。
とてもエキサイティングな経験（英語漬けとか）ができ、もっと精進しないとなという気持ちにもなり、ますます頑張らないとなと。</p>

<p>ということで、今後は日本中にElasticsearchやLogstash、Kibanaを広めるべく、いろいろな場所で話をしたいと思います。
興味のある方は、声をかけていただければと。</p>

<p>あと、東京で<a href="http://purchases.elasticsearch.com/class/elasticsearch/core-elasticsearch/tokyo/2014-05-20">ElasticsearchのCoreトレーニング</a>が行われます。
通常は2日間ですが、通訳の方が付く関係で3日間の開催となっています。
開発者2名がトレーナーとして来日します。開発者に質問をできる良い機会ですので、興味のある方は参加してみてはいかがでしょうか。
<strong>また、CTOのShay Banonも来日する予定です。</strong></p>

<p>トレーナー2名とShayは<a href="http://elasticsearch.doorkeeper.jp/events/12028">7/14の勉強会</a>でも話をしてくれます。
こちらも興味のある方は参加してみてください。（参加登録はこの後、すぐに開始します。）</p>

<p>まだまだ、勉強しなければいけないことだらけですが、ElasticsearchのいろいろなプロダクトやOSSについて広めていきたいと思いますので、よろしくお願いいたします。</p>

<h2>おまけ</h2>

<p>ということで、一度やってみたかったのでリンクを貼ってみます。</p>

<p><a href="http://www.amazon.co.jp/registry/wishlist/29EMX20UN9P16">ほしい物リストはこちら</a></p>
]]></content>
  </entry>
  
</feed>
