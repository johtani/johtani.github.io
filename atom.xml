<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[@johtaniの日記 2nd]]></title>
  <link href="http://blog.johtani.info/atom.xml" rel="self"/>
  <link href="http://blog.johtani.info/"/>
  <updated>2014-11-19T14:46:12+09:00</updated>
  <id>http://blog.johtani.info/</id>
  <author>
    <name><![CDATA[johtani]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[第7回Elasticsearch勉強会を開催しました。#elasticsearchjp]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/19/hold-on-7th-elasticsearch-jp/"/>
    <updated>2014-11-19T11:19:07+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/19/hold-on-7th-elasticsearch-jp</id>
    <content type="html"><![CDATA[<p><a href="http://elasticsearch.doorkeeper.jp/events/16837">第7回Elsticsearch勉強会</a>を開催しました。
スタッフの皆さん、スピーカーの皆さん、開場提供していただいた<a href="http://recruit-tech.co.jp">リクルートテクノロジーズさん</a>、ありがとうございました！
次回もよろしくお願いします！参加していただき盛り上げていただいた参加者の皆さんもありがとうございました。</p>

<p>昨日も紹介しましたが、<a href="http://qiita.com/advent-calendar/2014/elasticsearch">Elasticsearch Advent Calendar 2014</a>を用意してみました。まだ、空きがありますので、登録お待ちしております！</p>

<!-- more -->


<p>今回は出足が好調で、早々に180人の枠を超えるという嬉しい事態でした。
最終的な参加人数は130名程度で、懇親会参加者が50名弱といったところです。</p>

<h2>「Kibana4」</h2>

<h3>Elasticsearch Inc. Jun Ohtani @johtani</h3>

<p>スライド：<a href="https://speakerdeck.com/johtani/kibana4">Kibana4</a></p>

<p>ということで、Kibana4の紹介と、Kibana4のBeta2を利用したデモを行いました。
デモの開始のところで少し環境がうまく動いてなくて手間取ってしまいましたが。。。</p>

<p>発表で1点だけ修正があります。JRubyを選択しているのがElasticsearchのライブラリを使用するためという説明をしましたが、
こちらは、Logstashに関する話でした。Kibana4は現時点では、ElasticsearchへのProxyとしての動作が主なものとなります。Rubyでも動作可能です。
bin/kibanaについてはJavaを使った起動になります。
参考：<a href="https://github.com/elasticsearch/kibana/tree/master/src/server">https://github.com/elasticsearch/kibana/tree/master/src/server</a></p>

<p>発表でも主張しましたが、ダウンロードして、Elasticsearchを用意すれば簡単に動作させることが可能です。
ぜひ、ローカルで試して見てもらえればと思います。
今回のデモのデータを入れるのに利用したLogstashの設定などについては、ブログで記事を書こうと思います。</p>

<h2>niconicoの検索を支えるElasticsearch</h2>

<h3>株式会社ドワンゴ 伊藤 祥 さん</h3>

<p>スライド：<a href="https://speakerdeck.com/shoito/niconico-elasticsearch">niconicoの検索を支えるElasticsearch</a></p>

<ul>
<li>リアルタイム検索の実現、新しい検索への対応</li>
<li>検索のアーキテクチャとか。</li>
<li>Capistranoでデプロイとかを管理</li>
<li>1.4.1が出たら、クラスタを更新予定</li>
</ul>


<p>ということで、実際に導入した話から、現在の運用の仕方、クラスタのアップグレードなど多岐にわたる内容でおもしろかったです。
遭遇した問題点とかもあったので。
Marvel便利なのでぜひ導入を検討してもらえればw</p>

<h2>Elasticsearch at CrowdWorks </h2>

<h3>株式会社クラウドワークス 九岡 佑介 さん @mumoshu</h3>

<p>スライド：<a href="http://www.slideshare.net/mumoshu/20141118-es">Elasticsearch at CrowdWorks</a></p>

<ul>
<li>会社の紹介</li>
<li>仕事が検索対象</li>
<li>検索時間が1桁減少！</li>
<li>Graceful Degradationで失敗したら、InnoDB FTSで代替：<a href="https://github.com/crowdworks/gracefully">Gracefully</a></li>
<li><a href="http://www.found.no">found.no</a>のサービスを利用</li>
<li>elasticsearch-modelの拡張を作成してOSSとして公開：<a href="https://github.com/crowdworks/elasticsearch-model-extensions">elasticsearch-model-extensions</a></li>
</ul>


<p>Gracefullyで切り替えとかは面白いなと思いました。
検索での利用の話でしたが、他のシーンでも使えそうですよね。
日本にFoundユーザがいるのも初めて知りました。
彼らの開発者ブログも質の良い情報が載っているので、参考になりますよね。</p>

<p>次は、どんなMappingで運用しているのかとか、どういった工夫をしているかといった点を詳しく聞きたいなと思いました。
またお待ちしております。</p>

<h2>1分で作るElasticsearchプラグイン</h2>

<h3>株式会社エヌツーエスエム 菅谷 信介 さん</h3>

<p>スライド：<a href="http://www.slideshare.net/shinsuke/plugins-ates7">Elasticsearchプラグインの作り方</a></p>

<ul>
<li>プラグインの作り方とか。</li>
<li>十数個のプラグインの紹介。プラグインはこちらで公開中。<a href="https://github.com/codelibs/">https://github.com/codelibs/</a></li>
<li>実際に、業務で必要なものから作成</li>
<li>まだまだ作りたいものがある</li>
</ul>


<p>コミュニティ還元できるものはPR送ってもらえるとうれしいです。
前よりは体制も増えてるので、PRも目にとまるようになってるはずです。</p>

<p>あとは、使ってみたいと思う方も多数いると思うので、ぜひ、OSSなので、貢献しましょう！
フィードバックがあるだけで、OSS活動やってるものにとってはやる気につながると思いますし。</p>

<h2>LT：GISとして活用するElasticsearch </h2>

<h3>船戸 隆さん</h3>

<p>スライド：<a href="https://speakerdeck.com/tfunato/gistositehuo-yong-suruelasticsearch">GISとして活用するElasticsearch </a></p>

<ul>
<li>java-jaからIngressの青（Registance）の勧誘に来られた方w</li>
<li>APIをハックして、情報を取得し、Kibanaで可視化</li>
<li>残念ながら、APIが変更されて見れなくなったらしい。</li>
</ul>


<p>Ingress実際にやったことはないのですが、おもしろそうでした。
発表される方の会社の採用紹介ではなく、Ingressの勧誘をされるとは想定外でしたw</p>

<p>興味のあるデータをKibanaで可視化するのも面白い例だと思うので、活用してもらえればと思います。</p>

<h2>その他、感想などのブログ</h2>

<p>適当に見つけたブログを列挙してあります。これもあるよ！などあれば、教えてください。</p>

<ul>
<li><a href="http://blog.yoslab.com/entry/2014/11/18/203159">勉強会メモ - 第7回elasticsearch勉強会</a></li>
<li><a href="http://qiita.com/t-sato/items/940ccfa9e4a668b91967">第7回elasticsearch勉強会 #elasticsearch #elasticsearchjp</a></li>
</ul>


<h2>まとめ</h2>

<p>JJUGの時とは違い、Elasticsearch勉強会ではさすがに、企業としてのElasticsearchの知名度が高かったのはありがたいことでした。
自分の発表のために始めた勉強会でもありますが、まだまだ、発表するときは緊張しますし、分かりにくいんじゃないかなぁと思うことも多々あります。
この辺がわかりにくかった、この辺をもっと知りたいなど、フィードバックをお待ちしております。</p>

<p>冒頭にも書きましたが、<a href="http://qiita.com/advent-calendar/2014/elasticsearch">Elasticsearch Advent Calendar 2014</a>の登録をお待ちしております。どんなことでも歓迎なので、Elasticsearch、Kibana、Logstashなどについて書いてもらえるとうれしいです。</p>

<p>次回ももちろん2ヶ月後くらいに行います。 スピーカー募集中ですので、コメント、メール、ツイートなど、コンタクトしていただければと思います。 よろしくお願いいたします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 1.4.0および1.3.5リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/11/06/elasticsearch-1-4-0-ja/"/>
    <updated>2014-11-06T01:30:33+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/11/06/elasticsearch-1-4-0-ja</id>
    <content type="html"><![CDATA[<p><strong>※この記事は次のブログを翻訳したものになります。</strong></p>

<p>原文：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-released/">elasticsearch-1.4.0 and 1.3.5 released</a></p>

<p>本日、<strong>Lucene 4.10.2</strong>をベースにした<strong>Elasticsearch 1.4.0</strong>と、バグフィックスリリースである、<strong>Elasticsearch 1.3.5</strong>をリリースしました。
ダウンロードおよび変更リストはそれぞれ次のリンクからアクセスできます。</p>

<ul>
<li>最新ステーブルリリース：<a href="http://www.elasticsearch.org/downloads/1-4-0">Elasticsearch 1.4.0</a></li>
<li>1.3.x系バグフィックス：<a href="http://www.elasticsearch.org/downloads/1-3-5">Elasticsearch 1.3.5</a></li>
</ul>


<p>1.3ブランチに関する過去のリリースについてのブログは次のとおりです：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-4-released/">1.3.4</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-3-released/">1.3.3</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-2-released/">1.3.2</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-1-released/">1.3.1</a>, <a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-0-released/">1.3.0</a>.</p>

<!-- more -->


<p>Beta1リリースでも言及しましたが、1.4.0の主なテーマは<em>resiliency(復元性、弾力性)</em>です。
Elasticsearchをより安定し信頼性のあるものにし、メモリ管理を改善し、ディスカバリアルゴリズムを改善し、破損したデータの検知を改善しました。
Beta1リリースからのハイライトも含んでいます。</p>

<ul>
<li>Doc values (インデックス時にディスクに保存される<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/fielddata-formats.html#fielddata-formats">fielddata</a>)がヒープ利用率を激減</li>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-fielddata.html#request-circuit-breaker">Request circuit breaker</a>:
メモリを消費しすぎる検索リクエストの中断</li>
<li>Bloom filterの<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-update-settings.html#codec-bloom-load">デフォルト無効</a>、高速なインデキシングのためにもはや必要とされないため。</li>
<li>ノードディスカバリ、シャードリカバリの数多くのバグフィックス及び改善</li>
<li>データ破損の早期検知のためのチェックサムのさらなる利用</li>
<li>GroovyをMVELの代わりに<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/modules-scripting.html#modules-scripting">デフォルトスクリプト言語に</a></li>
<li>CORSを<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/modules-http.html#_settings_2">デフォルト無効</a>に。XSS攻撃防止の為。</li>
<li><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-shard-query-cache.html#index-modules-shard-query-cache">クエリキャッシュ</a>、変更されていないシャードからすぐにaggregation結果を返す</li>
<li>新しいAggregation：<code>filter</code>(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-filters-aggregation.html#search-aggregations-bucket-filters-aggregation">ドキュメント</a>)、<code>children</code>(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-children-aggregation.html#search-aggregations-bucket-children-aggregation">ドキュメント</a>)、<code>scripted_metric</code>(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-metrics-scripted-metric-aggregation.html#search-aggregations-metrics-scripted-metric-aggregation">ドキュメント</a>)</li>
<li>新しい<code>GET /index</code>API。インデックスのsettings、mappings、warmers、aliasesを1回のリクエストで返却(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-get-index.html#indices-get-index">ドキュメント</a>)</li>
<li>自動付与ドキュメントIDのためのFlake ID。プライマリキーの探索パフォーマンスの改善。</li>
<li>ドキュメントに変更のない更新によるドキュメントの再インデックスの防止</li>
<li><code>function_score</code>クエリの関数で<code>weight</code>パラメータによる個別の改善を可能に。(<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/query-dsl-function-score-query.html#_weight">ドキュメント</a>)</li>
</ul>


<p>詳細については<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-beta-released/">1.4.0.Beta1のブログ(英語)</a>(<a href="http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja/">日本語訳</a>)をご覧ください。</p>

<p>Beta1以降の1.4.0の変更の全てについては、<a href="http://www.elasticsearch.org/downloads/1-4-0">1.4.0 release notes</a>でご覧いただけます。
以下では、2つの主な変更について紹介します。</p>

<h2>HTTP Pipelining</h2>

<p>HTTP pipeliningは複数のリクエストを1回のコネクションで、関連するレスポンスを待つことなく送信することができます。
そして、レスポンスは、受け取ったリクエストと同じ順序で返却されます。
HTTP/1.1の仕様で、pipeliningのサポートが必要です。ElasticsearchはHTTP/1.1であるとしてきましたが、pipeliningはサポートしていませんでした。この問題は.NETユーザで問題を引き起こしました。</p>

<p>現在、HTTP pipeliningは公式にサポート済みで、デフォルトで利用できます。<a href="https://github.com/elasticsearch/elasticsearch/pull/8299">#8299</a>をご覧ください。</p>

<h2>Upgrade API</h2>

<p>Luceneのすべてのリリースではバグフィックスや最適化が提供されます。しかし、多くのユーザは古いバージョンのLuceneで作成されたインデックスを持っており、より最新の改善による利点を利用できないことがあります。
新しい<code>upgrade</code>APIは、あなたのインデックスすべてもしくは一部を最新のLuceneフォーマットに透過的にアップグレードできます。</p>

<p><code>GET _upgrade</code>リクエストは、インデックスのアップグレードが必要かどうかを提示し、アップグレードに必要なセグメントのサイズをリポートすることによって、どのくらいの時間が必要かの目安を提供します。
<code>POST _upgrade</code>コマンドはバックグラウンドでインデックスを最新のLuceneフォーマットに書き換えます。</p>

<p>より詳しい情報は<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-upgrade.html"><code>upgrade</code>APIドキュメント</a>をご覧ください。</p>

<h2>試してみてください。</h2>

<p>Beta1リリースを利用し、経験・体験を報告していただいたベータテスターの方々に感謝します。
1.4.0がこれまでの最高のリリースになると確信しています。
ぜひ、<a href="http://www.elasticsearch.org/downloads/1-4-0">Elasticsearch 1.4.0</a>をダウンロードして、試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/elasticsearch/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[validate APIの利用]]></title>
    <link href="http://blog.johtani.info/blog/2014/10/27/how-to-use-validate-api/"/>
    <updated>2014-10-27T18:42:31+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/10/27/how-to-use-validate-api</id>
    <content type="html"><![CDATA[<p>久しぶりに翻訳ではないブログを。書こうと思いながらかけてなかったので。。。</p>

<p>今回は<a href="http://www.elasticsearch.org/guide/ep/elasticsearch/reference/current/search-validate.html">validate API</a>の紹介です。</p>

<!-- more -->


<h2>背景</h2>

<p>Elasticsearchのクエリは<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl.html">Query DSL</a>というJSONで
クエリを定義できるものを提供しています。
これは、様々な<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl-queries.html">クエリ</a>、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl-filters.html">フィルタ</a>を定義するために必要です。</p>

<p>自分の望んでいる条件を記述するために、JSONのネストと格闘することも必要となります。。。
また、クエリ、フィルタには様々なパラメータが用意されています。
これらのパラメータをすべて覚えるのは無理でしょうし、タイプミスなどもありますよね。
タイプミスやカッコのミスマッチなどで格闘して1時間が経過してしまったなどもあると思います。</p>

<p>そんな時に便利なAPIとして用意されているのが<a href="http://www.elasticsearch.org/guide/ep/elasticsearch/reference/current/search-validate.html">validate API</a>です。</p>

<h2>利用方法</h2>

<p>APIが用意されています。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>http://ホスト名:ポート番号/インデックス名/タイプ名/_validate/query</span></code></pre></td></tr></table></div></figure>


<p><code>インデックス名</code>や<code>タイプ名</code>は省略可能ですが、マッピングが異なると思うので、タイプ名まで指定するほうが良いと思います。
上記のAPIに対してクエリを送信するだけです。</p>

<h3>クエリの確認</h3>

<p>たとえば、<a href="https://gist.github.com/johtani/08dee5fb4da62037ef9e">こちらのGist</a>にあるようなマッピングのインデックスに対して
検索クエリを組み立てていて、エラーが出るとします。
※このクエリは<code>match_all</code>のところを<code>match_al</code>と、<code>l</code>が1文字足りないクエリになっています。</p>

<p><strong><em>検索クエリのリクエスト（エラーあり）</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_search
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "match_al": {}
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>実行結果のレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "error": "SearchPhaseExecutionException[Failed to execute phase [query], all shards failed; shardFailures {[rwkb01chTZq2V7FD0Tlwrw][pref_aggs][0]: SearchParseException[[pref_aggs][0]: from[-1],size[-1]: Parse Failure [Failed to parse source [{\n  \"query\": {\n    \"match_al\": { }\n  }\n}\n]]]; nested: QueryParsingException[[pref_aggs] No query registered for [match_al]]; }{[rwkb01chTZq2V7FD0Tlwrw][pref_aggs][1]: SearchParseException[[pref_aggs][1]: from[-1],size[-1]: Parse Failure [Failed to parse source [{\n  \"query\": {\n    \"match_al\": { }\n  }\n}\n]]]; nested: QueryParsingException[[pref_aggs] No query registered for [match_al]]; }]",
</span><span class='line'>   "status": 400
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>とこんなかんじで、エラーが帰っては来るのですが、非常に読みづらいです。</p>

<p>そこで、<code>validate API</code>を利用します。
リクエスト先を<code>/_search</code>から<code>/_validate/query</code>に変更します。</p>

<p><strong><em>validate API</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_validate/query
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "match_al": {}
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": false,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>すると、非常にシンプルな結果が返ってきます。
<code>"valid": false</code>となっているため、クエリに問題があることがわかります。</p>

<h3>エラーの詳細</h3>

<p>問題がある事自体はわかりましたが、エラーの内容も知りたいですよね？
その場合は、<code>explain</code>というパラメータを追加します。
（正しくは<code>explain=true</code>を追加しますが、<code>=true</code>を省略可能です。）</p>

<p><strong><em>validate API(explainあり、クエリ自体は省略)</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_validate/query?explain
</span><span class='line'>{...}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": false,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "pref_aggs",
</span><span class='line'>         "valid": false,
</span><span class='line'>         "error": "org.elasticsearch.index.query.QueryParsingException: [pref_aggs] No query registered for [match_al]"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><code>explanations</code>という項目が追加されました。
ここに<code>error</code>という項目として、エラーの詳細が返ってきます。<code>_search</code>の時よりも見やすいですね。
今回のエラーは、<code>match_all</code>が正しいクエリですの、<em><code>match_al</code>というクエリは登録されていないというエラー</em>でした。
では、クエリを修正して実行しましょう。</p>

<p><strong><em>validate API(エラー無し)</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET pref_aggs/_validate/query?explain
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "match_all": {}
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": true,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "pref_aggs",
</span><span class='line'>         "valid": true,
</span><span class='line'>         "explanation": "ConstantScore(*:*)"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>今度はクエリに問題はありません。<code>"valid": true</code>です。
そして、<code>explanations</code>の項目には、<code>error</code>の代わりに<code>explanation</code>という項目が返ってきました。
これが、実際にElasticsearch内部で実行されるクエリになります。</p>

<h3>実際のクエリに利用される単語の確認</h3>

<p>この機能はこの他に、クエリの解析にも利用できます。
思ったとおりに検索にヒットしない場合があって、困ったことはないですか？
フィールドに指定されたアナライザによっては、単語を変形したりするものが存在します。</p>

<p><strong><em>サンプルマッピング</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>PUT /validate_sample
</span><span class='line'>{
</span><span class='line'>  "mappings": {
</span><span class='line'>    "several_analyzer": {
</span><span class='line'>      "properties": {
</span><span class='line'>        "title": {"type": "string"},
</span><span class='line'>        "body_ja": {"type": "string", "analyzer": "kuromoji"},
</span><span class='line'>        "body_en": {"type": "string", "analyzer": "english"}
</span><span class='line'>      }
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>例えば、このように<code>kuromoji</code>、<code>english</code>、デフォルト(<code>standard</code>)アナライザを利用したマッピングがあるとします。
このフィールドに対して<code>powerful</code>という単語で検索したとします。</p>

<p><strong><em>validate API</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET /validate_sample/_validate/query?explain
</span><span class='line'>{
</span><span class='line'>  "query": {
</span><span class='line'>    "multi_match": {
</span><span class='line'>      "fields": ["body_en","body_ja","title"],
</span><span class='line'>      "query": "powerful"
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>この場合、レスポンスは次のとおりです。</p>

<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": true,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "validate_sample",
</span><span class='line'>         "valid": true,
</span><span class='line'>         "explanation": "(title:powerful | body_en:power | body_ja:powerful)"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><code>title</code>、<code>body_ja</code>については入力された単語がそのままクエリとして利用されています。
<code>body_en</code>については、<code>power</code>という単語に変換されて実行されています。
これは、<code>english</code>アナライザがステミングを行った結果がクエリとして利用されるという意味です。
また、<code>powerful</code>を<code>秋葉原</code>といった日本語に変更して実行すると次のようになります。
日本語は<code>standard</code>アナライザなどでは、1文字ずつ区切られてしまうことがわかります。</p>

<p><strong><em>validate APIのレスポンス</em></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>   "valid": true,
</span><span class='line'>   "_shards": {
</span><span class='line'>      "total": 1,
</span><span class='line'>      "successful": 1,
</span><span class='line'>      "failed": 0
</span><span class='line'>   },
</span><span class='line'>   "explanations": [
</span><span class='line'>      {
</span><span class='line'>         "index": "validate_sample",
</span><span class='line'>         "valid": true,
</span><span class='line'>         "explanation": "((title:秋 title:葉 title:原) | (body_en:秋 body_en:葉 body_en:原) | ((body_ja:秋葉 body_ja:秋葉原) body_ja:原))"
</span><span class='line'>      }
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>このように、クエリの単語がどのような単語に変換されてクエリに利用されているかなども知ることが可能です。</p>

<p>また、クエリを組み立てて、ヒットするはずが、0件となってしまうという場合にも、どのようなクエリが組み立てられているかを確認するという点で、
<code>validate API</code>が役立ちます。
検索がヒットするが、望んだクエリになっていないのでは？という場合は<code>_search API</code>の<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-request-explain.html"><code>explain</code>パラメータ</a>を
利用すれば、クエリの構成がわかるのですが、検索結果が0件の場合はクエリの構成は表示されません。</p>

<h2>解決できない問題は？</h2>

<p>便利なvalidate APIですが、以下の問題に対しては残念ながら確認できません。</p>

<ul>
<li><code>query</code>以外の項目のvalidate不可

<ul>
<li>たとえば、<code>_search API</code>の<code>size</code>などの項目についてはチェックできないです。</li>
</ul>
</li>
<li>存在しないフィールドの指定

<ul>
<li>上記<code>validate_sample</code>のマッピングの例でクエリに<code>body_eng</code>という存在しないフィールドを指定してもエラーとはなりません。</li>
</ul>
</li>
</ul>


<h2>まとめ</h2>

<p>書いたクエリがうまく動かない、JSONのタグがおかしいといった場合は、
まずはこの<code>validate API</code>で確認してみるのがオススメです。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sonatypeのバージョン番号で困ったので]]></title>
    <link href="http://blog.johtani.info/blog/2014/10/15/versioning-of-sonatype/"/>
    <updated>2014-10-15T15:26:08+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/10/15/versioning-of-sonatype</id>
    <content type="html"><![CDATA[<p><a href="http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja/">Elasticsearch 1.4.0.Beta1がリリース</a>されました。</p>

<p>個人で<a href="https://github.com/johtani/elasticsearch-extended-analyze">elasticsearch-extended-analyze</a>というプラグインを開発してます。
こちらも1.4.0.Beta1に対応するべく作業をしてて、少し戸惑ったことがあったので、メモをば。</p>

<!-- more -->


<p>ここ最近はプラグインのバージョン番号をElasticsearchのバージョン番号と同じものを利用していました。
（プラグインの機能追加をサボってる？？）
その時に、<code>1.4.0.Beta1</code>という番号を指定したのですが、意味不明なエラーに悩まされてしまいまして。</p>

<p>プラグインのリリースでは、以下のコマンドを実行します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ mvn release:prepare
</span><span class='line'>$ mvn release:perform</span></code></pre></td></tr></table></div></figure>


<p>最初のコマンド（prepare）で、パッケージングを実施し、Githubにリリースタグを打ったバージョンがpushされます。
次のコマンド（perform）で、パッケージングされたzipファイルがsonatypeのサイトに公開するためにアップロードされます。</p>

<p><code>1.4.0.Beta1</code>というバージョン文字列を利用した場合、prepareは問題なく実行できたのですが、
performで以下の様なエラーが返ってきました。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Return code is: 401, ReasonPhrase: Unauthorized.</span></code></pre></td></tr></table></div></figure>


<p>バージョン番号が<code>1.3.0</code>では特に問題はなかったのですが、、、
結局、バージョン番号を<code>1.4.0-beta1</code>に変更すると問題なくリリースが完了しました。</p>

<p>mike_neckさんと話をしていて、<a href="http://semver.org">Semantic Versioning</a>に関係しているのかなぁという話にはなったのですが、
詳しく調べていません。。。</p>

<p>そのうち調べようかなぁ。。。。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[elasticsearch 1.4.0.Beta1のリリース]]></title>
    <link href="http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja/"/>
    <updated>2014-10-02T19:14:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/10/02/elasticsearch-1-4-0-beta-released-ja</id>
    <content type="html"><![CDATA[<p>※この記事は次のブログを翻訳したものになります。</p>

<p>原文：<a href="http://www.elasticsearch.org/blog/elasticsearch-1-4-0-beta-released/">elasticsearch 1.4.0.beta1 released</a></p>

<p>本日、<em>Lucene 4.10.1</em>をベースにした、<em>Elasticsearch 1.4.0.Beta1</em>をリリースしました。
<a href="http://www.elasticsearch.org/downloads/1-4-0-Beta1">Elasticsearch 1.4.0.Beta1</a>からダウンロードできます。
また、すべての変更点に関してもこちらをご覧ください。</p>

<!-- more -->


<p>1.4.0のテーマは<em>resiliency(復元性、弾力性)</em>です。
<em>resiliency</em>とはElasticsearchをより安定し信頼性のあるものにすることを意味します。
すべての機能が正常に機能している場合は信頼することは簡単です。
予想外のことが発生した時に難しくなります：ノードでout of memoryの発生、スローGCや重いI/O、ネットワーク障害、不安定なデータの送信によるノードのパフォーマンス低下など。</p>

<p>本ベータリリースは、resiliencyの主な3つの改善を含んでいます。</p>

<ul>
<li><a href="#memory-mgmt">メモリ使用量の低下</a>によるノードの安定性向上</li>
<li>discoveryアルゴリズムの改善による<a href="#cluster-stability">クラスタの安定性</a>向上</li>
<li><a href="#checksums">チェックサム</a>の導入による破損したデータの検知</li>
</ul>


<p>分散システムは複雑です。
決して想像できないような状況をシミュレーションするために、ランダムなシナリオを作成する広範囲なテストスイートを持っています。
しかし、無数のエッジケース(特殊なケース)があることも認識しています。
1.4.0.Beta1はこれまで私たちが行ってきた改善のすべてを含んでいます。
これらの変更を実際にテストしていただき、<a href="https://github.com/elasticsearch/elasticsearch/issues">何か問題があった場合は私たちに教えてください</a>。</p>

<h2><a name="memory-mgmt">メモリ管理</a></h2>

<p>ヒープ空間は限られたリソースです。
上限を32GBとし、利用可能なRAMの50%をヒープの上限にすることを推奨します。
この上限を超えた場合、JVMは圧縮したポインタを使用することができず、GCが非常に遅くなります。
ノードの不安定性の主な原因は遅いGCです。それは、次のようなことから発生します。</p>

<ul>
<li>メモリプレッシャー</li>
<li>スワップ(参照：<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/setup-configuration.html#setup-configuration-memory">memory settings</a>)</li>
<li>非常に大きなヒープ</li>
</ul>


<p>本リリースは、メモリ管理の改善し、（結果として）ノードの安定性を改善するいくつかの変更を含んでいます。</p>

<h3>doc values</h3>

<p>メモリの利用の最も大きなものの1つは<strong>fielddata</strong>です
aggregation、ソート、スクリプトがフィールドの値に素早くアクセスするために、フィールドの値をメモリにロードして保持します。
ヒープは貴重なため、1ビットも無駄にしないためにメモリ内のデータは高度な圧縮と最適化を行っています。
これは、ヒープスペース以上のデータをもつまでは、非常によく動作します。
これは、多くのノードを追加することによって常に解決できる問題です。
しかし、CPUやI/Oが限界に達してしまうずっと前に、ヒープ空間の容量に到達します。</p>

<p>最近のリリースは、<strong>doc values</strong>によるサポートがあります。
基本的に、doc valuesはin-memory fielddataと同じ機能を提供します。
doc valuesの提供する利点は、それらが、非常に少量のヒープ空間しか使用しない点です。
doc valuesはメモリからではなく、ディスクから読み込まれます。
ディスクアクセスは遅いですが、doc valuesはカーネルのファイルシステムキャッシュの利点を得られます。
ファイルシステムキャッシュはJVMヒープとはことなり、32GBの制限による束縛がありません。
ヒープからファイルシステムキャッシュにfielddataを移行することによって、より小さなヒープを使うことができます。これは、GCがより早くなり、ノードが更に安定することを意味します。</p>

<p>本リリースより前は、doc valuesはin-memory fielddataよりもかなり遅かったです。
本リリースに含まれる変更は、パフォーマンスをかなり向上させ、in-memory fielddataとほぼ同じくらいの速度になっています。</p>

<p>in-memory fielddataの代わりにdoc valuesを利用するために必要なことは、次のように新しいフィールドをマッピングすることです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>PUT /my_index
</span><span class='line'>{
</span><span class='line'>  "mappings": {
</span><span class='line'>    "my_type": {
</span><span class='line'>      "properties": {
</span><span class='line'>        "timestamp": {
</span><span class='line'>          "type":       "date",
</span><span class='line'>          "doc_values": true
</span><span class='line'>        }
</span><span class='line'>      }
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>このマッピングで、このフィールドに対するfielddataの利用は、メモリにフィールドをロードする代わりに、自動的にディスクからdoc valuesを利用します。
<em>注意：</em>現時点で、doc valuesはanalyzedな<code>string</code>フィールドはサポートしていません。</p>

<h3>request circuit breaker</h3>

<p>fielddata circuit breakerはfielddataによって利用されるメモリの上限を制限するために追加され、OOMEの最も大きな原因の1つを防ぎました。
そして、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-fielddata.html#request-circuit-breaker">リクエストレベルのcircuit-breaker</a>を提供するために、コンセプトを拡張しました。
これは、単一のリクエストによって使用されるメモリの上限を制限します。</p>

<h3>bloom filters</h3>

<p><a href="http://en.wikipedia.org/wiki/Bloom_filter">Bloom filters</a> はインデキシング(前のバージョンのドキュメントが存在するかどうかのチェックのため)や、
IDによるドキュメントの検索(ドキュメントを含むセグメントがどれかを決定するため)に関する重要な性能最適化を提供しました。
しかし、もちろんそれらはコスト（メモリ）を必要とします。
現在の改善は、bloom filterの必要性を取り除きました。
現在では、Elasticsearchはまだ、インデックス時にそれらを構築します(実世界の経験がテストシナリオにそぐわない場合に備えて)。
しかし、デフォルトではメモリにはロードされません。
すべてが予定通りに運べば、将来のバージョンで完全にこれらは除去します。</p>

<h2><a name="cluster-stability">クラスタの安定性</a></h2>

<p>クラスタの安定性向上のために私たちができる最も大きなことは、ノードの安定性の向上です。
もし、ノードが安定しておりタイミングよく反応すれば、クラスタが不安定になる可能性が大いに減少します。
私たちは不完全な世界に住んでいます。- 物事は予想外にうまく行きません。クラスタはデータを失うことなくこのような状況から回復できる必要があります。</p>

<p>私たちは、<code>improve_zen</code>ブランチ上で、Elasticsearchの障害からの復旧するための能力の向上に数ヶ月費やしてきました。
まず、複雑なネットワークレベルの障害を繰り返すためのテストを追加しました。
次に、各テストのための修正を追加しました。
そこには、より多くの行うことが存在します。しかし、私たちは、<a href="https://github.com/elasticsearch/elasticsearch/issues/2488">issue #2488</a>(&ldquo;分割が交差している場合、minimum_master_nodesはsplit-brainを防げない&rdquo;)に含まれる、ユーザが経験してきた大部分の問題を私たちは解決しました。</p>

<p>私たちはクラスタのresiliencyを非常に真剣に取り組んでいます。
私たちは、Elasticsearchが何ができるか、その上で何が弱点であるかを理解してほしいと思っています。
これを考慮して、私たちは<a href="http://www.elasticsearch.org/guide/en/elasticsearch/resiliency/current/index.html">Resiliency Status Document</a>を作成しました。
このドキュメントは、私たち(または私たちユーザ)が遭遇したresiliencyの問題の、何が修正済みで、何が修正されないまま残っているかを記録します。
このドキュメントを慎重に読み、あなたのデータを保護するために適切な方法を選択してください。</p>

<h2><a name="checksums">データ破損の検知</a></h2>

<p>ネットワークをまたいだシャードリカバリのチェックサムは、圧縮ライブラリのバグを発見する助けとなりました。
それは、バージョン1.3.2で修正済みです。
それ以来、私たちはElasticsearchのいたるところにチェックサムとチェックサムの確認を追加しました。</p>

<ul>
<li>マージ中に、あるセグメント内すべてのチェックサムの確認(<a href="https://github.com/elasticsearch/elasticsearch/issues/7360">#7360</a>)</li>
<li>インデックス再オープン時に、あるセグメント内の最も小さなファイルの完全な確認と、より大きなファイルの軽量な打ち切りチェック(<a href="https://issues.apache.org/jira/browse/LUCENE-5842">LUCENE-5842</a>)</li>
<li>トランザクションログからイベントを再生するとき、各イベントはチェックサムを確認される(<a href="https://github.com/elasticsearch/elasticsearch/issues/6554">#6554</a>)</li>
<li>シャードのリカバリ中もしくは、スナップショットからのリストア中にElasticsearchはローカルファイルとリモートのコピーが同一であるか確認する必要がある。ファイルの長さとチェックサムのみを使うのは不十分であることが確認された。このため、現在はセグメントのすべてのファイルの同一性を確認(<a href="https://github.com/elasticsearch/elasticsearch/issues/7159">#7159</a>)</li>
</ul>


<h2>その他のハイライト</h2>

<p><a href="http://www.elasticsearch.org/downloads/1-4-0-Beta1">Elasticsearch 1.4.0.Beta1のchangelog</a>に本リリースの多くの機能、改善、バグフィックスについて読むことができます。
ここでは、特筆すべきいくつかの変更について述べます。</p>

<h3>groovyによるmvelの置き換え</h3>

<p>Groovyは現在、デフォルトのscripting languageです。
以前のデフォルトはMVELで、古くなってきており、サンドボックス内で実行できないという事実は、セキュリティ問題でした。
Groovyはサンドボックスであり(それは、ボックスの外へは許可が必要)、メンテナンスされており、速いです！
詳しくは<a href="http://www.elasticsearch.org/blog/scripting/">scriptingについてのブログ記事</a>をご覧ください。</p>

<h3>デフォルトでcorsはオフ</h3>

<p>Elasticsearchのデフォルト設定はクロスサイトスクリプティングに対して脆弱でした。
私たちはデフォルトで<a href="http://en.wikipedia.org/wiki/Cross-origin_resource_sharing">CORS</a>をオフにすることで修正しました。
Elasticsearchにインストールされたサイトプラグインはこれまで同様に機能します。
しかし、CORSを再度オンにすることがない限り、外部のウェブサイトがリモートのクラスタにアクセスすることはできません。
ウェブサイトがあなたのクラスタにアクセス可能に制御できるように、さらに<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/modules-http.html#_settings_2">CORS settings</a>を追加しました。
詳しくは<a href="http://www.elasticsearch.org/community/security">security page</a>をご覧ください。</p>

<h3>クエリキャッシュ</h3>

<p>新しい試験的な<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/index-modules-shard-query-cache.html">shardレベルのクエリキャッシュ</a>は、静的なインデックスのアグリゲーションをほとんど即座に反応できます。
ウエブサイトのアクセスの日毎のページビュー数を見るダッシュボードを持っていると想像してみてください。
これらの数値は古いインデックスでは変更がありません。しかし、アグリゲーションはダッシュボードのリフレッシュのたびに再計算されます。
新しいクエリキャッシュを利用すると、シャードのデータが変更されない限り、アグリゲーションの結果はキャッシュから直接返却されます。
キャッシュから古い結果を決して取得することはありません。それは、常に、キャッシュされていないリクエストと同じ結果を返します。</p>

<h3>新しいaggregations</h3>

<p>3つの新しいaggregationsがあります。</p>

<ul>
<li><p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-filters-aggregation.html"><code>filters</code></a></p>

<ul>
<li>これは<code>filter</code> aggregationの拡張です。複数のバケットを定義し、バケット毎に異なるフィルタを利用できます。</li>
</ul>
</li>
<li><p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-bucket-children-aggregation.html"><code>children</code></a></p>

<ul>
<li><code>nested</code>アグリゲーションの親子版。<code>children</code> aggは親のドキュメントに属する子のドキュメントを集計できる</li>
</ul>
</li>
<li><p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/search-aggregations-metrics-scripted-metric-aggregation.html"><code>scripted_metric</code></a></p>

<ul>
<li>このaggregationは、データによって計算されたメトリックを完全にコントロールできます。これは、初期化フェーズ、ドキュメント収集フェーズ、shardレベル結合フェーズ、global reduceフェーズを提供します。</li>
</ul>
</li>
</ul>


<h3>get /index api</h3>

<p>以前、ある1つのインデックスのaliases、mappings、settings、warmersを取得出来ました。しかし、それらを個別にです。
<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/indices-get-index.html"><code>get-index</code> API</a> はこれらのすべてもしくは一部を、複数もしくはひとつのインデックスに対して一緒に取得できます。
これは、既存のインデックスと同一もしくはほぼ同一であるインデックスを作成したいときに非常に役に立ちます。</p>

<h3>登録と更新</h3>

<p>ドキュメントの登録と更新にいくつかの改善があります。</p>

<ul>
<li>現在、ドキュメントIDの自動生成のために<a href="http://boundary.com/blog/2012/01/12/flake-a-decentralized-k-ordered-unique-id-generator-in-erlang">Flake ID</a>を使用しています。これは、プライマリキー探索時に素晴らしい性能向上を提供します。</li>
<li><code>detect_noop</code>に<code>true</code>を設定すると、ドキュメントに変更を与えない更新が軽量になります。この設定を有効にすると、<code>_source</code>フィールドのコンテンツを変更する更新リクエストだけ、ドキュメントの新しいバージョンを書き込みます。</li>
<li>更新はスクリプトから完全に操作できます。以前は、スクリプトはドキュメントがすでに存在しているときだけ実行可能で、それ以外は、<code>upsert</code>ドキュメントで登録しました。<code>script_upsert</code>パラメータでスクリプトから直接ドキュメントの作成が操作できます。</li>
</ul>


<h3>function score</h3>

<p>すでに非常に便利な<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/1.4/query-dsl-function-score-query.html"><code>function_score</code>クエリ</a>が、新しく<code>weight</code>パラメータをサポートします。
これは、それぞれの指定された関数の影響をチューニングするのに使われます。
これは、人気度よりも更新日時により重みをかけたり、地理情報よりも価格により重みをかけるといったことを可能にします。
また、<code>random_score</code>機能はセグメントマージによる影響を受けません。これにより、より一貫した順序が提供されます。</p>

<h2>試してみてください。</h2>

<p>ぜひ、<a href="http://www.elasticsearch.org/downloads/1-4-0-Beta1">Elasticsearch 1.4.0.Beta1</a>をダウンロードして、試してみてください。
そして、感想をTwitter(<a href="https://twitter.com/elasticsearch">@elasticsearch</a>)などで教えて下さい。
また、問題がありましたら、<a href="https://github.com/elasticsearch/elasticsearch/issues">GitHub issues page</a>で報告をお願いします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第6回Elasticsearch勉強会を開催しました。#elasticsearchjp]]></title>
    <link href="http://blog.johtani.info/blog/2014/09/17/hold-on-6th-elasticsearch-jp/"/>
    <updated>2014-09-17T13:22:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/09/17/hold-on-6th-elasticsearch-jp</id>
    <content type="html"><![CDATA[<p><a href="http://elasticsearch.doorkeeper.jp/events/13917">第6回Elsticsearch勉強会</a>を開催しました。
スタッフの皆さん、スピーカーの皆さん、開場提供していただいた<a href="http://recruit-tech.co.jp">リクルートテクノロジーズさん</a>、ありがとうございました！
次回もよろしくお願いします！参加していただき盛り上げていただいた参加者の皆さんもありがとうございました。
今回は、スタッフが私を含めて3，4名ということで、ドタバタしてしまってスミマセンでした。</p>

<!-- more -->


<p>今回はキャンセルが多く、最終的には90人弱の参加となりましたが、今回も多数の方にお集まりいただきありがとうございました。
同じ日に他の勉強会もあった影響でしょうか？</p>

<h2>「Aggregationあれこれ」Elasticsearch Inc. Jun Ohtani @johtani</h2>

<p>スライド：<a href="https://speakerdeck.com/johtani/aggregationarekore">Aggregationあれこれ</a></p>

<ul>
<li>ちょっと長かったですかね。。。</li>
<li>Aggregationの概要、内部動作、種類などを簡単に紹介してみました。</li>
<li>個々のAggregationもいろいろなオプションなどがあるので、色々と試してみていただければと思います。</li>
<li>アニメーション入りのスライドになってましたが、UpしてあるスライドはPDF版になります。</li>
</ul>


<h2>「秒間3万の広告配信ログをElasticSearchでリアルタイム集計してきた戦いの記録」 株式会社サイバーエージェント　山田直行さん　@satully</h2>

<p>スライド：<a href="http://www.slideshare.net/Satully/elasticsearch-study6threaltime20140916">秒間3万の広告配信ログをElasticSearchでリアルタイム集計してきた戦いの記録</a></p>

<ul>
<li>ディスプレイ広告配信DSPの話</li>
<li>システム: Fluentd、S3、Elasticsearch、Redis、MySQL</li>
<li>7月に秒間3万〜4万のリクエストをさばいている。</li>
<li>なぜElasticsearchを選んだのか、今の構成など</li>
<li>実際に苦労された点なども交えて話していただき面白かったです。</li>
<li>7月時点のお話ということで、現時点ではまた違う構成っぽかったので、また話を聞きたいなぁ。</li>
</ul>


<h2>「Elasticsearch 日本語スキーマレス環境構築と、ついでに多言語対応」ナレッジワークス株式会社　木戸国彦さん @9215</h2>

<p>スライド：<a href="https://speakerdeck.com/kunihikokido/elasticsearch-ri-ben-yu-sukimaresuhuan-jing-gou-zhu-to-tuideniduo-yan-yu-dui-ying">Elasticsearch 日本語スキーマレス環境構築と、ついでに多言語対応</a></p>

<ul>
<li>Dynamic TemplateやIndex Templateの説明</li>
<li>日本語や多言語化するときのMappingのサンプルになりそうなものがゴロゴロ紹介されてました。</li>
<li>いくつかの例があって、後で見直したいなと。</li>
<li>途中で出てきた、fielddata（インデックスに入っている単語区切りのデータ）を見るのに使ってたクエリは<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-request-fielddata-fields.html">field data fields</a>だったかな。</li>
</ul>


<h2>「elasticsearchソースコードを読みはじめてみた」@furandon_pig さん</h2>

<p>スライド：<a href="http://www.slideshare.net/furandon_pig/elasticsearch-39175134">elasticsearchソースコードを読みはじめてみた</a></p>

<ul>
<li>リクエストを受けて検索してる部分から読むといいって言われたらしいが、起動スクリプトから読み始めてみた。</li>
<li>時間かかりそうｗ</li>
<li>ただ、人がどんな感じでソースを読んだり理解してるかがわかりやすかったので面白かったです。</li>
<li>定期的に続きを聞いてみたいです。</li>
</ul>


<h2>LT</h2>

<h3>「reroute APIを使用してシャード配置を制御する」 株式会社富士通ソフトウェアテクノロジーズ 滝田聖己さん @pisatoshi</h3>

<p>スライド：<a href="https://speakerdeck.com/pisatoshi/elasticsearch-rerouteapiwoshi-tutasiyadopei-zhi-falsezhi-yu">reroute APIを使用してシャード配置を制御する</a></p>

<ul>
<li>シャードの再配置が自動で行われるので、それをオフにしないと、せっかく移動しても無駄になることがというあるあるネタ</li>
<li>Bonsaiロゴを作成するLT</li>
<li>実際にいくら掛かったのかが知りたかった。</li>
</ul>


<h3>「検索のダウンタイム0でバックアップからIndexをリストアする方法」株式会社ドワンゴモバイル 西田和史さん</h3>

<p>スライド：<a href="http://www.slideshare.net/kbigwheel/0index-39143333">検索のダウンタイム0でバックアップからIndexをリストアする方法</a></p>

<ul>
<li>擬似無停止のやりかた。</li>
<li>aliasを活用して、かつ、Restoreで再構築するという方法。</li>
<li>aliasまで一緒にリストアされるので注意が必要っていうのは、実際にやってみたからわかることという感じですね。</li>
</ul>


<h2>その他、感想などのブログ</h2>

<p>適当に見つけたブログを列挙してあります。これもあるよ！などあれば、教えてください。</p>

<ul>
<li><a href="http://s-wool.blog.jp/archives/1009404632.html">第6回elasticsearch勉強会に行ってきましたのでそのメモ</a></li>
<li><a href="http://arika.hateblo.jp/entry/2014/09/17/100921">elasticsearch 勉強会 第6回</a></li>
</ul>


<h3>まとめ</h3>

<p>今回も、ためになる話がいっぱい聞けたかなと。
個人的な印象としては、いつものメンバーよりも新しい方が多かった印象です。
また、ほとんどの方が、Elasticsearchをご存知でした。
そこそこ知名度は上がってきているようで嬉しい限りです。（東京以外での知名度なども知りたいかなと。）</p>

<p>あと、懇親会の部屋の案内が遅くなってしまってスミマセンでした。
さすがにスタッフ3名はきつかったです。。。</p>

<p>19時半開始にしてみましたが、懇親会の時間がやはり短めになってしまうなぁという印象でした。</p>

<p>次回ももちろん2ヶ月後くらいに行います。
スピーカー募集中ですので、コメント、メール、ツイートなど、コンタクトしていただければと思います。
よろしくお願いいたします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[elasticsearch.もうちょっと入門という話をしてきました #gihyo_efk]]></title>
    <link href="http://blog.johtani.info/blog/2014/09/16/book-publication-event/"/>
    <updated>2014-09-16T13:21:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/09/16/book-publication-event</id>
    <content type="html"><![CDATA[<p>先日2014年9月9日(火)に<a href="http://eventdots.jp/event/137658">『サーバ/インフラエンジニア養成読本 ログ収集〜可視化編』　出版記念！執筆者が語る大講演会！</a>で、
<a href="https://speakerdeck.com/johtani/elasticsearchmoutiyotutoru-men">「elasticsearch.もうちょっと入門」</a>というタイトルで発表してきました。
会場のGMOのみなさま、Treasure Data、技術評論社のみなさま、どうもありがとうございました。</p>

<p>書籍に興味のある方は、右のリンクから購入してもらえるとうれしいです。Kindle版も用意されています。</p>

<!-- more -->


<p>提供のTDの方に目をつぶってもらいながらLogstashについての発表となってしまいましたが、楽しんでいただけたかなぁと。
書籍では主にKibana3をメインにしたElasticsearchの使い方だったので、それ以外の機能ということで、Aggregationについて説明してみました。</p>

<p>そのあとは、おそらく初めてですが、パネルディスカッションにも参加しました。
<a href="https://twitter.com/naoya_ito">@naoya_ito</a>さんをモデレーターに、rebuild.fm風に進めていただき、話しやすかったかなと。
（少なくとも私は楽しめました！）
ただ、私だけバックグラウンドが少し異なることもあり、話をうまく繋げられなかったかもと気にしていたりもしますが。。。</p>

<p>パネルディスカッションでもありましたが、エンジニアが「趣味」で入れて試してみるのにはもってこいのツール群だと思います。
ちょっと入れてみて、可視化をしてみるといろいろと発見があると思います。
何かを発見するためにもまず試してみるのが何事も重要かなと最近思ってるのもあるので、気軽に試してみてもらえればと。</p>

<p>不明点などあれば、著者陣に気軽に聞いていただけると良いかと思います（いいですよね、みなさんｗ）。
Fluentd（もちろん、Logstashも）、Elasticsearch、Kibanaを利用して、データについて試行錯誤してもらって、
システムやビジネスに必要なものを探索して見てください。</p>

<h3>参考</h3>

<p>他の方々のブログをメモとして。</p>

<ul>
<li><a href="http://suzuken.hatenablog.jp/entry/2014/09/11/210059">サービス改善とログデータ解析について発表してきました</a></li>
<li><a href="http://blog.harukasan.jp/entry/2014/09/12/144217">Kibanaではじめるダッシュボードについて発表してきました #gihyo_efk</a></li>
<li><a href="http://y-ken.hatenablog.com/entry/fluentd-system-design-pattern">Fluentdのお勧めシステム構成パターンについて発表しました</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearchのインデキシングに関するパフォーマンス検討]]></title>
    <link href="http://blog.johtani.info/blog/2014/09/09/performance-considerations-for-elasticsearch-indexing/"/>
    <updated>2014-09-09T17:11:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/09/09/performance-considerations-for-elasticsearch-indexing</id>
    <content type="html"><![CDATA[<p>Elasticsearchのインデキシングに関するパフォーマンス検討</p>

<p>原文：<a href="http://www.elasticsearch.org/blog/performance-considerations-elasticsearch-indexing/">performance considerations for elasticsearch indexing</a></p>

<p>Elasticsearchユーザは様々な楽しいユースケースを持っています。小さなログを追加することから、Webスケールの大きなドキュメントの集合をインデキシングするようなことまでです。また、インデキシングのスループットを最大化することが重要で一般的な目標となります。
「典型的な」アプリケーションに対して良いデフォルト値を設定するようにしていますが、次のちょっとした簡単なベストプラクティスによってインデキシングのパフォーマンスをすぐに改善することができます。それらについて記述します。</p>

<!-- more -->


<p>第一に、制御できないならば、巨大なJavaヒープを使用しない：必要なサイズ（マシンの持つRAMの半分以下）のheapだけを設定しましょう。Elasticsearchの利用方法のために必要な全体量を設定します。これは、OSにIOキャッシュを制御するためのRAMを残すことを意味します。OSが<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-configuration.html">javaプロセスをスワップアウト</a>していないことも確認しましょう。</p>

<p>最新バージョン（<a href="http://www.elasticsearch.org/downloads/1-3-2/">現時点では1.3.2</a>）のElasticsearchにアップグレードしましょう：多数のインデキシングに関連する問題点が最新リリースで修正されています。</p>

<p>詳細に入る前に警告：ここで述べるすべての情報は現時点での最新（<a href="http://www.elasticsearch.org/downloads/1-3-2/">1.3.2</a>）の情報です。しかし、Elasticsearchの更新は日々行われています。この情報をあなたが見た時点では最新ではなく、正確ではなくなっているかもしれません。自信がない場合は<a href="http://www.elasticsearch.org/community">ユーザメーリングリスト</a>で質問してください。</p>

<p>クラスタのインデキシングスループットをチューニングする場合、<a href="http://www.elasticsearch.org/overview/marvel">Marvel</a>は非常に有用なツールです：ここで述べている各設定を継続的に試し、変更の影響がクラスタの挙動をどのように変更されたかを簡単に可視化することが可能です。</p>

<h2>クライアントサイド</h2>

<p><a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/docs-bulk.html">bulk API</a>を常に使いましょう。1リクエストで複数のドキュメントをインデキシングでき、各バルクリクエストで送るのに良いドキュメント数を試しましょう。最適なサイズは多くの要因に依存しますが、最適サイズからずれるならば多すぎるよりも少なすぎる方が良いでしょう。クライアントサイドのスレッドで並列にbulkリクエストを使うか、個別の非同期リクエストを使ってください。</p>

<p>インデキシングが遅いと結論付ける前に、クラスタのハードウェアの性能を引き出せているかを確認して下さい：すべてのノードでCPUやIOが溢れていないかを確認するために<code>iostat</code>や<code>top</code>、<code>ps</code>といったツールを使いましょう。もし、溢れていなければ、より多くの並列なリクエストが必要です。しかし、javaクライアントからの<code>EsRejectedExecutionException</code>や、RESTリクエストのHTTPレスポンスとして<code>TOO_MANY_REQUESTS (429)</code>が返ってきた場合は並列リクエストを多く送りすぎています。もし<a href="http://www.elasticsearch.org/overview/marvel">Marvel</a>を利用しているなら、<a href="http://www.elasticsearch.org/guide/en/marvel/current/#_node_amp_index_statistics">Node Statistics Dashboard</a>の<code>THREAD POOLS - BULK</code>にリジェクトされた数が表示されます。bulkスレッドプールサイズ（デフォルト値はコア数）を増やすのは得策ではありません。インデキシングスループットを減少させるでしょう。クライアントサイドの並列度を下げるか、ノードを増やすのが良い選択です。</p>

<p>ここでは、1シャードに対してインデキシングスループットを最大化する設定に注目します。1つのLuceneインデックスのドキュメントの容量を測定するために、単一ノード（単一シャード、レプリカなし）で最初にテストをして最適化し、クラスタ全体にスケールする前にチューニングを繰り返します。これはまた、インデキシングスループットの要件を見つけるために、クラスタ全体にどのくらいのノードが必要かをラフに見積もるためのベースラインを与えてくれます。</p>

<p>単一シャードが十分機能したら、Elasticsearchのスケーラビリティの最大の利点や、クラスタでの複数ノードによるレプリカ数やシャード数の増加の利点が得られます。</p>

<p>結論を導き出す前に、ある程度の時間（60分）くらいクラスタ全体の性能を計測しましょう。このテストは、巨大なマージ、GCサイクル、シャードの移動、OSのIOキャッシュ、予期しないスワップの可能性などのイベントのライフサイクルをカバーできます。</p>

<h2>ストレージデバイス</h2>

<p>当然ながらインデックスを保存するストレージデバイスはインデキシングの性能に多大な影響を及ぼします：</p>

<ul>
<li>SSDを利用する：これらは最も速いHDDよりも速いです。ランダムアクセスのための消費電力が低いだけでなく、シーケンシャルIOアクセスも高いです。また、同時に発生するインデキシング、マージや検索のための並列的なIOも高速です。</li>
<li>インデックスをリモートマウントされたファイルシステム（例：<a href="http://en.wikipedia.org/wiki/Network_File_System">NFS</a>や<a href="http://en.wikipedia.org/wiki/Server_Message_Block">SMB/CIFS</a>）上に配置しない：代わりにローカルストレージを使う</li>
<li>仮想化されたストレージ（Amazonの<a href="http://aws.amazon.com/ebs/">Elastic Block Storage</a>など）に注意：仮想化されたストレージはElasticsearchで十分に動作します。また、十分早く簡単に用意できることから魅力的です。しかし、残念なことに、ローカルストレージと比較すると本質的に遅いです。最近の非公式なテストでは、<a href="http://aws.amazon.com/ebs/details/#PIOPS">最高の性能を持つプロビジョニングされたIOPSのSSDオプションのEBS</a>でさえ、ローカルインスタンスにあるSSDよりも遅いです。ローカルインスタンスにあるSSDは物理マシン上のすべての仮想マシンから共有されてアクセスされます。もし他の仮想マシンが急にIOが集中した場合に不可解なスローダウンとなることがあることを覚えておいてください。</li>
<li>複数のSSDを<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-dir-layout.html">複数の<code>path.data</code>ディレクトリ</a>にインデックスをストライピング（<a href="http://en.wikipedia.org/wiki/RAID_0#RAID_0">RAID0</a>のように）：2つは同様で、ファイルブロックレベルでストライピングする代わりに、個別にインデックスファイルレベルでElasticsearchの&#8221;stripes&#8221;となります。これらのアプローチは、いづれかのSSDの故障によりインデックスが壊れるという、1シャードが故障する(IO性能を高速化することとトレードオフ)というリスクを増加させることに注意してください。これは、一般的に行うのに良いトレードオフです：単一シャードで最大のパフォーマンスを最適化し、異なるノード間でレプリカを追加すると、ノードの故障への冗長化ができます。また、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-snapshots.html">snapshotやrestore</a>を使って保険のためにインデックスのバックアップを取ることもできます。</li>
</ul>


<h2>セグメントとマージ</h2>

<p>新しくインデキシングされたドキュメントは最初にLuceneの<code>IndexWriter</code>によってRAMに保存されます。RAMバッファがいっぱいになった時もしくは、Elasticsearchがflushもしくはrefreshを実行した時など定期的にこれらのドキュメントはディスクに新しいセグメントとして書き込まれます。最後に、セグメントが多くなった時に、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-merge.html">Merge PolicyとSucheduler</a>によってそれらがマージされます。このプロセスは連続的に生じます：マージされたセグメントはより大きなセグメントとなり、小さなマージが幾つか実行され、また、大きなセグメントにマージされます。これらがどのように動作するかを<a href="http://blog.mikemccandless.com/2011/02/visualizing-lucenes-segment-merges.html">わかりやすく可視化したブログはこちら</a>です。</p>

<p>マージ、特に大きなマージは非常に時間がかかります。これは、通常は問題ありません。そのようなマージはレアで全体のインデックスのコストと比べればささいなものです。しかし、マージすることがインデキシングについていけない場合、インデックスに非常に多くのセグメントがあるような深刻な問題を防ぐために、Elasticsearchはやってくるインデキシングリクエストを単一スレッド(1.2以降)に制限します。</p>

<p>もし、INFOレベルのログメッセージに<code>now throttling indexing</code>と表示されていたり、<a href="http://www.elasticsearch.org/guide/en/marvel/current">Marvel</a>でのセグメント数が増加しているを見た場合、マージが遅れているとわかります。Marvelは<a href="http://www.elasticsearch.org/guide/en/marvel/current/#_node_amp_index_statistics">Index Statistics dashboard</a>の<code>MANAGEMENT EXTENDED</code>の部分にセグメント数をプロットしており、それは、非常にゆっくりと指数対数的に増加しており、大きなマージが終了したところがのこぎりの歯のような形で見て取れます。</p>

<p><img src="http://www.elasticsearch.org/content/uploads/2014/09/segmentCounts.png" title="セグメント数" ></p>

<p>なぜマージが遅れるのでしょう？デフォルトでElasticsearchはすべてのマージの書き込みのバイト数をわずか20MB/secに制限しています。スピニングディスク（HDD）に対して、これはマージによって典型的なドライブのIOキャパシティを飽和させず、並列に検索を十分に実行させることを保証します。しかし、もし、インデキシング中に検索をしない場合や、検索性能がインデキシングのスループットよりも重要でない場合、インデックスの保存にSSDを使用している場合などは、<code>index.store.throttle.type</code>に<code>none</code>を設定して、マージの速度制限を無効化するべきです（詳細は<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-store.html">こちら</a>をご覧ください）。なおバージョン1.2以前には<a href="https://github.com/elasticsearch/elasticsearch/issues/6018">期待以上のマージIO制限の発生</a>といったバグが存在します。アップグレードを！</p>

<p>もし、不幸にもスピニングディスク（それはSSDと同等の並列なIOを扱えません）をまだ使っている場合、<code>index.merge.scheduler.max_thread_count</code>に<code>1</code>を設定しなければなりません。そうでない場合は、（SSDを支持する）デフォルト値が多くのマージを同時に実行させるでしょう。</p>

<p>活発に更新が行われているインデックスで<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-optimize.html"><code>optimize</code></a>を実行しないでください。それは、非常にコストの高い操作(すべてのセグメントをマージ)です。しかし、もし、インデックスにドキュメントを追加が終わった直後はオプティマイズのタイミングとしては良いタイミングです。それは、検索時のリソースを減らすからです。例えば、時間ベースのインデックスを持っており、新しいインデックスに日々のログを追加している場合、過去の日付のインデックスをオプティマイズするのは良い考えです。特に、ノードが多くの日付のインデックスを持っている場合です。</p>

<p>更にチューニングするための設定：</p>

<ul>
<li>実際に必要のないフィールドをオフにする。例えば<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-all-field.html"><code>_all</code>フィールドをオフ</a>。また、保持したいフィールドでは、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-core-types.html"><code>indexed</code>か<code>stored</code>かを検討する</a>。</li>
<li>もし、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-source-field.html"><code>_source</code>フィールドをオフ</a>にしたくなるかもしれないが、インデキシングコストは小さい(保存するだけで、インデキシングしない)、また、それは、将来の更新や、前のインデックスを再インデキシングするために非常に価値があり、それはディスク使用率の懸念事項がない限り、オフにする価値はあまりない。それは、ディスクが比較的安価であるので価値がない。</li>
<li>もし、インデックスされたドキュメントの検索までの遅延を許容できるなら、<code>index.refresh_interval</code>を<code>30s</code>に増やすか、<code>-1</code>を設定して、オフにする。これは、巨大なセグメントをフラッシュし、マージのプレッシャーを減らすことができる。</li>
<li><a href="http://www.elasticsearch.org/downloads/1-3-2/">Elasticsearch 1.3.2</a>(稀に、フラッシュ時に過度のRAMを使用するという<a href="https://github.com/elasticsearch/elasticsearch/issues/6443">問題</a>を<a href="https://github.com/elasticsearch/elasticsearch/issues/6379">修正した</a>)にアップグレードすることで、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-translog.html"><code>index.translog.flush_threshold_size</code></a>をデフォルト(200mb)から1gbに増加し、インデックスファイルのfsyncの頻度を減らす。
Marvelに<a href="http://www.elasticsearch.org/guide/en/marvel/current/#_node_amp_index_statistics"><code>Index Statistics dashboard</code></a>の<code>MANAGEMENT</code>にフラッシュの頻度がプロットされている。</li>
</ul>


<h2>インデックスバッファサイズ</h2>

<p>巨大なインデックスを構築中はレプリカ数を0にし、あとから、レプリカを有効にする。レプリカが0ということは、データを失った(ステータスがred)時に冗長性がないので、ノードの故障に注意すること。もし、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-optimize.html"><code>optimize</code></a>(ドキュメントの追加をすることがないので)を計画するなら、インデキシングが終わったあとで、レプリカを作成する前に実行するのが良いでしょう。レプリカはオプティマイズされたセグメントをコピーするだけになります。詳細は<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-update-settings.html">インデックス設定更新</a>を参照。</p>

<p>もし、ノードがヘビーなインデキシングを行っているだけなら、アクティブなシャードのインデキシングバッファに多くてい512MBを<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-indices.html">indices.memory.index_buffer_size</a>に与えてください。(超えてもインデキシングのパフォーマンスは一般的には改善されません。)Elasticsearchはその設定(Javaヒープのパーセンテージもしくはバイト数)を受けて、min_index_buffer_sizeとmax_index_buffer_sizeの値を前提にノードのアクティブシャードに均等に割り当てます；大きな値はLuceneが最初のセグメントをより大きくし、将来的なマージのプレッシャーを減らすことを意味します。</p>

<p>デフォルトは10%で、それで十分です；例えば、もし、5つのアクティブなシャードがノードにあり、ヒープが25GBの場合、各シャードは25GBの10%の1/5=512MB（すでに最大値）を持っています。ヘビーなインデキシングのあと、この設定をデフォルトに下げましょう。検索時のデータ構造のために十分なRAMを確保するために。この設定はまだ動的な設定変更はできません。<a href="https://github.com/elasticsearch/elasticsearch/issues/7045">Issueがここに</a>あります。</p>

<p>インデックスバッファによって現在利用されているバイト数は1.3.0の<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-stats.html">indices stats API</a>に追加されています。<code>indices.segments.index_writer_memory</code>の値を見ることができます。これはMarvelではまだプロットされていませんが、将来のバージョンで追加される予定です。しかし、自分でグラフに追加することもできます。(Marvelはデータは収集しています)</p>

<p>1.4.0では、<a href="https://github.com/elasticsearch/elasticsearch/issues/7440"><code>indices.segments.index_writer_max_memory</code></a>として、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-stats.html">indices stats API</a>にアクティブシャードにどのくらいのRAMバッファが割り当てられているかも表示されます。これらの値はインデックスのシャード事の値として見ることができ、<code>http://host:9200/&lt;indexName&gt;/_stats?level=shards</code>を使ってみることができます；これは、全シャードに対する合計と、各シャードごとのstatsを返すでしょう。</p>

<h2>オートIDの利用もしくは良いIDの利用</h2>

<p>もし、ドキュメントの<code>ID</code>がなんでも良い場合、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/docs-index_.html#_automatic_id_generation" title="">Elasticsearchで採番すること</a>ができます：これは、(1.2以降)ドキュメントIDをバージョンを探さずに保存できるように<a href="https://github.com/elasticsearch/elasticsearch/pull/5917">最適化</a>され、Elasticsearchの<a href="http://benchmarks.elasticsearch.org/">日毎のベンチマーク</a>で異なるパフォーマンスを見ることができます。(<code>Fast</code>と<code>FastUpdate</code>のグラフを比較)</p>

<p>もし、IDを自身が持っていて、自分の支配下で<a href="http://blog.mikemccandless.com/2014/05/choosing-fast-unique-identifier-uuid.html">Luceneに対して素早く選ぼうとしている</a>なら、1.3.2にアップグレードしましょう、IDのルックアップが<a href="https://github.com/elasticsearch/elasticsearch/issues/6212">さらにオプティマイズ</a>されています。Javaの<a href="http://docs.oracle.com/javase/7/docs/api/java/util/UUID.html">UUID.randomUUID()</a>はやめましょう。それは、セグメントに対してどのようにIDを割り当てるかという予測やパターン性がないため、最悪のケースで<a href="http://blog.mikemccandless.com/2014/05/choosing-fast-unique-identifier-uuid.html">セグメントごとのシーク</a>が発生します。</p>

<p><a href="http://boundary.com/blog/2012/01/12/flake-a-decentralized-k-ordered-unique-id-generator-in-erlang/">Flake IDs</a>を利用した時の<a href="http://www.elasticsearch.org/overview/marvel">Marvel</a>によるインデックス性能の違い：</p>

<p><img src="http://www.elasticsearch.org/content/uploads/2014/09/flakeIDsPerf.png" title="flakeIDsPerf" ></p>

<p>ランダムUUIDを利用した場合：</p>

<p><img src="http://www.elasticsearch.org/content/uploads/2014/09/uuidsPerf.png" title="uuidsPerf" ></p>

<p>次の1.4.0では、ElasticsearchのID自動採番を<a href="https://github.com/elasticsearch/elasticsearch/issues/5941">UUIDからFlake IDに変更</a>します。</p>

<p>もし、Luceneのローレベル操作がインデックスに対してなにをやっているかについて興味があるなら、<a href="https://github.com/elasticsearch/elasticsearch/issues/5891"><code>lucene.iw</code>をTRACEログレベルで出力できるように</a>してみましょう(1.2から利用可能)。これは、多くの出力がありますが、Luceneの<code>IndexWriter</code>レベルで何が起きているかを理解するのに非常に役に立ちます。出力は非常にローレベルです：<a href="http://www.elasticsearch.org/guide/en/marvel/current">Marvel</a>がインデックスに何が起きているかをよりリアルタイムにグラフを描画してくれます。</p>

<h2>スケールアウト</h2>

<p>我々は、単一シャード(Luceneインデックス)性能のチューニングに注目してきました。しかし、一旦それに満足できたならば、Elasticsearchはクラスタ全体にわたってインデキシングや検索を簡単にスケールアウトすることに長けています。シャード数(デフォルトでは5)を増やすのは可能です。それは、マシン全体に対して並列度、巨大なインデックスのサイズ、検索時のレイテンシの低下など得ることができます。また、レプリカを1位上にすることは、ハードウェア故障に対する冗長性を持つことを意味します。</p>

<p>最後に、このドキュメントを見ても問題解決しない場合は<a href="http://www.elasticsearch.org/community">コミュニティに参加</a>しましょう。例えば、<a href="https://groups.google.com/forum/?fromgroups#!forum/elasticsearch">ElasticsearchのユーザML</a>に投稿するなど。おそらく、修正すべきエキサイティングなバグがあるでしょう。(パッチも常に歓迎です！)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[サーバ/インフラエンジニア養成読本 ログ収集~可視化編 を手伝いました]]></title>
    <link href="http://blog.johtani.info/blog/2014/08/04/release-magazine-book-of-log-aggs-and-viz/"/>
    <updated>2014-08-04T21:54:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/08/04/release-magazine-book-of-log-aggs-and-viz</id>
    <content type="html"><![CDATA[<p>懲りずにまた、執筆してみました。みなさん「買って」から感想をいただけるとうれしいです！</p>

<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&nou=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=johtani-22&o=9&p=8&l=as1&m=amazon&f=ifr&ref=tf_til&asins=4774169838" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>




<!-- more -->


<h2>本書について</h2>

<p>共著者の方々のブログが詳しいので、そちらを読んでもらいつつ。
実際にログを収集して解析されている方々と一緒に書かせていただくことで色々と勉強させていただいています。</p>

<h3>共著者の方々のブログ</h3>

<ul>
<li><a href="https://twitter.com/suzu_v">@suzu_v</a>さん：<a href="http://suzuken.hatenablog.jp/entry/2014/07/18/084555">サーバ/インフラエンジニア養成読本 ログ収集~可視化編 を書きました</a></li>
<li><a href="https://twitter.com/yoshi_ken">@yoshi_ken</a>さん：<a href="http://y-ken.hatenablog.com/entry/published-elasticsearch-fluentd-kibana-book">ログ収集や可視化で話題のFluentd、Elasticsearch、Kibanaを徹底解説したムック本が発売となります</a></li>
<li><a href="https://twitter.com/harukasan">@harukasan</a>さん：<a href="http://blog.harukasan.jp/entry/2014/07/18/180351">書きました: サーバ/インフラエンジニア養成読本 ログ収集~可視化編</a></li>
</ul>


<h3>どの辺を書いたの？</h3>

<p>「特集３：Elasticsearch入門」（なんか、入門ばっかりだなぁ）を書かせていただきました。
データストア入門ということで、ほんとうに簡単な他のデータストアを説明し、Elasticsearchってどんなものかを単語の説明をしつつ紹介してみました。</p>

<p>Elasticsearch自体は多くの機能を持っており、それ単体で分厚い書籍がかけるので、ログ検索に関係ありそうな部分をピックアップしてみました。
あとは、運用時に気をつける点や便利なツール（Curatorなど）の紹介をしています。</p>

<p>また、Hadoopと合わせて利用してみたい、すでにHadoopにあるデータも活用してみたいという話もありそうだということで、<a href="https://github.com/elasticsearch/elasticsearch-hadoop">elasticsearch-hadoop</a>についても簡単ですが紹介してあります。</p>

<h2>その他感想</h2>

<p>個人的に、忙しい時期<a href="http://blog.johtani.info/blog/2014/07/01/join-elasticsearch/">（参考記事）</a>だったので、あんまり力になれてないので大変申し訳なく思っています。。。
ただ、素晴らしい出来（カラーでKibanaの解説が日本語で読めたり、Fluentdの逆引きのリストがあったり、ログを貯めて可視化する意義を説明してあったり）です。</p>

<p>ぜひ、読んだ感想をいただければと！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[プロキシ環境でのpluginコマンドの実行]]></title>
    <link href="http://blog.johtani.info/blog/2014/08/01/plugin-using-under-proxy-env/"/>
    <updated>2014-08-01T15:24:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/08/01/plugin-using-under-proxy-env</id>
    <content type="html"><![CDATA[<p>Proxy環境で働いている方も結構いると思います。
Twitter上で、Elasticsearchのpluginコマンドでプラグインがインストールできなくて困っている方がいたので、
調べてみたのでメモしておきます。</p>

<!-- more -->


<h2>プラグインコマンド</h2>

<p>Elasticsearchでは、プラグインという形でいくつかの便利な機能が公開されています。
<a href="https://github.com/elasticsearch/elasticsearch-analysis-kuromoji">形態素解析ライブラリのKuromoji</a>を使うためのプラグインや、<a href="https://github.com/lmenezes/elasticsearch-kopf">クラスタの管理がGUIで可能なkopf</a>プラグインなどがあります。
公式、サードパーティいろいろです。</p>

<p>これらのプラグインをElasticsearchにインストールする場合、以下のコマンドを実行すれば
自動的にダウンロードして<code>plugins</code>ディレクトリにインストールしてくれます。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./bin/plugin -i elasticsearch/elasticsearch-analysis-kuromoji/2.3.0</span></code></pre></td></tr></table></div></figure>


<p>ここで、<code>elasticsearch/elasticsearch-analysis-kuromoji/2.3.0</code>がプラグインのパスになります（例では、<code>提供元/プラグイン名/プラグインバージョン</code>となっています。）。</p>

<p>この<code>plugin</code>コマンドがダウンロード元にアクセスに行くのですが、プロキシ環境だとプロキシの設定が必要になります。</p>

<h2>プロキシの指定（Mac/LinuxとWindowsでの違い）</h2>

<h3>Mac/Linux(shコマンド)</h3>

<p><a href="http://blog.johtani.info/blog/2013/09/03/ja-wikipedia-with-kuromoji/">以前の記事</a>でプロキシのポート番号などの指定方法を
以下のように説明していました。
（※昔の記事のため、kuromojiプラグインのバージョンが古いです）</p>

<p>ElasticsearchのpluginコマンドはJavaで実装されています。（org.elasticsearch.common.http.client.HttpDownloadHelper）
プラグインのダウンロードには、java.net.URL.openConnection()から取得URLConnectionを使用しています。</p>

<p>ですので、pluginのインストールを行う際に、Proxy環境にある場合は以下のようにコマンドを実行します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./bin/plugin -DproxyPort=ポート番号 -DproxyHost=ホスト名 -i elasticsearch/elasticsearch-analysis-kuromoji/1.5.0</span></code></pre></td></tr></table></div></figure>


<p>LinuxやMacの環境であれば、こちらのコマンドでプロキシの指定が可能です。
ただし、Windows環境ではうまくいきません。</p>

<p>Elasticsearchは、環境の違いにより、ダウンロードするファイルが異なります。
Windows環境の方は、zipファイルをダウンロードしてもらうようになっています。
elasticsearchコマンドおよびpluginコマンドがbat形式で提供されているのがzipファイルとなるからです。</p>

<h3>Windows(batコマンド)</h3>

<p>Windows環境では次のように指定します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>set JAVA_OPTS="-DproxyHost=ホスト名 -DproxyPort=ポート番号"
</span><span class='line'>bin\plugin -i elasticsearch/elasticsearch-analysis-kuromoji/2.3.0</span></code></pre></td></tr></table></div></figure>


<p>コマンドの実装方法が少し異なるために、このようになっています。</p>

<h2>まとめ</h2>

<p>プロキシ環境で利用される場合は、プラグインコマンドは上記のように実行していただければと。</p>

<p>公式ガイドには、これらの情報を追記するPRを送る予定です。
また、WindowsのコマンドでもMac/Linuxと同様にできたほうがいい気がするので、Issueをあげようと思います。</p>

<p>不明点などあれば、コメントいただければと。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 1.3.1 リリース（日本語訳）]]></title>
    <link href="http://blog.johtani.info/blog/2014/07/29/elasticsearch-1-3-1-release/"/>
    <updated>2014-07-29T12:22:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/07/29/elasticsearch-1-3-1-release</id>
    <content type="html"><![CDATA[<p><a href="http://www.elasticsearch.org/blog/elasticsearch-1-3-1-released/">原文：Elasticsearch 1.3.1 Released</a>を日本語に翻訳したものです。</p>

<p>バグフィックス版のElasticsearch 1.3.1をリリースしました。
ダウンロードおよび変更履歴は<a href="http://www.elasticsearch.org/downloads/1-3-1/">Elasticsearch 1.3.1</a>からお願いいたします。</p>

<!-- more -->


<p>このリリースはインデックスリカバリ時の後方互換性バグ（<a href="https://github.com/elasticsearch/elasticsearch/pull/7055">#7055</a>）への対応です。
このバグは<strong>データの欠損は起こりません。</strong> Elasticsearch 1.3.1へアップグレードすることで問題を回避できます。
このバグは、以下のElasticsearchのバージョンで作成されたセグメントを含むインデックスを1.3.0へアップグレードしようとすると発生します。</p>

<ul>
<li>Elasticsearch 0.90.7</li>
<li>Elasticsearch 0.90.2</li>
<li>Elasticsearch 0.90.0以前のバージョン</li>
</ul>


<p>このバグは、これらの古いインデックスをレプリカからリカバリできなくします。
これらのバージョンのセグメントを持つインデックスが、レプリカは可能ですが、
ステータスがYellowのままGreenに決してなりません。
ログには次のようなExceptionが発生します。</p>

<blockquote><p>IllegalArgumentException[No enum constant org.apache.lucene.util.Version.x.x.x]</p></blockquote>

<p>Luceneの特定のバージョンではLuceneのマイナーバージョンを含んでおらず、誤ったバージョン番号がセグメントに記録されました。
<a href="https://issues.apache.org/jira/browse/LUCENE-5850">LUCENE-5850</a>のチケットがこの問題に対処するためにオープンされています。
この問題は我々の後方互換テストで見つかるべき問題ですが、Luceneで不足しているため発見されませんでした。
テストスイートは今後の可能性のために改良されます。</p>

<p>このリリースはその他に、Aggregationのマイナーバグフィックスも含まれています。
詳細は<a href="http://www.elasticsearch.org/downloads/1-3-1/">リリースノート</a>をご覧ください</p>

<p><a href="http://www.elasticsearch.org/downloads/1-3-1/">Elasticsearch 1.3.1</a>をダウンロードし、試してください。
もし問題を見つけた場合は<a href="https://github.com/elasticsearch/elasticsearch/issues">GitHubのIssues</a>へご報告をお願いいたします。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Curator 1.2および1.1について]]></title>
    <link href="http://blog.johtani.info/blog/2014/07/28/curator-2-0-and-1-1/"/>
    <updated>2014-07-28T14:19:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/07/28/curator-2-0-and-1-1</id>
    <content type="html"><![CDATA[<p><a href="http://www.elasticsearch.org/blog/curator-1-2-0-released/">Curatorの1.2.0がリリース</a>されました。</p>

<p><a href="http://blog.johtani.info/blog/2014/01/24/curator-tending-your-time-series-indices-in-japanese/">前回のCuratorの記事</a>が古くなってしまった（1.1.0からコマンドのI/Fが変更された）ので
1.1.0および1.2.0に関する記事を翻訳しておきます。</p>

<p>ちなみに、<a href="https://github.com/elasticsearch/curator/">Curator</a>とは、Elasticsearchに時系列のインデックス（例：LogstashやFluentdでログを保存）を保存している場合にそれらのインデックスを管理（削除したり、クローズしたり）するための便利なツールです。
Curatorの概要については、<a href="https://github.com/elasticsearch/curator/">GitHubリポジトリ</a>か<a href="http://blog.johtani.info/blog/2014/01/24/curator-tending-your-time-series-indices-in-japanese/">前回の記事</a>をご覧ください。</p>

<!-- more -->


<h1>Curator 1.1.0リリース (2014/06/13公開)<a name="curator_v110"/></h1>

<p>元記事：<a href="http://www.elasticsearch.org/blog/elasticsearch-curator-version-1-1-0-released/">elasticsearch curator - version 1.1.0 released</a></p>

<p>Elasticsearch 1.0.0がリリースされ、新しい機能、Snapshot &amp; Restoreが利用できるようになりました。
Snapshotはある時点でのインデックスの写真を撮るように、バックアップを作成することができます。
1.0.0が発表されてすぐに、この機能に関するリクエストが寄せられるようになりました。
「Curatorにスナップショットを追加して！」もしくは「いつCuratorでスナップショットが使えるようになる？」といった感じです。
これがあなたの要望なら、それはついに叶えられました。しかも他の追加機能も一緒にです。</p>

<h2>新機能</h2>

<p>Curatorの新機能は以下のとおりです。</p>

<ul>
<li>新CLI構造</li>
<li>スナップショット(Snapshot)</li>
<li>エイリアス(Aliases)</li>
<li>パターンによる除外インデックス指定</li>
<li>配置ルーティング(Allocation Routing)</li>
<li>インデックスとスナップショットの表示</li>
<li>リポジトリ管理(個別のスクリプトによる)</li>
<li><a href="https://github.com/elasticsearch/curator/wiki">ドキュメントWiki</a></li>
</ul>


<h3>新コマンドライン構造</h3>

<p><strong>注意</strong>：コマンドライン構造の変更とは、Curator 1.1.0以前のcron記述が動作しないことを意味します。Curator 1.1.0にアップグレードする場合はコマンドも修正が必要となるので注意してください。</p>

<p>シンプルにするために、<em>commands</em>という概念を追加しました。
また、ヘルプの出力もわかりやすくなっています。
前のバージョンと同じタスクをCuratorは実行できますが、異なるフォーマットを用いるようになりました。</p>

<p>旧コマンド：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator -d 30</span></code></pre></td></tr></table></div></figure>


<p>新コマンド：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator delete --older-than 30</span></code></pre></td></tr></table></div></figure>


<p>コマンドは、フラグとは異なりハイフンを前に付けないことに注意してください。
また、似たような名前のフラグがあることに気をつけてください。
例えば、<code>--older-than</code>フラグは多くのコマンドに利用できます。
指定される値は各ケースにおいて同一です。「指定された数よりも古いインデックス」となります。</p>

<p>新しいコマンドのリストは次のとおりです。</p>

<ul>
<li>alias</li>
<li>allocation</li>
<li>bloom</li>
<li>close</li>
<li>delete</li>
<li>optimize</li>
<li>show</li>
<li>snapshot</li>
</ul>


<p>コマンドのヘルプは次のコマンドで表示されます。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator [COMMAND] --help</span></code></pre></td></tr></table></div></figure>


<p>コマンドに関係あるフラグがすべて表示されます。</p>

<h3>スナップショット(snapshots)</h3>

<p><code>snapshot</code>コマンドで、存在しているリポジトリにインデックスのスナップショットを保存することができます。</p>

<p>Curatorはインデックス毎に1つのスナップショットを作成し、インデックスから名前をつけます。
例えば、インデックスの名前が<code>logstash-2014.06.10</code>の場合、スナップショットの名前は<code>logstash-2014.06.10</code>となります。
指定した条件を元に、シーケンシャルに、1つずつインデックスのスナップショットを作成していきます。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator snapshot --older-than 20 --repository REPOSITORY_NAME</span></code></pre></td></tr></table></div></figure>


<p>このコマンドは、20日以上古いインデックスすべてのスナップショットを作成し、<code>REPOSITORY_NAME</code>で指定されたリポジトリに保存します。</p>

<p><code>es_repo_mgr</code>と呼ばれるリポジトリ作成を支援するスクリプトがCuratorには含まれています。
ファイルシステムおよびS3タイプのリポジトリ両方の作成を支援します。</p>

<p>さらに、古いインデックスのスナップショットを取ることができることに加えて、Curatorは最新のインデックスをアップロードする方法も提供します。
これは、<a href="http://www.elasticsearch.org/overview/marvel/">Elasticsearch Marvel</a>のインデックスをアップロードするときに便利です。
トラブルシューティングを目的として、パフォーマンスデータを他の人に見せる場合などです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator snapshot --most-recent 3 --prefix .marvel- --repository REPOSITORY_NAME</span></code></pre></td></tr></table></div></figure>


<p>このコマンドでは、最新の3つのMarvelインデックスのスナップショットを指定されたリポジトリに保存できます。</p>

<h3>エイリアス(aliases)</h3>

<p>Curatorはすでに存在するエイリアスにインデックスを追加することも、削除することもできるようになりました。
ただし、エイリアスがすでに存在している必要があります。エイリアスの作成はできません。</p>

<p><code>last_week</code>という前の一週間のインデックスのエイリアスを保持していること想像してください。
この場合、次の2つのコマンドを利用することで、エイリアスを管理できます。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator alias --alias-older-than 7 --alias last_week
</span><span class='line'>curator alias --unalias-older-than 14 --alias last_week</span></code></pre></td></tr></table></div></figure>


<p>新しく作られたインデックスが<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-templates.html#indices-templates">インデックステンプレート</a>によって
自動的にエイリアスの一部となるようにElasticsearchに設定しておくと、さらに便利です。
この場合、新しいインデックスが自動的に<code>this_week</code>というエイリアスの一部になるようにしてあれば、以下のコマンドのみとなります。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator alias --unalias-older-than 7 --alias this_week</span></code></pre></td></tr></table></div></figure>


<p><code>this_week</code>と<code>last_week</code>のエイリアスのアップデートを保持できます。</p>

<h3>パターンによる除外(exclude pattern)</h3>

<p>時には、指定したインデックスを操作から除外したくなる場合もあるでしょう。
ここまでは、プレフィックスや日付によって選択されたインデックスのみを対象にしてきました。
そこで、<code>--exclude-pattern</code>オプションです。これは、指定したインデックスを除いて処理を行うことができます。</p>

<p><code>logstash-2014.06.11</code>というインデックスを決して削除したくないとします。
この場合、次のコマンドのようになります。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator delete --older-than 15 --exclude-pattern 2014.06.11</span></code></pre></td></tr></table></div></figure>


<p>Curatorはデフォルトで<code>logstash-</code>というプレフィックスにマッチしますが、<code>2014.06.11</code>というインデックスは対象外となります。</p>

<h3>配置ルーティング(allocation routing)</h3>

<p>Elasticsearchはノードにタグを付けることができます。
これらのタグはインデックスやシャードをクラスタのどこに配置するかをコントロールするために役立ちます。
一般的なユースケースだと、高性能なSSDドライブを持ったノードをインデキシングのために、ハードディスクを持った性能の低いマシンは検索頻度が低い古いインデックスを配置するといった場合です。
この場合、HDDノードには、<code>elasticsearch.yml</code>に<code>node.tag: hdd</code>、SSDノードには<code>node.tag: ssd</code>と設定されているべきです。
Curatorはこの時、インデックスをタグに基づいてオフピークの時間帯に再配置させることができます。</p>

<p>コマンド：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator allocation --older-than 2 --rule tag=hdd</span></code></pre></td></tr></table></div></figure>


<p><code>index.routing.allocation.require.tag=hdd</code>という設定が２日よりも古いインデックスに適用されます。
これは、インデックスのシャードが<code>node.tag: hdd</code>というノードに再配置される必要があると、Elasticsearchに伝えます。</p>

<h3>インデックスとスナップショットの表示(show indices and snapshots)</h3>

<p>これは、単にあなたの持っているインデックスやスナップショットがどんなものかを表示します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator show --show-indices</span></code></pre></td></tr></table></div></figure>


<p>これは、デフォルトプレフィックスの<code>logstash-</code>にマッチするすべてのインデックスを表示します。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator show --show-snapshots --repository REPOSITORY_NAME</span></code></pre></td></tr></table></div></figure>


<p>これは、指定されたリポジトリにある、デフォルトプレフィックスの<code>logstash-</code>にマッチするすべてのスナップショットを表示します。</p>

<h3>リポジトリ管理(repository management)</h3>

<p>前に説明したとおり、<code>es_repo_mgr</code>と呼ばれるヘルパースクリプトをCuratorは含んでいます。
現時点では、<code>fs</code>と<code>s3</code>タイプをサポートしています。
リポジトリを作る前に利用したいタイプのドキュメントを読むようにしてください。
例えば、<code>fs</code>タイプのリポジトリを各ノードで使う場合は、同じ共有ファイルシステムに、同じパスでアクセスできなければなりません。
パスの指定は<code>--location</code>です。</p>

<p><code>fs</code>タイプリポジトリの作成</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>es_repo_mgr create_fs --location '/tmp/REPOSITORY_LOCATION' --repository REPOSITORY_NAME</span></code></pre></td></tr></table></div></figure>


<p>削除</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>es_repo_mgr delete --repository REPOSITORY_NAME</span></code></pre></td></tr></table></div></figure>


<h3>ドキュメントWiki</h3>

<p><a href="https://github.com/elasticsearch/curator/wiki">Curatorのドキュメント</a>が更新され、オンラインにWiki形式でだれでも更新できるようになっています。
コマンドやフラグのより詳細の情報はこちらで見つけることができます。また、もし、興味があれば、ドキュメントを追加することもできます。</p>

<h2>インストールと更新</h2>

<p>Curator 1.1.0は<a href="https://pypi.python.org/pypi?%3Aaction=pkg_edit&amp;name=elasticsearch-curator">PyPi</a>リポジトリにあります。
インストールは以下のとおりです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pip install elasticsearch-curator</span></code></pre></td></tr></table></div></figure>


<p>バージョン1.0.0からアップグレードする場合は以下のとおりです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pip uninstall elasticsearch-curator
</span><span class='line'>pip install elasticsearch-curator</span></code></pre></td></tr></table></div></figure>


<p>バージョン1.0.0よりも古いバージョンからのアップグレードは以下のとおりです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pip uninstall elasticsearch-curator
</span><span class='line'>pip uninstall elasticsearch
</span><span class='line'>pip install elasticsearch-curator</span></code></pre></td></tr></table></div></figure>


<p><code>pip uninstall elasticsearch</code>で、古いパイションモジュールをを削除します。
適切なバージョンが依存関係により再インストールされます。</p>

<h2>まとめ</h2>

<p>Curatorの新機能は素晴らしいです！このリリースは大きな改善です。
もし、トラブルや足りないものを見つけた場合は<a href="http://github.com/elasticsearch/curator/issues">GitHub Issue</a>に報告してください。
また、Curatorが便利だと思ったら、私たちに伝えてください。<code>#elasticsearch</code>タグを付けてツイートしてください！</p>

<p>Curatorはまだ、始まったばかりです。Curator 2.0のロードマップを作業中です。ここまで読んでいただきありがとうございます。
Happy Curating!</p>

<hr />

<h1>Curator 1.2.0リリース(2014/07/24)</h1>

<p>元記事：<a href="http://www.elasticsearch.org/blog/curator-1-2-0-released/">curator 1.2.0 released</a></p>

<p><a href="#curator_v110">Curator v1.1.0</a>のリリースから、数週間が経ちました。
私たちは、Curator 1.2.0をリリースしました。</p>

<h2>新機能(new features)</h2>

<ul>
<li>ユーザ指定の日付パターン：長い間リクエストされていた機能</li>
<li>ウィークリーインデックスのサポート：これも長い間リクエストされていた機能</li>
<li>複数の<a href="https://github.com/elasticsearch/curator/wiki/Logformat">ログフォーマット</a>オプション：Logstashフォーマットが利用可能</li>
</ul>


<p>これらの変更は<a href="https://github.com/elasticsearch/curator/wiki">Curatorドキュメント</a>にも記載されています。</p>

<h2>更新(updates)</h2>

<ul>
<li>ログ出力の整理：デフォルトのログ出力を整理しました。デバッグログはすべて表示されます。</li>
<li>ドライランのログ出力の詳細化：テスト実行時に何が起きたかをわかりやすくしました。</li>
</ul>


<h2>日付パターンと<code>--timestring</code>(date patterns and &ndash;timestring)</h2>

<p>前のリリースで、セパレータ文字を利用して、インデックス名のエレメントを分離することで、日付を計算しました。
この設計の決定は、プログラムが管理するために設計されたLogstashのインデックスを使うのには簡単でした。
しかし、Curatorは時系列インデックス管理に成長しています。これは、異なる命名規則のインデックスを意味しています。</p>

<p>また、インターバルによって、日付の計算が必要になる場合もあります。
<code>--time-unit</code>オプションが残っており、<code>weeks</code>という単位を指定することもできます。
デフォルトの<code>--timestring</code>オプションは、以前のコマンドと同様の動作をしなければなりません。次のようになります。</p>

<table>
<thead>
<tr>
<th> Time Unit </th>
<th> Timestring </th>
</tr>
</thead>
<tbody>
<tr>
<td> days      </td>
<td> <code>%Y.%m.%d</code></td>
</tr>
<tr>
<td> hours     </td>
<td> <code>%Y.%m.%d.%H</code></td>
</tr>
<tr>
<td> weeks     </td>
<td> <code>%Y.%W</code></td>
</tr>
</tbody>
</table>


<p>これが意味するものは、もし、単位に<code>hours</code>をした場合、<code>--timestring</code>を指定しなかった場合は<code>%Y.%m.%d.%H</code>となります。
これは、<a href="https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior">Pythonのstrftimeフォーマット</a>で&#8221;年.月.日.時&#8221;を意味します。
同様に、<code>weeks</code>を単位に指定した場合、Curatorはデフォルトの<code>--timestring</code>は<code>%Y.%W</code>となります。</p>

<p>この機能は、日付の間にセパレーター文字のないインデックスでも機能します。
例えば、<code>production-20140724</code>のような日時インデックスがある場合、2日よりも古いインデックスに対する<a href="https://github.com/elasticsearch/curator/wiki/Disable-Bloom-Filter-Cache">ブルームフィルタっキャッシュのオフ</a>のコマンドは次のようになります。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator bloom --prefix production- --older-than 2 --timestring %Y%m%d</span></code></pre></td></tr></table></div></figure>


<p>この例で、デフォルトの単位は<code>days</code>であることに注意してください。<code>hourly-2014072414</code>のような時間インデックスの場合は次のようになります。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator bloom --prefix hourly- --older-than 2 --time-unit hours --timestring %Y%m%d%H</span></code></pre></td></tr></table></div></figure>


<h2><code>--separator</code>の置き換え</h2>

<p>もし、Curatorの前のバージョンでカスタムセパレータ文字を利用していた場合、次のように変更すべきです。
前のコマンドで<code>cerberus-2014-07-24</code>のようなインデックスがある場合、コマンドを<code>--separator -</code>の用に置き換える必要があります。
新しいコマンドは次のとおりです。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curator delete --prefix cerberus- --older-than 30 --timestring %Y-%m-%d</span></code></pre></td></tr></table></div></figure>


<p>年(<code>％Y</code>)と月(<code>%m</code>)と日(&lsquo;%d&rsquo;)の間にセパレータ文字を置くだけです。</p>

<p>これは、また、Curatorで以前は不可能であったことをできるようにもします。
異なるセパレータ文字の混在です。
<code>logs-2014.07.24-14</code>というようなインデックスを処理するときに<code>--timestring</code>は<code>%Y.%m.%d-%H</code>のようになります.</p>

<p><code>--timestring</code>の詳細は<a href="https://github.com/elasticsearch/curator/wiki/Timestring">Curatorのドキュメント</a>をご覧ください。</p>

<h2>フィードバック</h2>

<p>これらの新しい機能はユーザのコメントやリクエストから来ています。もし、機能のリクエストやバグを発見したら、<a href="https://github.com/elasticsearch/curator/issues">こちら</a>まで連絡してください。</p>

<p>また、Twitterでもお待ちしています。私たちのTwitter IDは<code>@elasticsearch</code>です。</p>

<p>Happy Curating!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第5回Elasticsearch勉強会を開催しました。#elasticsearchjp]]></title>
    <link href="http://blog.johtani.info/blog/2014/07/19/hold-on-5th-elasticsearch-jp/"/>
    <updated>2014-07-19T21:52:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/07/19/hold-on-5th-elasticsearch-jp</id>
    <content type="html"><![CDATA[<p><a href="http://elasticsearch.doorkeeper.jp/events/12028">第5回Elasticsearch勉強会</a>を開催しました。
遅くなってしまいましたが、まとめてみました。</p>

<p>今回は、Elasticsearchに入って初の勉強会でした。タイミングが良いことに、Honza、Igor、Shayの3名がトレーニングのために
来日していたため、特別回ということにして、話をしてもらいました。</p>

<p>そして、<a href="http://samuraism.com/">サムライズム</a>の<a href="https://twitter.com/yusuke">@yusuke</a>さんにテキスト翻訳してもらいました。
早くて正確なタイピング＋翻訳、本当にありがとうございました。</p>

<p>開場提供していただいた<a href="http://recruit-tech.co.jp">リクルートテクノロジーズさん</a>、ありがとうございました！
次回もよろしくお願いします！
参加していただき盛り上げていただいた参加者の皆さんもありがとうございました。</p>

<blockquote class="twitter-tweet" lang="ja"><p>amazing turnout to the elasticsearch at Tokyo <a href="https://twitter.com/hashtag/elasticsearchjp?src=hash">#elasticsearchjp</a> <a href="http://t.co/Aa88eVf5dF">pic.twitter.com/Aa88eVf5dF</a></p>&mdash; Shay Banon (@kimchy) <a href="https://twitter.com/kimchy/statuses/488686274375843841">2014, 7月 14</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>




<!-- more -->


<p>動画があとで、アップされる予定です。お楽しみに。</p>

<h2>Honza&rsquo;s talk</h2>

<ul>
<li>djangoの開発者！であり、ElasticsearchのPythonクライアント、Curatorの開発者</li>
<li>Python Clientを利用しながら、ライブコーディングのような形で説明する方法が新鮮</li>
<li>Aggregationの便利さについての説明</li>
<li>Python Clientがクエリを組み立てるのにすごく便利そうだった</li>
<li>Pythonユーザが結構いたので助かりましたｗ</li>
</ul>


<h2>Igor&rsquo;s talk</h2>

<p>スライド：<a href="https://speakerdeck.com/imotov/elasticsearch-data">elasticsearch data/</a></p>

<ul>
<li>Snapshot/Restoreの開発などを行っている開発者</li>
<li>Elasticsearchのデータ、ディレクトリ構造に関するお話</li>
<li>シャードの話から、ディレクトリ構造、メタデータに関する説明</li>
<li>transaction logの挙動の説明</li>
<li>検索のフェーズの説明</li>
</ul>


<p>Igorは、実は私がElasticsearch社の人とコンタクトがとれた最初の人だと思います。
第1回Elasticsearch勉強会が開催する当日に帰国されるという不運だったのですが、1年越しでトークしてもらえました！</p>

<blockquote class="twitter-tweet" lang="ja"><p><a href="https://twitter.com/johtani">@johtani</a> I am so bummed! I am leaving Tokyo Thursday morning.</p>&mdash; Igor Motov (@imotov) <a href="https://twitter.com/imotov/statuses/372340973121986560">2013, 8月 27</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


<h2>QA</h2>

<p>ShayをメインにいくつかのQAをしてもらいました。
NetflixなどのMeetupの動画で見てたのですが、こんな形で日本でも実現できるとは。</p>

<ul>
<li>Q: なんで、ファイルデスクリプタの設定を大きくするの？

<ul>
<li>A: Luceneのインデックスは複数のセグメントから構成されている。メモリに作られたあと、ファイルにfsyncされる。</li>
</ul>
</li>
<li>Q: KibanaでAggregation使いたいんだけど？

<ul>
<li>A: Kibana 4で対応するよ！異なるフィールドの値を1つのグラフにすることも出来るよ！</li>
</ul>
</li>
<li>Q: なんでElasticsearch作ったの？

<ul>
<li>A: 暇だったからｗ奥さんのレシピ検索を作ってみようと思って作り始めて、Luceneを触って感動して。。。検索すげー、Compassってのを触ってこれもすごいと思いつつ、もっとLucene活用できるんじゃないかということでElasticsearch作ったんだ。奥さんのレシピ検索？まだ完成してないよｗ</li>
</ul>
</li>
<li>Q: 2000くらいスナップショット撮ったらパフォーマンスが悪くなっててなんで？

<ul>
<li>A: 差分でスナップショットを作るんだけど、差分の計算に昔のスナップショットを見るので、定期的に新しくしたほうがいい。もし、気になることがあったらIssue上げたりMLに投げてくれるとうれしい。<br/>
（あとでちょっと聞いたけど、古いスナップショットを消すのも有効っぽい。差分でスナップショットを作るけど、昔のを消した場合は、新しいスナップショットが利用しているファイルは残る仕組みになっているから。）</li>
</ul>
</li>
<li>Q: Relevancyのチューニングってどうすればいい？ドキュメントが少なくない？

<ul>
<li>A: ドキュメンテーションは頑張ってるので、応援してねｗあとは、<a href="http://www.elasticsearch.org/guide/en/elasticsearch/guide/current/index.html">definitive guide</a>も参考になるよ。スコアはfunction_scoreクエリがすごいのでいろいろ使ってね。MVELをGroovyに帰る予定。性能もだけど、サンドボックス的な意味もあります。</li>
</ul>
</li>
<li>Q: 次のVisionは？現時点は検索だけど。（最後の質問がとてもナイスで、助かりましたｗ私がしたほうがいい気がするｗｗ）

<ul>
<li>A: 今後はアナリティクスのプラットフォームに向かってる。Aggregationとかね。メモリ効率よくしたりしてるよ。あとは、Field-collapsionも実装中だよ。あと、マシンラーニングとかもね。データを探索するための機能を色々作ってくよ。障害性にも。チェックサム機能をLuceneに入れて、ESにも入れていく予定。Zenの機能も改善している。</li>
</ul>
</li>
</ul>


<h2>まとめ</h2>

<p>今週は、トレーニングがあったり、いろいろな打ち合わせがあったりと、テンパってたので至らない点が多かったかもしれないですが。。。
楽しんでいただけと思います。
数日、Shay、Honza、Igorと行動を共にして、本当に情熱のあるチームでユーザのことを気にかけているなと感じることができました。
少しでもその片鱗を勉強会で感じてもらえたんじゃないかと。特に、QAでのShayによる情熱が伝わったんじゃないかと。</p>

<p>懇親会でも数人の方から、日本語のサポートを望んでいるという声も頂きました。
興味のある方は私までコンタクトいただければと。</p>

<p>あと、@yusukeさんのテキスト翻訳が素晴らしくて、参加してもらった方たちも絶賛してました。
次回も英語スピーカーの場合に助けてもらえると嬉しいです（私もそこまで出来るように頑張ります）</p>

<h2>その他のブログ</h2>

<p>ブログ記事ありがとうございます！</p>

<ul>
<li><a href="http://arika.hateblo.jp/entry/2014/07/15/011241">第5回elasticsearch勉強会にいってきました - はやさがたりない。</a></li>
<li><a href="http://blog.yoslab.com/entry/2014/07/15/073000">感想戦：aggrigation から見える検索エンジンの次 - 第5回 Elasticsearch勉強会 - よしだのブログ</a></li>
<li><a href="http://uchimanajet7.hatenablog.com/entry/2014/07/15/114632">「第5回elasticsearch勉強会 #elasticsearch #elasticsearchjp」（2014年07月14日）の参加メモ - uchimanajet7のメモ</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[転職しました]]></title>
    <link href="http://blog.johtani.info/blog/2014/07/01/join-elasticsearch/"/>
    <updated>2014-07-01T11:30:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/07/01/join-elasticsearch</id>
    <content type="html"><![CDATA[<p>ということで、転職しました。
どーしてもやりたいことが出てきたので、無理を言って転職することにしてみました。</p>

<!-- more -->


<p><a href="http://samuraism.com">サムライズム</a>ではなく、<a href="http://www.elasticsearch.com">Elasticsearch</a>にジョインします。（というか、しました。）</p>

<blockquote class="twitter-tweet" lang="ja"><p>初出社 <a href="https://twitter.com/hashtag/%E3%82%B5%E3%83%A0%E3%83%A9%E3%82%A4%E3%82%BA%E3%83%A0?src=hash">#サムライズム</a></p>&mdash; Jun Ohtani (@johtani) <a href="https://twitter.com/johtani/statuses/483793778541465600">2014, 7月 1</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>冗談でツイートしたのですが、その前に英語アカウントのツイートがRTされてしまっていまいちでした。。。</p>

<p><img src="http://blog.johtani.info/images/entries/20140701/schiphol.jpg" title="スキポール空港" ></p>

<p>先週、アムステルダムに行っていたのも退職前に休みをいただき、Elasticsearchの全社会議に参加していたためです。
とてもエキサイティングな経験（英語漬けとか）ができ、もっと精進しないとなという気持ちにもなり、ますます頑張らないとなと。</p>

<p>ということで、今後は日本中にElasticsearchやLogstash、Kibanaを広めるべく、いろいろな場所で話をしたいと思います。
興味のある方は、声をかけていただければと。</p>

<p>あと、東京で<a href="http://purchases.elasticsearch.com/class/elasticsearch/core-elasticsearch/tokyo/2014-05-20">ElasticsearchのCoreトレーニング</a>が行われます。
通常は2日間ですが、通訳の方が付く関係で3日間の開催となっています。
開発者2名がトレーナーとして来日します。開発者に質問をできる良い機会ですので、興味のある方は参加してみてはいかがでしょうか。
<strong>また、CTOのShay Banonも来日する予定です。</strong></p>

<p>トレーナー2名とShayは<a href="http://elasticsearch.doorkeeper.jp/events/12028">7/14の勉強会</a>でも話をしてくれます。
こちらも興味のある方は参加してみてください。（参加登録はこの後、すぐに開始します。）</p>

<p>まだまだ、勉強しなければいけないことだらけですが、ElasticsearchのいろいろなプロダクトやOSSについて広めていきたいと思いますので、よろしくお願いいたします。</p>

<h2>おまけ</h2>

<p>ということで、一度やってみたかったのでリンクを貼ってみます。</p>

<p><a href="http://www.amazon.co.jp/registry/wishlist/29EMX20UN9P16">ほしい物リストはこちら</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[退職しました]]></title>
    <link href="http://blog.johtani.info/blog/2014/06/30/resignation/"/>
    <updated>2014-06-30T23:19:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/06/30/resignation</id>
    <content type="html"><![CDATA[<p>退職しました。</p>

<!-- more -->


<p>色々と書きたいんですが、時差ボケで頭痛いので、このくらいです。
余裕出たら書くかも。</p>

<p><a href="http://www.amazon.co.jp/registry/wishlist/29EMX20UN9P16">ほしい物リストはこちら</a></p>

<p>新天地についてはまた明日。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch server 2nd editionのファーストインプレッション]]></title>
    <link href="http://blog.johtani.info/blog/2014/06/16/first-impression-elasticsearch-server-2nd-edition/"/>
    <updated>2014-06-16T17:47:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/06/16/first-impression-elasticsearch-server-2nd-edition</id>
    <content type="html"><![CDATA[<p><a href="http://bit.ly/1kbu5Xd">Elasticsearch server 2nd edition</a>が発売されています。</p>

<p>私が翻訳したのは前のバージョンですが。。。
まずは、目次を元にどのくらい変わってるかを見てみました。
（全部まだ読んでなくて。。。）</p>

<!-- more -->


<h2>1章 Getting Started with the Elasticsearch Cluster</h2>

<p>冒頭に、全文検索とは、転置インデックスとはどんなものか、
Luceneの簡単なアーキテクチャの仕組みについて説明が追加されています。
検索の仕組みを知らない人が読んでもわかりやすくなっています。</p>

<p>インストール方法なども少し追記されています。
バージョニングと簡単なデータ登録と検索方法についてもここで触れられています。
検索結果の構造の説明もちょっとあります。
まず簡単に触ってみるというところまでが1章でまとめられた感じです。</p>

<h2>2章 Indexing Your Data</h2>

<p>新しく、切りだされた形です。
前のバージョンでは1章で説明されていた、Mapping周りが切りだされています。
シャードやレプリカの説明もこちらです。</p>

<p>IPアドレスタイプ（IPv4のみ）と<code>token_count</code>タイプの説明も追加されてます。
similarityやpostingsフォーマットなどは新しく追記されています。
また、メタフィールドと呼ばれる<code>_type</code>などはこちらに移動しているようです。
マージ処理などの説明も追記されています。このあたりは、<a href="http://www.packtpub.com/mastering-elasticsearch-querying-and-data-handling/book">Mastering ElasticSearch</a>に
記載されているものが移植された感じでしょうか。</p>

<h2>3章 Searching Your Data</h2>

<p>前のバージョンでは2章だった章です。
クエリについては1.0で追加された<code>simple_query_string</code>などが追記されています。
<code>constant_score</code>や<code>dismax</code>などもです。</p>

<p>また、前のバージョンの3章で説明されていたハイライトや8章で触れられていた<code>validate API</code>についても
移動しています。</p>

<h2>4章 Extending Your Index Structure</h2>

<p>前のバージョンの3章で触れられていた、データの構造に関する部分がこの章になります。
親子や配列、ネスト等のデータのインデックスや検索の方法です。</p>

<h2>5章 Make Your Search Better</h2>

<p>スクリプティングや言語判定などの仕組みが記載されています。
また、ブーストについても同様です。Synonymについてもここです。
スパンクエリについては省略されたのかな？</p>

<h2>6章 Beyond Full-text Searching</h2>

<p>1.0の目玉機能の一つであるAggregationの説明から始まります。
その後、ファセットやPercolatorについてです。メモリに関する注意点もありそうです。
また、Geoについての説明がこちらに移動されていました。
<code>scroll API</code>についてもこちらで説明されています。</p>

<h2>7章 Elasticsearch Cluster in Detail</h2>

<p>前の7章で記載されていたElasticsearchの分散の仕組み（Node Discovery）についての記載があります。
また、1.0で追加された<code>circuit breaker</code>やスレッドプール、インデックスのリフレッシュレートなど、<a href="http://www.packtpub.com/elasticsearch-server-second-edition/book">Mastering ElasticSearch</a>の
内容も追記されている気がします。</p>

<p>インデックスやマッピングのテンプレート機能についてもここで説明があるみたいです。</p>

<h2>8章 Administrating Your Cluster</h2>

<p>1.0で追加された<code>snapshot/restore</code>の説明から始まります。
あとは、前のバージョンの7章で説明されていたクラスタ管理用のAPIについての説明です。
いくつか（例えば<code>cat API</code>）、1.0で追加されています。</p>

<p>また、シャードのリバランスの話も追加されているようです。
エイリアスやプラグインの話はこちらに移動してるみたいです。</p>

<h2>感想</h2>

<p>ということで、とりあえず、駆け足で目次ベースで違いを見てみました。
<a href="http://www.packtpub.com/elasticsearch-server-second-edition/book">Mastering ElasticSearch</a>での
知見がフィードバックされ、しかも1.0（すでに1.3が出そうな勢いですが。。。）にバージョンアップされた内容になっています。
冒頭がわかりやすくなっているので、検索をやったことのない方にもおすすめな書籍になった気がします。
英語が苦にならなければ、おすすめの一冊だと思います。</p>

<p>来月から読み進めるつもりなので、また、面白い内容があったら感想を書いていこうと思います。
（また翻訳できるといいかもなー）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[可視化ツール現状確認会に参加してきました。#可視化]]></title>
    <link href="http://blog.johtani.info/blog/2014/06/04/attending-visualize-study/"/>
    <updated>2014-06-04T21:15:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/06/04/attending-visualize-study</id>
    <content type="html"><![CDATA[<p><a href="http://www.zusaar.com/event/7437003">可視化ツール現状確認会</a>に参加して、<strike>カジュアルウォーターじゃなくて</strike>可視化ツールの現状を確認してきました。</p>

<p>ということで、いつものメモです。</p>

<!-- more -->


<h2>Mackerel と Graphite について （y_uuk1さん）</h2>

<h3>Graphite</h3>

<ul>
<li>時系列</li>
<li>工夫すればスケーラブル</li>
<li>SensuやCollectdと組み合わせたり</li>
<li>GrafanaとGrapheneでGUI</li>
<li>Mackerel素敵だよと。</li>
<li>架空のわかりやすいグラフが見れた</li>
</ul>


<h2>Kibana &amp; Grafana &amp; Influga （hakoberaさん）</h2>

<ul>
<li>Kibana

<ul>
<li>かっこいい。</li>
<li>JVM大変。
*</li>
</ul>
</li>
<li>Grafana

<ul>
<li>Graphiteがカッコ悪いのでKibanaをフォーク</li>
<li>なぜか、ESが必要。</li>
<li>InfluxDBに浮気しそう</li>
</ul>
</li>
<li><p>Influga</p>

<ul>
<li>@haoberaさん作</li>
<li>InfluxDB Queryサポート</li>
</ul>
</li>
<li><p>迷ったら、Kibana入れとけ。</p></li>
<li><p>DistinctがKibana出できないけど、それ以外はある程度行けるらしい。</p>

<ul>
<li>aggregationがサポートされたら、できると思う。</li>
</ul>
</li>
<li><p>Kibana以外は、バックエンドがタイムシリーズなので、縛りがある</p></li>
</ul>


<h2>可視化ツール紹介（仮） （showyouさん）</h2>

<ul>
<li>誰がチャートを作るの？</li>
<li>誰が見るの？</li>
<li>一覧化されてて、あとで眺めたい</li>
<li>IPython Notebookのデモ</li>
<li>R shiny Serverのデモ</li>
<li>Pentaho CE+Saikuのデモはネットワークがダメだったので割愛</li>
<li>分析側の視点を見せたかったので。</li>
</ul>


<h2>可視化とは何だったのか （harukasanさん）</h2>

<ul>
<li>インフラ</li>
<li>モニタリング、アナライズ、可視化どれ？</li>
<li>可視化は目的ではないよねと。</li>
<li>熱く、ユーザとサービスプロバイダ間の距離のお話。

<ul>
<li>ログ</li>
<li>生ファイルで残すのが重要</li>
</ul>
</li>
</ul>


<p>トータルで必要とか考えないといけないことがわかって面白かったｗ</p>

<h2>あなたの知らないrrdtool （shoichimasuharaさん）</h2>

<ul>
<li>すげー！</li>
<li>いろいろできるらしい（ノートPCの前にいなかったｗ）</li>
</ul>


<h2>D3.jsとジオマッピング （Takaki_さん）</h2>

<ul>
<li>時空間推進課！すげー！</li>
<li>ジオデータのおはなし。</li>
<li>TopoJSONとかGeoJSONとか</li>
</ul>


<h2>Zipkinについて （synkさん）</h2>

<ul>
<li>ものすごい数のJVMがThriftで殴りあってるらしい。</li>
<li>ZipkinはTwitterが作ったもの</li>
<li>Brave、HTraceというのが、PureJava用のZipkinトレーシングプラグイン</li>
<li>見積もりする必要がないくらいでかいHBaseがあるので、そこにためてる。</li>
<li>まとめ

<ul>
<li>LINEはエンジニアを大募集中</li>
</ul>
</li>
</ul>


<h2>Graphiteについて (mickey19821 さん)</h2>

<ul>
<li>ドリコムさんのGraphiteのおはなし</li>
<li>Metricsの収集はCollectd</li>
<li>Graphite-webがスケールできなくて困ってるらしい。</li>
<li>Graphiteで可視化ツラいｗ</li>
</ul>


<h2>まとめ</h2>

<p><strong>RRDTool最高</strong></p>

<p>あと、クックパッドの技術力がすごいという発表なんかもありました。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[最新インフラエンジニア技術勉強に参加しました。]]></title>
    <link href="http://blog.johtani.info/blog/2014/05/23/attending-drecom-infra-study/"/>
    <updated>2014-05-23T19:18:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/05/23/attending-drecom-infra-study</id>
    <content type="html"><![CDATA[<p>今月2回目の目黒で、初のドリコムさんです。
「<a href="http://drecom-study.doorkeeper.jp/events/11137">最新インフラエンジニア技術勉強～Fluentd, Elasticsearch,Chefの実践実例～</a>」に参加してきました。
もちろん、Elasticsearchってキーワードがあったからです。</p>

<p>ざっくりメモです。</p>

<!-- more -->


<h2>ドリコムのInfrastructure as Code/ひらしーさん</h2>

<ul>
<li>CM：jojoss、トレクル、など</li>
<li>サーバ300台、クラウド○○台。月30〜50台の割合で増加中。</li>
<li>少人数でいかに回すか。</li>
</ul>


<h4>Chef</h4>

<ul>
<li>Rubyが書ける人が多いから。</li>
</ul>


<h4>serverspec</h4>

<ul>
<li>テストだよと。</li>
</ul>


<p>すみません、色々と聞き逃しました。。。</p>

<h2>Winning the metrics battle/mickeyさん</h2>

<ul>
<li>Graphiteとかを触っている。</li>
<li>1300台超えたら、色々大変だった。</li>
</ul>


<h4>失敗談</h4>

<ul>
<li>Cactiを利用して、色々と運用が大変だった。DCが別なのでProxyとか。</li>
</ul>


<h4>成功例？現行システム？</h4>

<ul>
<li>最大値、平均値、最小値などをプロット</li>
<li>collectdを収集、送信に採用して、独自で開発？</li>
<li>受信して保存するのに、Graphite（carbon-relay、carbon-cache、DRBD、graphite-web）ってなってる。</li>
<li>1300台程度のサーバから、5分間隔で、問題ない。</li>
<li>Graphite良いツールだよ。</li>
</ul>


<p>Q：過去データはどのくらい？
A：5分間隔で1年分。</p>

<p>Q：移動平均とかを使ったグラフとか時間かかりませんか？100台だと
A：100台でもほとんど時間はかからない。</p>

<h2>Fluentd プラグイン開発講座/外山 寛さん</h2>

<ul>
<li>Fluentdプラグインを作ることができると威力倍増</li>
<li>Elasticsearchの勉強会の話までしてくれました！</li>
<li>勉強会スペース貸出しています。</li>
<li>未公開だけど、sedueのプラグインもあるらしい。</li>
<li>CHUNKとBUFFERとか覚えときましょう</li>
<li>プラグインの作り方的なのがなかった気がしたので、今回の発表です。</li>
<li>gem作らなくてもディレクトリにおけば使えるよと。</li>
<li>td-agent使ってる人が大多数だよね。（fluentdを素で使ってる人は会場にはいなかった）</li>
<li>エンジニア募集中</li>
</ul>


<p>Q：エラー処理どうしてますか？
A：今は、スルーしています</p>

<p>Q：単体テストの書き方は？
A：人によってバラバラみたいですね。</p>

<h2>MySQLと組み合わせて始める全文検索エンジン「elasticsearch」/yoshi_ken</h2>

<p>スライド：<a href="http://www.slideshare.net/y-ken/introduce-elasticsearch-mysql-importer">http://www.slideshare.net/y-ken/introduce-elasticsearch-mysql-importer</a></p>

<ul>
<li>Elasticsearch歴は1年位です。</li>
<li>MySQLを使っていて、モダンな検索がほしいですよね？ね？</li>
<li>サジェスト、ファセット、位置情報、ネスト検索などなど。</li>
<li>GoogleトレンドだとSolrに迫る勢いと。</li>
<li><p>実データを用いて、手軽にElasticsearchと連携。</p></li>
<li><p>BinaryLogではなく、SQLの結果を同意する方式。yamabiko</p></li>
<li><p>今日は、新しいものを公開します。</p>

<ul>
<li><a href="https://github.com/y-ken/elasticsearch_mysql_importer">bulk import file generator as well as nested document from MySQL for elasticsearch bulk api</a></li>
</ul>
</li>
<li><a href="http://purchases.elasticsearch.com/class/elasticsearch/core-elasticsearch/tokyo/2014-05-20">東京トレーニング</a></li>
<li>Elasticsearch本については、右にあるリンクをクリックしてくれるとうれしいなぁ。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「よくわかるAmazon #CloudSearch 」に行ってきました！]]></title>
    <link href="http://blog.johtani.info/blog/2014/05/15/amazon-cloud-seaarch-study-session/"/>
    <updated>2014-05-15T17:50:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/05/15/amazon-cloud-seaarch-study-session</id>
    <content type="html"><![CDATA[<p>どうやら、中身がSolrベース？Luceneベース？になったらしいということで、
今日は<a href="http://kokucheese.com/event/index/168838/">「AWSプロダクトシリーズ｜よくわかるAmazon CloudSearch」</a>に行ってきました。</p>

<p><strong>※ElasticSearchではありません！</strong></p>

<!-- more -->


<p>ということで、いつものメモ。</p>

<h2>CloudSearch Overview</h2>

<h3>Amazon Web Services, Inc. Pravin Muthukumar(Product Manager) / Vivek Sriram (Business Development)</h3>

<h4>Introduction to Search</h4>

<ul>
<li>検索の紹介。アイアンマンのDVD？のページにいろんな項目（フィールド）があるよねと。（もちろん、Amazonのページ）</li>
<li>ファセット、Geo、テキスト処理（Analysis処理）、Postings listとか。とかとか</li>
<li>ランキングも</li>
</ul>


<h4>Amazon CloudSearch</h4>

<ul>
<li>独自実装orRDB拡張もある。</li>
<li>OSSもあるよね。</li>
<li><strong>Legacy</strong> Enterprise SearchとしてFASTとかもある。</li>
</ul>


<h4>Building with CloudSearch</h4>

<ul>
<li>他のサービス同様、コンソールとかあるし、色々できるし、すぐ起動できるよと。</li>
</ul>


<p>自動で、データが増えたら、パーティションが増えると。</p>

<ul>
<li>日本語の形態素解析があるらしい。何を使ってるのかな？</li>
<li>ICUのノーマライズとかもやってくれるらしい。これかな？<a href="http://lucene.apache.org/core/4_8_0/analyzers-icu/index.html">http://lucene.apache.org/core/4_8_0/analyzers-icu/index.html</a></li>
<li>ユーザが辞書を指定できるのかな？</li>
</ul>


<p>備えてる機能の説明</p>

<ul>
<li>ファセット</li>
<li>SimpleQuery</li>
<li>Autocomplete</li>
<li>Highlight</li>
</ul>


<p>などなど</p>

<ul>
<li>Multi-AZにも対応</li>
</ul>


<h4>QA</h4>

<ul>
<li>Q：NGramありますか？

<ul>
<li>A：今はないです。</li>
</ul>
</li>
<li>Q：ユーザ辞書対応してますか？

<ul>
<li>A：今はないです。</li>
</ul>
</li>
<li>Q：lang-detectあるか？

<ul>
<li>A：今はないので、自分で判定して、適切なフィールドに入れてね。</li>
</ul>
</li>
</ul>


<h2>Expectation for CloudSearch</h2>

<h3>Apache Solr contributor　大須賀　稔氏</h3>

<ul>
<li>Solr本の宣伝ありがとうございます！（右のアイコンから買ってもらえると更に嬉しいですｗ）</li>
<li>Kinesisとかとの組み合わせとか、自然言語処理とか、いろいろとあるAWSのコンポーネントと組み合わせる例が欲しいと。</li>
<li>すばらしい、最後はManifoldCFがらみに持っていくとは。ACLがらみのクローリングとかあるといいじゃないでしょうかと。</li>
</ul>


<h2>Impression of using CloudSearch</h2>

<h3>吉田　匠氏　(@yoshi0309　<a href="http://blog.yoslab.com/">http://blog.yoslab.com/</a>)</h3>

<p>スライド：<a href="https://speakerdeck.com/yoshi0309/impression-of-using-cloudsearch">https://speakerdeck.com/yoshi0309/impression-of-using-cloudsearch</a></p>

<ul>
<li>お見かけしたことある気がするなぁ。</li>
<li>全部置き換えできる！わけではなさそう。。。</li>
</ul>


<h4>いいところ。</h4>

<ul>
<li>UIがいいし、セットアップが簡単</li>
<li>auto scaleがうれしい</li>
<li>マルチドメイン、マルチスキーマがいい</li>
<li>Luceneのdismaxサポートがいい。（edismaxじゃないのかな？）</li>
</ul>


<p>dismaxって書いてあるな。</p>

<p><a href="http://docs.aws.amazon.com/cloudsearch/latest/developerguide/search-api.html">http://docs.aws.amazon.com/cloudsearch/latest/developerguide/search-api.html</a></p>

<ul>
<li><p>フィードの仕方に気をつけて！</p>

<ul>
<li>バッチサイズで課金されるので、1件ずつじゃなくて、複数件送ったほうがいい。</li>
</ul>
</li>
<li><p>いきなりスケールアウトできるわけじゃない？</p></li>
<li><p>ウォームアップ機能がない。インスタンス上限がデフォルト50件</p></li>
<li><p>VPC対応してほしい。</p>

<ul>
<li>インターネット経由になってしまう</li>
<li>フィードのスピードが</li>
<li>セキュリティグループ機能が使えない</li>
</ul>
</li>
</ul>


<h2>CloudSearch UseCase - SnapDish</h2>

<h3>Vuzz Inc.　清田　史和氏</h3>

<ul>
<li>独自辞書をもって、Tokenizeは独自でやって、空白区切りでデータ登録している。</li>
<li>インデックス更新はSQSを使ってる。</li>
<li>古いAPIを使ってるらしい。</li>
<li>移行が結構大変らしい。</li>
</ul>


<h2>感想</h2>

<p>使ったことないんですが、きめ細かい検索したい場合はちょっとテクニックが要るかもと思いました。
AWS初心者なんで、なんとも言えないんですが。。。</p>

<p>といあえず、テキスト処理（アナライズ処理）で、単語がどうやって区切られるのかってのがわからないのはキツイんじゃなかろうかと。
ただ、簡単に起動できて、オートスケールできるのは素晴らしいと思います。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[外の世界を知るということ]]></title>
    <link href="http://blog.johtani.info/blog/2014/05/14/spiritual-entry1/"/>
    <updated>2014-05-14T01:44:00+09:00</updated>
    <id>http://blog.johtani.info/blog/2014/05/14/spiritual-entry1</id>
    <content type="html"><![CDATA[<p>酔っ払ってなんとなく書きたくなったスピリチュアルなブログなので、流していただければと。</p>

<!-- more -->


<p>最近、勉強会やTwitterで知り合いになって話をする人が増えたりで、
その方たちに色々と教えてもらうことが多いなぁと感じてます。
また、知り合いに恵まれてきたなぁとも。</p>

<p>そもそも私が勉強会に参加し始めたきっかけはSolr勉強会（第1回から参加してて、気づいたら主催者になってた）で、
そのころは、Solr初心者で色々とやってる人、知ってる人がいて無料で話が聞けるのすごいと興奮したのを覚えてます。
（もちろん、ぼっちでしたが）</p>

<p>Solr勉強会が定期的に開かれて、それに参加しているうちに少しずつ知り合いもできて、
面白そうな勉強会（Hadoopとか）が他にもあるんだ、参加してみようかって思うようになってと。</p>

<p>そこにプラスで、関口さんと知りあえてSolr本を書く話が出てきて、本を書いてみたら、
今度は勉強会で話してみませんかとなって。</p>

<p>スピーカーやると、顔を覚えてもらえるようで、また知り合いが増えてと。</p>

<p>人のつながりって大事だし、自分が発信することで教えてもらえることもあるしと。
前にも書いた気がするけど、Solr勉強会（当時の主催の方）や関口さんやElasticsearch勉強会のスタッフの方や
スピーカーやってくれた方、会場提供を心よくしてくれてるVOYAGE GROUP、リクルートテクノロジーズさん、という具合にどんどん頭が上がらなくなってきてるなぁと。</p>

<p>ということで、外の世界を知ると色々とつながりが出来て面白いですよという、個人的な感想でした。
ま、自分が思ってるだけで、違う意見もいっぱいあると思うけど。</p>

<p>あー、なんか、酔って勢いで書いてしまった。。。
脈略のない文章なきがするけど、エイヤで公開しちゃおう。</p>
]]></content>
  </entry>
  
</feed>
